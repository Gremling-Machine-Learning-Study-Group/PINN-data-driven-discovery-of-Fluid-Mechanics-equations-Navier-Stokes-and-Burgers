{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Burgers_nu4_2000_2 layers_menos.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvsbii5zbr9p",
        "outputId": "6d6ff4ff-4dbd-4ef8-e070-1a29ff951de3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-lmodern fonts-noto-mono libcupsfilters1\n",
            "  libcupsimage2 libgs9 libgs9-common libijs-0.35 libjbig2dec0 libkpathsea6\n",
            "  libpotrace0 libptexenc1 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13\n",
            "  lmodern poppler-data t1utils tex-common texlive-base texlive-binaries\n",
            "  texlive-latex-base\n",
            "Suggested packages:\n",
            "  fonts-noto poppler-utils ghostscript fonts-japanese-mincho\n",
            "  | fonts-ipafont-mincho fonts-japanese-gothic | fonts-ipafont-gothic\n",
            "  fonts-arphic-ukai fonts-arphic-uming fonts-nanum debhelper gv\n",
            "  | postscript-viewer perl-tk xpdf-reader | pdf-viewer texlive-latex-base-doc\n",
            "  texlive-latex-recommended-doc texlive-pstricks\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-lmodern fonts-noto-mono libcupsfilters1\n",
            "  libcupsimage2 libgs9 libgs9-common libijs-0.35 libjbig2dec0 libkpathsea6\n",
            "  libpotrace0 libptexenc1 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13\n",
            "  lmodern poppler-data t1utils tex-common texlive-base texlive-binaries\n",
            "  texlive-latex-base texlive-latex-recommended\n",
            "0 upgraded, 24 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 68.4 MB of archives.\n",
            "After this operation, 223 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 tex-common all 6.09 [33.0 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lmodern all 2.004.5-3 [4,551 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.15 [5,092 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.15 [2,265 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkpathsea6 amd64 2017.20170613.44572-8ubuntu0.1 [54.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpotrace0 amd64 1.14-2 [17.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libptexenc1 amd64 2017.20170613.44572-8ubuntu0.1 [34.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsynctex1 amd64 2017.20170613.44572-8ubuntu0.1 [41.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexlua52 amd64 2017.20170613.44572-8ubuntu0.1 [91.2 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexluajit2 amd64 2017.20170613.44572-8ubuntu0.1 [230 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libzzip-0-13 amd64 0.13.62-3.1ubuntu0.18.04.1 [26.0 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 lmodern all 2.004.5-3 [9,631 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 t1utils amd64 1.41-2 [56.0 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 texlive-binaries amd64 2017.20170613.44572-8ubuntu0.1 [8,179 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-base all 2017.20180305-1 [18.7 MB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-base all 2017.20180305-1 [951 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-recommended all 2017.20180305-1 [14.9 MB]\n",
            "Fetched 68.4 MB in 4s (18.6 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 24.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 155335 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../01-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../02-tex-common_6.09_all.deb ...\n",
            "Unpacking tex-common (6.09) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../03-fonts-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../04-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../05-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../06-libcupsimage2_2.2.7-1ubuntu2.8_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../07-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../08-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../09-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.15_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../10-libgs9_9.26~dfsg+0-0ubuntu0.18.04.15_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../11-libkpathsea6_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libpotrace0.\n",
            "Preparing to unpack .../12-libpotrace0_1.14-2_amd64.deb ...\n",
            "Unpacking libpotrace0 (1.14-2) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../13-libptexenc1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libsynctex1:amd64.\n",
            "Preparing to unpack .../14-libsynctex1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexlua52:amd64.\n",
            "Preparing to unpack .../15-libtexlua52_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../16-libtexluajit2_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../17-libzzip-0-13_0.13.62-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../18-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../19-t1utils_1.41-2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-2) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../20-texlive-binaries_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../21-texlive-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../22-texlive-latex-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../23-texlive-latex-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2017.20180305-1) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n",
            "Setting up libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up t1utils (1.41-2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up libpotrace0 (1.14-2) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n",
            "Setting up libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-lmodern (2.004.5-3) ...\n",
            "Setting up texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up texlive-base (2017.20180305-1) ...\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/config/pdftexconfig.tex\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up texlive-latex-base (2017.20180305-1) ...\n",
            "Setting up lmodern (2.004.5-3) ...\n",
            "Setting up texlive-latex-recommended (2017.20180305-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-lato fonts-texgyre javascript-common libjs-jquery libruby2.5\n",
            "  preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration tex-gyre texlive-fonts-recommended texlive-pictures\n",
            "  texlive-plain-generic tipa\n",
            "Suggested packages:\n",
            "  apache2 | lighttpd | httpd ri ruby-dev bundler texlive-fonts-recommended-doc\n",
            "  python-pygments icc-profiles libfile-which-perl\n",
            "  libspreadsheet-parseexcel-perl texlive-latex-extra-doc dot2tex prerex\n",
            "  ruby-tcltk | libtcltk-ruby texlive-pictures-doc vprerex\n",
            "The following NEW packages will be installed:\n",
            "  fonts-lato fonts-texgyre javascript-common libjs-jquery libruby2.5\n",
            "  preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration tex-gyre texlive-fonts-recommended texlive-latex-extra\n",
            "  texlive-pictures texlive-plain-generic tipa\n",
            "0 upgraded, 21 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 66.6 MB of archives.\n",
            "After this operation, 216 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lato all 2.0-2 [2,698 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-texgyre all 20160520-1 [8,761 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 rubygems-integration all 1.11 [4,994 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ruby2.5 amd64 2.5.1-1ubuntu1.11 [48.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby amd64 1:2.5.1 [5,712 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 rake all 12.3.1-1ubuntu0.1 [44.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-did-you-mean all 1.2.0-2 [9,700 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-minitest all 5.10.3-1 [38.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-power-assert all 0.3.0-1 [7,952 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-test-unit all 3.2.5-1 [61.1 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libruby2.5 amd64 2.5.1-1ubuntu1.11 [3,072 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 preview-latex-style all 11.91-1ubuntu1 [185 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tex-gyre all 20160520-1 [4,998 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-recommended all 2017.20180305-1 [5,262 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-pictures all 2017.20180305-1 [4,026 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-latex-extra all 2017.20180305-2 [10.6 MB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-plain-generic all 2017.20180305-2 [23.6 MB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tipa all 2:1.3-20 [2,978 kB]\n",
            "Fetched 66.6 MB in 4s (16.9 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 21.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-lato.\n",
            "(Reading database ... 162669 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-lato_2.0-2_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../01-fonts-texgyre_20160520-1_all.deb ...\n",
            "Unpacking fonts-texgyre (20160520-1) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../02-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../03-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../04-rubygems-integration_1.11_all.deb ...\n",
            "Unpacking rubygems-integration (1.11) ...\n",
            "Selecting previously unselected package ruby2.5.\n",
            "Preparing to unpack .../05-ruby2.5_2.5.1-1ubuntu1.11_amd64.deb ...\n",
            "Unpacking ruby2.5 (2.5.1-1ubuntu1.11) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../06-ruby_1%3a2.5.1_amd64.deb ...\n",
            "Unpacking ruby (1:2.5.1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../07-rake_12.3.1-1ubuntu0.1_all.deb ...\n",
            "Unpacking rake (12.3.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-did-you-mean.\n",
            "Preparing to unpack .../08-ruby-did-you-mean_1.2.0-2_all.deb ...\n",
            "Unpacking ruby-did-you-mean (1.2.0-2) ...\n",
            "Selecting previously unselected package ruby-minitest.\n",
            "Preparing to unpack .../09-ruby-minitest_5.10.3-1_all.deb ...\n",
            "Unpacking ruby-minitest (5.10.3-1) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../10-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-power-assert.\n",
            "Preparing to unpack .../11-ruby-power-assert_0.3.0-1_all.deb ...\n",
            "Unpacking ruby-power-assert (0.3.0-1) ...\n",
            "Selecting previously unselected package ruby-test-unit.\n",
            "Preparing to unpack .../12-ruby-test-unit_3.2.5-1_all.deb ...\n",
            "Unpacking ruby-test-unit (3.2.5-1) ...\n",
            "Selecting previously unselected package libruby2.5:amd64.\n",
            "Preparing to unpack .../13-libruby2.5_2.5.1-1ubuntu1.11_amd64.deb ...\n",
            "Unpacking libruby2.5:amd64 (2.5.1-1ubuntu1.11) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../14-preview-latex-style_11.91-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (11.91-1ubuntu1) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../15-tex-gyre_20160520-1_all.deb ...\n",
            "Unpacking tex-gyre (20160520-1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../16-texlive-fonts-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../17-texlive-pictures_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-pictures (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../18-texlive-latex-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-latex-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../19-texlive-plain-generic_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-plain-generic (2017.20180305-2) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../20-tipa_2%3a1.3-20_all.deb ...\n",
            "Unpacking tipa (2:1.3-20) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up texlive-pictures (2017.20180305-1) ...\n",
            "Setting up tex-gyre (20160520-1) ...\n",
            "Setting up tipa (2:1.3-20) ...\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-DEBIAN'... done.\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST'... done.\n",
            "update-fmtutil has updated the following file(s):\n",
            "\t/var/lib/texmf/fmtutil.cnf-DEBIAN\n",
            "\t/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST\n",
            "If you want to activate the changes in the above file(s),\n",
            "you should run fmtutil-sys or fmtutil.\n",
            "Setting up preview-latex-style (11.91-1ubuntu1) ...\n",
            "Setting up fonts-texgyre (20160520-1) ...\n",
            "Setting up fonts-lato (2.0-2) ...\n",
            "Setting up ruby-did-you-mean (1.2.0-2) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up rubygems-integration (1.11) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-plain-generic (2017.20180305-2) ...\n",
            "Setting up ruby-minitest (5.10.3-1) ...\n",
            "Setting up ruby-power-assert (0.3.0-1) ...\n",
            "Setting up texlive-latex-extra (2017.20180305-2) ...\n",
            "Setting up ruby-test-unit (3.2.5-1) ...\n",
            "Setting up libruby2.5:amd64 (2.5.1-1ubuntu1.11) ...\n",
            "Setting up ruby2.5 (2.5.1-1ubuntu1.11) ...\n",
            "Setting up ruby (1:2.5.1) ...\n",
            "Setting up rake (12.3.1-1ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running mktexlsr. This may take some time... done.\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  ghostscript gsfonts\n",
            "Suggested packages:\n",
            "  ghostscript-x\n",
            "The following NEW packages will be installed:\n",
            "  dvipng ghostscript gsfonts\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 3,250 kB of archives.\n",
            "After this operation, 4,947 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.15 [51.4 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 dvipng amd64 1.15-1 [78.2 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.4 [3,120 kB]\n",
            "Fetched 3,250 kB in 1s (2,620 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package ghostscript.\n",
            "(Reading database ... 181020 files and directories currently installed.)\n",
            "Preparing to unpack .../ghostscript_9.26~dfsg+0-0ubuntu0.18.04.15_amd64.deb ...\n",
            "Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n",
            "Selecting previously unselected package dvipng.\n",
            "Preparing to unpack .../dvipng_1.15-1_amd64.deb ...\n",
            "Unpacking dvipng (1.15-1) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.4_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n",
            "Setting up dvipng (1.15-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cm-super-minimal pfb2t1c2pfb\n",
            "The following NEW packages will be installed:\n",
            "  cm-super cm-super-minimal pfb2t1c2pfb\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 24.5 MB of archives.\n",
            "After this operation, 59.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cm-super-minimal all 0.3.4-11 [5,810 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 pfb2t1c2pfb amd64 0.3-11 [9,342 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cm-super all 0.3.4-11 [18.7 MB]\n",
            "Fetched 24.5 MB in 2s (12.2 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package cm-super-minimal.\n",
            "(Reading database ... 181213 files and directories currently installed.)\n",
            "Preparing to unpack .../cm-super-minimal_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super-minimal (0.3.4-11) ...\n",
            "Selecting previously unselected package pfb2t1c2pfb.\n",
            "Preparing to unpack .../pfb2t1c2pfb_0.3-11_amd64.deb ...\n",
            "Unpacking pfb2t1c2pfb (0.3-11) ...\n",
            "Selecting previously unselected package cm-super.\n",
            "Preparing to unpack .../cm-super_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super (0.3.4-11) ...\n",
            "Setting up pfb2t1c2pfb (0.3-11) ...\n",
            "Setting up cm-super-minimal (0.3.4-11) ...\n",
            "Setting up cm-super (0.3.4-11) ...\n",
            "Creating fonts. This may take some time... done.\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running mktexlsr. This may take some time... done.\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ],
      "source": [
        "#devido aos plots no final do script devemos intalar latex na máquina\n",
        "! sudo apt-get install texlive-latex-recommended \n",
        "! sudo apt install texlive-latex-extra\n",
        "! sudo apt install dvipng\n",
        "! sudo apt install cm-super\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.15.2\n",
        "import tensorflow as tf   #machine learning framework\n",
        "#tf.disable_v2_behavior()\n",
        "print('TensorFlow version: ', tf.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBCUeYMwbyT4",
        "outputId": "55b56294-47a2-489c-bb10-a5b0ee06d652"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15.2`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "TensorFlow version:  <module 'tensorflow._api.v1.version' from '/tensorflow-1.15.2/python3.7/tensorflow_core/_api/v1/version/__init__.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "@author: Maziar Raissi\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, '../../Utilities/')\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "from plotting import newfig, savefig\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.gridspec as gridspec\n",
        "import time\n",
        "\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)"
      ],
      "metadata": {
        "id": "ReZIGxTKnaNa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PhysicsInformedNN:\n",
        "    # Initialize the class\n",
        "    def __init__(self, X, u, layers, lb, ub):\n",
        "        \n",
        "        self.lb = lb\n",
        "        self.ub = ub\n",
        "        \n",
        "        self.x = X[:,0:1]\n",
        "        self.t = X[:,1:2]\n",
        "        self.u = u\n",
        "        \n",
        "        self.layers = layers\n",
        "        \n",
        "        # Initialize NNs\n",
        "        self.weights, self.biases = self.initialize_NN(layers)\n",
        "        \n",
        "        # tf placeholders and graph\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "        \n",
        "        # Initialize parameters\n",
        "        self.lambda_1 = tf.Variable([0.0], dtype=tf.float32)\n",
        "        self.lambda_2 = tf.Variable([-6.0], dtype=tf.float32)\n",
        "        \n",
        "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n",
        "        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n",
        "        self.u_tf = tf.placeholder(tf.float32, shape=[None, self.u.shape[1]])\n",
        "                \n",
        "        self.u_pred = self.net_u(self.x_tf, self.t_tf)\n",
        "        self.f_pred = self.net_f(self.x_tf, self.t_tf)\n",
        "        \n",
        "        self.loss = tf.reduce_mean(tf.square(self.u_tf - self.u_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.f_pred))\n",
        "        \n",
        "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
        "                                                                method = 'L-BFGS-B', \n",
        "                                                                options = {'maxiter': 50000,\n",
        "                                                                           'maxfun': 50000,\n",
        "                                                                           'maxcor': 50,\n",
        "                                                                           'maxls': 50,\n",
        "                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n",
        "    \n",
        "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    def initialize_NN(self, layers):        \n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers) \n",
        "        for l in range(0,num_layers-1):\n",
        "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
        "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)        \n",
        "        return weights, biases\n",
        "        \n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]        \n",
        "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
        "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
        "    \n",
        "    def neural_net(self, X, weights, biases):\n",
        "        num_layers = len(weights) + 1\n",
        "        \n",
        "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
        "        for l in range(0,num_layers-2):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        Y = tf.add(tf.matmul(H, W), b)\n",
        "        return Y\n",
        "            \n",
        "    def net_u(self, x, t):  \n",
        "        u = self.neural_net(tf.concat([x,t],1), self.weights, self.biases)\n",
        "        return u\n",
        "    \n",
        "    def net_f(self, x, t):\n",
        "        lambda_1 = self.lambda_1        \n",
        "        lambda_2 = tf.exp(self.lambda_2)\n",
        "        u = self.net_u(x,t)\n",
        "        u_t = tf.gradients(u, t)[0]\n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        u_xx = tf.gradients(u_x, x)[0]\n",
        "        f = u_t + lambda_1*u*u_x - lambda_2*u_xx\n",
        "        \n",
        "        return f\n",
        "    \n",
        "    def callback(self, loss, lambda_1, lambda_2):\n",
        "        print('Loss: %e, l1: %.5f, l2: %.5f' % (loss, lambda_1, np.exp(lambda_2)))\n",
        "        \n",
        "        \n",
        "    def train(self, nIter):\n",
        "        tf_dict = {self.x_tf: self.x, self.t_tf: self.t, self.u_tf: self.u}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(nIter):\n",
        "            self.sess.run(self.train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.loss, tf_dict)\n",
        "                lambda_1_value = self.sess.run(self.lambda_1)\n",
        "                lambda_2_value = np.exp(self.sess.run(self.lambda_2))\n",
        "                print('It: %d, Loss: %.3e, Lambda_1: %.3f, Lambda_2: %.6f, Time: %.2f' % \n",
        "                      (it, loss_value, lambda_1_value, lambda_2_value, elapsed))\n",
        "                start_time = time.time()\n",
        "        \n",
        "        self.optimizer.minimize(self.sess,\n",
        "                                feed_dict = tf_dict,\n",
        "                                fetches = [self.loss, self.lambda_1, self.lambda_2],\n",
        "                                loss_callback = self.callback)\n",
        "        \n",
        "        \n",
        "    def predict(self, X_star):\n",
        "        \n",
        "        tf_dict = {self.x_tf: X_star[:,0:1], self.t_tf: X_star[:,1:2]}\n",
        "        \n",
        "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
        "        f_star = self.sess.run(self.f_pred, tf_dict)\n",
        "        \n",
        "        return u_star, f_star"
      ],
      "metadata": {
        "id": "bfhlzV7fnbJb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\": \n",
        "     \n",
        "    nu = 1/np.pi   #nu: valor de lambda_2\n",
        "\n",
        "    N_u = 2000  #N: número de elementos de treino\n",
        "    layers = [2, 20, 20, 20, 20, 20, 20, 1] #2 layers a menos\n",
        "    \n",
        "    data = scipy.io.loadmat('../content/un1000.mat')\n",
        "    \n",
        "    t = data['t'].flatten()[:,None]\n",
        "    x = data['x'].flatten()[:,None]\n",
        "    Exact = np.real(data['usol']).T   #.T: transposição da matriz de dados usol\n",
        "    \n",
        "    X, T = np.meshgrid(x,t)\n",
        "    \n",
        "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
        "    u_star = Exact.flatten()[:,None]              \n",
        "\n",
        "    # Domain bounds\n",
        "    lb = X_star.min(0)\n",
        "    ub = X_star.max(0)    \n",
        "    \n",
        "    ######################################################################\n",
        "    ######################## Noiseless Data ###############################\n",
        "    ######################################################################\n",
        "    noise = 0.0            \n",
        "             \n",
        "    idx = np.random.choice(X_star.shape[0], N_u, replace=False)\n",
        "    X_u_train = X_star[idx,:]\n",
        "    u_train = u_star[idx,:]\n",
        "    \n",
        "    model = PhysicsInformedNN(X_u_train, u_train, layers, lb, ub)\n",
        "    model.train(2000)\n",
        "    \n",
        "    u_pred, f_pred = model.predict(X_star)\n",
        "            \n",
        "    error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
        "    \n",
        "    U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
        "        \n",
        "    lambda_1_value = model.sess.run(model.lambda_1)\n",
        "    lambda_2_value = model.sess.run(model.lambda_2)\n",
        "    lambda_2_value = np.exp(lambda_2_value)\n",
        "    \n",
        "    error_lambda_1 = np.abs(lambda_1_value - 1.0)*100\n",
        "    error_lambda_2 = np.abs(lambda_2_value - nu)/nu * 100\n",
        "    \n",
        "    print('Error u: %e' % (error_u))    \n",
        "    print('Error l1: %.5f%%' % (error_lambda_1))                             \n",
        "    print('Error l2: %.5f%%' % (error_lambda_2))  \n",
        "    \n",
        "                               "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWIWsRhBnzr2",
        "outputId": "206637c1-bc88-442f-e1b4-63585db34116"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "It: 0, Loss: 6.291e-02, Lambda_1: 0.001, Lambda_2: 0.002477, Time: 0.97\n",
            "It: 10, Loss: 5.310e-02, Lambda_1: -0.005, Lambda_2: 0.002492, Time: 0.22\n",
            "It: 20, Loss: 4.886e-02, Lambda_1: -0.016, Lambda_2: 0.002519, Time: 0.21\n",
            "It: 30, Loss: 4.759e-02, Lambda_1: -0.027, Lambda_2: 0.002548, Time: 0.24\n",
            "It: 40, Loss: 4.663e-02, Lambda_1: -0.039, Lambda_2: 0.002580, Time: 0.22\n",
            "It: 50, Loss: 4.573e-02, Lambda_1: -0.051, Lambda_2: 0.002616, Time: 0.20\n",
            "It: 60, Loss: 4.474e-02, Lambda_1: -0.064, Lambda_2: 0.002654, Time: 0.21\n",
            "It: 70, Loss: 4.364e-02, Lambda_1: -0.077, Lambda_2: 0.002695, Time: 0.20\n",
            "It: 80, Loss: 4.224e-02, Lambda_1: -0.089, Lambda_2: 0.002738, Time: 0.21\n",
            "It: 90, Loss: 4.042e-02, Lambda_1: -0.101, Lambda_2: 0.002786, Time: 0.23\n",
            "It: 100, Loss: 3.810e-02, Lambda_1: -0.112, Lambda_2: 0.002837, Time: 0.20\n",
            "It: 110, Loss: 3.557e-02, Lambda_1: -0.120, Lambda_2: 0.002891, Time: 0.21\n",
            "It: 120, Loss: 3.350e-02, Lambda_1: -0.125, Lambda_2: 0.002948, Time: 0.22\n",
            "It: 130, Loss: 3.239e-02, Lambda_1: -0.123, Lambda_2: 0.003007, Time: 0.25\n",
            "It: 140, Loss: 3.193e-02, Lambda_1: -0.114, Lambda_2: 0.003068, Time: 0.21\n",
            "It: 150, Loss: 3.164e-02, Lambda_1: -0.102, Lambda_2: 0.003129, Time: 0.19\n",
            "It: 160, Loss: 3.142e-02, Lambda_1: -0.088, Lambda_2: 0.003193, Time: 0.19\n",
            "It: 170, Loss: 3.124e-02, Lambda_1: -0.076, Lambda_2: 0.003258, Time: 0.20\n",
            "It: 180, Loss: 3.109e-02, Lambda_1: -0.066, Lambda_2: 0.003324, Time: 0.21\n",
            "It: 190, Loss: 3.095e-02, Lambda_1: -0.058, Lambda_2: 0.003391, Time: 0.20\n",
            "It: 200, Loss: 3.083e-02, Lambda_1: -0.051, Lambda_2: 0.003458, Time: 0.19\n",
            "It: 210, Loss: 3.072e-02, Lambda_1: -0.045, Lambda_2: 0.003526, Time: 0.20\n",
            "It: 220, Loss: 3.061e-02, Lambda_1: -0.040, Lambda_2: 0.003594, Time: 0.21\n",
            "It: 230, Loss: 3.052e-02, Lambda_1: -0.036, Lambda_2: 0.003662, Time: 0.22\n",
            "It: 240, Loss: 3.044e-02, Lambda_1: -0.032, Lambda_2: 0.003729, Time: 0.20\n",
            "It: 250, Loss: 3.037e-02, Lambda_1: -0.030, Lambda_2: 0.003797, Time: 0.20\n",
            "It: 260, Loss: 3.029e-02, Lambda_1: -0.027, Lambda_2: 0.003865, Time: 0.21\n",
            "It: 270, Loss: 3.022e-02, Lambda_1: -0.025, Lambda_2: 0.003933, Time: 0.25\n",
            "It: 280, Loss: 3.016e-02, Lambda_1: -0.023, Lambda_2: 0.004001, Time: 0.23\n",
            "It: 290, Loss: 3.010e-02, Lambda_1: -0.022, Lambda_2: 0.004069, Time: 0.22\n",
            "It: 300, Loss: 3.004e-02, Lambda_1: -0.021, Lambda_2: 0.004137, Time: 0.20\n",
            "It: 310, Loss: 2.999e-02, Lambda_1: -0.019, Lambda_2: 0.004206, Time: 0.22\n",
            "It: 320, Loss: 2.994e-02, Lambda_1: -0.018, Lambda_2: 0.004275, Time: 0.22\n",
            "It: 330, Loss: 2.990e-02, Lambda_1: -0.018, Lambda_2: 0.004345, Time: 0.21\n",
            "It: 340, Loss: 2.989e-02, Lambda_1: -0.017, Lambda_2: 0.004415, Time: 0.22\n",
            "It: 350, Loss: 2.982e-02, Lambda_1: -0.016, Lambda_2: 0.004486, Time: 0.22\n",
            "It: 360, Loss: 2.977e-02, Lambda_1: -0.016, Lambda_2: 0.004557, Time: 0.21\n",
            "It: 370, Loss: 2.973e-02, Lambda_1: -0.016, Lambda_2: 0.004629, Time: 0.22\n",
            "It: 380, Loss: 2.969e-02, Lambda_1: -0.015, Lambda_2: 0.004702, Time: 0.20\n",
            "It: 390, Loss: 2.965e-02, Lambda_1: -0.015, Lambda_2: 0.004776, Time: 0.21\n",
            "It: 400, Loss: 2.962e-02, Lambda_1: -0.015, Lambda_2: 0.004850, Time: 0.24\n",
            "It: 410, Loss: 2.958e-02, Lambda_1: -0.015, Lambda_2: 0.004926, Time: 0.22\n",
            "It: 420, Loss: 2.954e-02, Lambda_1: -0.015, Lambda_2: 0.005002, Time: 0.22\n",
            "It: 430, Loss: 2.951e-02, Lambda_1: -0.015, Lambda_2: 0.005079, Time: 0.21\n",
            "It: 440, Loss: 2.972e-02, Lambda_1: -0.016, Lambda_2: 0.005157, Time: 0.20\n",
            "It: 450, Loss: 2.950e-02, Lambda_1: -0.016, Lambda_2: 0.005237, Time: 0.21\n",
            "It: 460, Loss: 2.943e-02, Lambda_1: -0.017, Lambda_2: 0.005317, Time: 0.23\n",
            "It: 470, Loss: 2.938e-02, Lambda_1: -0.017, Lambda_2: 0.005398, Time: 0.20\n",
            "It: 480, Loss: 2.934e-02, Lambda_1: -0.018, Lambda_2: 0.005480, Time: 0.21\n",
            "It: 490, Loss: 2.931e-02, Lambda_1: -0.018, Lambda_2: 0.005564, Time: 0.21\n",
            "It: 500, Loss: 2.928e-02, Lambda_1: -0.019, Lambda_2: 0.005648, Time: 0.20\n",
            "It: 510, Loss: 2.925e-02, Lambda_1: -0.020, Lambda_2: 0.005734, Time: 0.23\n",
            "It: 520, Loss: 2.922e-02, Lambda_1: -0.020, Lambda_2: 0.005821, Time: 0.21\n",
            "It: 530, Loss: 2.919e-02, Lambda_1: -0.021, Lambda_2: 0.005909, Time: 0.23\n",
            "It: 540, Loss: 2.917e-02, Lambda_1: -0.022, Lambda_2: 0.005998, Time: 0.24\n",
            "It: 550, Loss: 2.914e-02, Lambda_1: -0.022, Lambda_2: 0.006089, Time: 0.22\n",
            "It: 560, Loss: 2.912e-02, Lambda_1: -0.023, Lambda_2: 0.006180, Time: 0.21\n",
            "It: 570, Loss: 2.910e-02, Lambda_1: -0.023, Lambda_2: 0.006273, Time: 0.21\n",
            "It: 580, Loss: 2.926e-02, Lambda_1: -0.023, Lambda_2: 0.006367, Time: 0.21\n",
            "It: 590, Loss: 2.906e-02, Lambda_1: -0.023, Lambda_2: 0.006463, Time: 0.21\n",
            "It: 600, Loss: 2.906e-02, Lambda_1: -0.023, Lambda_2: 0.006560, Time: 0.22\n",
            "It: 610, Loss: 2.901e-02, Lambda_1: -0.023, Lambda_2: 0.006658, Time: 0.21\n",
            "It: 620, Loss: 2.900e-02, Lambda_1: -0.023, Lambda_2: 0.006758, Time: 0.21\n",
            "It: 630, Loss: 2.897e-02, Lambda_1: -0.022, Lambda_2: 0.006860, Time: 0.21\n",
            "It: 640, Loss: 2.895e-02, Lambda_1: -0.022, Lambda_2: 0.006963, Time: 0.22\n",
            "It: 650, Loss: 2.893e-02, Lambda_1: -0.021, Lambda_2: 0.007067, Time: 0.22\n",
            "It: 660, Loss: 2.891e-02, Lambda_1: -0.021, Lambda_2: 0.007174, Time: 0.21\n",
            "It: 670, Loss: 2.889e-02, Lambda_1: -0.020, Lambda_2: 0.007282, Time: 0.24\n",
            "It: 680, Loss: 2.887e-02, Lambda_1: -0.020, Lambda_2: 0.007392, Time: 0.22\n",
            "It: 690, Loss: 2.884e-02, Lambda_1: -0.019, Lambda_2: 0.007504, Time: 0.22\n",
            "It: 700, Loss: 2.882e-02, Lambda_1: -0.018, Lambda_2: 0.007618, Time: 0.20\n",
            "It: 710, Loss: 2.880e-02, Lambda_1: -0.017, Lambda_2: 0.007734, Time: 0.20\n",
            "It: 720, Loss: 2.878e-02, Lambda_1: -0.016, Lambda_2: 0.007852, Time: 0.22\n",
            "It: 730, Loss: 2.876e-02, Lambda_1: -0.016, Lambda_2: 0.007972, Time: 0.20\n",
            "It: 740, Loss: 2.875e-02, Lambda_1: -0.015, Lambda_2: 0.008094, Time: 0.21\n",
            "It: 750, Loss: 2.872e-02, Lambda_1: -0.014, Lambda_2: 0.008218, Time: 0.21\n",
            "It: 760, Loss: 2.870e-02, Lambda_1: -0.013, Lambda_2: 0.008345, Time: 0.21\n",
            "It: 770, Loss: 2.866e-02, Lambda_1: -0.011, Lambda_2: 0.008473, Time: 0.21\n",
            "It: 780, Loss: 2.863e-02, Lambda_1: -0.010, Lambda_2: 0.008604, Time: 0.22\n",
            "It: 790, Loss: 2.860e-02, Lambda_1: -0.009, Lambda_2: 0.008738, Time: 0.20\n",
            "It: 800, Loss: 2.858e-02, Lambda_1: -0.009, Lambda_2: 0.008873, Time: 0.19\n",
            "It: 810, Loss: 2.855e-02, Lambda_1: -0.008, Lambda_2: 0.009012, Time: 0.24\n",
            "It: 820, Loss: 2.852e-02, Lambda_1: -0.007, Lambda_2: 0.009153, Time: 0.21\n",
            "It: 830, Loss: 2.850e-02, Lambda_1: -0.006, Lambda_2: 0.009296, Time: 0.23\n",
            "It: 840, Loss: 2.847e-02, Lambda_1: -0.005, Lambda_2: 0.009442, Time: 0.20\n",
            "It: 850, Loss: 2.844e-02, Lambda_1: -0.003, Lambda_2: 0.009591, Time: 0.20\n",
            "It: 860, Loss: 2.841e-02, Lambda_1: -0.002, Lambda_2: 0.009742, Time: 0.22\n",
            "It: 870, Loss: 2.838e-02, Lambda_1: -0.001, Lambda_2: 0.009896, Time: 0.22\n",
            "It: 880, Loss: 2.835e-02, Lambda_1: -0.000, Lambda_2: 0.010054, Time: 0.22\n",
            "It: 890, Loss: 2.832e-02, Lambda_1: 0.001, Lambda_2: 0.010214, Time: 0.20\n",
            "It: 900, Loss: 2.829e-02, Lambda_1: 0.002, Lambda_2: 0.010377, Time: 0.20\n",
            "It: 910, Loss: 2.826e-02, Lambda_1: 0.003, Lambda_2: 0.010543, Time: 0.19\n",
            "It: 920, Loss: 2.841e-02, Lambda_1: 0.004, Lambda_2: 0.010712, Time: 0.20\n",
            "It: 930, Loss: 2.826e-02, Lambda_1: 0.005, Lambda_2: 0.010885, Time: 0.22\n",
            "It: 940, Loss: 2.819e-02, Lambda_1: 0.006, Lambda_2: 0.011060, Time: 0.21\n",
            "It: 950, Loss: 2.814e-02, Lambda_1: 0.008, Lambda_2: 0.011239, Time: 0.22\n",
            "It: 960, Loss: 2.809e-02, Lambda_1: 0.009, Lambda_2: 0.011422, Time: 0.21\n",
            "It: 970, Loss: 2.805e-02, Lambda_1: 0.010, Lambda_2: 0.011608, Time: 0.21\n",
            "It: 980, Loss: 2.802e-02, Lambda_1: 0.012, Lambda_2: 0.011797, Time: 0.19\n",
            "It: 990, Loss: 2.798e-02, Lambda_1: 0.013, Lambda_2: 0.011991, Time: 0.23\n",
            "It: 1000, Loss: 2.794e-02, Lambda_1: 0.014, Lambda_2: 0.012188, Time: 0.21\n",
            "It: 1010, Loss: 2.790e-02, Lambda_1: 0.015, Lambda_2: 0.012388, Time: 0.19\n",
            "It: 1020, Loss: 2.786e-02, Lambda_1: 0.017, Lambda_2: 0.012593, Time: 0.21\n",
            "It: 1030, Loss: 2.782e-02, Lambda_1: 0.018, Lambda_2: 0.012802, Time: 0.19\n",
            "It: 1040, Loss: 2.778e-02, Lambda_1: 0.019, Lambda_2: 0.013014, Time: 0.21\n",
            "It: 1050, Loss: 2.774e-02, Lambda_1: 0.020, Lambda_2: 0.013231, Time: 0.21\n",
            "It: 1060, Loss: 2.805e-02, Lambda_1: 0.022, Lambda_2: 0.013452, Time: 0.19\n",
            "It: 1070, Loss: 2.769e-02, Lambda_1: 0.023, Lambda_2: 0.013677, Time: 0.21\n",
            "It: 1080, Loss: 2.765e-02, Lambda_1: 0.025, Lambda_2: 0.013906, Time: 0.23\n",
            "It: 1090, Loss: 2.758e-02, Lambda_1: 0.027, Lambda_2: 0.014140, Time: 0.20\n",
            "It: 1100, Loss: 2.753e-02, Lambda_1: 0.028, Lambda_2: 0.014379, Time: 0.20\n",
            "It: 1110, Loss: 2.748e-02, Lambda_1: 0.030, Lambda_2: 0.014622, Time: 0.20\n",
            "It: 1120, Loss: 2.743e-02, Lambda_1: 0.031, Lambda_2: 0.014871, Time: 0.22\n",
            "It: 1130, Loss: 2.738e-02, Lambda_1: 0.032, Lambda_2: 0.015124, Time: 0.20\n",
            "It: 1140, Loss: 2.733e-02, Lambda_1: 0.034, Lambda_2: 0.015382, Time: 0.20\n",
            "It: 1150, Loss: 2.728e-02, Lambda_1: 0.035, Lambda_2: 0.015646, Time: 0.21\n",
            "It: 1160, Loss: 2.723e-02, Lambda_1: 0.037, Lambda_2: 0.015914, Time: 0.22\n",
            "It: 1170, Loss: 2.718e-02, Lambda_1: 0.038, Lambda_2: 0.016188, Time: 0.20\n",
            "It: 1180, Loss: 2.712e-02, Lambda_1: 0.040, Lambda_2: 0.016468, Time: 0.21\n",
            "It: 1190, Loss: 2.707e-02, Lambda_1: 0.041, Lambda_2: 0.016753, Time: 0.21\n",
            "It: 1200, Loss: 2.701e-02, Lambda_1: 0.043, Lambda_2: 0.017044, Time: 0.21\n",
            "It: 1210, Loss: 2.696e-02, Lambda_1: 0.044, Lambda_2: 0.017340, Time: 0.22\n",
            "It: 1220, Loss: 2.696e-02, Lambda_1: 0.046, Lambda_2: 0.017643, Time: 0.24\n",
            "It: 1230, Loss: 2.702e-02, Lambda_1: 0.047, Lambda_2: 0.017952, Time: 0.20\n",
            "It: 1240, Loss: 2.682e-02, Lambda_1: 0.049, Lambda_2: 0.018266, Time: 0.20\n",
            "It: 1250, Loss: 2.674e-02, Lambda_1: 0.051, Lambda_2: 0.018586, Time: 0.21\n",
            "It: 1260, Loss: 2.666e-02, Lambda_1: 0.053, Lambda_2: 0.018913, Time: 0.21\n",
            "It: 1270, Loss: 2.660e-02, Lambda_1: 0.055, Lambda_2: 0.019247, Time: 0.20\n",
            "It: 1280, Loss: 2.653e-02, Lambda_1: 0.057, Lambda_2: 0.019588, Time: 0.21\n",
            "It: 1290, Loss: 2.646e-02, Lambda_1: 0.058, Lambda_2: 0.019936, Time: 0.20\n",
            "It: 1300, Loss: 2.639e-02, Lambda_1: 0.060, Lambda_2: 0.020291, Time: 0.21\n",
            "It: 1310, Loss: 2.632e-02, Lambda_1: 0.062, Lambda_2: 0.020653, Time: 0.19\n",
            "It: 1320, Loss: 2.625e-02, Lambda_1: 0.064, Lambda_2: 0.021023, Time: 0.21\n",
            "It: 1330, Loss: 2.618e-02, Lambda_1: 0.065, Lambda_2: 0.021400, Time: 0.21\n",
            "It: 1340, Loss: 2.611e-02, Lambda_1: 0.067, Lambda_2: 0.021785, Time: 0.20\n",
            "It: 1350, Loss: 2.603e-02, Lambda_1: 0.069, Lambda_2: 0.022178, Time: 0.22\n",
            "It: 1360, Loss: 2.596e-02, Lambda_1: 0.070, Lambda_2: 0.022578, Time: 0.25\n",
            "It: 1370, Loss: 2.588e-02, Lambda_1: 0.072, Lambda_2: 0.022987, Time: 0.20\n",
            "It: 1380, Loss: 2.583e-02, Lambda_1: 0.074, Lambda_2: 0.023404, Time: 0.20\n",
            "It: 1390, Loss: 2.593e-02, Lambda_1: 0.076, Lambda_2: 0.023830, Time: 0.20\n",
            "It: 1400, Loss: 2.570e-02, Lambda_1: 0.078, Lambda_2: 0.024262, Time: 0.22\n",
            "It: 1410, Loss: 2.558e-02, Lambda_1: 0.081, Lambda_2: 0.024703, Time: 0.21\n",
            "It: 1420, Loss: 2.548e-02, Lambda_1: 0.083, Lambda_2: 0.025154, Time: 0.21\n",
            "It: 1430, Loss: 2.538e-02, Lambda_1: 0.086, Lambda_2: 0.025615, Time: 0.21\n",
            "It: 1440, Loss: 2.529e-02, Lambda_1: 0.088, Lambda_2: 0.026085, Time: 0.22\n",
            "It: 1450, Loss: 2.519e-02, Lambda_1: 0.090, Lambda_2: 0.026565, Time: 0.20\n",
            "It: 1460, Loss: 2.510e-02, Lambda_1: 0.091, Lambda_2: 0.027055, Time: 0.21\n",
            "It: 1470, Loss: 2.500e-02, Lambda_1: 0.093, Lambda_2: 0.027555, Time: 0.23\n",
            "It: 1480, Loss: 2.491e-02, Lambda_1: 0.095, Lambda_2: 0.028065, Time: 0.20\n",
            "It: 1490, Loss: 2.481e-02, Lambda_1: 0.097, Lambda_2: 0.028585, Time: 0.22\n",
            "It: 1500, Loss: 2.471e-02, Lambda_1: 0.098, Lambda_2: 0.029116, Time: 0.22\n",
            "It: 1510, Loss: 2.460e-02, Lambda_1: 0.100, Lambda_2: 0.029658, Time: 0.21\n",
            "It: 1520, Loss: 2.450e-02, Lambda_1: 0.102, Lambda_2: 0.030212, Time: 0.20\n",
            "It: 1530, Loss: 2.439e-02, Lambda_1: 0.104, Lambda_2: 0.030776, Time: 0.20\n",
            "It: 1540, Loss: 2.428e-02, Lambda_1: 0.105, Lambda_2: 0.031352, Time: 0.22\n",
            "It: 1550, Loss: 2.417e-02, Lambda_1: 0.107, Lambda_2: 0.031940, Time: 0.21\n",
            "It: 1560, Loss: 2.418e-02, Lambda_1: 0.108, Lambda_2: 0.032539, Time: 0.20\n",
            "It: 1570, Loss: 2.416e-02, Lambda_1: 0.110, Lambda_2: 0.033150, Time: 0.20\n",
            "It: 1580, Loss: 2.390e-02, Lambda_1: 0.112, Lambda_2: 0.033769, Time: 0.21\n",
            "It: 1590, Loss: 2.372e-02, Lambda_1: 0.116, Lambda_2: 0.034400, Time: 0.20\n",
            "It: 1600, Loss: 2.358e-02, Lambda_1: 0.118, Lambda_2: 0.035046, Time: 0.20\n",
            "It: 1610, Loss: 2.346e-02, Lambda_1: 0.121, Lambda_2: 0.035706, Time: 0.20\n",
            "It: 1620, Loss: 2.333e-02, Lambda_1: 0.122, Lambda_2: 0.036380, Time: 0.19\n",
            "It: 1630, Loss: 2.320e-02, Lambda_1: 0.124, Lambda_2: 0.037067, Time: 0.22\n",
            "It: 1640, Loss: 2.307e-02, Lambda_1: 0.124, Lambda_2: 0.037768, Time: 0.20\n",
            "It: 1650, Loss: 2.293e-02, Lambda_1: 0.125, Lambda_2: 0.038483, Time: 0.20\n",
            "It: 1660, Loss: 2.279e-02, Lambda_1: 0.126, Lambda_2: 0.039213, Time: 0.19\n",
            "It: 1670, Loss: 2.265e-02, Lambda_1: 0.127, Lambda_2: 0.039957, Time: 0.21\n",
            "It: 1680, Loss: 2.251e-02, Lambda_1: 0.127, Lambda_2: 0.040715, Time: 0.21\n",
            "It: 1690, Loss: 2.236e-02, Lambda_1: 0.128, Lambda_2: 0.041489, Time: 0.20\n",
            "It: 1700, Loss: 2.222e-02, Lambda_1: 0.128, Lambda_2: 0.042278, Time: 0.20\n",
            "It: 1710, Loss: 2.207e-02, Lambda_1: 0.129, Lambda_2: 0.043083, Time: 0.20\n",
            "It: 1720, Loss: 2.191e-02, Lambda_1: 0.129, Lambda_2: 0.043903, Time: 0.20\n",
            "It: 1730, Loss: 2.176e-02, Lambda_1: 0.129, Lambda_2: 0.044740, Time: 0.22\n",
            "It: 1740, Loss: 2.160e-02, Lambda_1: 0.129, Lambda_2: 0.045593, Time: 0.21\n",
            "It: 1750, Loss: 2.213e-02, Lambda_1: 0.129, Lambda_2: 0.046462, Time: 0.20\n",
            "It: 1760, Loss: 2.196e-02, Lambda_1: 0.128, Lambda_2: 0.047345, Time: 0.19\n",
            "It: 1770, Loss: 2.122e-02, Lambda_1: 0.130, Lambda_2: 0.048232, Time: 0.22\n",
            "It: 1780, Loss: 2.098e-02, Lambda_1: 0.134, Lambda_2: 0.049141, Time: 0.23\n",
            "It: 1790, Loss: 2.080e-02, Lambda_1: 0.135, Lambda_2: 0.050072, Time: 0.19\n",
            "It: 1800, Loss: 2.061e-02, Lambda_1: 0.135, Lambda_2: 0.051022, Time: 0.21\n",
            "It: 1810, Loss: 2.043e-02, Lambda_1: 0.133, Lambda_2: 0.051989, Time: 0.19\n",
            "It: 1820, Loss: 2.025e-02, Lambda_1: 0.132, Lambda_2: 0.052975, Time: 0.19\n",
            "It: 1830, Loss: 2.007e-02, Lambda_1: 0.131, Lambda_2: 0.053979, Time: 0.22\n",
            "It: 1840, Loss: 1.988e-02, Lambda_1: 0.130, Lambda_2: 0.055001, Time: 0.20\n",
            "It: 1850, Loss: 1.970e-02, Lambda_1: 0.128, Lambda_2: 0.056042, Time: 0.19\n",
            "It: 1860, Loss: 1.950e-02, Lambda_1: 0.127, Lambda_2: 0.057102, Time: 0.19\n",
            "It: 1870, Loss: 1.931e-02, Lambda_1: 0.126, Lambda_2: 0.058182, Time: 0.20\n",
            "It: 1880, Loss: 1.911e-02, Lambda_1: 0.125, Lambda_2: 0.059281, Time: 0.21\n",
            "It: 1890, Loss: 1.892e-02, Lambda_1: 0.123, Lambda_2: 0.060399, Time: 0.21\n",
            "It: 1900, Loss: 1.871e-02, Lambda_1: 0.122, Lambda_2: 0.061538, Time: 0.20\n",
            "It: 1910, Loss: 1.851e-02, Lambda_1: 0.121, Lambda_2: 0.062696, Time: 0.19\n",
            "It: 1920, Loss: 1.830e-02, Lambda_1: 0.120, Lambda_2: 0.063875, Time: 0.23\n",
            "It: 1930, Loss: 1.809e-02, Lambda_1: 0.120, Lambda_2: 0.065074, Time: 0.21\n",
            "It: 1940, Loss: 1.788e-02, Lambda_1: 0.119, Lambda_2: 0.066294, Time: 0.20\n",
            "It: 1950, Loss: 1.835e-02, Lambda_1: 0.119, Lambda_2: 0.067535, Time: 0.23\n",
            "It: 1960, Loss: 1.778e-02, Lambda_1: 0.116, Lambda_2: 0.068792, Time: 0.22\n",
            "It: 1970, Loss: 1.730e-02, Lambda_1: 0.120, Lambda_2: 0.070052, Time: 0.22\n",
            "It: 1980, Loss: 1.704e-02, Lambda_1: 0.124, Lambda_2: 0.071336, Time: 0.19\n",
            "It: 1990, Loss: 1.683e-02, Lambda_1: 0.125, Lambda_2: 0.072645, Time: 0.20\n",
            "Loss: 1.661965e-02, l1: 0.12388, l2: 0.07384\n",
            "Loss: 6.139235e+00, l1: 0.12413, l2: 0.11695\n",
            "Loss: 1.661373e-02, l1: 0.12388, l2: 0.07387\n",
            "Loss: 1.660777e-02, l1: 0.12388, l2: 0.07389\n",
            "Loss: 1.660372e-02, l1: 0.12388, l2: 0.07391\n",
            "Loss: 1.658870e-02, l1: 0.12387, l2: 0.07405\n",
            "Loss: 1.655497e-02, l1: 0.12386, l2: 0.07440\n",
            "Loss: 1.646635e-02, l1: 0.12383, l2: 0.07543\n",
            "Loss: 1.626661e-02, l1: 0.12376, l2: 0.07797\n",
            "Loss: 1.588733e-02, l1: 0.12363, l2: 0.08344\n",
            "Loss: 1.530471e-02, l1: 0.12350, l2: 0.09220\n",
            "Loss: 1.401219e-02, l1: 0.12363, l2: 0.11705\n",
            "Loss: 1.288342e-02, l1: 0.12414, l2: 0.15427\n",
            "Loss: 1.122250e-02, l1: 0.12467, l2: 0.15361\n",
            "Loss: 1.088148e-02, l1: 0.12487, l2: 0.15884\n",
            "Loss: 1.078240e-02, l1: 0.12510, l2: 0.16024\n",
            "Loss: 1.075048e-02, l1: 0.12524, l2: 0.16241\n",
            "Loss: 1.043667e-02, l1: 0.12680, l2: 0.17400\n",
            "Loss: 9.966578e-03, l1: 0.12990, l2: 0.18670\n",
            "Loss: 9.708111e-03, l1: 0.13418, l2: 0.19491\n",
            "Loss: 9.150240e-03, l1: 0.13601, l2: 0.18788\n",
            "Loss: 9.033883e-03, l1: 0.13564, l2: 0.18026\n",
            "Loss: 8.941201e-03, l1: 0.13621, l2: 0.17958\n",
            "Loss: 8.531220e-03, l1: 0.13937, l2: 0.18161\n",
            "Loss: 8.288294e-03, l1: 0.14184, l2: 0.18805\n",
            "Loss: 8.089948e-03, l1: 0.14493, l2: 0.19684\n",
            "Loss: 7.958800e-03, l1: 0.14772, l2: 0.20317\n",
            "Loss: 7.823823e-03, l1: 0.15072, l2: 0.20607\n",
            "Loss: 7.507547e-03, l1: 0.15874, l2: 0.20883\n",
            "Loss: 7.037573e-03, l1: 0.16990, l2: 0.20950\n",
            "Loss: 6.420786e-03, l1: 0.19879, l2: 0.22304\n",
            "Loss: 5.744475e-03, l1: 0.19992, l2: 0.21310\n",
            "Loss: 5.570918e-03, l1: 0.19965, l2: 0.21518\n",
            "Loss: 5.490088e-03, l1: 0.20043, l2: 0.21576\n",
            "Loss: 5.420872e-03, l1: 0.20180, l2: 0.21690\n",
            "Loss: 5.188544e-03, l1: 0.20799, l2: 0.22435\n",
            "Loss: 5.069557e-03, l1: 0.20957, l2: 0.22925\n",
            "Loss: 4.823872e-03, l1: 0.21318, l2: 0.23465\n",
            "Loss: 4.665934e-03, l1: 0.21852, l2: 0.24163\n",
            "Loss: 4.471159e-03, l1: 0.21931, l2: 0.23946\n",
            "Loss: 4.365133e-03, l1: 0.21964, l2: 0.23954\n",
            "Loss: 4.327785e-03, l1: 0.21705, l2: 0.23922\n",
            "Loss: 4.290602e-03, l1: 0.21595, l2: 0.23992\n",
            "Loss: 4.201093e-03, l1: 0.21451, l2: 0.23903\n",
            "Loss: 4.077840e-03, l1: 0.21766, l2: 0.23484\n",
            "Loss: 4.002692e-03, l1: 0.22254, l2: 0.23122\n",
            "Loss: 3.961299e-03, l1: 0.22579, l2: 0.23149\n",
            "Loss: 3.855185e-03, l1: 0.23355, l2: 0.23412\n",
            "Loss: 3.712919e-03, l1: 0.24295, l2: 0.23900\n",
            "Loss: 3.483457e-03, l1: 0.25621, l2: 0.24665\n",
            "Loss: 3.328059e-03, l1: 0.26434, l2: 0.25324\n",
            "Loss: 3.262027e-03, l1: 0.26448, l2: 0.25465\n",
            "Loss: 3.231104e-03, l1: 0.26722, l2: 0.25736\n",
            "Loss: 3.177544e-03, l1: 0.26736, l2: 0.25566\n",
            "Loss: 2.877927e-03, l1: 0.27687, l2: 0.25612\n",
            "Loss: 2.623445e-03, l1: 0.29352, l2: 0.26115\n",
            "Loss: 2.486258e-03, l1: 0.30552, l2: 0.26716\n",
            "Loss: 2.439873e-03, l1: 0.31568, l2: 0.27306\n",
            "Loss: 2.406172e-03, l1: 0.31699, l2: 0.27482\n",
            "Loss: 2.375299e-03, l1: 0.31883, l2: 0.27698\n",
            "Loss: 2.335372e-03, l1: 0.32197, l2: 0.27849\n",
            "Loss: 2.300304e-03, l1: 0.32360, l2: 0.27777\n",
            "Loss: 2.267360e-03, l1: 0.32598, l2: 0.27634\n",
            "Loss: 2.240703e-03, l1: 0.32577, l2: 0.27390\n",
            "Loss: 2.215009e-03, l1: 0.32515, l2: 0.27278\n",
            "Loss: 2.186380e-03, l1: 0.32664, l2: 0.27239\n",
            "Loss: 2.136357e-03, l1: 0.33051, l2: 0.27393\n",
            "Loss: 2.037762e-03, l1: 0.34228, l2: 0.27652\n",
            "Loss: 1.877247e-03, l1: 0.36575, l2: 0.28566\n",
            "Loss: 1.731902e-03, l1: 0.39098, l2: 0.28615\n",
            "Loss: 1.637631e-03, l1: 0.41659, l2: 0.29648\n",
            "Loss: 1.556495e-03, l1: 0.40738, l2: 0.29580\n",
            "Loss: 1.502480e-03, l1: 0.41120, l2: 0.29155\n",
            "Loss: 1.470859e-03, l1: 0.41565, l2: 0.29251\n",
            "Loss: 1.441927e-03, l1: 0.42209, l2: 0.29256\n",
            "Loss: 1.405438e-03, l1: 0.42431, l2: 0.29247\n",
            "Loss: 1.371047e-03, l1: 0.42096, l2: 0.28755\n",
            "Loss: 1.345348e-03, l1: 0.42468, l2: 0.28665\n",
            "Loss: 1.334038e-03, l1: 0.42350, l2: 0.28668\n",
            "Loss: 1.320829e-03, l1: 0.42042, l2: 0.28648\n",
            "Loss: 1.300137e-03, l1: 0.41866, l2: 0.28701\n",
            "Loss: 1.273846e-03, l1: 0.41548, l2: 0.28823\n",
            "Loss: 1.239501e-03, l1: 0.41599, l2: 0.29096\n",
            "Loss: 1.186066e-03, l1: 0.41908, l2: 0.29685\n",
            "Loss: 1.132565e-03, l1: 0.42683, l2: 0.30385\n",
            "Loss: 1.081933e-03, l1: 0.43565, l2: 0.31008\n",
            "Loss: 1.046197e-03, l1: 0.44523, l2: 0.31199\n",
            "Loss: 1.018118e-03, l1: 0.45360, l2: 0.31303\n",
            "Loss: 9.852296e-04, l1: 0.45869, l2: 0.31198\n",
            "Loss: 9.383989e-04, l1: 0.47228, l2: 0.31060\n",
            "Loss: 8.689477e-04, l1: 0.49213, l2: 0.30869\n",
            "Loss: 8.289088e-04, l1: 0.50283, l2: 0.30900\n",
            "Loss: 7.817104e-04, l1: 0.49878, l2: 0.31018\n",
            "Loss: 7.656420e-04, l1: 0.49977, l2: 0.31428\n",
            "Loss: 7.624484e-04, l1: 0.49586, l2: 0.31239\n",
            "Loss: 7.606864e-04, l1: 0.49759, l2: 0.31300\n",
            "Loss: 7.600671e-04, l1: 0.49715, l2: 0.31325\n",
            "Loss: 7.587747e-04, l1: 0.49643, l2: 0.31363\n",
            "Loss: 7.569761e-04, l1: 0.49461, l2: 0.31396\n",
            "Loss: 7.555495e-04, l1: 0.49418, l2: 0.31353\n",
            "Loss: 7.527182e-04, l1: 0.49345, l2: 0.31233\n",
            "Loss: 7.488610e-04, l1: 0.49274, l2: 0.31086\n",
            "Loss: 7.406254e-04, l1: 0.49264, l2: 0.30876\n",
            "Loss: 7.266222e-04, l1: 0.49531, l2: 0.30679\n",
            "Loss: 7.053978e-04, l1: 0.50405, l2: 0.30665\n",
            "Loss: 6.903343e-04, l1: 0.51479, l2: 0.30968\n",
            "Loss: 6.831914e-04, l1: 0.51833, l2: 0.31162\n",
            "Loss: 6.805905e-04, l1: 0.52010, l2: 0.31214\n",
            "Loss: 6.790814e-04, l1: 0.52136, l2: 0.31288\n",
            "Loss: 6.776978e-04, l1: 0.52312, l2: 0.31261\n",
            "Loss: 6.747148e-04, l1: 0.52530, l2: 0.31201\n",
            "Loss: 6.709838e-04, l1: 0.52853, l2: 0.31096\n",
            "Loss: 6.668064e-04, l1: 0.53118, l2: 0.31055\n",
            "Loss: 6.632897e-04, l1: 0.52792, l2: 0.31047\n",
            "Loss: 6.597206e-04, l1: 0.52812, l2: 0.31105\n",
            "Loss: 6.552648e-04, l1: 0.52657, l2: 0.31213\n",
            "Loss: 6.520405e-04, l1: 0.52538, l2: 0.31355\n",
            "Loss: 6.509189e-04, l1: 0.52486, l2: 0.31411\n",
            "Loss: 6.504763e-04, l1: 0.52493, l2: 0.31432\n",
            "Loss: 6.497349e-04, l1: 0.52526, l2: 0.31448\n",
            "Loss: 6.482339e-04, l1: 0.52626, l2: 0.31483\n",
            "Loss: 6.452065e-04, l1: 0.52843, l2: 0.31528\n",
            "Loss: 6.395705e-04, l1: 0.53235, l2: 0.31620\n",
            "Loss: 6.300151e-04, l1: 0.53901, l2: 0.31698\n",
            "Loss: 6.169488e-04, l1: 0.54927, l2: 0.31902\n",
            "Loss: 5.977780e-04, l1: 0.55089, l2: 0.32050\n",
            "Loss: 5.797070e-04, l1: 0.55891, l2: 0.32129\n",
            "Loss: 5.809569e-04, l1: 0.55234, l2: 0.31961\n",
            "Loss: 5.724138e-04, l1: 0.55573, l2: 0.32048\n",
            "Loss: 5.674749e-04, l1: 0.55794, l2: 0.32041\n",
            "Loss: 5.647669e-04, l1: 0.56326, l2: 0.32251\n",
            "Loss: 5.632491e-04, l1: 0.56138, l2: 0.32187\n",
            "Loss: 5.628339e-04, l1: 0.56208, l2: 0.32196\n",
            "Loss: 5.621012e-04, l1: 0.56330, l2: 0.32222\n",
            "Loss: 5.607540e-04, l1: 0.56620, l2: 0.32240\n",
            "Loss: 5.593253e-04, l1: 0.56788, l2: 0.32216\n",
            "Loss: 5.571750e-04, l1: 0.57078, l2: 0.32109\n",
            "Loss: 5.551545e-04, l1: 0.57063, l2: 0.32044\n",
            "Loss: 5.532618e-04, l1: 0.57201, l2: 0.31981\n",
            "Loss: 5.506302e-04, l1: 0.57146, l2: 0.31853\n",
            "Loss: 5.484184e-04, l1: 0.57126, l2: 0.31792\n",
            "Loss: 5.468660e-04, l1: 0.57002, l2: 0.31821\n",
            "Loss: 5.456525e-04, l1: 0.57189, l2: 0.31822\n",
            "Loss: 5.447534e-04, l1: 0.57193, l2: 0.31853\n",
            "Loss: 5.433985e-04, l1: 0.57161, l2: 0.31923\n",
            "Loss: 5.426332e-04, l1: 0.57066, l2: 0.31877\n",
            "Loss: 5.418029e-04, l1: 0.56846, l2: 0.31797\n",
            "Loss: 5.414000e-04, l1: 0.56649, l2: 0.31712\n",
            "Loss: 5.408885e-04, l1: 0.56571, l2: 0.31709\n",
            "Loss: 5.403167e-04, l1: 0.56492, l2: 0.31719\n",
            "Loss: 5.397926e-04, l1: 0.56411, l2: 0.31722\n",
            "Loss: 5.392213e-04, l1: 0.56387, l2: 0.31724\n",
            "Loss: 5.383369e-04, l1: 0.56388, l2: 0.31714\n",
            "Loss: 5.366283e-04, l1: 0.56505, l2: 0.31708\n",
            "Loss: 5.334882e-04, l1: 0.56822, l2: 0.31672\n",
            "Loss: 5.282615e-04, l1: 0.57526, l2: 0.31672\n",
            "Loss: 5.225139e-04, l1: 0.58218, l2: 0.31700\n",
            "Loss: 5.187014e-04, l1: 0.58697, l2: 0.31835\n",
            "Loss: 5.246193e-04, l1: 0.59419, l2: 0.31837\n",
            "Loss: 5.167155e-04, l1: 0.58948, l2: 0.31836\n",
            "Loss: 5.154080e-04, l1: 0.58853, l2: 0.31795\n",
            "Loss: 5.146397e-04, l1: 0.58920, l2: 0.31791\n",
            "Loss: 5.138641e-04, l1: 0.59099, l2: 0.31848\n",
            "Loss: 5.132155e-04, l1: 0.59273, l2: 0.31866\n",
            "Loss: 5.126901e-04, l1: 0.59450, l2: 0.31900\n",
            "Loss: 5.122115e-04, l1: 0.59534, l2: 0.31896\n",
            "Loss: 5.117769e-04, l1: 0.59657, l2: 0.31904\n",
            "Loss: 5.114668e-04, l1: 0.59562, l2: 0.31870\n",
            "Loss: 5.111173e-04, l1: 0.59654, l2: 0.31869\n",
            "Loss: 5.107677e-04, l1: 0.59644, l2: 0.31884\n",
            "Loss: 5.102793e-04, l1: 0.59643, l2: 0.31870\n",
            "Loss: 5.096224e-04, l1: 0.59677, l2: 0.31846\n",
            "Loss: 5.087798e-04, l1: 0.59747, l2: 0.31827\n",
            "Loss: 5.070309e-04, l1: 0.59877, l2: 0.31838\n",
            "Loss: 5.050226e-04, l1: 0.59953, l2: 0.31903\n",
            "Loss: 5.017645e-04, l1: 0.59881, l2: 0.32033\n",
            "Loss: 4.984583e-04, l1: 0.59757, l2: 0.32155\n",
            "Loss: 4.965885e-04, l1: 0.59471, l2: 0.32206\n",
            "Loss: 4.954301e-04, l1: 0.59598, l2: 0.32181\n",
            "Loss: 4.947101e-04, l1: 0.59654, l2: 0.32107\n",
            "Loss: 4.940787e-04, l1: 0.59670, l2: 0.32032\n",
            "Loss: 4.937119e-04, l1: 0.59759, l2: 0.32011\n",
            "Loss: 4.933759e-04, l1: 0.59762, l2: 0.31995\n",
            "Loss: 4.929007e-04, l1: 0.59853, l2: 0.32015\n",
            "Loss: 4.923612e-04, l1: 0.59950, l2: 0.32031\n",
            "Loss: 4.919096e-04, l1: 0.60039, l2: 0.32040\n",
            "Loss: 4.915585e-04, l1: 0.60139, l2: 0.32042\n",
            "Loss: 4.911625e-04, l1: 0.60210, l2: 0.32037\n",
            "Loss: 4.902668e-04, l1: 0.60381, l2: 0.32055\n",
            "Loss: 4.884516e-04, l1: 0.60532, l2: 0.32053\n",
            "Loss: 4.885885e-04, l1: 0.60986, l2: 0.32059\n",
            "Loss: 4.873404e-04, l1: 0.60764, l2: 0.32056\n",
            "Loss: 4.844627e-04, l1: 0.60959, l2: 0.32048\n",
            "Loss: 4.822988e-04, l1: 0.60913, l2: 0.31985\n",
            "Loss: 4.802553e-04, l1: 0.60693, l2: 0.31905\n",
            "Loss: 4.803030e-04, l1: 0.60921, l2: 0.31865\n",
            "Loss: 4.795544e-04, l1: 0.60808, l2: 0.31885\n",
            "Loss: 4.787151e-04, l1: 0.60965, l2: 0.31881\n",
            "Loss: 4.777079e-04, l1: 0.61019, l2: 0.31834\n",
            "Loss: 4.767223e-04, l1: 0.61126, l2: 0.31825\n",
            "Loss: 4.759505e-04, l1: 0.61268, l2: 0.31845\n",
            "Loss: 4.752301e-04, l1: 0.61312, l2: 0.31889\n",
            "Loss: 4.746380e-04, l1: 0.61422, l2: 0.31920\n",
            "Loss: 4.743302e-04, l1: 0.61516, l2: 0.31892\n",
            "Loss: 4.741116e-04, l1: 0.61550, l2: 0.31831\n",
            "Loss: 4.738455e-04, l1: 0.61598, l2: 0.31825\n",
            "Loss: 4.735177e-04, l1: 0.61680, l2: 0.31802\n",
            "Loss: 4.731142e-04, l1: 0.61730, l2: 0.31798\n",
            "Loss: 4.726575e-04, l1: 0.61865, l2: 0.31807\n",
            "Loss: 4.719757e-04, l1: 0.62104, l2: 0.31837\n",
            "Loss: 4.710800e-04, l1: 0.62312, l2: 0.31888\n",
            "Loss: 4.695648e-04, l1: 0.62692, l2: 0.32015\n",
            "Loss: 4.665887e-04, l1: 0.63151, l2: 0.32139\n",
            "Loss: 4.627469e-04, l1: 0.63775, l2: 0.32310\n",
            "Loss: 4.638603e-04, l1: 0.63644, l2: 0.32348\n",
            "Loss: 4.610993e-04, l1: 0.63718, l2: 0.32327\n",
            "Loss: 4.590160e-04, l1: 0.63955, l2: 0.32316\n",
            "Loss: 4.577342e-04, l1: 0.63807, l2: 0.32250\n",
            "Loss: 4.562014e-04, l1: 0.63529, l2: 0.32135\n",
            "Loss: 4.548890e-04, l1: 0.63440, l2: 0.32108\n",
            "Loss: 4.532326e-04, l1: 0.63372, l2: 0.32059\n",
            "Loss: 4.519635e-04, l1: 0.63359, l2: 0.32042\n",
            "Loss: 4.509955e-04, l1: 0.63427, l2: 0.32052\n",
            "Loss: 4.503831e-04, l1: 0.63399, l2: 0.32020\n",
            "Loss: 4.503065e-04, l1: 0.63361, l2: 0.32017\n",
            "Loss: 4.497182e-04, l1: 0.63283, l2: 0.31995\n",
            "Loss: 4.492973e-04, l1: 0.63215, l2: 0.31975\n",
            "Loss: 4.486604e-04, l1: 0.63101, l2: 0.31946\n",
            "Loss: 4.479739e-04, l1: 0.63052, l2: 0.31925\n",
            "Loss: 4.465093e-04, l1: 0.63020, l2: 0.31907\n",
            "Loss: 4.441336e-04, l1: 0.63057, l2: 0.31881\n",
            "Loss: 4.413743e-04, l1: 0.63293, l2: 0.31872\n",
            "Loss: 4.361488e-04, l1: 0.63617, l2: 0.31838\n",
            "Loss: 4.358872e-04, l1: 0.64471, l2: 0.31812\n",
            "Loss: 4.336335e-04, l1: 0.63936, l2: 0.31829\n",
            "Loss: 4.427430e-04, l1: 0.65328, l2: 0.31796\n",
            "Loss: 4.302591e-04, l1: 0.64435, l2: 0.31817\n",
            "Loss: 4.322167e-04, l1: 0.65263, l2: 0.31696\n",
            "Loss: 4.263192e-04, l1: 0.64828, l2: 0.31759\n",
            "Loss: 4.228867e-04, l1: 0.65172, l2: 0.31698\n",
            "Loss: 4.202022e-04, l1: 0.66278, l2: 0.31780\n",
            "Loss: 4.171438e-04, l1: 0.65690, l2: 0.31736\n",
            "Loss: 4.225061e-04, l1: 0.66715, l2: 0.31847\n",
            "Loss: 4.146342e-04, l1: 0.66075, l2: 0.31778\n",
            "Loss: 4.118495e-04, l1: 0.66178, l2: 0.31888\n",
            "Loss: 4.085443e-04, l1: 0.66375, l2: 0.31968\n",
            "Loss: 4.042002e-04, l1: 0.66987, l2: 0.32082\n",
            "Loss: 4.020302e-04, l1: 0.67509, l2: 0.32113\n",
            "Loss: 4.005728e-04, l1: 0.67233, l2: 0.31895\n",
            "Loss: 3.968808e-04, l1: 0.67588, l2: 0.31872\n",
            "Loss: 4.003830e-04, l1: 0.67810, l2: 0.31950\n",
            "Loss: 3.960153e-04, l1: 0.67655, l2: 0.31896\n",
            "Loss: 3.947699e-04, l1: 0.68106, l2: 0.31930\n",
            "Loss: 3.939906e-04, l1: 0.68358, l2: 0.31960\n",
            "Loss: 3.926669e-04, l1: 0.68564, l2: 0.31965\n",
            "Loss: 3.921247e-04, l1: 0.68672, l2: 0.31987\n",
            "Loss: 3.918191e-04, l1: 0.68803, l2: 0.32018\n",
            "Loss: 3.916422e-04, l1: 0.68845, l2: 0.32010\n",
            "Loss: 3.915172e-04, l1: 0.68827, l2: 0.31990\n",
            "Loss: 3.912611e-04, l1: 0.68832, l2: 0.31944\n",
            "Loss: 3.909764e-04, l1: 0.68764, l2: 0.31906\n",
            "Loss: 3.907874e-04, l1: 0.68581, l2: 0.31787\n",
            "Loss: 3.898040e-04, l1: 0.68664, l2: 0.31851\n",
            "Loss: 3.891125e-04, l1: 0.68742, l2: 0.31925\n",
            "Loss: 3.882049e-04, l1: 0.68692, l2: 0.31958\n",
            "Loss: 3.867069e-04, l1: 0.68694, l2: 0.31956\n",
            "Loss: 3.838267e-04, l1: 0.68707, l2: 0.31915\n",
            "Loss: 3.814715e-04, l1: 0.68568, l2: 0.31832\n",
            "Loss: 3.793114e-04, l1: 0.68789, l2: 0.31756\n",
            "Loss: 3.769512e-04, l1: 0.68814, l2: 0.31766\n",
            "Loss: 3.750395e-04, l1: 0.68947, l2: 0.31784\n",
            "Loss: 3.718537e-04, l1: 0.69110, l2: 0.31841\n",
            "Loss: 3.697246e-04, l1: 0.68659, l2: 0.31800\n",
            "Loss: 3.681997e-04, l1: 0.68655, l2: 0.31831\n",
            "Loss: 3.668401e-04, l1: 0.68464, l2: 0.31740\n",
            "Loss: 3.656266e-04, l1: 0.68227, l2: 0.31667\n",
            "Loss: 3.646571e-04, l1: 0.68073, l2: 0.31630\n",
            "Loss: 3.630209e-04, l1: 0.67782, l2: 0.31597\n",
            "Loss: 3.621450e-04, l1: 0.67752, l2: 0.31640\n",
            "Loss: 3.617120e-04, l1: 0.67822, l2: 0.31698\n",
            "Loss: 3.615039e-04, l1: 0.67973, l2: 0.31738\n",
            "Loss: 3.612987e-04, l1: 0.68045, l2: 0.31778\n",
            "Loss: 3.611582e-04, l1: 0.68048, l2: 0.31789\n",
            "Loss: 3.610270e-04, l1: 0.68034, l2: 0.31789\n",
            "Loss: 3.609423e-04, l1: 0.68012, l2: 0.31790\n",
            "Loss: 3.608393e-04, l1: 0.67961, l2: 0.31793\n",
            "Loss: 3.605865e-04, l1: 0.67885, l2: 0.31808\n",
            "Loss: 3.601925e-04, l1: 0.67743, l2: 0.31811\n",
            "Loss: 3.593627e-04, l1: 0.67544, l2: 0.31841\n",
            "Loss: 3.579686e-04, l1: 0.67231, l2: 0.31859\n",
            "Loss: 3.559462e-04, l1: 0.67049, l2: 0.31878\n",
            "Loss: 3.505256e-04, l1: 0.66751, l2: 0.31941\n",
            "Loss: 3.894893e-04, l1: 0.65976, l2: 0.32011\n",
            "Loss: 3.490286e-04, l1: 0.66609, l2: 0.31954\n",
            "Loss: 3.465973e-04, l1: 0.66795, l2: 0.31990\n",
            "Loss: 3.502514e-04, l1: 0.65993, l2: 0.31947\n",
            "Loss: 3.444155e-04, l1: 0.66481, l2: 0.31973\n",
            "Loss: 3.437079e-04, l1: 0.66376, l2: 0.31963\n",
            "Loss: 3.430270e-04, l1: 0.66416, l2: 0.31949\n",
            "Loss: 3.428141e-04, l1: 0.66444, l2: 0.31994\n",
            "Loss: 3.424351e-04, l1: 0.66387, l2: 0.31988\n",
            "Loss: 3.420313e-04, l1: 0.66396, l2: 0.31987\n",
            "Loss: 3.414207e-04, l1: 0.66398, l2: 0.32017\n",
            "Loss: 3.399024e-04, l1: 0.66327, l2: 0.32088\n",
            "Loss: 3.384793e-04, l1: 0.66279, l2: 0.32135\n",
            "Loss: 3.363608e-04, l1: 0.66226, l2: 0.32167\n",
            "Loss: 3.341360e-04, l1: 0.66217, l2: 0.32189\n",
            "Loss: 3.330610e-04, l1: 0.66208, l2: 0.32179\n",
            "Loss: 3.316922e-04, l1: 0.66271, l2: 0.32125\n",
            "Loss: 3.318527e-04, l1: 0.65873, l2: 0.32066\n",
            "Loss: 3.304289e-04, l1: 0.66076, l2: 0.32096\n",
            "Loss: 3.288623e-04, l1: 0.66293, l2: 0.32052\n",
            "Loss: 3.273472e-04, l1: 0.66470, l2: 0.32008\n",
            "Loss: 3.249324e-04, l1: 0.66777, l2: 0.31954\n",
            "Loss: 3.219730e-04, l1: 0.67075, l2: 0.31889\n",
            "Loss: 3.191726e-04, l1: 0.67356, l2: 0.31931\n",
            "Loss: 3.174490e-04, l1: 0.67316, l2: 0.31957\n",
            "Loss: 3.179790e-04, l1: 0.67288, l2: 0.32051\n",
            "Loss: 3.165892e-04, l1: 0.67304, l2: 0.31999\n",
            "Loss: 3.199048e-04, l1: 0.67462, l2: 0.32139\n",
            "Loss: 3.158436e-04, l1: 0.67352, l2: 0.32042\n",
            "Loss: 3.148915e-04, l1: 0.67319, l2: 0.32082\n",
            "Loss: 3.140769e-04, l1: 0.67146, l2: 0.32097\n",
            "Loss: 3.126199e-04, l1: 0.66873, l2: 0.32131\n",
            "Loss: 3.111170e-04, l1: 0.66612, l2: 0.32112\n",
            "Loss: 3.089699e-04, l1: 0.66230, l2: 0.32051\n",
            "Loss: 3.058316e-04, l1: 0.65908, l2: 0.31877\n",
            "Loss: 3.031213e-04, l1: 0.65640, l2: 0.31663\n",
            "Loss: 3.047753e-04, l1: 0.65212, l2: 0.31420\n",
            "Loss: 3.016786e-04, l1: 0.65465, l2: 0.31563\n",
            "Loss: 3.019646e-04, l1: 0.65416, l2: 0.31488\n",
            "Loss: 3.010682e-04, l1: 0.65442, l2: 0.31528\n",
            "Loss: 2.999356e-04, l1: 0.65427, l2: 0.31445\n",
            "Loss: 2.985125e-04, l1: 0.65096, l2: 0.31459\n",
            "Loss: 2.977199e-04, l1: 0.65049, l2: 0.31514\n",
            "Loss: 2.964611e-04, l1: 0.65010, l2: 0.31592\n",
            "Loss: 2.952890e-04, l1: 0.64884, l2: 0.31616\n",
            "Loss: 2.944973e-04, l1: 0.64792, l2: 0.31597\n",
            "Loss: 2.939347e-04, l1: 0.64692, l2: 0.31561\n",
            "Loss: 2.937177e-04, l1: 0.64696, l2: 0.31544\n",
            "Loss: 2.934875e-04, l1: 0.64598, l2: 0.31518\n",
            "Loss: 2.931636e-04, l1: 0.64679, l2: 0.31536\n",
            "Loss: 2.928347e-04, l1: 0.64794, l2: 0.31580\n",
            "Loss: 2.921646e-04, l1: 0.64832, l2: 0.31604\n",
            "Loss: 2.913904e-04, l1: 0.64792, l2: 0.31593\n",
            "Loss: 2.907262e-04, l1: 0.64756, l2: 0.31610\n",
            "Loss: 2.899560e-04, l1: 0.64679, l2: 0.31599\n",
            "Loss: 2.890787e-04, l1: 0.64659, l2: 0.31601\n",
            "Loss: 2.873167e-04, l1: 0.64585, l2: 0.31634\n",
            "Loss: 2.864432e-04, l1: 0.64582, l2: 0.31643\n",
            "Loss: 2.847413e-04, l1: 0.64823, l2: 0.31694\n",
            "Loss: 2.837317e-04, l1: 0.64695, l2: 0.31728\n",
            "Loss: 2.831980e-04, l1: 0.64811, l2: 0.31754\n",
            "Loss: 2.827456e-04, l1: 0.64884, l2: 0.31768\n",
            "Loss: 2.815687e-04, l1: 0.64979, l2: 0.31768\n",
            "Loss: 2.810388e-04, l1: 0.65167, l2: 0.31710\n",
            "Loss: 2.794565e-04, l1: 0.65162, l2: 0.31676\n",
            "Loss: 2.789723e-04, l1: 0.65106, l2: 0.31664\n",
            "Loss: 2.780902e-04, l1: 0.65086, l2: 0.31629\n",
            "Loss: 2.763489e-04, l1: 0.65150, l2: 0.31591\n",
            "Loss: 2.753005e-04, l1: 0.65399, l2: 0.31582\n",
            "Loss: 2.731188e-04, l1: 0.65495, l2: 0.31606\n",
            "Loss: 2.722421e-04, l1: 0.65684, l2: 0.31659\n",
            "Loss: 2.715121e-04, l1: 0.65824, l2: 0.31712\n",
            "Loss: 2.702761e-04, l1: 0.65935, l2: 0.31742\n",
            "Loss: 2.683872e-04, l1: 0.66085, l2: 0.31787\n",
            "Loss: 2.665220e-04, l1: 0.65849, l2: 0.31737\n",
            "Loss: 2.650048e-04, l1: 0.65739, l2: 0.31690\n",
            "Loss: 2.630919e-04, l1: 0.65425, l2: 0.31622\n",
            "Loss: 2.617820e-04, l1: 0.65136, l2: 0.31600\n",
            "Loss: 2.600924e-04, l1: 0.64857, l2: 0.31594\n",
            "Loss: 2.590782e-04, l1: 0.64657, l2: 0.31606\n",
            "Loss: 2.580357e-04, l1: 0.64701, l2: 0.31620\n",
            "Loss: 2.574185e-04, l1: 0.64677, l2: 0.31611\n",
            "Loss: 2.567708e-04, l1: 0.64679, l2: 0.31585\n",
            "Loss: 2.563417e-04, l1: 0.64700, l2: 0.31551\n",
            "Loss: 2.558546e-04, l1: 0.64661, l2: 0.31559\n",
            "Loss: 2.553072e-04, l1: 0.64646, l2: 0.31602\n",
            "Loss: 2.548863e-04, l1: 0.64599, l2: 0.31648\n",
            "Loss: 2.543143e-04, l1: 0.64579, l2: 0.31717\n",
            "Loss: 2.537813e-04, l1: 0.64490, l2: 0.31759\n",
            "Loss: 2.532103e-04, l1: 0.64403, l2: 0.31764\n",
            "Loss: 2.527196e-04, l1: 0.64261, l2: 0.31719\n",
            "Loss: 2.523595e-04, l1: 0.64253, l2: 0.31663\n",
            "Loss: 2.519913e-04, l1: 0.64267, l2: 0.31620\n",
            "Loss: 2.515738e-04, l1: 0.64328, l2: 0.31595\n",
            "Loss: 2.510598e-04, l1: 0.64408, l2: 0.31621\n",
            "Loss: 2.506609e-04, l1: 0.64467, l2: 0.31629\n",
            "Loss: 2.502833e-04, l1: 0.64395, l2: 0.31634\n",
            "Loss: 2.499460e-04, l1: 0.64271, l2: 0.31660\n",
            "Loss: 2.496241e-04, l1: 0.64214, l2: 0.31664\n",
            "Loss: 2.490732e-04, l1: 0.64151, l2: 0.31623\n",
            "Loss: 2.487473e-04, l1: 0.64150, l2: 0.31604\n",
            "Loss: 2.481650e-04, l1: 0.64184, l2: 0.31591\n",
            "Loss: 2.472000e-04, l1: 0.64260, l2: 0.31546\n",
            "Loss: 2.461342e-04, l1: 0.64283, l2: 0.31543\n",
            "Loss: 2.448348e-04, l1: 0.64235, l2: 0.31573\n",
            "Loss: 2.436656e-04, l1: 0.64177, l2: 0.31605\n",
            "Loss: 2.438314e-04, l1: 0.63964, l2: 0.31685\n",
            "Loss: 2.429241e-04, l1: 0.64076, l2: 0.31643\n",
            "Loss: 2.417185e-04, l1: 0.64087, l2: 0.31681\n",
            "Loss: 2.379332e-04, l1: 0.64136, l2: 0.31782\n",
            "Loss: 2.349514e-04, l1: 0.64131, l2: 0.31842\n",
            "Loss: 2.317628e-04, l1: 0.64203, l2: 0.31856\n",
            "Loss: 2.280758e-04, l1: 0.64192, l2: 0.31838\n",
            "Loss: 2.240989e-04, l1: 0.64101, l2: 0.31742\n",
            "Loss: 2.257739e-04, l1: 0.64454, l2: 0.31616\n",
            "Loss: 2.220665e-04, l1: 0.64253, l2: 0.31688\n",
            "Loss: 2.195190e-04, l1: 0.64215, l2: 0.31614\n",
            "Loss: 2.174298e-04, l1: 0.64131, l2: 0.31551\n",
            "Loss: 2.166341e-04, l1: 0.64176, l2: 0.31522\n",
            "Loss: 2.163815e-04, l1: 0.64121, l2: 0.31534\n",
            "Loss: 2.154429e-04, l1: 0.64148, l2: 0.31528\n",
            "Loss: 2.144496e-04, l1: 0.63970, l2: 0.31499\n",
            "Loss: 2.137396e-04, l1: 0.63992, l2: 0.31469\n",
            "Loss: 2.131525e-04, l1: 0.63841, l2: 0.31443\n",
            "Loss: 2.131030e-04, l1: 0.63839, l2: 0.31428\n",
            "Loss: 2.129126e-04, l1: 0.63840, l2: 0.31435\n",
            "Loss: 2.125957e-04, l1: 0.63758, l2: 0.31427\n",
            "Loss: 2.124227e-04, l1: 0.63775, l2: 0.31447\n",
            "Loss: 2.121849e-04, l1: 0.63780, l2: 0.31473\n",
            "Loss: 2.117766e-04, l1: 0.63751, l2: 0.31493\n",
            "Loss: 2.110967e-04, l1: 0.63654, l2: 0.31494\n",
            "Loss: 2.183986e-04, l1: 0.63108, l2: 0.31472\n",
            "Loss: 2.108454e-04, l1: 0.63570, l2: 0.31490\n",
            "Loss: 2.101375e-04, l1: 0.63450, l2: 0.31442\n",
            "Loss: 2.095379e-04, l1: 0.63122, l2: 0.31325\n",
            "Loss: 2.092514e-04, l1: 0.63006, l2: 0.31263\n",
            "Loss: 2.087615e-04, l1: 0.63012, l2: 0.31270\n",
            "Loss: 2.084945e-04, l1: 0.62971, l2: 0.31286\n",
            "Loss: 2.082458e-04, l1: 0.62927, l2: 0.31276\n",
            "Loss: 2.078975e-04, l1: 0.62898, l2: 0.31274\n",
            "Loss: 2.074861e-04, l1: 0.62916, l2: 0.31297\n",
            "Loss: 2.071098e-04, l1: 0.62942, l2: 0.31302\n",
            "Loss: 2.064551e-04, l1: 0.63004, l2: 0.31330\n",
            "Loss: 2.056404e-04, l1: 0.63075, l2: 0.31378\n",
            "Loss: 2.050060e-04, l1: 0.63091, l2: 0.31393\n",
            "Loss: 2.044956e-04, l1: 0.63070, l2: 0.31398\n",
            "Loss: 2.040921e-04, l1: 0.63078, l2: 0.31399\n",
            "Loss: 2.035517e-04, l1: 0.63139, l2: 0.31413\n",
            "Loss: 2.030571e-04, l1: 0.63225, l2: 0.31429\n",
            "Loss: 2.027484e-04, l1: 0.63301, l2: 0.31433\n",
            "Loss: 2.024310e-04, l1: 0.63337, l2: 0.31449\n",
            "Loss: 2.021865e-04, l1: 0.63369, l2: 0.31463\n",
            "Loss: 2.018884e-04, l1: 0.63357, l2: 0.31479\n",
            "Loss: 2.016954e-04, l1: 0.63284, l2: 0.31470\n",
            "Loss: 2.016106e-04, l1: 0.63278, l2: 0.31484\n",
            "Loss: 2.015466e-04, l1: 0.63240, l2: 0.31475\n",
            "Loss: 2.014970e-04, l1: 0.63246, l2: 0.31469\n",
            "Loss: 2.013983e-04, l1: 0.63277, l2: 0.31473\n",
            "Loss: 2.012708e-04, l1: 0.63321, l2: 0.31468\n",
            "Loss: 2.011341e-04, l1: 0.63395, l2: 0.31478\n",
            "Loss: 2.010261e-04, l1: 0.63450, l2: 0.31484\n",
            "Loss: 2.009319e-04, l1: 0.63499, l2: 0.31495\n",
            "Loss: 2.008425e-04, l1: 0.63556, l2: 0.31503\n",
            "Loss: 2.007971e-04, l1: 0.63565, l2: 0.31503\n",
            "Loss: 2.007422e-04, l1: 0.63690, l2: 0.31506\n",
            "Loss: 2.006359e-04, l1: 0.63634, l2: 0.31498\n",
            "Loss: 2.005590e-04, l1: 0.63611, l2: 0.31488\n",
            "Loss: 2.003911e-04, l1: 0.63588, l2: 0.31470\n",
            "Loss: 2.001994e-04, l1: 0.63596, l2: 0.31454\n",
            "Loss: 2.000282e-04, l1: 0.63560, l2: 0.31430\n",
            "Loss: 2.029778e-04, l1: 0.63670, l2: 0.31343\n",
            "Loss: 1.998375e-04, l1: 0.63582, l2: 0.31413\n",
            "Loss: 1.995324e-04, l1: 0.63565, l2: 0.31421\n",
            "Loss: 1.992472e-04, l1: 0.63561, l2: 0.31434\n",
            "Loss: 1.990920e-04, l1: 0.63546, l2: 0.31430\n",
            "Loss: 1.988441e-04, l1: 0.63584, l2: 0.31445\n",
            "Loss: 1.985852e-04, l1: 0.63525, l2: 0.31429\n",
            "Loss: 1.983046e-04, l1: 0.63505, l2: 0.31431\n",
            "Loss: 1.980390e-04, l1: 0.63499, l2: 0.31438\n",
            "Loss: 1.982017e-04, l1: 0.63759, l2: 0.31478\n",
            "Loss: 1.977792e-04, l1: 0.63613, l2: 0.31456\n",
            "Loss: 1.973446e-04, l1: 0.63668, l2: 0.31478\n",
            "Loss: 1.967394e-04, l1: 0.63798, l2: 0.31523\n",
            "Loss: 1.961758e-04, l1: 0.63899, l2: 0.31552\n",
            "Loss: 1.950664e-04, l1: 0.64044, l2: 0.31584\n",
            "Loss: 1.933065e-04, l1: 0.64178, l2: 0.31601\n",
            "Loss: 1.900104e-04, l1: 0.64262, l2: 0.31615\n",
            "Loss: 1.911336e-04, l1: 0.64096, l2: 0.31566\n",
            "Loss: 1.879481e-04, l1: 0.64188, l2: 0.31593\n",
            "Loss: 1.862936e-04, l1: 0.63986, l2: 0.31488\n",
            "Loss: 1.853023e-04, l1: 0.64092, l2: 0.31543\n",
            "Loss: 1.883322e-04, l1: 0.63587, l2: 0.31406\n",
            "Loss: 1.827793e-04, l1: 0.63880, l2: 0.31486\n",
            "Loss: 1.806619e-04, l1: 0.63684, l2: 0.31387\n",
            "Loss: 1.784102e-04, l1: 0.63779, l2: 0.31428\n",
            "Loss: 1.781984e-04, l1: 0.63841, l2: 0.31450\n",
            "Loss: 1.775665e-04, l1: 0.63809, l2: 0.31439\n",
            "Loss: 1.766184e-04, l1: 0.63782, l2: 0.31494\n",
            "Loss: 1.757828e-04, l1: 0.63906, l2: 0.31578\n",
            "Loss: 1.751164e-04, l1: 0.63763, l2: 0.31560\n",
            "Loss: 1.746880e-04, l1: 0.63690, l2: 0.31567\n",
            "Loss: 1.742915e-04, l1: 0.63704, l2: 0.31599\n",
            "Loss: 1.739885e-04, l1: 0.63765, l2: 0.31638\n",
            "Loss: 1.737073e-04, l1: 0.63734, l2: 0.31630\n",
            "Loss: 1.732854e-04, l1: 0.63721, l2: 0.31653\n",
            "Loss: 1.729722e-04, l1: 0.63729, l2: 0.31575\n",
            "Loss: 1.727818e-04, l1: 0.63700, l2: 0.31567\n",
            "Loss: 1.727227e-04, l1: 0.63696, l2: 0.31572\n",
            "Loss: 1.725656e-04, l1: 0.63742, l2: 0.31579\n",
            "Loss: 1.723493e-04, l1: 0.63806, l2: 0.31580\n",
            "Loss: 1.719430e-04, l1: 0.63863, l2: 0.31552\n",
            "Loss: 1.715910e-04, l1: 0.63917, l2: 0.31521\n",
            "Loss: 1.713098e-04, l1: 0.63978, l2: 0.31489\n",
            "Loss: 1.711300e-04, l1: 0.63983, l2: 0.31447\n",
            "Loss: 1.709538e-04, l1: 0.63988, l2: 0.31441\n",
            "Loss: 1.707179e-04, l1: 0.63983, l2: 0.31431\n",
            "Loss: 1.705195e-04, l1: 0.63999, l2: 0.31425\n",
            "Loss: 1.704860e-04, l1: 0.64001, l2: 0.31435\n",
            "Loss: 1.702768e-04, l1: 0.63981, l2: 0.31430\n",
            "Loss: 1.701786e-04, l1: 0.63978, l2: 0.31426\n",
            "Loss: 1.700203e-04, l1: 0.63953, l2: 0.31427\n",
            "Loss: 1.698576e-04, l1: 0.63944, l2: 0.31425\n",
            "Loss: 1.696075e-04, l1: 0.63915, l2: 0.31432\n",
            "Loss: 1.694553e-04, l1: 0.63874, l2: 0.31428\n",
            "Loss: 1.692252e-04, l1: 0.63865, l2: 0.31429\n",
            "Loss: 1.690796e-04, l1: 0.63840, l2: 0.31432\n",
            "Loss: 1.688083e-04, l1: 0.63806, l2: 0.31424\n",
            "Loss: 1.685264e-04, l1: 0.63763, l2: 0.31431\n",
            "Loss: 1.682395e-04, l1: 0.63780, l2: 0.31437\n",
            "Loss: 1.678828e-04, l1: 0.63744, l2: 0.31459\n",
            "Loss: 1.676312e-04, l1: 0.63698, l2: 0.31480\n",
            "Loss: 1.674080e-04, l1: 0.63729, l2: 0.31487\n",
            "Loss: 1.672634e-04, l1: 0.63727, l2: 0.31488\n",
            "Loss: 1.670797e-04, l1: 0.63751, l2: 0.31495\n",
            "Loss: 1.668976e-04, l1: 0.63744, l2: 0.31497\n",
            "Loss: 1.666441e-04, l1: 0.63761, l2: 0.31501\n",
            "Loss: 1.664451e-04, l1: 0.63715, l2: 0.31499\n",
            "Loss: 1.662427e-04, l1: 0.63758, l2: 0.31508\n",
            "Loss: 1.661097e-04, l1: 0.63747, l2: 0.31506\n",
            "Loss: 1.659393e-04, l1: 0.63741, l2: 0.31490\n",
            "Loss: 1.656615e-04, l1: 0.63721, l2: 0.31483\n",
            "Loss: 1.652148e-04, l1: 0.63678, l2: 0.31467\n",
            "Loss: 1.649216e-04, l1: 0.63659, l2: 0.31466\n",
            "Loss: 1.646578e-04, l1: 0.63607, l2: 0.31473\n",
            "Loss: 1.643259e-04, l1: 0.63569, l2: 0.31492\n",
            "Loss: 1.639536e-04, l1: 0.63532, l2: 0.31516\n",
            "Loss: 1.636471e-04, l1: 0.63533, l2: 0.31547\n",
            "Loss: 1.632498e-04, l1: 0.63540, l2: 0.31580\n",
            "Loss: 1.629238e-04, l1: 0.63623, l2: 0.31599\n",
            "Loss: 1.626078e-04, l1: 0.63633, l2: 0.31578\n",
            "Loss: 1.624102e-04, l1: 0.63662, l2: 0.31556\n",
            "Loss: 1.622325e-04, l1: 0.63723, l2: 0.31535\n",
            "Loss: 1.620200e-04, l1: 0.63767, l2: 0.31533\n",
            "Loss: 1.617084e-04, l1: 0.63794, l2: 0.31547\n",
            "Loss: 1.613703e-04, l1: 0.63793, l2: 0.31593\n",
            "Loss: 1.629020e-04, l1: 0.63760, l2: 0.31575\n",
            "Loss: 1.612273e-04, l1: 0.63785, l2: 0.31589\n",
            "Loss: 1.609597e-04, l1: 0.63630, l2: 0.31558\n",
            "Loss: 1.606586e-04, l1: 0.63611, l2: 0.31542\n",
            "Loss: 1.607796e-04, l1: 0.63676, l2: 0.31501\n",
            "Loss: 1.603118e-04, l1: 0.63641, l2: 0.31523\n",
            "Loss: 1.600911e-04, l1: 0.63588, l2: 0.31516\n",
            "Loss: 1.599932e-04, l1: 0.63577, l2: 0.31518\n",
            "Loss: 1.598440e-04, l1: 0.63583, l2: 0.31525\n",
            "Loss: 1.596456e-04, l1: 0.63621, l2: 0.31536\n",
            "Loss: 1.592900e-04, l1: 0.63706, l2: 0.31556\n",
            "Loss: 1.589860e-04, l1: 0.63811, l2: 0.31580\n",
            "Loss: 1.587787e-04, l1: 0.63812, l2: 0.31558\n",
            "Loss: 1.586845e-04, l1: 0.63816, l2: 0.31540\n",
            "Loss: 1.586225e-04, l1: 0.63824, l2: 0.31538\n",
            "Loss: 1.585000e-04, l1: 0.63829, l2: 0.31544\n",
            "Loss: 1.585433e-04, l1: 0.63910, l2: 0.31558\n",
            "Loss: 1.584259e-04, l1: 0.63865, l2: 0.31550\n",
            "Loss: 1.582809e-04, l1: 0.63869, l2: 0.31564\n",
            "Loss: 1.581402e-04, l1: 0.63897, l2: 0.31580\n",
            "Loss: 1.580350e-04, l1: 0.63935, l2: 0.31586\n",
            "Loss: 1.579281e-04, l1: 0.63984, l2: 0.31588\n",
            "Loss: 1.577589e-04, l1: 0.64041, l2: 0.31590\n",
            "Loss: 1.574566e-04, l1: 0.64114, l2: 0.31596\n",
            "Loss: 1.570659e-04, l1: 0.64170, l2: 0.31619\n",
            "Loss: 1.567502e-04, l1: 0.64149, l2: 0.31646\n",
            "Loss: 1.563868e-04, l1: 0.64106, l2: 0.31673\n",
            "Loss: 1.560556e-04, l1: 0.64018, l2: 0.31657\n",
            "Loss: 1.557663e-04, l1: 0.63964, l2: 0.31667\n",
            "Loss: 1.554400e-04, l1: 0.63891, l2: 0.31696\n",
            "Loss: 1.550952e-04, l1: 0.63805, l2: 0.31735\n",
            "Loss: 1.548343e-04, l1: 0.63777, l2: 0.31756\n",
            "Loss: 1.544656e-04, l1: 0.63760, l2: 0.31772\n",
            "Loss: 1.545684e-04, l1: 0.63476, l2: 0.31810\n",
            "Loss: 1.540295e-04, l1: 0.63623, l2: 0.31790\n",
            "Loss: 1.533958e-04, l1: 0.63637, l2: 0.31773\n",
            "Loss: 1.525837e-04, l1: 0.63487, l2: 0.31656\n",
            "Loss: 1.537740e-04, l1: 0.63545, l2: 0.31744\n",
            "Loss: 1.522073e-04, l1: 0.63506, l2: 0.31685\n",
            "Loss: 1.516710e-04, l1: 0.63326, l2: 0.31671\n",
            "Loss: 1.504567e-04, l1: 0.62794, l2: 0.31628\n",
            "Loss: 1.494266e-04, l1: 0.62508, l2: 0.31603\n",
            "Loss: 1.483571e-04, l1: 0.61757, l2: 0.31561\n",
            "Loss: 1.467199e-04, l1: 0.61900, l2: 0.31568\n",
            "Loss: 1.460203e-04, l1: 0.61725, l2: 0.31537\n",
            "Loss: 1.456614e-04, l1: 0.61481, l2: 0.31460\n",
            "Loss: 1.454147e-04, l1: 0.61514, l2: 0.31491\n",
            "Loss: 1.452547e-04, l1: 0.61466, l2: 0.31518\n",
            "Loss: 1.450714e-04, l1: 0.61535, l2: 0.31507\n",
            "Loss: 1.449518e-04, l1: 0.61554, l2: 0.31487\n",
            "Loss: 1.448304e-04, l1: 0.61503, l2: 0.31459\n",
            "Loss: 1.447710e-04, l1: 0.61487, l2: 0.31452\n",
            "Loss: 1.446991e-04, l1: 0.61430, l2: 0.31450\n",
            "Loss: 1.446231e-04, l1: 0.61379, l2: 0.31453\n",
            "Loss: 1.445400e-04, l1: 0.61258, l2: 0.31464\n",
            "Loss: 1.444814e-04, l1: 0.61184, l2: 0.31460\n",
            "Loss: 1.444489e-04, l1: 0.61191, l2: 0.31460\n",
            "Loss: 1.444294e-04, l1: 0.61157, l2: 0.31457\n",
            "Loss: 1.443954e-04, l1: 0.61140, l2: 0.31453\n",
            "Loss: 1.443366e-04, l1: 0.61119, l2: 0.31445\n",
            "Loss: 1.442251e-04, l1: 0.61069, l2: 0.31418\n",
            "Loss: 1.441681e-04, l1: 0.61025, l2: 0.31422\n",
            "Loss: 1.439538e-04, l1: 0.61023, l2: 0.31396\n",
            "Loss: 1.438101e-04, l1: 0.61034, l2: 0.31380\n",
            "Loss: 1.436341e-04, l1: 0.61013, l2: 0.31370\n",
            "Loss: 1.433995e-04, l1: 0.60996, l2: 0.31367\n",
            "Loss: 1.431068e-04, l1: 0.60919, l2: 0.31385\n",
            "Loss: 1.428461e-04, l1: 0.60874, l2: 0.31405\n",
            "Loss: 1.426105e-04, l1: 0.60786, l2: 0.31435\n",
            "Loss: 1.422177e-04, l1: 0.60785, l2: 0.31453\n",
            "Loss: 1.419886e-04, l1: 0.60582, l2: 0.31441\n",
            "Loss: 1.416424e-04, l1: 0.60680, l2: 0.31431\n",
            "Loss: 1.414891e-04, l1: 0.60601, l2: 0.31433\n",
            "Loss: 1.413010e-04, l1: 0.60539, l2: 0.31424\n",
            "Loss: 1.410091e-04, l1: 0.60356, l2: 0.31401\n",
            "Loss: 1.406411e-04, l1: 0.60153, l2: 0.31385\n",
            "Loss: 1.401514e-04, l1: 0.59665, l2: 0.31352\n",
            "Loss: 1.394228e-04, l1: 0.59428, l2: 0.31339\n",
            "Loss: 1.393475e-04, l1: 0.58898, l2: 0.31336\n",
            "Loss: 1.390444e-04, l1: 0.59195, l2: 0.31338\n",
            "Loss: 1.384091e-04, l1: 0.58763, l2: 0.31361\n",
            "Loss: 1.377538e-04, l1: 0.58705, l2: 0.31378\n",
            "Loss: 1.371486e-04, l1: 0.58655, l2: 0.31359\n",
            "Loss: 1.371474e-04, l1: 0.57992, l2: 0.31287\n",
            "Loss: 1.366269e-04, l1: 0.58310, l2: 0.31322\n",
            "Loss: 1.356832e-04, l1: 0.58020, l2: 0.31249\n",
            "Loss: 1.351712e-04, l1: 0.57776, l2: 0.31209\n",
            "Loss: 1.346262e-04, l1: 0.57594, l2: 0.31223\n",
            "Loss: 1.342661e-04, l1: 0.57605, l2: 0.31254\n",
            "Loss: 1.335190e-04, l1: 0.57297, l2: 0.31274\n",
            "Loss: 1.324756e-04, l1: 0.57358, l2: 0.31280\n",
            "Loss: 1.309106e-04, l1: 0.57208, l2: 0.31287\n",
            "Loss: 1.298368e-04, l1: 0.57025, l2: 0.31253\n",
            "Loss: 1.285728e-04, l1: 0.56598, l2: 0.31204\n",
            "Loss: 1.277375e-04, l1: 0.56694, l2: 0.31206\n",
            "Loss: 1.252819e-04, l1: 0.56757, l2: 0.31276\n",
            "Loss: 1.241319e-04, l1: 0.56751, l2: 0.31254\n",
            "Loss: 1.232213e-04, l1: 0.56885, l2: 0.31232\n",
            "Loss: 1.223926e-04, l1: 0.57144, l2: 0.31257\n",
            "Loss: 1.213144e-04, l1: 0.57245, l2: 0.31310\n",
            "Loss: 1.198183e-04, l1: 0.57507, l2: 0.31374\n",
            "Loss: 1.179822e-04, l1: 0.58083, l2: 0.31498\n",
            "Loss: 1.181011e-04, l1: 0.58307, l2: 0.31525\n",
            "Loss: 1.171947e-04, l1: 0.58192, l2: 0.31511\n",
            "Loss: 1.165164e-04, l1: 0.58504, l2: 0.31535\n",
            "Loss: 1.162955e-04, l1: 0.58433, l2: 0.31474\n",
            "Loss: 1.160627e-04, l1: 0.58318, l2: 0.31446\n",
            "Loss: 1.156799e-04, l1: 0.58428, l2: 0.31446\n",
            "Loss: 1.151491e-04, l1: 0.58595, l2: 0.31426\n",
            "Loss: 1.145227e-04, l1: 0.58884, l2: 0.31398\n",
            "Loss: 1.152639e-04, l1: 0.59240, l2: 0.31360\n",
            "Loss: 1.143450e-04, l1: 0.58993, l2: 0.31386\n",
            "Loss: 1.141147e-04, l1: 0.59007, l2: 0.31369\n",
            "Loss: 1.139085e-04, l1: 0.59112, l2: 0.31384\n",
            "Loss: 1.137225e-04, l1: 0.59130, l2: 0.31399\n",
            "Loss: 1.134633e-04, l1: 0.59107, l2: 0.31397\n",
            "Loss: 1.136157e-04, l1: 0.59168, l2: 0.31397\n",
            "Loss: 1.132549e-04, l1: 0.59134, l2: 0.31397\n",
            "Loss: 1.130007e-04, l1: 0.59087, l2: 0.31370\n",
            "Loss: 1.126781e-04, l1: 0.59005, l2: 0.31329\n",
            "Loss: 1.123477e-04, l1: 0.58968, l2: 0.31324\n",
            "Loss: 1.118520e-04, l1: 0.58943, l2: 0.31333\n",
            "Loss: 1.116386e-04, l1: 0.59079, l2: 0.31365\n",
            "Loss: 1.114337e-04, l1: 0.59100, l2: 0.31390\n",
            "Loss: 1.113649e-04, l1: 0.59120, l2: 0.31394\n",
            "Loss: 1.113079e-04, l1: 0.59141, l2: 0.31398\n",
            "Loss: 1.112700e-04, l1: 0.59143, l2: 0.31398\n",
            "Loss: 1.112021e-04, l1: 0.59141, l2: 0.31401\n",
            "Loss: 1.111200e-04, l1: 0.59116, l2: 0.31408\n",
            "Loss: 1.109935e-04, l1: 0.59103, l2: 0.31421\n",
            "Loss: 1.108204e-04, l1: 0.59083, l2: 0.31438\n",
            "Loss: 1.105839e-04, l1: 0.59093, l2: 0.31460\n",
            "Loss: 1.103835e-04, l1: 0.59124, l2: 0.31470\n",
            "Loss: 1.101806e-04, l1: 0.59172, l2: 0.31472\n",
            "Loss: 1.099840e-04, l1: 0.59246, l2: 0.31476\n",
            "Loss: 1.097170e-04, l1: 0.59278, l2: 0.31447\n",
            "Loss: 1.094349e-04, l1: 0.59317, l2: 0.31437\n",
            "Loss: 1.090441e-04, l1: 0.59281, l2: 0.31424\n",
            "Loss: 1.081492e-04, l1: 0.59056, l2: 0.31410\n",
            "Loss: 1.072922e-04, l1: 0.58876, l2: 0.31373\n",
            "Loss: 1.068148e-04, l1: 0.58428, l2: 0.31340\n",
            "Loss: 1.064445e-04, l1: 0.57887, l2: 0.31312\n",
            "Loss: 1.054736e-04, l1: 0.58150, l2: 0.31325\n",
            "Loss: 1.063059e-04, l1: 0.58562, l2: 0.31351\n",
            "Loss: 1.047326e-04, l1: 0.58316, l2: 0.31336\n",
            "Loss: 1.038026e-04, l1: 0.58147, l2: 0.31365\n",
            "Loss: 1.039093e-04, l1: 0.57948, l2: 0.31408\n",
            "Loss: 1.033584e-04, l1: 0.58049, l2: 0.31386\n",
            "Loss: 1.029577e-04, l1: 0.58045, l2: 0.31400\n",
            "Loss: 1.025620e-04, l1: 0.57996, l2: 0.31396\n",
            "Loss: 1.018275e-04, l1: 0.57934, l2: 0.31418\n",
            "Loss: 1.212658e-04, l1: 0.57430, l2: 0.31262\n",
            "Loss: 1.013252e-04, l1: 0.57861, l2: 0.31395\n",
            "Loss: 1.008530e-04, l1: 0.57763, l2: 0.31388\n",
            "Loss: 1.003795e-04, l1: 0.57756, l2: 0.31397\n",
            "Loss: 1.001873e-04, l1: 0.57712, l2: 0.31373\n",
            "Loss: 9.997279e-05, l1: 0.57749, l2: 0.31357\n",
            "Loss: 9.974213e-05, l1: 0.57651, l2: 0.31361\n",
            "Loss: 9.960614e-05, l1: 0.57682, l2: 0.31360\n",
            "Loss: 9.943652e-05, l1: 0.57647, l2: 0.31363\n",
            "Loss: 9.924895e-05, l1: 0.57609, l2: 0.31361\n",
            "Loss: 9.915838e-05, l1: 0.57616, l2: 0.31416\n",
            "Loss: 9.968544e-05, l1: 0.57691, l2: 0.31440\n",
            "Loss: 9.906764e-05, l1: 0.57637, l2: 0.31423\n",
            "Loss: 9.889901e-05, l1: 0.57637, l2: 0.31408\n",
            "Loss: 9.874970e-05, l1: 0.57642, l2: 0.31404\n",
            "Loss: 9.849081e-05, l1: 0.57618, l2: 0.31384\n",
            "Loss: 9.805850e-05, l1: 0.57613, l2: 0.31427\n",
            "Loss: 9.757731e-05, l1: 0.57558, l2: 0.31448\n",
            "Loss: 9.685871e-05, l1: 0.57294, l2: 0.31467\n",
            "Loss: 9.673595e-05, l1: 0.57373, l2: 0.31457\n",
            "Loss: 9.652921e-05, l1: 0.57292, l2: 0.31431\n",
            "Loss: 9.642779e-05, l1: 0.57249, l2: 0.31409\n",
            "Loss: 9.631876e-05, l1: 0.57232, l2: 0.31389\n",
            "Loss: 9.613125e-05, l1: 0.57303, l2: 0.31361\n",
            "Loss: 9.695546e-05, l1: 0.57130, l2: 0.31336\n",
            "Loss: 9.595307e-05, l1: 0.57252, l2: 0.31354\n",
            "Loss: 9.571720e-05, l1: 0.57279, l2: 0.31370\n",
            "Loss: 9.526464e-05, l1: 0.57329, l2: 0.31417\n",
            "Loss: 9.484443e-05, l1: 0.57326, l2: 0.31446\n",
            "Loss: 9.442016e-05, l1: 0.57307, l2: 0.31459\n",
            "Loss: 9.405732e-05, l1: 0.57323, l2: 0.31453\n",
            "Loss: 9.396103e-05, l1: 0.57328, l2: 0.31424\n",
            "Loss: 9.366849e-05, l1: 0.57415, l2: 0.31437\n",
            "Loss: 9.350009e-05, l1: 0.57459, l2: 0.31450\n",
            "Loss: 9.315810e-05, l1: 0.57597, l2: 0.31460\n",
            "Loss: 9.278207e-05, l1: 0.57864, l2: 0.31473\n",
            "Loss: 9.255542e-05, l1: 0.58016, l2: 0.31483\n",
            "Loss: 9.240524e-05, l1: 0.58156, l2: 0.31470\n",
            "Loss: 9.210138e-05, l1: 0.58152, l2: 0.31464\n",
            "Loss: 9.193339e-05, l1: 0.58211, l2: 0.31467\n",
            "Loss: 9.165459e-05, l1: 0.58222, l2: 0.31477\n",
            "Loss: 9.138002e-05, l1: 0.58390, l2: 0.31488\n",
            "Loss: 9.100184e-05, l1: 0.58547, l2: 0.31507\n",
            "Loss: 9.064605e-05, l1: 0.58560, l2: 0.31532\n",
            "Loss: 9.037991e-05, l1: 0.58551, l2: 0.31555\n",
            "Loss: 9.021169e-05, l1: 0.58425, l2: 0.31559\n",
            "Loss: 9.012014e-05, l1: 0.58379, l2: 0.31561\n",
            "Loss: 9.006244e-05, l1: 0.58362, l2: 0.31562\n",
            "Loss: 8.997438e-05, l1: 0.58375, l2: 0.31565\n",
            "Loss: 8.986141e-05, l1: 0.58400, l2: 0.31560\n",
            "Loss: 8.977595e-05, l1: 0.58427, l2: 0.31575\n",
            "Loss: 8.977803e-05, l1: 0.58510, l2: 0.31566\n",
            "Loss: 8.974052e-05, l1: 0.58468, l2: 0.31570\n",
            "Loss: 8.968654e-05, l1: 0.58463, l2: 0.31573\n",
            "Loss: 8.965947e-05, l1: 0.58460, l2: 0.31567\n",
            "Loss: 8.958906e-05, l1: 0.58459, l2: 0.31552\n",
            "Loss: 8.956616e-05, l1: 0.58490, l2: 0.31543\n",
            "Loss: 8.951690e-05, l1: 0.58486, l2: 0.31548\n",
            "Loss: 8.945846e-05, l1: 0.58491, l2: 0.31556\n",
            "Loss: 8.939092e-05, l1: 0.58508, l2: 0.31566\n",
            "Loss: 8.933258e-05, l1: 0.58567, l2: 0.31585\n",
            "Loss: 8.912793e-05, l1: 0.58604, l2: 0.31592\n",
            "Loss: 8.897038e-05, l1: 0.58623, l2: 0.31587\n",
            "Loss: 8.881674e-05, l1: 0.58666, l2: 0.31576\n",
            "Loss: 8.869743e-05, l1: 0.58688, l2: 0.31579\n",
            "Loss: 8.864552e-05, l1: 0.58699, l2: 0.31601\n",
            "Loss: 8.850274e-05, l1: 0.58736, l2: 0.31592\n",
            "Loss: 8.837254e-05, l1: 0.58699, l2: 0.31586\n",
            "Loss: 8.822180e-05, l1: 0.58651, l2: 0.31575\n",
            "Loss: 8.813752e-05, l1: 0.58550, l2: 0.31563\n",
            "Loss: 8.798258e-05, l1: 0.58560, l2: 0.31563\n",
            "Loss: 8.790556e-05, l1: 0.58573, l2: 0.31548\n",
            "Loss: 8.785425e-05, l1: 0.58588, l2: 0.31540\n",
            "Loss: 8.781547e-05, l1: 0.58609, l2: 0.31539\n",
            "Loss: 8.775335e-05, l1: 0.58621, l2: 0.31543\n",
            "Loss: 8.771777e-05, l1: 0.58712, l2: 0.31556\n",
            "Loss: 8.767401e-05, l1: 0.58627, l2: 0.31562\n",
            "Loss: 8.763999e-05, l1: 0.58625, l2: 0.31559\n",
            "Loss: 8.760527e-05, l1: 0.58601, l2: 0.31558\n",
            "Loss: 8.756811e-05, l1: 0.58564, l2: 0.31557\n",
            "Loss: 8.754162e-05, l1: 0.58524, l2: 0.31557\n",
            "Loss: 8.752267e-05, l1: 0.58502, l2: 0.31560\n",
            "Loss: 8.750772e-05, l1: 0.58501, l2: 0.31555\n",
            "Loss: 8.748303e-05, l1: 0.58505, l2: 0.31561\n",
            "Loss: 8.746223e-05, l1: 0.58533, l2: 0.31562\n",
            "Loss: 8.742967e-05, l1: 0.58581, l2: 0.31564\n",
            "Loss: 8.741060e-05, l1: 0.58602, l2: 0.31565\n",
            "Loss: 8.736311e-05, l1: 0.58632, l2: 0.31567\n",
            "Loss: 8.732719e-05, l1: 0.58646, l2: 0.31573\n",
            "Loss: 8.727881e-05, l1: 0.58658, l2: 0.31576\n",
            "Loss: 8.715058e-05, l1: 0.58643, l2: 0.31580\n",
            "Loss: 8.704045e-05, l1: 0.58716, l2: 0.31585\n",
            "Loss: 8.683513e-05, l1: 0.58694, l2: 0.31587\n",
            "Loss: 8.658705e-05, l1: 0.58687, l2: 0.31580\n",
            "Loss: 8.622734e-05, l1: 0.58621, l2: 0.31549\n",
            "Loss: 8.604725e-05, l1: 0.58466, l2: 0.31550\n",
            "Loss: 8.594534e-05, l1: 0.58478, l2: 0.31547\n",
            "Loss: 8.580653e-05, l1: 0.58387, l2: 0.31526\n",
            "Loss: 8.571680e-05, l1: 0.58370, l2: 0.31523\n",
            "Loss: 8.566392e-05, l1: 0.58389, l2: 0.31519\n",
            "Loss: 8.561749e-05, l1: 0.58364, l2: 0.31514\n",
            "Loss: 8.558058e-05, l1: 0.58385, l2: 0.31508\n",
            "Loss: 8.555512e-05, l1: 0.58356, l2: 0.31497\n",
            "Loss: 8.551305e-05, l1: 0.58395, l2: 0.31495\n",
            "Loss: 8.549486e-05, l1: 0.58375, l2: 0.31496\n",
            "Loss: 8.547874e-05, l1: 0.58369, l2: 0.31492\n",
            "Loss: 8.546241e-05, l1: 0.58339, l2: 0.31488\n",
            "Loss: 8.542665e-05, l1: 0.58289, l2: 0.31480\n",
            "Loss: 8.532167e-05, l1: 0.58193, l2: 0.31468\n",
            "Loss: 8.517811e-05, l1: 0.58037, l2: 0.31436\n",
            "Loss: 8.498511e-05, l1: 0.58006, l2: 0.31436\n",
            "Loss: 8.477840e-05, l1: 0.57959, l2: 0.31439\n",
            "Loss: 8.445032e-05, l1: 0.57994, l2: 0.31477\n",
            "Loss: 8.421968e-05, l1: 0.58087, l2: 0.31511\n",
            "Loss: 8.403318e-05, l1: 0.58074, l2: 0.31553\n",
            "Loss: 8.365384e-05, l1: 0.58138, l2: 0.31550\n",
            "Loss: 8.320572e-05, l1: 0.58036, l2: 0.31523\n",
            "Loss: 8.274322e-05, l1: 0.57990, l2: 0.31521\n",
            "Loss: 8.234608e-05, l1: 0.57954, l2: 0.31518\n",
            "Loss: 8.198829e-05, l1: 0.57921, l2: 0.31509\n",
            "Loss: 8.165617e-05, l1: 0.58121, l2: 0.31502\n",
            "Loss: 8.118887e-05, l1: 0.58180, l2: 0.31478\n",
            "Loss: 8.108748e-05, l1: 0.58236, l2: 0.31505\n",
            "Loss: 8.058548e-05, l1: 0.58291, l2: 0.31484\n",
            "Loss: 8.039728e-05, l1: 0.58406, l2: 0.31468\n",
            "Loss: 8.025467e-05, l1: 0.58411, l2: 0.31471\n",
            "Loss: 8.013321e-05, l1: 0.58383, l2: 0.31453\n",
            "Loss: 8.004141e-05, l1: 0.58411, l2: 0.31449\n",
            "Loss: 7.994154e-05, l1: 0.58440, l2: 0.31452\n",
            "Loss: 7.983127e-05, l1: 0.58499, l2: 0.31455\n",
            "Loss: 7.974610e-05, l1: 0.58522, l2: 0.31458\n",
            "Loss: 7.966586e-05, l1: 0.58528, l2: 0.31465\n",
            "Loss: 7.959652e-05, l1: 0.58470, l2: 0.31475\n",
            "Loss: 7.957101e-05, l1: 0.58511, l2: 0.31481\n",
            "Loss: 7.949166e-05, l1: 0.58451, l2: 0.31483\n",
            "Loss: 7.943546e-05, l1: 0.58447, l2: 0.31480\n",
            "Loss: 7.936417e-05, l1: 0.58484, l2: 0.31479\n",
            "Loss: 7.926311e-05, l1: 0.58529, l2: 0.31488\n",
            "Loss: 7.993924e-05, l1: 0.58777, l2: 0.31517\n",
            "Loss: 7.920389e-05, l1: 0.58584, l2: 0.31494\n",
            "Loss: 7.909229e-05, l1: 0.58658, l2: 0.31502\n",
            "Loss: 7.901267e-05, l1: 0.58730, l2: 0.31507\n",
            "Loss: 7.899570e-05, l1: 0.58792, l2: 0.31520\n",
            "Loss: 7.895863e-05, l1: 0.58788, l2: 0.31517\n",
            "Loss: 7.893708e-05, l1: 0.58781, l2: 0.31514\n",
            "Loss: 7.891365e-05, l1: 0.58784, l2: 0.31516\n",
            "Loss: 7.887730e-05, l1: 0.58833, l2: 0.31525\n",
            "Loss: 7.886378e-05, l1: 0.58855, l2: 0.31527\n",
            "Loss: 7.884561e-05, l1: 0.58893, l2: 0.31537\n",
            "Loss: 7.883642e-05, l1: 0.58904, l2: 0.31538\n",
            "Loss: 7.882606e-05, l1: 0.58922, l2: 0.31540\n",
            "Loss: 7.881124e-05, l1: 0.58930, l2: 0.31550\n",
            "Loss: 7.880856e-05, l1: 0.59025, l2: 0.31558\n",
            "Loss: 7.879901e-05, l1: 0.58979, l2: 0.31554\n",
            "Loss: 7.878018e-05, l1: 0.58980, l2: 0.31552\n",
            "Loss: 7.876380e-05, l1: 0.58983, l2: 0.31553\n",
            "Loss: 7.875356e-05, l1: 0.58997, l2: 0.31557\n",
            "Loss: 7.873994e-05, l1: 0.59012, l2: 0.31563\n",
            "Loss: 7.874702e-05, l1: 0.59068, l2: 0.31572\n",
            "Loss: 7.873305e-05, l1: 0.59036, l2: 0.31567\n",
            "Loss: 7.872103e-05, l1: 0.59036, l2: 0.31568\n",
            "Loss: 7.870361e-05, l1: 0.59045, l2: 0.31571\n",
            "Loss: 7.868587e-05, l1: 0.59052, l2: 0.31572\n",
            "Loss: 7.869107e-05, l1: 0.59125, l2: 0.31568\n",
            "Loss: 7.866304e-05, l1: 0.59086, l2: 0.31570\n",
            "Loss: 7.862610e-05, l1: 0.59066, l2: 0.31575\n",
            "Loss: 7.858945e-05, l1: 0.59055, l2: 0.31574\n",
            "Loss: 7.852931e-05, l1: 0.59030, l2: 0.31570\n",
            "Loss: 7.845899e-05, l1: 0.59025, l2: 0.31563\n",
            "Loss: 7.832878e-05, l1: 0.59028, l2: 0.31530\n",
            "Loss: 7.816002e-05, l1: 0.59080, l2: 0.31531\n",
            "Loss: 7.796998e-05, l1: 0.59120, l2: 0.31526\n",
            "Loss: 7.793194e-05, l1: 0.59126, l2: 0.31517\n",
            "Loss: 7.788320e-05, l1: 0.59123, l2: 0.31522\n",
            "Loss: 7.783503e-05, l1: 0.59122, l2: 0.31512\n",
            "Loss: 7.779888e-05, l1: 0.59123, l2: 0.31517\n",
            "Loss: 7.777843e-05, l1: 0.59119, l2: 0.31515\n",
            "Loss: 7.776541e-05, l1: 0.59130, l2: 0.31515\n",
            "Loss: 7.775638e-05, l1: 0.59120, l2: 0.31513\n",
            "Loss: 7.774738e-05, l1: 0.59145, l2: 0.31513\n",
            "Loss: 7.775132e-05, l1: 0.59133, l2: 0.31512\n",
            "Loss: 7.774098e-05, l1: 0.59140, l2: 0.31513\n",
            "Loss: 7.772213e-05, l1: 0.59154, l2: 0.31515\n",
            "Loss: 7.768872e-05, l1: 0.59198, l2: 0.31519\n",
            "Loss: 7.766278e-05, l1: 0.59222, l2: 0.31526\n",
            "Loss: 7.766065e-05, l1: 0.59255, l2: 0.31533\n",
            "Loss: 7.763064e-05, l1: 0.59230, l2: 0.31530\n",
            "Loss: 7.761687e-05, l1: 0.59212, l2: 0.31532\n",
            "Loss: 7.759900e-05, l1: 0.59194, l2: 0.31537\n",
            "Loss: 7.758069e-05, l1: 0.59186, l2: 0.31541\n",
            "Loss: 7.755474e-05, l1: 0.59202, l2: 0.31549\n",
            "Loss: 7.755819e-05, l1: 0.59238, l2: 0.31554\n",
            "Loss: 7.753718e-05, l1: 0.59220, l2: 0.31551\n",
            "Loss: 7.751041e-05, l1: 0.59254, l2: 0.31554\n",
            "Loss: 7.745874e-05, l1: 0.59330, l2: 0.31562\n",
            "Loss: 7.740936e-05, l1: 0.59378, l2: 0.31567\n",
            "Loss: 7.734272e-05, l1: 0.59433, l2: 0.31575\n",
            "Loss: 7.729212e-05, l1: 0.59488, l2: 0.31579\n",
            "Loss: 7.722188e-05, l1: 0.59494, l2: 0.31578\n",
            "Loss: 7.706843e-05, l1: 0.59549, l2: 0.31572\n",
            "Loss: 7.699482e-05, l1: 0.59619, l2: 0.31549\n",
            "Loss: 7.689838e-05, l1: 0.59692, l2: 0.31553\n",
            "Loss: 7.680294e-05, l1: 0.59765, l2: 0.31550\n",
            "Loss: 7.668951e-05, l1: 0.59829, l2: 0.31546\n",
            "Loss: 7.660585e-05, l1: 0.59930, l2: 0.31544\n",
            "Loss: 7.649817e-05, l1: 0.59974, l2: 0.31538\n",
            "Loss: 7.641717e-05, l1: 0.59934, l2: 0.31524\n",
            "Loss: 7.634114e-05, l1: 0.60008, l2: 0.31525\n",
            "Loss: 7.627107e-05, l1: 0.60015, l2: 0.31516\n",
            "Loss: 7.614406e-05, l1: 0.60092, l2: 0.31503\n",
            "Loss: 7.607795e-05, l1: 0.60101, l2: 0.31478\n",
            "Loss: 7.600377e-05, l1: 0.60074, l2: 0.31477\n",
            "Loss: 7.590905e-05, l1: 0.60183, l2: 0.31467\n",
            "Loss: 7.581195e-05, l1: 0.60145, l2: 0.31459\n",
            "Loss: 7.571270e-05, l1: 0.60137, l2: 0.31442\n",
            "Loss: 7.562267e-05, l1: 0.60140, l2: 0.31422\n",
            "Loss: 7.551422e-05, l1: 0.60142, l2: 0.31404\n",
            "Loss: 7.535935e-05, l1: 0.60104, l2: 0.31384\n",
            "Loss: 7.525083e-05, l1: 0.60062, l2: 0.31381\n",
            "Loss: 7.514343e-05, l1: 0.59974, l2: 0.31395\n",
            "Loss: 7.506666e-05, l1: 0.59957, l2: 0.31410\n",
            "Loss: 7.496540e-05, l1: 0.59990, l2: 0.31430\n",
            "Loss: 7.488870e-05, l1: 0.60051, l2: 0.31441\n",
            "Loss: 7.481058e-05, l1: 0.60134, l2: 0.31449\n",
            "Loss: 7.474329e-05, l1: 0.60201, l2: 0.31455\n",
            "Loss: 7.466178e-05, l1: 0.60280, l2: 0.31461\n",
            "Loss: 7.457472e-05, l1: 0.60374, l2: 0.31471\n",
            "Loss: 7.449359e-05, l1: 0.60387, l2: 0.31474\n",
            "Loss: 7.442727e-05, l1: 0.60387, l2: 0.31478\n",
            "Loss: 7.435426e-05, l1: 0.60384, l2: 0.31490\n",
            "Loss: 7.443254e-05, l1: 0.60578, l2: 0.31525\n",
            "Loss: 7.429063e-05, l1: 0.60462, l2: 0.31504\n",
            "Loss: 7.421013e-05, l1: 0.60427, l2: 0.31509\n",
            "Loss: 7.417708e-05, l1: 0.60452, l2: 0.31518\n",
            "Loss: 7.412668e-05, l1: 0.60421, l2: 0.31521\n",
            "Loss: 7.411298e-05, l1: 0.60419, l2: 0.31521\n",
            "Loss: 7.408761e-05, l1: 0.60410, l2: 0.31525\n",
            "Loss: 7.406658e-05, l1: 0.60377, l2: 0.31529\n",
            "Loss: 7.405027e-05, l1: 0.60346, l2: 0.31530\n",
            "Loss: 7.405526e-05, l1: 0.60269, l2: 0.31525\n",
            "Loss: 7.403553e-05, l1: 0.60310, l2: 0.31528\n",
            "Loss: 7.401601e-05, l1: 0.60278, l2: 0.31524\n",
            "Loss: 7.399361e-05, l1: 0.60224, l2: 0.31515\n",
            "Loss: 7.397918e-05, l1: 0.60189, l2: 0.31510\n",
            "Loss: 7.396295e-05, l1: 0.60162, l2: 0.31506\n",
            "Loss: 7.394468e-05, l1: 0.60158, l2: 0.31509\n",
            "Loss: 7.396173e-05, l1: 0.60143, l2: 0.31493\n",
            "Loss: 7.393375e-05, l1: 0.60152, l2: 0.31503\n",
            "Loss: 7.391586e-05, l1: 0.60172, l2: 0.31505\n",
            "Loss: 7.389893e-05, l1: 0.60196, l2: 0.31508\n",
            "Loss: 7.388848e-05, l1: 0.60217, l2: 0.31511\n",
            "Loss: 7.388210e-05, l1: 0.60217, l2: 0.31509\n",
            "Loss: 7.386754e-05, l1: 0.60214, l2: 0.31509\n",
            "Loss: 7.385022e-05, l1: 0.60216, l2: 0.31512\n",
            "Loss: 7.386310e-05, l1: 0.60269, l2: 0.31518\n",
            "Loss: 7.384445e-05, l1: 0.60235, l2: 0.31514\n",
            "Loss: 7.382998e-05, l1: 0.60243, l2: 0.31518\n",
            "Loss: 7.381715e-05, l1: 0.60262, l2: 0.31520\n",
            "Loss: 7.380397e-05, l1: 0.60283, l2: 0.31523\n",
            "Loss: 7.378716e-05, l1: 0.60300, l2: 0.31520\n",
            "Loss: 7.376257e-05, l1: 0.60310, l2: 0.31516\n",
            "Loss: 7.402146e-05, l1: 0.60450, l2: 0.31548\n",
            "Loss: 7.375678e-05, l1: 0.60328, l2: 0.31520\n",
            "Loss: 7.372889e-05, l1: 0.60313, l2: 0.31511\n",
            "Loss: 7.369592e-05, l1: 0.60293, l2: 0.31505\n",
            "Loss: 7.367431e-05, l1: 0.60245, l2: 0.31503\n",
            "Loss: 7.364170e-05, l1: 0.60239, l2: 0.31511\n",
            "Loss: 7.359871e-05, l1: 0.60218, l2: 0.31517\n",
            "Loss: 7.385358e-05, l1: 0.60293, l2: 0.31612\n",
            "Loss: 7.356558e-05, l1: 0.60237, l2: 0.31541\n",
            "Loss: 7.354308e-05, l1: 0.60247, l2: 0.31550\n",
            "Loss: 7.352434e-05, l1: 0.60235, l2: 0.31545\n",
            "Loss: 7.351098e-05, l1: 0.60209, l2: 0.31538\n",
            "Loss: 7.349172e-05, l1: 0.60173, l2: 0.31531\n",
            "Loss: 7.345094e-05, l1: 0.60107, l2: 0.31520\n",
            "Loss: 7.338043e-05, l1: 0.60027, l2: 0.31510\n",
            "Loss: 7.327178e-05, l1: 0.59943, l2: 0.31505\n",
            "Loss: 7.319827e-05, l1: 0.59900, l2: 0.31507\n",
            "Loss: 7.306111e-05, l1: 0.59946, l2: 0.31531\n",
            "Loss: 7.300054e-05, l1: 0.60004, l2: 0.31550\n",
            "Loss: 7.291138e-05, l1: 0.60023, l2: 0.31565\n",
            "Loss: 7.277627e-05, l1: 0.60034, l2: 0.31577\n",
            "Loss: 7.250457e-05, l1: 0.60035, l2: 0.31585\n",
            "Loss: 7.227363e-05, l1: 0.60009, l2: 0.31584\n",
            "Loss: 7.210921e-05, l1: 0.59965, l2: 0.31550\n",
            "Loss: 7.189089e-05, l1: 0.60023, l2: 0.31537\n",
            "Loss: 7.179627e-05, l1: 0.60096, l2: 0.31549\n",
            "Loss: 7.164259e-05, l1: 0.60222, l2: 0.31561\n",
            "Loss: 7.151930e-05, l1: 0.60223, l2: 0.31559\n",
            "Loss: 7.145588e-05, l1: 0.60397, l2: 0.31559\n",
            "Loss: 7.145748e-05, l1: 0.60327, l2: 0.31612\n",
            "Loss: 7.134405e-05, l1: 0.60362, l2: 0.31585\n",
            "Loss: 7.127538e-05, l1: 0.60352, l2: 0.31569\n",
            "Loss: 7.103069e-05, l1: 0.60406, l2: 0.31563\n",
            "Loss: 7.088578e-05, l1: 0.60475, l2: 0.31557\n",
            "Loss: 7.069483e-05, l1: 0.60476, l2: 0.31550\n",
            "Loss: 7.049971e-05, l1: 0.60492, l2: 0.31541\n",
            "Loss: 7.038889e-05, l1: 0.60543, l2: 0.31547\n",
            "Loss: 7.028555e-05, l1: 0.60607, l2: 0.31557\n",
            "Loss: 7.013310e-05, l1: 0.60641, l2: 0.31578\n",
            "Loss: 6.990552e-05, l1: 0.60759, l2: 0.31605\n",
            "Loss: 6.956926e-05, l1: 0.60812, l2: 0.31648\n",
            "Loss: 6.932302e-05, l1: 0.60861, l2: 0.31647\n",
            "Loss: 6.912618e-05, l1: 0.60808, l2: 0.31625\n",
            "Loss: 6.914575e-05, l1: 0.60715, l2: 0.31598\n",
            "Loss: 6.898946e-05, l1: 0.60762, l2: 0.31612\n",
            "Loss: 6.883179e-05, l1: 0.60839, l2: 0.31595\n",
            "Loss: 6.863245e-05, l1: 0.61021, l2: 0.31596\n",
            "Loss: 6.843008e-05, l1: 0.61149, l2: 0.31593\n",
            "Loss: 6.832494e-05, l1: 0.61206, l2: 0.31590\n",
            "Loss: 6.825354e-05, l1: 0.61271, l2: 0.31589\n",
            "Loss: 6.809206e-05, l1: 0.61262, l2: 0.31565\n",
            "Loss: 6.792359e-05, l1: 0.61260, l2: 0.31565\n",
            "Loss: 6.777640e-05, l1: 0.61276, l2: 0.31569\n",
            "Loss: 6.767923e-05, l1: 0.61230, l2: 0.31581\n",
            "Loss: 6.752561e-05, l1: 0.61292, l2: 0.31579\n",
            "Loss: 6.739920e-05, l1: 0.61294, l2: 0.31572\n",
            "Loss: 6.730020e-05, l1: 0.61253, l2: 0.31556\n",
            "Loss: 6.725024e-05, l1: 0.61227, l2: 0.31546\n",
            "Loss: 6.720373e-05, l1: 0.61178, l2: 0.31542\n",
            "Loss: 6.716023e-05, l1: 0.61186, l2: 0.31548\n",
            "Loss: 6.712510e-05, l1: 0.61204, l2: 0.31549\n",
            "Loss: 6.709217e-05, l1: 0.61251, l2: 0.31554\n",
            "Loss: 6.704257e-05, l1: 0.61290, l2: 0.31549\n",
            "Loss: 6.699828e-05, l1: 0.61322, l2: 0.31543\n",
            "Loss: 6.694390e-05, l1: 0.61279, l2: 0.31526\n",
            "Loss: 6.690741e-05, l1: 0.61250, l2: 0.31523\n",
            "Loss: 6.688805e-05, l1: 0.61286, l2: 0.31531\n",
            "Loss: 6.684140e-05, l1: 0.61241, l2: 0.31526\n",
            "Loss: 6.682010e-05, l1: 0.61238, l2: 0.31525\n",
            "Loss: 6.680038e-05, l1: 0.61260, l2: 0.31524\n",
            "Loss: 6.678659e-05, l1: 0.61288, l2: 0.31523\n",
            "Loss: 6.677186e-05, l1: 0.61339, l2: 0.31522\n",
            "Loss: 6.675479e-05, l1: 0.61360, l2: 0.31520\n",
            "Loss: 6.673853e-05, l1: 0.61375, l2: 0.31518\n",
            "Loss: 6.672186e-05, l1: 0.61377, l2: 0.31517\n",
            "Loss: 6.670783e-05, l1: 0.61368, l2: 0.31516\n",
            "Loss: 6.667808e-05, l1: 0.61361, l2: 0.31514\n",
            "Loss: 6.664323e-05, l1: 0.61386, l2: 0.31514\n",
            "Loss: 6.661069e-05, l1: 0.61388, l2: 0.31512\n",
            "Loss: 6.658680e-05, l1: 0.61417, l2: 0.31509\n",
            "Loss: 6.657350e-05, l1: 0.61466, l2: 0.31501\n",
            "Loss: 6.656186e-05, l1: 0.61457, l2: 0.31496\n",
            "Loss: 6.654317e-05, l1: 0.61449, l2: 0.31489\n",
            "Loss: 6.651902e-05, l1: 0.61449, l2: 0.31481\n",
            "Loss: 6.648643e-05, l1: 0.61463, l2: 0.31466\n",
            "Loss: 6.644659e-05, l1: 0.61483, l2: 0.31457\n",
            "Loss: 6.640254e-05, l1: 0.61569, l2: 0.31454\n",
            "Loss: 6.632044e-05, l1: 0.61642, l2: 0.31459\n",
            "Loss: 6.626259e-05, l1: 0.61733, l2: 0.31468\n",
            "Loss: 6.621416e-05, l1: 0.61837, l2: 0.31482\n",
            "Loss: 6.619547e-05, l1: 0.61941, l2: 0.31481\n",
            "Loss: 6.614486e-05, l1: 0.61941, l2: 0.31494\n",
            "Loss: 6.609286e-05, l1: 0.61949, l2: 0.31496\n",
            "Loss: 6.604218e-05, l1: 0.62043, l2: 0.31496\n",
            "Loss: 6.601406e-05, l1: 0.62098, l2: 0.31501\n",
            "Loss: 6.598719e-05, l1: 0.62152, l2: 0.31506\n",
            "Loss: 6.596228e-05, l1: 0.62192, l2: 0.31507\n",
            "Loss: 6.591504e-05, l1: 0.62284, l2: 0.31508\n",
            "Loss: 6.583465e-05, l1: 0.62328, l2: 0.31502\n",
            "Loss: 6.579546e-05, l1: 0.62441, l2: 0.31460\n",
            "Loss: 6.568497e-05, l1: 0.62461, l2: 0.31467\n",
            "Loss: 6.563350e-05, l1: 0.62386, l2: 0.31466\n",
            "Loss: 6.558919e-05, l1: 0.62461, l2: 0.31469\n",
            "Loss: 6.556560e-05, l1: 0.62554, l2: 0.31466\n",
            "Loss: 6.556472e-05, l1: 0.62605, l2: 0.31456\n",
            "Loss: 6.553315e-05, l1: 0.62577, l2: 0.31461\n",
            "Loss: 6.550856e-05, l1: 0.62557, l2: 0.31468\n",
            "Loss: 6.547505e-05, l1: 0.62583, l2: 0.31467\n",
            "Loss: 6.545839e-05, l1: 0.62656, l2: 0.31468\n",
            "Loss: 6.543152e-05, l1: 0.62679, l2: 0.31468\n",
            "Loss: 6.538432e-05, l1: 0.62786, l2: 0.31473\n",
            "Loss: 6.534632e-05, l1: 0.62844, l2: 0.31468\n",
            "Loss: 6.531557e-05, l1: 0.62924, l2: 0.31467\n",
            "Loss: 6.528324e-05, l1: 0.62984, l2: 0.31463\n",
            "Loss: 6.527013e-05, l1: 0.62930, l2: 0.31455\n",
            "Loss: 6.523798e-05, l1: 0.62971, l2: 0.31449\n",
            "Loss: 6.522497e-05, l1: 0.62986, l2: 0.31455\n",
            "Loss: 6.520607e-05, l1: 0.63000, l2: 0.31455\n",
            "Loss: 6.517779e-05, l1: 0.63044, l2: 0.31446\n",
            "Loss: 6.515234e-05, l1: 0.63104, l2: 0.31438\n",
            "Loss: 6.512410e-05, l1: 0.63127, l2: 0.31439\n",
            "Loss: 6.509724e-05, l1: 0.63211, l2: 0.31439\n",
            "Loss: 6.507102e-05, l1: 0.63224, l2: 0.31438\n",
            "Loss: 6.504244e-05, l1: 0.63306, l2: 0.31435\n",
            "Loss: 6.500950e-05, l1: 0.63320, l2: 0.31437\n",
            "Loss: 6.496459e-05, l1: 0.63396, l2: 0.31436\n",
            "Loss: 6.491568e-05, l1: 0.63502, l2: 0.31441\n",
            "Loss: 6.486190e-05, l1: 0.63607, l2: 0.31440\n",
            "Loss: 6.481624e-05, l1: 0.63623, l2: 0.31445\n",
            "Loss: 6.477302e-05, l1: 0.63702, l2: 0.31449\n",
            "Loss: 6.475891e-05, l1: 0.63673, l2: 0.31455\n",
            "Loss: 6.467143e-05, l1: 0.63734, l2: 0.31453\n",
            "Loss: 6.463197e-05, l1: 0.63788, l2: 0.31452\n",
            "Loss: 6.458860e-05, l1: 0.63879, l2: 0.31447\n",
            "Loss: 6.453658e-05, l1: 0.63907, l2: 0.31447\n",
            "Loss: 6.449358e-05, l1: 0.64024, l2: 0.31449\n",
            "Loss: 6.446993e-05, l1: 0.64031, l2: 0.31443\n",
            "Loss: 6.444826e-05, l1: 0.64038, l2: 0.31446\n",
            "Loss: 6.442954e-05, l1: 0.64063, l2: 0.31445\n",
            "Loss: 6.440213e-05, l1: 0.64069, l2: 0.31443\n",
            "Loss: 6.436626e-05, l1: 0.64071, l2: 0.31443\n",
            "Loss: 6.438712e-05, l1: 0.64086, l2: 0.31436\n",
            "Loss: 6.434385e-05, l1: 0.64077, l2: 0.31440\n",
            "Loss: 6.431158e-05, l1: 0.64095, l2: 0.31438\n",
            "Loss: 6.427590e-05, l1: 0.64133, l2: 0.31441\n",
            "Loss: 6.422486e-05, l1: 0.64241, l2: 0.31443\n",
            "Loss: 6.416464e-05, l1: 0.64335, l2: 0.31456\n",
            "Loss: 6.413084e-05, l1: 0.64461, l2: 0.31466\n",
            "Loss: 6.407365e-05, l1: 0.64423, l2: 0.31463\n",
            "Loss: 6.404843e-05, l1: 0.64414, l2: 0.31467\n",
            "Loss: 6.401946e-05, l1: 0.64477, l2: 0.31474\n",
            "Loss: 6.399025e-05, l1: 0.64595, l2: 0.31485\n",
            "Loss: 6.397153e-05, l1: 0.64629, l2: 0.31486\n",
            "Loss: 6.395944e-05, l1: 0.64665, l2: 0.31486\n",
            "Loss: 6.394526e-05, l1: 0.64722, l2: 0.31486\n",
            "Loss: 6.392984e-05, l1: 0.64763, l2: 0.31486\n",
            "Loss: 6.390972e-05, l1: 0.64823, l2: 0.31488\n",
            "Loss: 6.388042e-05, l1: 0.64867, l2: 0.31490\n",
            "Loss: 6.383716e-05, l1: 0.64900, l2: 0.31489\n",
            "Loss: 6.379927e-05, l1: 0.64957, l2: 0.31492\n",
            "Loss: 6.379002e-05, l1: 0.65004, l2: 0.31457\n",
            "Loss: 6.370011e-05, l1: 0.65006, l2: 0.31473\n",
            "Loss: 6.365518e-05, l1: 0.65054, l2: 0.31478\n",
            "Loss: 6.362356e-05, l1: 0.65059, l2: 0.31472\n",
            "Loss: 6.359158e-05, l1: 0.65138, l2: 0.31468\n",
            "Loss: 6.356382e-05, l1: 0.65139, l2: 0.31465\n",
            "Loss: 6.353128e-05, l1: 0.65140, l2: 0.31464\n",
            "Loss: 6.348494e-05, l1: 0.65131, l2: 0.31465\n",
            "Loss: 6.355351e-05, l1: 0.65192, l2: 0.31500\n",
            "Loss: 6.344037e-05, l1: 0.65155, l2: 0.31479\n",
            "Loss: 6.335708e-05, l1: 0.65128, l2: 0.31471\n",
            "Loss: 6.330763e-05, l1: 0.65146, l2: 0.31472\n",
            "Loss: 6.324844e-05, l1: 0.65194, l2: 0.31469\n",
            "Loss: 6.319447e-05, l1: 0.65240, l2: 0.31464\n",
            "Loss: 6.314018e-05, l1: 0.65271, l2: 0.31456\n",
            "Loss: 6.332390e-05, l1: 0.65321, l2: 0.31418\n",
            "Loss: 6.312381e-05, l1: 0.65283, l2: 0.31447\n",
            "Loss: 6.309680e-05, l1: 0.65353, l2: 0.31446\n",
            "Loss: 6.307128e-05, l1: 0.65362, l2: 0.31442\n",
            "Loss: 6.305391e-05, l1: 0.65390, l2: 0.31441\n",
            "Loss: 6.304114e-05, l1: 0.65388, l2: 0.31439\n",
            "Loss: 6.301976e-05, l1: 0.65387, l2: 0.31438\n",
            "Loss: 6.298950e-05, l1: 0.65372, l2: 0.31438\n",
            "Loss: 6.295322e-05, l1: 0.65380, l2: 0.31442\n",
            "Loss: 6.291737e-05, l1: 0.65401, l2: 0.31447\n",
            "Loss: 6.287194e-05, l1: 0.65501, l2: 0.31453\n",
            "Loss: 6.287555e-05, l1: 0.65570, l2: 0.31455\n",
            "Loss: 6.285800e-05, l1: 0.65534, l2: 0.31454\n",
            "Loss: 6.284130e-05, l1: 0.65579, l2: 0.31451\n",
            "Loss: 6.282672e-05, l1: 0.65642, l2: 0.31447\n",
            "Loss: 6.281703e-05, l1: 0.65652, l2: 0.31445\n",
            "Loss: 6.280767e-05, l1: 0.65661, l2: 0.31445\n",
            "Loss: 6.280129e-05, l1: 0.65644, l2: 0.31445\n",
            "Loss: 6.279066e-05, l1: 0.65637, l2: 0.31448\n",
            "Loss: 6.277707e-05, l1: 0.65625, l2: 0.31448\n",
            "Loss: 6.276259e-05, l1: 0.65633, l2: 0.31450\n",
            "Loss: 6.273690e-05, l1: 0.65682, l2: 0.31452\n",
            "Loss: 6.274346e-05, l1: 0.65741, l2: 0.31453\n",
            "Loss: 6.273082e-05, l1: 0.65706, l2: 0.31452\n",
            "Loss: 6.272035e-05, l1: 0.65720, l2: 0.31451\n",
            "Loss: 6.271094e-05, l1: 0.65729, l2: 0.31452\n",
            "Loss: 6.269651e-05, l1: 0.65748, l2: 0.31458\n",
            "Loss: 6.268519e-05, l1: 0.65743, l2: 0.31464\n",
            "Loss: 6.266287e-05, l1: 0.65749, l2: 0.31478\n",
            "Loss: 6.263656e-05, l1: 0.65680, l2: 0.31491\n",
            "Loss: 6.260707e-05, l1: 0.65709, l2: 0.31492\n",
            "Loss: 6.256437e-05, l1: 0.65763, l2: 0.31497\n",
            "Loss: 6.253353e-05, l1: 0.65716, l2: 0.31485\n",
            "Loss: 6.249176e-05, l1: 0.65740, l2: 0.31491\n",
            "Loss: 6.243843e-05, l1: 0.65704, l2: 0.31503\n",
            "Loss: 6.240551e-05, l1: 0.65690, l2: 0.31498\n",
            "Loss: 6.234673e-05, l1: 0.65639, l2: 0.31492\n",
            "Loss: 6.223880e-05, l1: 0.65547, l2: 0.31491\n",
            "Loss: 6.213825e-05, l1: 0.65521, l2: 0.31482\n",
            "Loss: 6.198922e-05, l1: 0.65429, l2: 0.31484\n",
            "Loss: 6.190580e-05, l1: 0.65483, l2: 0.31490\n",
            "Loss: 6.186941e-05, l1: 0.65442, l2: 0.31495\n",
            "Loss: 6.184180e-05, l1: 0.65435, l2: 0.31504\n",
            "Loss: 6.182071e-05, l1: 0.65434, l2: 0.31505\n",
            "Loss: 6.180083e-05, l1: 0.65420, l2: 0.31506\n",
            "Loss: 6.177282e-05, l1: 0.65427, l2: 0.31502\n",
            "Loss: 6.175638e-05, l1: 0.65457, l2: 0.31499\n",
            "Loss: 6.169376e-05, l1: 0.65464, l2: 0.31501\n",
            "Loss: 6.163676e-05, l1: 0.65507, l2: 0.31505\n",
            "Loss: 6.158178e-05, l1: 0.65553, l2: 0.31511\n",
            "Loss: 6.157858e-05, l1: 0.65569, l2: 0.31532\n",
            "Loss: 6.154841e-05, l1: 0.65561, l2: 0.31522\n",
            "Loss: 6.147810e-05, l1: 0.65597, l2: 0.31523\n",
            "Loss: 6.140408e-05, l1: 0.65587, l2: 0.31521\n",
            "Loss: 6.133629e-05, l1: 0.65553, l2: 0.31513\n",
            "Loss: 6.130059e-05, l1: 0.65534, l2: 0.31508\n",
            "Loss: 6.127191e-05, l1: 0.65520, l2: 0.31502\n",
            "Loss: 6.125021e-05, l1: 0.65494, l2: 0.31498\n",
            "Loss: 6.122907e-05, l1: 0.65460, l2: 0.31496\n",
            "Loss: 6.120268e-05, l1: 0.65422, l2: 0.31490\n",
            "Loss: 6.116505e-05, l1: 0.65393, l2: 0.31482\n",
            "Loss: 6.110220e-05, l1: 0.65365, l2: 0.31473\n",
            "Loss: 6.102200e-05, l1: 0.65307, l2: 0.31453\n",
            "Loss: 6.096333e-05, l1: 0.65362, l2: 0.31454\n",
            "Loss: 6.091492e-05, l1: 0.65336, l2: 0.31451\n",
            "Loss: 6.089247e-05, l1: 0.65350, l2: 0.31455\n",
            "Loss: 6.087644e-05, l1: 0.65380, l2: 0.31451\n",
            "Loss: 6.085827e-05, l1: 0.65382, l2: 0.31444\n",
            "Loss: 6.084116e-05, l1: 0.65397, l2: 0.31434\n",
            "Loss: 6.081362e-05, l1: 0.65365, l2: 0.31431\n",
            "Loss: 6.079324e-05, l1: 0.65356, l2: 0.31435\n",
            "Loss: 6.074193e-05, l1: 0.65327, l2: 0.31446\n",
            "Loss: 6.070574e-05, l1: 0.65307, l2: 0.31450\n",
            "Loss: 6.065096e-05, l1: 0.65259, l2: 0.31449\n",
            "Loss: 6.062253e-05, l1: 0.65263, l2: 0.31453\n",
            "Loss: 6.059048e-05, l1: 0.65236, l2: 0.31453\n",
            "Loss: 6.055687e-05, l1: 0.65234, l2: 0.31454\n",
            "Loss: 6.054038e-05, l1: 0.65242, l2: 0.31461\n",
            "Loss: 6.051635e-05, l1: 0.65251, l2: 0.31474\n",
            "Loss: 6.049975e-05, l1: 0.65239, l2: 0.31486\n",
            "Loss: 6.048800e-05, l1: 0.65244, l2: 0.31492\n",
            "Loss: 6.047973e-05, l1: 0.65224, l2: 0.31492\n",
            "Loss: 6.046802e-05, l1: 0.65214, l2: 0.31490\n",
            "Loss: 6.045903e-05, l1: 0.65205, l2: 0.31486\n",
            "Loss: 6.045214e-05, l1: 0.65204, l2: 0.31485\n",
            "Loss: 6.045091e-05, l1: 0.65289, l2: 0.31489\n",
            "Loss: 6.043043e-05, l1: 0.65232, l2: 0.31491\n",
            "Loss: 6.042266e-05, l1: 0.65250, l2: 0.31492\n",
            "Loss: 6.040424e-05, l1: 0.65265, l2: 0.31494\n",
            "Loss: 6.037350e-05, l1: 0.65308, l2: 0.31500\n",
            "Loss: 6.034367e-05, l1: 0.65363, l2: 0.31506\n",
            "Loss: 6.030677e-05, l1: 0.65411, l2: 0.31507\n",
            "Loss: 6.034841e-05, l1: 0.65512, l2: 0.31523\n",
            "Loss: 6.029211e-05, l1: 0.65445, l2: 0.31512\n",
            "Loss: 6.026598e-05, l1: 0.65444, l2: 0.31516\n",
            "Loss: 6.028953e-05, l1: 0.65399, l2: 0.31508\n",
            "Loss: 6.025515e-05, l1: 0.65428, l2: 0.31513\n",
            "Loss: 6.025204e-05, l1: 0.65401, l2: 0.31520\n",
            "Loss: 6.023466e-05, l1: 0.65414, l2: 0.31517\n",
            "Loss: 6.021284e-05, l1: 0.65404, l2: 0.31516\n",
            "Loss: 6.017563e-05, l1: 0.65399, l2: 0.31517\n",
            "Loss: 6.014786e-05, l1: 0.65418, l2: 0.31517\n",
            "Loss: 6.029170e-05, l1: 0.65485, l2: 0.31547\n",
            "Loss: 6.013529e-05, l1: 0.65433, l2: 0.31523\n",
            "Loss: 6.011190e-05, l1: 0.65451, l2: 0.31523\n",
            "Loss: 6.008870e-05, l1: 0.65462, l2: 0.31522\n",
            "Loss: 6.007170e-05, l1: 0.65457, l2: 0.31520\n",
            "Loss: 6.005902e-05, l1: 0.65450, l2: 0.31519\n",
            "Loss: 6.004747e-05, l1: 0.65431, l2: 0.31515\n",
            "Loss: 6.003836e-05, l1: 0.65428, l2: 0.31512\n",
            "Loss: 6.003289e-05, l1: 0.65420, l2: 0.31513\n",
            "Loss: 6.002819e-05, l1: 0.65422, l2: 0.31513\n",
            "Loss: 6.002322e-05, l1: 0.65421, l2: 0.31513\n",
            "Loss: 6.001658e-05, l1: 0.65401, l2: 0.31512\n",
            "Loss: 6.000879e-05, l1: 0.65384, l2: 0.31510\n",
            "Loss: 6.000220e-05, l1: 0.65357, l2: 0.31508\n",
            "Loss: 5.999187e-05, l1: 0.65343, l2: 0.31507\n",
            "Loss: 5.997685e-05, l1: 0.65315, l2: 0.31506\n",
            "Loss: 5.996384e-05, l1: 0.65326, l2: 0.31509\n",
            "Loss: 5.995106e-05, l1: 0.65297, l2: 0.31509\n",
            "Loss: 5.994023e-05, l1: 0.65297, l2: 0.31511\n",
            "Loss: 5.992713e-05, l1: 0.65298, l2: 0.31518\n",
            "Loss: 5.991486e-05, l1: 0.65288, l2: 0.31522\n",
            "Loss: 5.989538e-05, l1: 0.65284, l2: 0.31524\n",
            "Loss: 5.984992e-05, l1: 0.65249, l2: 0.31529\n",
            "Loss: 5.984163e-05, l1: 0.65258, l2: 0.31526\n",
            "Loss: 5.983352e-05, l1: 0.65252, l2: 0.31526\n",
            "Loss: 5.982287e-05, l1: 0.65266, l2: 0.31526\n",
            "Loss: 5.980175e-05, l1: 0.65295, l2: 0.31527\n",
            "Loss: 5.978517e-05, l1: 0.65372, l2: 0.31532\n",
            "Loss: 5.976033e-05, l1: 0.65388, l2: 0.31529\n",
            "Loss: 5.974436e-05, l1: 0.65447, l2: 0.31541\n",
            "Loss: 5.974199e-05, l1: 0.65497, l2: 0.31534\n",
            "Loss: 5.972545e-05, l1: 0.65472, l2: 0.31537\n",
            "Loss: 5.970825e-05, l1: 0.65487, l2: 0.31536\n",
            "Loss: 5.969263e-05, l1: 0.65574, l2: 0.31546\n",
            "Loss: 5.968646e-05, l1: 0.65568, l2: 0.31548\n",
            "Loss: 5.967918e-05, l1: 0.65585, l2: 0.31551\n",
            "Loss: 5.967249e-05, l1: 0.65600, l2: 0.31555\n",
            "Loss: 5.966675e-05, l1: 0.65602, l2: 0.31558\n",
            "Loss: 5.965648e-05, l1: 0.65622, l2: 0.31558\n",
            "Loss: 5.965484e-05, l1: 0.65571, l2: 0.31557\n",
            "Loss: 5.963820e-05, l1: 0.65623, l2: 0.31556\n",
            "Loss: 5.963153e-05, l1: 0.65647, l2: 0.31553\n",
            "Loss: 5.962047e-05, l1: 0.65689, l2: 0.31549\n",
            "Loss: 5.964980e-05, l1: 0.65709, l2: 0.31539\n",
            "Loss: 5.961483e-05, l1: 0.65694, l2: 0.31546\n",
            "Loss: 5.960975e-05, l1: 0.65715, l2: 0.31546\n",
            "Loss: 5.960253e-05, l1: 0.65738, l2: 0.31550\n",
            "Loss: 5.959708e-05, l1: 0.65742, l2: 0.31553\n",
            "Loss: 5.959323e-05, l1: 0.65753, l2: 0.31557\n",
            "Loss: 5.958772e-05, l1: 0.65756, l2: 0.31558\n",
            "Loss: 5.957865e-05, l1: 0.65789, l2: 0.31559\n",
            "Loss: 5.956658e-05, l1: 0.65802, l2: 0.31553\n",
            "Loss: 5.955511e-05, l1: 0.65853, l2: 0.31546\n",
            "Loss: 5.954588e-05, l1: 0.65852, l2: 0.31538\n",
            "Loss: 5.953700e-05, l1: 0.65871, l2: 0.31536\n",
            "Loss: 5.952151e-05, l1: 0.65905, l2: 0.31538\n",
            "Loss: 5.950452e-05, l1: 0.65950, l2: 0.31540\n",
            "Loss: 5.949360e-05, l1: 0.65920, l2: 0.31541\n",
            "Loss: 5.947958e-05, l1: 0.65905, l2: 0.31542\n",
            "Loss: 5.946685e-05, l1: 0.65886, l2: 0.31540\n",
            "Loss: 5.944500e-05, l1: 0.65857, l2: 0.31538\n",
            "Loss: 5.942706e-05, l1: 0.65854, l2: 0.31536\n",
            "Loss: 5.941006e-05, l1: 0.65881, l2: 0.31537\n",
            "Loss: 5.939357e-05, l1: 0.65926, l2: 0.31540\n",
            "Loss: 5.936877e-05, l1: 0.65983, l2: 0.31543\n",
            "Loss: 5.934416e-05, l1: 0.66017, l2: 0.31549\n",
            "Loss: 5.930199e-05, l1: 0.66069, l2: 0.31551\n",
            "Loss: 5.924041e-05, l1: 0.66109, l2: 0.31553\n",
            "Loss: 5.918688e-05, l1: 0.66183, l2: 0.31550\n",
            "Loss: 5.915500e-05, l1: 0.66159, l2: 0.31549\n",
            "Loss: 5.914397e-05, l1: 0.66164, l2: 0.31551\n",
            "Loss: 5.913081e-05, l1: 0.66164, l2: 0.31554\n",
            "Loss: 5.910151e-05, l1: 0.66179, l2: 0.31564\n",
            "Loss: 5.907087e-05, l1: 0.66186, l2: 0.31575\n",
            "Loss: 5.903484e-05, l1: 0.66186, l2: 0.31580\n",
            "Loss: 5.898801e-05, l1: 0.66248, l2: 0.31586\n",
            "Loss: 5.895660e-05, l1: 0.66221, l2: 0.31583\n",
            "Loss: 5.893119e-05, l1: 0.66234, l2: 0.31582\n",
            "Loss: 5.890685e-05, l1: 0.66208, l2: 0.31577\n",
            "Loss: 5.888362e-05, l1: 0.66170, l2: 0.31573\n",
            "Loss: 5.886146e-05, l1: 0.66161, l2: 0.31573\n",
            "Loss: 5.887105e-05, l1: 0.66091, l2: 0.31556\n",
            "Loss: 5.883146e-05, l1: 0.66128, l2: 0.31565\n",
            "Loss: 5.877357e-05, l1: 0.66148, l2: 0.31566\n",
            "Loss: 5.870361e-05, l1: 0.66198, l2: 0.31564\n",
            "Loss: 5.864331e-05, l1: 0.66313, l2: 0.31558\n",
            "Loss: 5.861392e-05, l1: 0.66355, l2: 0.31553\n",
            "Loss: 5.851988e-05, l1: 0.66426, l2: 0.31557\n",
            "Loss: 5.848845e-05, l1: 0.66424, l2: 0.31557\n",
            "Loss: 5.845402e-05, l1: 0.66422, l2: 0.31553\n",
            "Loss: 5.842813e-05, l1: 0.66404, l2: 0.31550\n",
            "Loss: 5.840932e-05, l1: 0.66436, l2: 0.31549\n",
            "Loss: 5.838994e-05, l1: 0.66436, l2: 0.31549\n",
            "Loss: 5.835046e-05, l1: 0.66404, l2: 0.31552\n",
            "Loss: 5.832715e-05, l1: 0.66378, l2: 0.31550\n",
            "Loss: 5.831765e-05, l1: 0.66318, l2: 0.31565\n",
            "Loss: 5.828275e-05, l1: 0.66356, l2: 0.31557\n",
            "Loss: 5.826630e-05, l1: 0.66360, l2: 0.31555\n",
            "Loss: 5.823753e-05, l1: 0.66434, l2: 0.31560\n",
            "Loss: 5.820453e-05, l1: 0.66463, l2: 0.31568\n",
            "Loss: 5.814679e-05, l1: 0.66546, l2: 0.31585\n",
            "Loss: 5.809546e-05, l1: 0.66694, l2: 0.31570\n",
            "Loss: 5.802822e-05, l1: 0.66649, l2: 0.31573\n",
            "Loss: 5.798333e-05, l1: 0.66698, l2: 0.31576\n",
            "Loss: 5.793980e-05, l1: 0.66745, l2: 0.31575\n",
            "Loss: 5.794342e-05, l1: 0.66856, l2: 0.31576\n",
            "Loss: 5.791186e-05, l1: 0.66800, l2: 0.31576\n",
            "Loss: 5.787468e-05, l1: 0.66810, l2: 0.31570\n",
            "Loss: 5.782951e-05, l1: 0.66857, l2: 0.31561\n",
            "Loss: 5.780449e-05, l1: 0.66865, l2: 0.31555\n",
            "Loss: 5.779180e-05, l1: 0.66916, l2: 0.31556\n",
            "Loss: 5.777962e-05, l1: 0.66914, l2: 0.31560\n",
            "Loss: 5.776603e-05, l1: 0.66931, l2: 0.31563\n",
            "Loss: 5.775015e-05, l1: 0.66942, l2: 0.31564\n",
            "Loss: 5.771597e-05, l1: 0.66970, l2: 0.31561\n",
            "Loss: 5.767974e-05, l1: 0.66997, l2: 0.31558\n",
            "Loss: 5.762283e-05, l1: 0.67052, l2: 0.31554\n",
            "Loss: 5.764660e-05, l1: 0.67157, l2: 0.31552\n",
            "Loss: 5.758980e-05, l1: 0.67098, l2: 0.31553\n",
            "Loss: 5.753399e-05, l1: 0.67153, l2: 0.31555\n",
            "Loss: 5.742985e-05, l1: 0.67248, l2: 0.31557\n",
            "Loss: 5.732675e-05, l1: 0.67410, l2: 0.31562\n",
            "Loss: 5.720226e-05, l1: 0.67498, l2: 0.31568\n",
            "Loss: 5.711610e-05, l1: 0.67683, l2: 0.31570\n",
            "Loss: 5.707291e-05, l1: 0.67595, l2: 0.31562\n",
            "Loss: 5.698814e-05, l1: 0.67669, l2: 0.31562\n",
            "Loss: 5.693071e-05, l1: 0.67789, l2: 0.31561\n",
            "Loss: 5.686523e-05, l1: 0.67853, l2: 0.31555\n",
            "Loss: 5.678519e-05, l1: 0.67897, l2: 0.31547\n",
            "Loss: 5.674771e-05, l1: 0.67971, l2: 0.31543\n",
            "Loss: 5.671652e-05, l1: 0.68023, l2: 0.31536\n",
            "Loss: 5.668358e-05, l1: 0.68009, l2: 0.31528\n",
            "Loss: 5.665120e-05, l1: 0.68058, l2: 0.31516\n",
            "Loss: 5.676178e-05, l1: 0.68252, l2: 0.31508\n",
            "Loss: 5.662135e-05, l1: 0.68121, l2: 0.31513\n",
            "Loss: 5.657964e-05, l1: 0.68237, l2: 0.31497\n",
            "Loss: 5.653426e-05, l1: 0.68229, l2: 0.31500\n",
            "Loss: 5.654250e-05, l1: 0.68250, l2: 0.31492\n",
            "Loss: 5.651206e-05, l1: 0.68238, l2: 0.31496\n",
            "Loss: 5.647565e-05, l1: 0.68289, l2: 0.31501\n",
            "Loss: 5.644246e-05, l1: 0.68323, l2: 0.31503\n",
            "Loss: 5.642572e-05, l1: 0.68380, l2: 0.31500\n",
            "Loss: 5.639989e-05, l1: 0.68423, l2: 0.31501\n",
            "Loss: 5.638002e-05, l1: 0.68454, l2: 0.31502\n",
            "Loss: 5.635606e-05, l1: 0.68504, l2: 0.31505\n",
            "Loss: 5.633352e-05, l1: 0.68544, l2: 0.31509\n",
            "Loss: 5.630729e-05, l1: 0.68593, l2: 0.31506\n",
            "Loss: 5.628068e-05, l1: 0.68648, l2: 0.31502\n",
            "Loss: 5.626716e-05, l1: 0.68671, l2: 0.31498\n",
            "Loss: 5.625319e-05, l1: 0.68688, l2: 0.31499\n",
            "Loss: 5.623820e-05, l1: 0.68669, l2: 0.31500\n",
            "Loss: 5.622489e-05, l1: 0.68695, l2: 0.31501\n",
            "Loss: 5.620682e-05, l1: 0.68668, l2: 0.31504\n",
            "Loss: 5.617172e-05, l1: 0.68662, l2: 0.31509\n",
            "Loss: 5.614072e-05, l1: 0.68660, l2: 0.31518\n",
            "Loss: 5.610802e-05, l1: 0.68699, l2: 0.31527\n",
            "Loss: 5.608940e-05, l1: 0.68753, l2: 0.31530\n",
            "Loss: 5.607067e-05, l1: 0.68779, l2: 0.31531\n",
            "Loss: 5.604864e-05, l1: 0.68810, l2: 0.31527\n",
            "Loss: 5.602978e-05, l1: 0.68787, l2: 0.31524\n",
            "Loss: 5.601442e-05, l1: 0.68784, l2: 0.31521\n",
            "Loss: 5.599589e-05, l1: 0.68756, l2: 0.31519\n",
            "Loss: 5.597210e-05, l1: 0.68761, l2: 0.31517\n",
            "Loss: 5.594680e-05, l1: 0.68768, l2: 0.31517\n",
            "Loss: 5.592258e-05, l1: 0.68799, l2: 0.31512\n",
            "Loss: 5.602189e-05, l1: 0.68793, l2: 0.31512\n",
            "Loss: 5.590869e-05, l1: 0.68798, l2: 0.31512\n",
            "Loss: 5.589143e-05, l1: 0.68816, l2: 0.31510\n",
            "Loss: 5.587677e-05, l1: 0.68820, l2: 0.31506\n",
            "Loss: 5.586224e-05, l1: 0.68808, l2: 0.31503\n",
            "Loss: 5.584373e-05, l1: 0.68765, l2: 0.31500\n",
            "Loss: 5.583606e-05, l1: 0.68760, l2: 0.31498\n",
            "Loss: 5.582977e-05, l1: 0.68745, l2: 0.31497\n",
            "Loss: 5.582604e-05, l1: 0.68744, l2: 0.31497\n",
            "Loss: 5.580610e-05, l1: 0.68744, l2: 0.31487\n",
            "Loss: 5.578822e-05, l1: 0.68736, l2: 0.31486\n",
            "Loss: 5.576346e-05, l1: 0.68729, l2: 0.31484\n",
            "Loss: 5.575240e-05, l1: 0.68716, l2: 0.31481\n",
            "Loss: 5.574104e-05, l1: 0.68710, l2: 0.31479\n",
            "Loss: 5.575096e-05, l1: 0.68655, l2: 0.31468\n",
            "Loss: 5.574037e-05, l1: 0.68693, l2: 0.31476\n",
            "Loss: 5.573019e-05, l1: 0.68714, l2: 0.31478\n",
            "Loss: 5.579798e-05, l1: 0.68670, l2: 0.31461\n",
            "Loss: 5.572334e-05, l1: 0.68704, l2: 0.31474\n",
            "Loss: 5.571169e-05, l1: 0.68728, l2: 0.31474\n",
            "Loss: 5.569611e-05, l1: 0.68770, l2: 0.31472\n",
            "Loss: 5.568215e-05, l1: 0.68776, l2: 0.31472\n",
            "Loss: 5.566418e-05, l1: 0.68772, l2: 0.31473\n",
            "Loss: 5.563073e-05, l1: 0.68762, l2: 0.31467\n",
            "Loss: 5.559697e-05, l1: 0.68711, l2: 0.31463\n",
            "Loss: 5.557310e-05, l1: 0.68729, l2: 0.31462\n",
            "Loss: 5.555705e-05, l1: 0.68727, l2: 0.31461\n",
            "Loss: 5.554800e-05, l1: 0.68746, l2: 0.31461\n",
            "Loss: 5.552925e-05, l1: 0.68782, l2: 0.31461\n",
            "Loss: 5.551516e-05, l1: 0.68792, l2: 0.31462\n",
            "Loss: 5.556009e-05, l1: 0.68832, l2: 0.31445\n",
            "Loss: 5.550300e-05, l1: 0.68805, l2: 0.31456\n",
            "Loss: 5.547358e-05, l1: 0.68754, l2: 0.31461\n",
            "Loss: 5.545103e-05, l1: 0.68688, l2: 0.31463\n",
            "Loss: 5.543012e-05, l1: 0.68625, l2: 0.31466\n",
            "Loss: 5.540813e-05, l1: 0.68588, l2: 0.31467\n",
            "Loss: 5.538676e-05, l1: 0.68572, l2: 0.31469\n",
            "Loss: 5.535889e-05, l1: 0.68583, l2: 0.31474\n",
            "Loss: 5.534754e-05, l1: 0.68581, l2: 0.31472\n",
            "Loss: 5.533890e-05, l1: 0.68593, l2: 0.31472\n",
            "Loss: 5.531446e-05, l1: 0.68626, l2: 0.31473\n",
            "Loss: 5.529651e-05, l1: 0.68650, l2: 0.31473\n",
            "Loss: 5.529624e-05, l1: 0.68665, l2: 0.31480\n",
            "Loss: 5.528102e-05, l1: 0.68657, l2: 0.31477\n",
            "Loss: 5.525764e-05, l1: 0.68655, l2: 0.31479\n",
            "Loss: 5.524496e-05, l1: 0.68643, l2: 0.31480\n",
            "Loss: 5.523275e-05, l1: 0.68637, l2: 0.31481\n",
            "Loss: 5.521854e-05, l1: 0.68625, l2: 0.31483\n",
            "Loss: 5.520896e-05, l1: 0.68624, l2: 0.31484\n",
            "Loss: 5.518748e-05, l1: 0.68617, l2: 0.31484\n",
            "Loss: 5.517438e-05, l1: 0.68612, l2: 0.31484\n",
            "Loss: 5.515552e-05, l1: 0.68619, l2: 0.31485\n",
            "Loss: 5.512797e-05, l1: 0.68613, l2: 0.31489\n",
            "Loss: 5.508733e-05, l1: 0.68639, l2: 0.31499\n",
            "Loss: 5.503149e-05, l1: 0.68668, l2: 0.31518\n",
            "Loss: 5.500046e-05, l1: 0.68670, l2: 0.31532\n",
            "Loss: 5.498833e-05, l1: 0.68670, l2: 0.31538\n",
            "Loss: 5.497652e-05, l1: 0.68647, l2: 0.31542\n",
            "Loss: 5.496670e-05, l1: 0.68630, l2: 0.31547\n",
            "Loss: 5.495025e-05, l1: 0.68612, l2: 0.31554\n",
            "Loss: 5.494541e-05, l1: 0.68665, l2: 0.31562\n",
            "Loss: 5.493060e-05, l1: 0.68651, l2: 0.31563\n",
            "Loss: 5.492280e-05, l1: 0.68656, l2: 0.31563\n",
            "Loss: 5.491505e-05, l1: 0.68691, l2: 0.31564\n",
            "Loss: 5.490833e-05, l1: 0.68677, l2: 0.31564\n",
            "Loss: 5.490046e-05, l1: 0.68662, l2: 0.31564\n",
            "Loss: 5.489193e-05, l1: 0.68643, l2: 0.31565\n",
            "Loss: 5.488192e-05, l1: 0.68634, l2: 0.31565\n",
            "Loss: 5.486494e-05, l1: 0.68643, l2: 0.31565\n",
            "Loss: 5.485450e-05, l1: 0.68674, l2: 0.31562\n",
            "Loss: 5.485495e-05, l1: 0.68694, l2: 0.31554\n",
            "Loss: 5.484746e-05, l1: 0.68684, l2: 0.31558\n",
            "Loss: 5.483851e-05, l1: 0.68731, l2: 0.31552\n",
            "Loss: 5.482890e-05, l1: 0.68757, l2: 0.31550\n",
            "Loss: 5.481358e-05, l1: 0.68787, l2: 0.31546\n",
            "Loss: 5.480849e-05, l1: 0.68803, l2: 0.31549\n",
            "Loss: 5.479284e-05, l1: 0.68796, l2: 0.31547\n",
            "Loss: 5.478486e-05, l1: 0.68774, l2: 0.31549\n",
            "Loss: 5.476970e-05, l1: 0.68750, l2: 0.31551\n",
            "Loss: 5.475750e-05, l1: 0.68721, l2: 0.31554\n",
            "Loss: 5.474630e-05, l1: 0.68704, l2: 0.31554\n",
            "Loss: 5.473178e-05, l1: 0.68705, l2: 0.31553\n",
            "Loss: 5.472001e-05, l1: 0.68706, l2: 0.31548\n",
            "Loss: 5.470985e-05, l1: 0.68708, l2: 0.31544\n",
            "Loss: 5.469872e-05, l1: 0.68707, l2: 0.31538\n",
            "Loss: 5.468300e-05, l1: 0.68689, l2: 0.31535\n",
            "Loss: 5.466517e-05, l1: 0.68671, l2: 0.31533\n",
            "Loss: 5.464094e-05, l1: 0.68652, l2: 0.31530\n",
            "Loss: 5.462109e-05, l1: 0.68639, l2: 0.31530\n",
            "Loss: 5.460603e-05, l1: 0.68627, l2: 0.31533\n",
            "Loss: 5.458003e-05, l1: 0.68593, l2: 0.31538\n",
            "Loss: 5.456312e-05, l1: 0.68526, l2: 0.31538\n",
            "Loss: 5.452718e-05, l1: 0.68486, l2: 0.31537\n",
            "Loss: 5.449156e-05, l1: 0.68456, l2: 0.31540\n",
            "Loss: 5.445637e-05, l1: 0.68423, l2: 0.31541\n",
            "Loss: 5.442270e-05, l1: 0.68383, l2: 0.31533\n",
            "Loss: 5.438497e-05, l1: 0.68338, l2: 0.31529\n",
            "Loss: 5.435338e-05, l1: 0.68264, l2: 0.31529\n",
            "Loss: 5.434168e-05, l1: 0.68197, l2: 0.31531\n",
            "Loss: 5.432876e-05, l1: 0.68169, l2: 0.31537\n",
            "Loss: 5.431344e-05, l1: 0.68120, l2: 0.31541\n",
            "Loss: 5.428191e-05, l1: 0.68035, l2: 0.31548\n",
            "Loss: 5.424566e-05, l1: 0.67994, l2: 0.31553\n",
            "Loss: 5.419840e-05, l1: 0.67835, l2: 0.31556\n",
            "Loss: 5.414712e-05, l1: 0.67911, l2: 0.31553\n",
            "Loss: 5.410256e-05, l1: 0.67874, l2: 0.31559\n",
            "Loss: 5.406009e-05, l1: 0.67770, l2: 0.31564\n",
            "Loss: 5.402992e-05, l1: 0.67715, l2: 0.31553\n",
            "Loss: 5.400833e-05, l1: 0.67708, l2: 0.31546\n",
            "Loss: 5.398956e-05, l1: 0.67705, l2: 0.31546\n",
            "Loss: 5.396580e-05, l1: 0.67686, l2: 0.31549\n",
            "Loss: 5.395005e-05, l1: 0.67659, l2: 0.31555\n",
            "Loss: 5.393729e-05, l1: 0.67627, l2: 0.31560\n",
            "Loss: 5.393091e-05, l1: 0.67584, l2: 0.31562\n",
            "Loss: 5.393365e-05, l1: 0.67592, l2: 0.31563\n",
            "Loss: 5.392972e-05, l1: 0.67588, l2: 0.31562\n",
            "Loss: 5.392237e-05, l1: 0.67570, l2: 0.31562\n",
            "Loss: 5.391426e-05, l1: 0.67567, l2: 0.31563\n",
            "Loss: 5.390541e-05, l1: 0.67556, l2: 0.31561\n",
            "Loss: 5.389398e-05, l1: 0.67553, l2: 0.31566\n",
            "Loss: 5.387825e-05, l1: 0.67589, l2: 0.31560\n",
            "Loss: 5.386558e-05, l1: 0.67586, l2: 0.31556\n",
            "Loss: 5.385118e-05, l1: 0.67579, l2: 0.31552\n",
            "Loss: 5.383644e-05, l1: 0.67551, l2: 0.31550\n",
            "Loss: 5.382042e-05, l1: 0.67538, l2: 0.31551\n",
            "Loss: 5.379917e-05, l1: 0.67512, l2: 0.31558\n",
            "Loss: 5.378562e-05, l1: 0.67477, l2: 0.31565\n",
            "Loss: 5.376619e-05, l1: 0.67453, l2: 0.31566\n",
            "Loss: 5.374633e-05, l1: 0.67439, l2: 0.31560\n",
            "Loss: 5.373622e-05, l1: 0.67418, l2: 0.31556\n",
            "Loss: 5.373004e-05, l1: 0.67415, l2: 0.31552\n",
            "Loss: 5.372205e-05, l1: 0.67406, l2: 0.31550\n",
            "Loss: 5.371562e-05, l1: 0.67401, l2: 0.31549\n",
            "Loss: 5.370588e-05, l1: 0.67389, l2: 0.31549\n",
            "Loss: 5.369810e-05, l1: 0.67381, l2: 0.31550\n",
            "Loss: 5.368148e-05, l1: 0.67357, l2: 0.31547\n",
            "Loss: 5.365357e-05, l1: 0.67321, l2: 0.31542\n",
            "Loss: 5.361572e-05, l1: 0.67292, l2: 0.31532\n",
            "Loss: 5.358012e-05, l1: 0.67279, l2: 0.31522\n",
            "Loss: 5.354882e-05, l1: 0.67268, l2: 0.31511\n",
            "Loss: 5.351454e-05, l1: 0.67292, l2: 0.31501\n",
            "Loss: 5.348541e-05, l1: 0.67316, l2: 0.31498\n",
            "Loss: 5.346560e-05, l1: 0.67345, l2: 0.31499\n",
            "Loss: 5.343542e-05, l1: 0.67372, l2: 0.31500\n",
            "Loss: 5.339064e-05, l1: 0.67398, l2: 0.31506\n",
            "Loss: 5.337531e-05, l1: 0.67417, l2: 0.31511\n",
            "Loss: 5.336909e-05, l1: 0.67405, l2: 0.31513\n",
            "Loss: 5.336238e-05, l1: 0.67403, l2: 0.31513\n",
            "Loss: 5.335661e-05, l1: 0.67412, l2: 0.31513\n",
            "Loss: 5.334829e-05, l1: 0.67404, l2: 0.31514\n",
            "Loss: 5.334013e-05, l1: 0.67407, l2: 0.31514\n",
            "Loss: 5.332987e-05, l1: 0.67376, l2: 0.31512\n",
            "Loss: 5.331395e-05, l1: 0.67333, l2: 0.31513\n",
            "Loss: 5.330065e-05, l1: 0.67248, l2: 0.31512\n",
            "Loss: 5.328446e-05, l1: 0.67235, l2: 0.31512\n",
            "Loss: 5.327027e-05, l1: 0.67232, l2: 0.31514\n",
            "Loss: 5.325396e-05, l1: 0.67197, l2: 0.31519\n",
            "Loss: 5.323108e-05, l1: 0.67182, l2: 0.31525\n",
            "Loss: 5.319370e-05, l1: 0.67149, l2: 0.31529\n",
            "Loss: 5.314545e-05, l1: 0.67114, l2: 0.31528\n",
            "Loss: 5.365247e-05, l1: 0.67164, l2: 0.31547\n",
            "Loss: 5.312614e-05, l1: 0.67122, l2: 0.31531\n",
            "Loss: 5.306859e-05, l1: 0.67126, l2: 0.31527\n",
            "Loss: 5.300122e-05, l1: 0.67164, l2: 0.31518\n",
            "Loss: 5.295701e-05, l1: 0.67184, l2: 0.31511\n",
            "Loss: 5.292756e-05, l1: 0.67218, l2: 0.31510\n",
            "Loss: 5.289957e-05, l1: 0.67233, l2: 0.31512\n",
            "Loss: 5.286805e-05, l1: 0.67283, l2: 0.31510\n",
            "Loss: 5.284887e-05, l1: 0.67311, l2: 0.31508\n",
            "Loss: 5.281860e-05, l1: 0.67319, l2: 0.31506\n",
            "Loss: 5.278088e-05, l1: 0.67385, l2: 0.31503\n",
            "Loss: 5.273436e-05, l1: 0.67322, l2: 0.31511\n",
            "Loss: 5.270348e-05, l1: 0.67314, l2: 0.31513\n",
            "Loss: 5.268075e-05, l1: 0.67254, l2: 0.31517\n",
            "Loss: 5.266783e-05, l1: 0.67269, l2: 0.31518\n",
            "Loss: 5.264955e-05, l1: 0.67262, l2: 0.31518\n",
            "Loss: 5.262194e-05, l1: 0.67240, l2: 0.31517\n",
            "Loss: 5.259345e-05, l1: 0.67277, l2: 0.31515\n",
            "Loss: 5.254966e-05, l1: 0.67307, l2: 0.31515\n",
            "Loss: 5.250940e-05, l1: 0.67317, l2: 0.31520\n",
            "Loss: 5.246390e-05, l1: 0.67352, l2: 0.31523\n",
            "Loss: 5.242629e-05, l1: 0.67373, l2: 0.31525\n",
            "Loss: 5.239011e-05, l1: 0.67378, l2: 0.31525\n",
            "Loss: 5.236408e-05, l1: 0.67440, l2: 0.31526\n",
            "Loss: 5.233867e-05, l1: 0.67469, l2: 0.31526\n",
            "Loss: 5.229831e-05, l1: 0.67542, l2: 0.31524\n",
            "Loss: 5.224862e-05, l1: 0.67622, l2: 0.31520\n",
            "Loss: 5.221236e-05, l1: 0.67770, l2: 0.31513\n",
            "Loss: 5.218507e-05, l1: 0.67713, l2: 0.31513\n",
            "Loss: 5.217125e-05, l1: 0.67712, l2: 0.31511\n",
            "Loss: 5.215531e-05, l1: 0.67751, l2: 0.31510\n",
            "Loss: 5.212994e-05, l1: 0.67836, l2: 0.31507\n",
            "Loss: 5.210574e-05, l1: 0.67894, l2: 0.31506\n",
            "Loss: 5.207657e-05, l1: 0.67933, l2: 0.31510\n",
            "Loss: 5.205789e-05, l1: 0.67939, l2: 0.31511\n",
            "Loss: 5.204203e-05, l1: 0.67992, l2: 0.31512\n",
            "Loss: 5.202138e-05, l1: 0.68040, l2: 0.31509\n",
            "Loss: 5.199988e-05, l1: 0.68131, l2: 0.31507\n",
            "Loss: 5.198336e-05, l1: 0.68145, l2: 0.31502\n",
            "Loss: 5.196816e-05, l1: 0.68166, l2: 0.31493\n",
            "Loss: 5.195395e-05, l1: 0.68165, l2: 0.31483\n",
            "Loss: 5.193982e-05, l1: 0.68212, l2: 0.31473\n",
            "Loss: 5.192184e-05, l1: 0.68225, l2: 0.31472\n",
            "Loss: 5.190149e-05, l1: 0.68270, l2: 0.31474\n",
            "Loss: 5.188390e-05, l1: 0.68280, l2: 0.31482\n",
            "Loss: 5.186656e-05, l1: 0.68313, l2: 0.31488\n",
            "Loss: 5.185155e-05, l1: 0.68290, l2: 0.31494\n",
            "Loss: 5.183205e-05, l1: 0.68282, l2: 0.31495\n",
            "Loss: 5.180945e-05, l1: 0.68252, l2: 0.31494\n",
            "Loss: 5.177506e-05, l1: 0.68243, l2: 0.31491\n",
            "Loss: 5.174486e-05, l1: 0.68222, l2: 0.31483\n",
            "Loss: 5.172462e-05, l1: 0.68238, l2: 0.31482\n",
            "Loss: 5.171132e-05, l1: 0.68250, l2: 0.31484\n",
            "Loss: 5.170463e-05, l1: 0.68244, l2: 0.31487\n",
            "Loss: 5.169376e-05, l1: 0.68238, l2: 0.31492\n",
            "Loss: 5.168093e-05, l1: 0.68219, l2: 0.31497\n",
            "Loss: 5.166438e-05, l1: 0.68196, l2: 0.31501\n",
            "Loss: 5.170084e-05, l1: 0.68177, l2: 0.31520\n",
            "Loss: 5.165494e-05, l1: 0.68190, l2: 0.31507\n",
            "Loss: 5.162973e-05, l1: 0.68180, l2: 0.31512\n",
            "Loss: 5.158947e-05, l1: 0.68180, l2: 0.31520\n",
            "Loss: 5.156054e-05, l1: 0.68075, l2: 0.31545\n",
            "Loss: 5.151680e-05, l1: 0.68094, l2: 0.31547\n",
            "Loss: 5.147853e-05, l1: 0.68086, l2: 0.31556\n",
            "Loss: 5.145815e-05, l1: 0.68075, l2: 0.31563\n",
            "Loss: 5.143191e-05, l1: 0.68070, l2: 0.31573\n",
            "Loss: 5.138840e-05, l1: 0.68112, l2: 0.31576\n",
            "Loss: 5.134138e-05, l1: 0.68157, l2: 0.31576\n",
            "Loss: 5.131007e-05, l1: 0.68218, l2: 0.31574\n",
            "Loss: 5.128237e-05, l1: 0.68208, l2: 0.31571\n",
            "Loss: 5.126353e-05, l1: 0.68233, l2: 0.31568\n",
            "Loss: 5.122797e-05, l1: 0.68263, l2: 0.31568\n",
            "Loss: 5.120525e-05, l1: 0.68325, l2: 0.31570\n",
            "Loss: 5.120323e-05, l1: 0.68242, l2: 0.31564\n",
            "Loss: 5.118101e-05, l1: 0.68284, l2: 0.31567\n",
            "Loss: 5.115772e-05, l1: 0.68287, l2: 0.31568\n",
            "Loss: 5.114180e-05, l1: 0.68284, l2: 0.31571\n",
            "Loss: 5.112208e-05, l1: 0.68315, l2: 0.31572\n",
            "Loss: 5.109890e-05, l1: 0.68341, l2: 0.31569\n",
            "Loss: 5.108599e-05, l1: 0.68460, l2: 0.31564\n",
            "Loss: 5.106525e-05, l1: 0.68399, l2: 0.31562\n",
            "Loss: 5.104281e-05, l1: 0.68360, l2: 0.31563\n",
            "Loss: 5.103190e-05, l1: 0.68388, l2: 0.31568\n",
            "Loss: 5.102132e-05, l1: 0.68395, l2: 0.31567\n",
            "Loss: 5.099620e-05, l1: 0.68395, l2: 0.31565\n",
            "Loss: 5.098883e-05, l1: 0.68352, l2: 0.31568\n",
            "Loss: 5.094863e-05, l1: 0.68347, l2: 0.31562\n",
            "Loss: 5.092007e-05, l1: 0.68287, l2: 0.31561\n",
            "Loss: 5.087811e-05, l1: 0.68217, l2: 0.31558\n",
            "Loss: 5.083971e-05, l1: 0.68135, l2: 0.31559\n",
            "Loss: 5.082056e-05, l1: 0.68094, l2: 0.31559\n",
            "Loss: 5.080013e-05, l1: 0.68094, l2: 0.31558\n",
            "Loss: 5.078018e-05, l1: 0.68097, l2: 0.31559\n",
            "Loss: 5.077023e-05, l1: 0.68112, l2: 0.31557\n",
            "Loss: 5.075140e-05, l1: 0.68113, l2: 0.31554\n",
            "Loss: 5.073487e-05, l1: 0.68137, l2: 0.31549\n",
            "Loss: 5.072008e-05, l1: 0.68148, l2: 0.31546\n",
            "Loss: 5.070296e-05, l1: 0.68186, l2: 0.31542\n",
            "Loss: 5.068231e-05, l1: 0.68227, l2: 0.31541\n",
            "Loss: 5.065986e-05, l1: 0.68264, l2: 0.31541\n",
            "Loss: 5.064273e-05, l1: 0.68305, l2: 0.31544\n",
            "Loss: 5.063298e-05, l1: 0.68292, l2: 0.31544\n",
            "Loss: 5.062101e-05, l1: 0.68287, l2: 0.31543\n",
            "Loss: 5.060485e-05, l1: 0.68243, l2: 0.31545\n",
            "Loss: 5.057902e-05, l1: 0.68205, l2: 0.31543\n",
            "Loss: 5.054419e-05, l1: 0.68160, l2: 0.31537\n",
            "Loss: 5.052960e-05, l1: 0.68152, l2: 0.31535\n",
            "Loss: 5.052250e-05, l1: 0.68154, l2: 0.31532\n",
            "Loss: 5.051391e-05, l1: 0.68149, l2: 0.31532\n",
            "Loss: 5.050148e-05, l1: 0.68129, l2: 0.31531\n",
            "Loss: 5.048720e-05, l1: 0.68103, l2: 0.31534\n",
            "Loss: 5.047626e-05, l1: 0.68068, l2: 0.31540\n",
            "Loss: 5.046654e-05, l1: 0.68056, l2: 0.31544\n",
            "Loss: 5.045856e-05, l1: 0.68058, l2: 0.31547\n",
            "Loss: 5.045085e-05, l1: 0.68078, l2: 0.31550\n",
            "Loss: 5.044474e-05, l1: 0.68096, l2: 0.31552\n",
            "Loss: 5.044180e-05, l1: 0.68118, l2: 0.31553\n",
            "Loss: 5.043409e-05, l1: 0.68146, l2: 0.31555\n",
            "Loss: 5.042641e-05, l1: 0.68159, l2: 0.31557\n",
            "Loss: 5.041390e-05, l1: 0.68163, l2: 0.31559\n",
            "Loss: 5.040843e-05, l1: 0.68120, l2: 0.31566\n",
            "Loss: 5.039331e-05, l1: 0.68107, l2: 0.31563\n",
            "Loss: 5.038837e-05, l1: 0.68100, l2: 0.31560\n",
            "Loss: 5.038084e-05, l1: 0.68077, l2: 0.31556\n",
            "Loss: 5.037509e-05, l1: 0.68088, l2: 0.31552\n",
            "Loss: 5.036988e-05, l1: 0.68084, l2: 0.31549\n",
            "Loss: 5.036383e-05, l1: 0.68099, l2: 0.31548\n",
            "Loss: 5.036191e-05, l1: 0.68121, l2: 0.31547\n",
            "Loss: 5.035901e-05, l1: 0.68123, l2: 0.31548\n",
            "Loss: 5.035650e-05, l1: 0.68132, l2: 0.31549\n",
            "Loss: 5.035430e-05, l1: 0.68138, l2: 0.31549\n",
            "Loss: 5.035077e-05, l1: 0.68139, l2: 0.31549\n",
            "Loss: 5.034663e-05, l1: 0.68159, l2: 0.31547\n",
            "Loss: 5.034345e-05, l1: 0.68143, l2: 0.31552\n",
            "Loss: 5.033618e-05, l1: 0.68147, l2: 0.31549\n",
            "Loss: 5.032313e-05, l1: 0.68148, l2: 0.31544\n",
            "Loss: 5.030702e-05, l1: 0.68148, l2: 0.31541\n",
            "Loss: 5.030081e-05, l1: 0.68151, l2: 0.31547\n",
            "Loss: 5.027242e-05, l1: 0.68135, l2: 0.31540\n",
            "Loss: 5.026396e-05, l1: 0.68134, l2: 0.31542\n",
            "Loss: 5.026077e-05, l1: 0.68136, l2: 0.31545\n",
            "Loss: 5.025760e-05, l1: 0.68138, l2: 0.31547\n",
            "Loss: 5.025146e-05, l1: 0.68143, l2: 0.31549\n",
            "Loss: 5.024427e-05, l1: 0.68148, l2: 0.31549\n",
            "Loss: 5.023857e-05, l1: 0.68160, l2: 0.31547\n",
            "Loss: 5.022843e-05, l1: 0.68163, l2: 0.31541\n",
            "Loss: 5.021947e-05, l1: 0.68159, l2: 0.31537\n",
            "Loss: 5.020980e-05, l1: 0.68127, l2: 0.31533\n",
            "Loss: 5.020096e-05, l1: 0.68112, l2: 0.31534\n",
            "Loss: 5.019393e-05, l1: 0.67999, l2: 0.31537\n",
            "Loss: 5.018773e-05, l1: 0.68035, l2: 0.31538\n",
            "Loss: 5.018181e-05, l1: 0.68047, l2: 0.31541\n",
            "Loss: 5.017768e-05, l1: 0.68046, l2: 0.31543\n",
            "Loss: 5.016899e-05, l1: 0.68042, l2: 0.31545\n",
            "Loss: 5.016029e-05, l1: 0.68034, l2: 0.31542\n",
            "Loss: 5.015273e-05, l1: 0.68029, l2: 0.31540\n",
            "Loss: 5.014133e-05, l1: 0.68023, l2: 0.31537\n",
            "Loss: 5.013897e-05, l1: 0.68025, l2: 0.31537\n",
            "Loss: 5.011811e-05, l1: 0.68030, l2: 0.31535\n",
            "Loss: 5.010819e-05, l1: 0.68031, l2: 0.31535\n",
            "Loss: 5.009732e-05, l1: 0.68029, l2: 0.31536\n",
            "Loss: 5.008256e-05, l1: 0.68016, l2: 0.31541\n",
            "Loss: 5.006589e-05, l1: 0.67995, l2: 0.31546\n",
            "Loss: 5.004864e-05, l1: 0.67992, l2: 0.31553\n",
            "Loss: 5.001693e-05, l1: 0.67892, l2: 0.31567\n",
            "Loss: 4.998915e-05, l1: 0.67915, l2: 0.31564\n",
            "Loss: 4.995170e-05, l1: 0.67938, l2: 0.31564\n",
            "Loss: 5.003674e-05, l1: 0.67882, l2: 0.31554\n",
            "Loss: 4.994672e-05, l1: 0.67928, l2: 0.31562\n",
            "Loss: 4.993202e-05, l1: 0.67932, l2: 0.31565\n",
            "Loss: 4.990762e-05, l1: 0.67916, l2: 0.31573\n",
            "Loss: 4.987268e-05, l1: 0.67891, l2: 0.31584\n",
            "Loss: 4.983203e-05, l1: 0.67841, l2: 0.31597\n",
            "Loss: 4.980469e-05, l1: 0.67826, l2: 0.31609\n",
            "Loss: 4.978255e-05, l1: 0.67814, l2: 0.31610\n",
            "Loss: 4.976417e-05, l1: 0.67826, l2: 0.31609\n",
            "Loss: 4.974972e-05, l1: 0.67822, l2: 0.31611\n",
            "Loss: 4.973430e-05, l1: 0.67842, l2: 0.31615\n",
            "Loss: 4.971134e-05, l1: 0.67857, l2: 0.31618\n",
            "Loss: 4.970009e-05, l1: 0.67787, l2: 0.31630\n",
            "Loss: 4.965697e-05, l1: 0.67887, l2: 0.31625\n",
            "Loss: 4.964174e-05, l1: 0.67889, l2: 0.31624\n",
            "Loss: 4.962314e-05, l1: 0.67900, l2: 0.31622\n",
            "Loss: 4.959689e-05, l1: 0.67996, l2: 0.31628\n",
            "Loss: 4.957422e-05, l1: 0.67978, l2: 0.31631\n",
            "Loss: 4.955297e-05, l1: 0.67976, l2: 0.31634\n",
            "Loss: 4.952604e-05, l1: 0.67970, l2: 0.31646\n",
            "Loss: 4.949780e-05, l1: 0.68039, l2: 0.31653\n",
            "Loss: 4.946451e-05, l1: 0.68055, l2: 0.31659\n",
            "Loss: 4.940586e-05, l1: 0.68072, l2: 0.31656\n",
            "Loss: 4.938370e-05, l1: 0.68126, l2: 0.31652\n",
            "Loss: 4.935807e-05, l1: 0.68122, l2: 0.31651\n",
            "Loss: 4.933020e-05, l1: 0.68081, l2: 0.31646\n",
            "Loss: 4.929000e-05, l1: 0.68058, l2: 0.31652\n",
            "Loss: 4.928301e-05, l1: 0.67943, l2: 0.31644\n",
            "Loss: 4.923387e-05, l1: 0.67992, l2: 0.31652\n",
            "Loss: 4.921496e-05, l1: 0.68019, l2: 0.31655\n",
            "Loss: 4.918325e-05, l1: 0.68019, l2: 0.31658\n",
            "Loss: 4.915522e-05, l1: 0.68044, l2: 0.31655\n",
            "Loss: 4.911625e-05, l1: 0.68046, l2: 0.31653\n",
            "Loss: 4.909893e-05, l1: 0.68211, l2: 0.31635\n",
            "Loss: 4.907179e-05, l1: 0.68131, l2: 0.31644\n",
            "Loss: 4.900032e-05, l1: 0.68156, l2: 0.31643\n",
            "Loss: 4.890593e-05, l1: 0.68248, l2: 0.31647\n",
            "Loss: 4.883391e-05, l1: 0.68296, l2: 0.31651\n",
            "Loss: 4.877024e-05, l1: 0.68369, l2: 0.31652\n",
            "Loss: 4.868620e-05, l1: 0.68450, l2: 0.31648\n",
            "Loss: 4.871418e-05, l1: 0.68624, l2: 0.31640\n",
            "Loss: 4.866601e-05, l1: 0.68520, l2: 0.31645\n",
            "Loss: 4.863695e-05, l1: 0.68544, l2: 0.31640\n",
            "Loss: 4.861561e-05, l1: 0.68599, l2: 0.31633\n",
            "Loss: 4.859871e-05, l1: 0.68604, l2: 0.31627\n",
            "Loss: 4.857007e-05, l1: 0.68648, l2: 0.31623\n",
            "Loss: 4.853834e-05, l1: 0.68664, l2: 0.31625\n",
            "Loss: 4.849565e-05, l1: 0.68699, l2: 0.31620\n",
            "Loss: 4.844655e-05, l1: 0.68779, l2: 0.31645\n",
            "Loss: 4.835171e-05, l1: 0.68730, l2: 0.31646\n",
            "Loss: 4.821505e-05, l1: 0.68731, l2: 0.31644\n",
            "Loss: 4.815842e-05, l1: 0.68716, l2: 0.31658\n",
            "Loss: 4.811726e-05, l1: 0.68813, l2: 0.31663\n",
            "Loss: 4.808876e-05, l1: 0.68857, l2: 0.31662\n",
            "Loss: 4.801250e-05, l1: 0.68941, l2: 0.31657\n",
            "Loss: 4.790326e-05, l1: 0.69000, l2: 0.31640\n",
            "Loss: 4.785663e-05, l1: 0.68990, l2: 0.31634\n",
            "Loss: 4.775618e-05, l1: 0.68967, l2: 0.31623\n",
            "Loss: 4.770946e-05, l1: 0.68996, l2: 0.31623\n",
            "Loss: 4.767618e-05, l1: 0.68964, l2: 0.31625\n",
            "Loss: 4.763965e-05, l1: 0.68968, l2: 0.31623\n",
            "Loss: 4.761750e-05, l1: 0.68957, l2: 0.31618\n",
            "Loss: 4.758803e-05, l1: 0.68988, l2: 0.31624\n",
            "Loss: 4.756801e-05, l1: 0.68993, l2: 0.31630\n",
            "Loss: 4.753630e-05, l1: 0.69003, l2: 0.31639\n",
            "Loss: 4.747970e-05, l1: 0.69028, l2: 0.31643\n",
            "Loss: 4.756425e-05, l1: 0.69048, l2: 0.31675\n",
            "Loss: 4.744618e-05, l1: 0.69035, l2: 0.31654\n",
            "Loss: 4.738048e-05, l1: 0.68990, l2: 0.31658\n",
            "Loss: 4.731113e-05, l1: 0.69033, l2: 0.31642\n",
            "Loss: 4.725460e-05, l1: 0.69003, l2: 0.31638\n",
            "Loss: 4.720679e-05, l1: 0.68988, l2: 0.31634\n",
            "Loss: 4.716849e-05, l1: 0.69001, l2: 0.31632\n",
            "Loss: 4.714013e-05, l1: 0.68993, l2: 0.31633\n",
            "Loss: 4.710857e-05, l1: 0.69008, l2: 0.31631\n",
            "Loss: 4.707592e-05, l1: 0.69009, l2: 0.31630\n",
            "Loss: 4.701583e-05, l1: 0.68977, l2: 0.31613\n",
            "Loss: 4.699009e-05, l1: 0.68979, l2: 0.31607\n",
            "Loss: 4.695895e-05, l1: 0.68963, l2: 0.31600\n",
            "Loss: 4.693153e-05, l1: 0.68961, l2: 0.31589\n",
            "Loss: 4.690261e-05, l1: 0.68957, l2: 0.31581\n",
            "Loss: 4.687065e-05, l1: 0.68959, l2: 0.31574\n",
            "Loss: 4.683526e-05, l1: 0.68962, l2: 0.31575\n",
            "Loss: 4.679679e-05, l1: 0.68978, l2: 0.31580\n",
            "Loss: 4.675452e-05, l1: 0.69004, l2: 0.31586\n",
            "Loss: 4.670636e-05, l1: 0.69055, l2: 0.31586\n",
            "Loss: 4.665500e-05, l1: 0.69159, l2: 0.31577\n",
            "Loss: 4.663100e-05, l1: 0.69235, l2: 0.31572\n",
            "Loss: 4.661050e-05, l1: 0.69273, l2: 0.31563\n",
            "Loss: 4.659112e-05, l1: 0.69297, l2: 0.31553\n",
            "Loss: 4.657908e-05, l1: 0.69306, l2: 0.31537\n",
            "Loss: 4.655368e-05, l1: 0.69350, l2: 0.31535\n",
            "Loss: 4.652916e-05, l1: 0.69319, l2: 0.31541\n",
            "Loss: 4.649175e-05, l1: 0.69307, l2: 0.31548\n",
            "Loss: 4.658377e-05, l1: 0.69268, l2: 0.31553\n",
            "Loss: 4.646715e-05, l1: 0.69295, l2: 0.31550\n",
            "Loss: 4.641554e-05, l1: 0.69321, l2: 0.31551\n",
            "Loss: 4.638444e-05, l1: 0.69362, l2: 0.31544\n",
            "Loss: 4.635972e-05, l1: 0.69366, l2: 0.31541\n",
            "Loss: 4.635190e-05, l1: 0.69368, l2: 0.31532\n",
            "Loss: 4.632968e-05, l1: 0.69361, l2: 0.31532\n",
            "Loss: 4.632191e-05, l1: 0.69360, l2: 0.31533\n",
            "Loss: 4.631135e-05, l1: 0.69351, l2: 0.31532\n",
            "Loss: 4.630585e-05, l1: 0.69341, l2: 0.31532\n",
            "Loss: 4.629500e-05, l1: 0.69328, l2: 0.31534\n",
            "Loss: 4.628017e-05, l1: 0.69303, l2: 0.31535\n",
            "Loss: 4.626497e-05, l1: 0.69296, l2: 0.31541\n",
            "Loss: 4.624962e-05, l1: 0.69281, l2: 0.31545\n",
            "Loss: 4.623316e-05, l1: 0.69283, l2: 0.31549\n",
            "Loss: 4.621888e-05, l1: 0.69288, l2: 0.31553\n",
            "Loss: 4.620693e-05, l1: 0.69277, l2: 0.31556\n",
            "Loss: 4.618931e-05, l1: 0.69258, l2: 0.31558\n",
            "Loss: 4.617168e-05, l1: 0.69232, l2: 0.31558\n",
            "Loss: 4.615569e-05, l1: 0.69212, l2: 0.31556\n",
            "Loss: 4.613899e-05, l1: 0.69189, l2: 0.31553\n",
            "Loss: 4.612586e-05, l1: 0.69167, l2: 0.31551\n",
            "Loss: 4.611147e-05, l1: 0.69148, l2: 0.31553\n",
            "Loss: 4.609451e-05, l1: 0.69131, l2: 0.31555\n",
            "Loss: 4.605669e-05, l1: 0.69060, l2: 0.31562\n",
            "Loss: 4.603423e-05, l1: 0.68999, l2: 0.31565\n",
            "Loss: 4.612819e-05, l1: 0.68743, l2: 0.31581\n",
            "Loss: 4.602446e-05, l1: 0.68938, l2: 0.31569\n",
            "Loss: 4.599224e-05, l1: 0.68873, l2: 0.31573\n",
            "Loss: 4.596520e-05, l1: 0.68815, l2: 0.31575\n",
            "Loss: 4.593241e-05, l1: 0.68789, l2: 0.31580\n",
            "Loss: 4.590030e-05, l1: 0.68764, l2: 0.31581\n",
            "Loss: 4.587862e-05, l1: 0.68777, l2: 0.31583\n",
            "Loss: 4.589511e-05, l1: 0.68771, l2: 0.31592\n",
            "Loss: 4.587411e-05, l1: 0.68775, l2: 0.31586\n",
            "Loss: 4.586575e-05, l1: 0.68813, l2: 0.31587\n",
            "Loss: 4.585704e-05, l1: 0.68800, l2: 0.31587\n",
            "Loss: 4.585098e-05, l1: 0.68813, l2: 0.31584\n",
            "Loss: 4.584514e-05, l1: 0.68833, l2: 0.31583\n",
            "Loss: 4.584065e-05, l1: 0.68864, l2: 0.31588\n",
            "Loss: 4.583592e-05, l1: 0.68870, l2: 0.31587\n",
            "Loss: 4.583253e-05, l1: 0.68879, l2: 0.31586\n",
            "Loss: 4.583042e-05, l1: 0.68902, l2: 0.31585\n",
            "Loss: 4.582437e-05, l1: 0.68921, l2: 0.31585\n",
            "Loss: 4.582064e-05, l1: 0.68958, l2: 0.31583\n",
            "Loss: 4.581788e-05, l1: 0.68946, l2: 0.31585\n",
            "Loss: 4.581474e-05, l1: 0.68939, l2: 0.31585\n",
            "Loss: 4.581248e-05, l1: 0.68934, l2: 0.31583\n",
            "Loss: 4.580964e-05, l1: 0.68928, l2: 0.31583\n",
            "Loss: 4.580375e-05, l1: 0.68919, l2: 0.31581\n",
            "Loss: 4.608065e-05, l1: 0.68932, l2: 0.31579\n",
            "Loss: 4.580057e-05, l1: 0.68920, l2: 0.31581\n",
            "Loss: 4.579002e-05, l1: 0.68911, l2: 0.31580\n",
            "Loss: 4.579859e-05, l1: 0.68845, l2: 0.31585\n",
            "Loss: 4.578201e-05, l1: 0.68884, l2: 0.31582\n",
            "Loss: 4.576658e-05, l1: 0.68872, l2: 0.31581\n",
            "Loss: 4.574939e-05, l1: 0.68852, l2: 0.31580\n",
            "Loss: 4.572237e-05, l1: 0.68812, l2: 0.31577\n",
            "Loss: 4.570734e-05, l1: 0.68724, l2: 0.31575\n",
            "Loss: 4.568440e-05, l1: 0.68736, l2: 0.31573\n",
            "Loss: 4.566864e-05, l1: 0.68726, l2: 0.31569\n",
            "Loss: 4.565563e-05, l1: 0.68717, l2: 0.31567\n",
            "Loss: 4.564314e-05, l1: 0.68695, l2: 0.31564\n",
            "Loss: 4.562642e-05, l1: 0.68701, l2: 0.31563\n",
            "Loss: 4.560533e-05, l1: 0.68694, l2: 0.31561\n",
            "Loss: 4.557806e-05, l1: 0.68679, l2: 0.31567\n",
            "Loss: 4.555214e-05, l1: 0.68614, l2: 0.31570\n",
            "Loss: 4.552656e-05, l1: 0.68557, l2: 0.31580\n",
            "Loss: 4.550215e-05, l1: 0.68489, l2: 0.31586\n",
            "Loss: 4.547730e-05, l1: 0.68410, l2: 0.31588\n",
            "Loss: 4.546969e-05, l1: 0.68397, l2: 0.31583\n",
            "Loss: 4.546276e-05, l1: 0.68353, l2: 0.31584\n",
            "Loss: 4.544985e-05, l1: 0.68400, l2: 0.31579\n",
            "Loss: 4.544100e-05, l1: 0.68383, l2: 0.31578\n",
            "Loss: 4.543522e-05, l1: 0.68357, l2: 0.31577\n",
            "Loss: 4.542815e-05, l1: 0.68333, l2: 0.31577\n",
            "Loss: 4.542244e-05, l1: 0.68310, l2: 0.31578\n",
            "Loss: 4.541365e-05, l1: 0.68276, l2: 0.31583\n",
            "Loss: 4.540023e-05, l1: 0.68217, l2: 0.31587\n",
            "Loss: 4.539175e-05, l1: 0.68202, l2: 0.31593\n",
            "Loss: 4.538592e-05, l1: 0.68209, l2: 0.31590\n",
            "Loss: 4.538110e-05, l1: 0.68208, l2: 0.31588\n",
            "Loss: 4.537392e-05, l1: 0.68204, l2: 0.31585\n",
            "Loss: 4.536367e-05, l1: 0.68184, l2: 0.31581\n",
            "Loss: 4.536651e-05, l1: 0.68092, l2: 0.31576\n",
            "Loss: 4.535567e-05, l1: 0.68142, l2: 0.31579\n",
            "Loss: 4.534735e-05, l1: 0.68119, l2: 0.31578\n",
            "Loss: 4.538187e-05, l1: 0.68068, l2: 0.31574\n",
            "Loss: 4.533723e-05, l1: 0.68103, l2: 0.31577\n",
            "Loss: 4.532837e-05, l1: 0.68104, l2: 0.31575\n",
            "Loss: 4.531880e-05, l1: 0.68109, l2: 0.31571\n",
            "Loss: 4.531263e-05, l1: 0.68101, l2: 0.31567\n",
            "Loss: 4.530128e-05, l1: 0.68081, l2: 0.31561\n",
            "Loss: 4.530260e-05, l1: 0.68077, l2: 0.31556\n",
            "Loss: 4.529499e-05, l1: 0.68079, l2: 0.31559\n",
            "Loss: 4.528019e-05, l1: 0.68055, l2: 0.31553\n",
            "Loss: 4.526746e-05, l1: 0.68045, l2: 0.31552\n",
            "Loss: 4.524986e-05, l1: 0.68061, l2: 0.31552\n",
            "Loss: 4.523851e-05, l1: 0.68052, l2: 0.31549\n",
            "Loss: 4.522548e-05, l1: 0.68090, l2: 0.31552\n",
            "Loss: 4.521515e-05, l1: 0.68092, l2: 0.31553\n",
            "Loss: 4.520596e-05, l1: 0.68092, l2: 0.31551\n",
            "Loss: 4.519666e-05, l1: 0.68052, l2: 0.31548\n",
            "Loss: 4.518852e-05, l1: 0.68014, l2: 0.31543\n",
            "Loss: 4.518005e-05, l1: 0.67979, l2: 0.31540\n",
            "Loss: 4.517117e-05, l1: 0.67930, l2: 0.31538\n",
            "Loss: 4.516057e-05, l1: 0.67940, l2: 0.31536\n",
            "Loss: 4.515277e-05, l1: 0.67933, l2: 0.31538\n",
            "Loss: 4.513232e-05, l1: 0.67971, l2: 0.31540\n",
            "Loss: 4.511665e-05, l1: 0.68016, l2: 0.31541\n",
            "Loss: 4.510291e-05, l1: 0.68045, l2: 0.31536\n",
            "Loss: 4.509044e-05, l1: 0.68058, l2: 0.31528\n",
            "Loss: 4.508163e-05, l1: 0.68081, l2: 0.31527\n",
            "Loss: 4.507448e-05, l1: 0.68036, l2: 0.31525\n",
            "Loss: 4.506667e-05, l1: 0.68030, l2: 0.31526\n",
            "Loss: 4.506162e-05, l1: 0.68014, l2: 0.31526\n",
            "Loss: 4.505078e-05, l1: 0.67974, l2: 0.31526\n",
            "Loss: 4.503361e-05, l1: 0.67973, l2: 0.31522\n",
            "Loss: 4.501357e-05, l1: 0.67980, l2: 0.31518\n",
            "Loss: 4.500012e-05, l1: 0.67996, l2: 0.31516\n",
            "Loss: 4.499250e-05, l1: 0.68008, l2: 0.31518\n",
            "Loss: 4.498771e-05, l1: 0.68010, l2: 0.31522\n",
            "Loss: 4.498169e-05, l1: 0.68020, l2: 0.31520\n",
            "Loss: 4.496872e-05, l1: 0.68044, l2: 0.31520\n",
            "Loss: 4.495689e-05, l1: 0.68060, l2: 0.31518\n",
            "Loss: 4.494531e-05, l1: 0.68084, l2: 0.31518\n",
            "Loss: 4.493876e-05, l1: 0.68095, l2: 0.31518\n",
            "Loss: 4.492965e-05, l1: 0.68109, l2: 0.31516\n",
            "Loss: 4.492572e-05, l1: 0.68116, l2: 0.31517\n",
            "Loss: 4.494433e-05, l1: 0.68050, l2: 0.31523\n",
            "Loss: 4.492083e-05, l1: 0.68095, l2: 0.31519\n",
            "Loss: 4.491117e-05, l1: 0.68104, l2: 0.31517\n",
            "Loss: 4.489962e-05, l1: 0.68097, l2: 0.31515\n",
            "Loss: 4.488297e-05, l1: 0.68069, l2: 0.31509\n",
            "Loss: 4.487279e-05, l1: 0.68057, l2: 0.31505\n",
            "Loss: 4.485911e-05, l1: 0.68025, l2: 0.31502\n",
            "Loss: 4.485292e-05, l1: 0.68025, l2: 0.31503\n",
            "Loss: 4.484399e-05, l1: 0.68040, l2: 0.31503\n",
            "Loss: 4.483459e-05, l1: 0.68066, l2: 0.31504\n",
            "Loss: 4.482608e-05, l1: 0.68099, l2: 0.31504\n",
            "Loss: 4.481112e-05, l1: 0.68148, l2: 0.31504\n",
            "Loss: 4.479335e-05, l1: 0.68204, l2: 0.31502\n",
            "Loss: 4.477341e-05, l1: 0.68269, l2: 0.31500\n",
            "Loss: 4.475843e-05, l1: 0.68271, l2: 0.31499\n",
            "Loss: 4.474777e-05, l1: 0.68252, l2: 0.31499\n",
            "Loss: 4.474042e-05, l1: 0.68236, l2: 0.31499\n",
            "Loss: 4.472259e-05, l1: 0.68220, l2: 0.31499\n",
            "Loss: 4.470271e-05, l1: 0.68220, l2: 0.31499\n",
            "Loss: 4.467496e-05, l1: 0.68238, l2: 0.31501\n",
            "Loss: 4.465072e-05, l1: 0.68273, l2: 0.31505\n",
            "Loss: 4.463724e-05, l1: 0.68336, l2: 0.31511\n",
            "Loss: 4.462275e-05, l1: 0.68351, l2: 0.31517\n",
            "Loss: 4.461492e-05, l1: 0.68398, l2: 0.31521\n",
            "Loss: 4.460707e-05, l1: 0.68378, l2: 0.31520\n",
            "Loss: 4.459895e-05, l1: 0.68354, l2: 0.31518\n",
            "Loss: 4.459239e-05, l1: 0.68333, l2: 0.31517\n",
            "Loss: 4.458763e-05, l1: 0.68326, l2: 0.31517\n",
            "Loss: 4.457466e-05, l1: 0.68301, l2: 0.31519\n",
            "Loss: 4.456186e-05, l1: 0.68336, l2: 0.31521\n",
            "Loss: 4.454650e-05, l1: 0.68360, l2: 0.31519\n",
            "Loss: 4.452165e-05, l1: 0.68423, l2: 0.31514\n",
            "Loss: 4.451070e-05, l1: 0.68470, l2: 0.31512\n",
            "Loss: 4.449349e-05, l1: 0.68531, l2: 0.31512\n",
            "Loss: 4.448162e-05, l1: 0.68604, l2: 0.31513\n",
            "Loss: 4.446633e-05, l1: 0.68620, l2: 0.31515\n",
            "Loss: 4.444869e-05, l1: 0.68633, l2: 0.31517\n",
            "Loss: 4.441384e-05, l1: 0.68631, l2: 0.31520\n",
            "Loss: 4.438830e-05, l1: 0.68619, l2: 0.31514\n",
            "Loss: 4.434451e-05, l1: 0.68713, l2: 0.31493\n",
            "Loss: 4.429624e-05, l1: 0.68727, l2: 0.31474\n",
            "Loss: 4.427105e-05, l1: 0.68762, l2: 0.31472\n",
            "Loss: 4.424649e-05, l1: 0.68819, l2: 0.31469\n",
            "Loss: 4.421854e-05, l1: 0.68819, l2: 0.31466\n",
            "Loss: 4.418316e-05, l1: 0.68885, l2: 0.31468\n",
            "Loss: 4.415702e-05, l1: 0.68862, l2: 0.31473\n",
            "Loss: 4.411177e-05, l1: 0.68826, l2: 0.31481\n",
            "Loss: 4.406975e-05, l1: 0.68777, l2: 0.31480\n",
            "Loss: 4.402938e-05, l1: 0.68785, l2: 0.31473\n",
            "Loss: 4.396588e-05, l1: 0.68886, l2: 0.31459\n",
            "Loss: 4.391853e-05, l1: 0.68938, l2: 0.31444\n",
            "Loss: 4.385022e-05, l1: 0.69118, l2: 0.31433\n",
            "Loss: 4.379180e-05, l1: 0.69197, l2: 0.31434\n",
            "Loss: 4.399996e-05, l1: 0.69271, l2: 0.31434\n",
            "Loss: 4.376588e-05, l1: 0.69216, l2: 0.31434\n",
            "Loss: 4.371242e-05, l1: 0.69316, l2: 0.31426\n",
            "Loss: 4.365915e-05, l1: 0.69329, l2: 0.31420\n",
            "Loss: 4.359157e-05, l1: 0.69380, l2: 0.31416\n",
            "Loss: 4.357018e-05, l1: 0.69450, l2: 0.31417\n",
            "Loss: 4.356026e-05, l1: 0.69421, l2: 0.31418\n",
            "Loss: 4.353930e-05, l1: 0.69457, l2: 0.31418\n",
            "Loss: 4.351710e-05, l1: 0.69473, l2: 0.31420\n",
            "Loss: 4.349983e-05, l1: 0.69434, l2: 0.31424\n",
            "Loss: 4.346545e-05, l1: 0.69411, l2: 0.31427\n",
            "Loss: 4.337571e-05, l1: 0.69418, l2: 0.31443\n",
            "Loss: 4.326873e-05, l1: 0.69499, l2: 0.31447\n",
            "Loss: 4.314264e-05, l1: 0.69678, l2: 0.31449\n",
            "Loss: 4.306062e-05, l1: 0.69798, l2: 0.31456\n",
            "Loss: 4.298842e-05, l1: 0.69882, l2: 0.31452\n",
            "Loss: 4.289809e-05, l1: 0.69844, l2: 0.31456\n",
            "Loss: 4.282265e-05, l1: 0.69868, l2: 0.31458\n",
            "Loss: 4.276458e-05, l1: 0.69883, l2: 0.31468\n",
            "Loss: 4.270619e-05, l1: 0.69845, l2: 0.31471\n",
            "Loss: 4.266795e-05, l1: 0.69868, l2: 0.31474\n",
            "Loss: 4.260077e-05, l1: 0.69986, l2: 0.31480\n",
            "Loss: 4.257704e-05, l1: 0.69990, l2: 0.31474\n",
            "Loss: 4.253514e-05, l1: 0.69973, l2: 0.31465\n",
            "Loss: 4.250081e-05, l1: 0.69948, l2: 0.31468\n",
            "Loss: 4.248284e-05, l1: 0.69991, l2: 0.31466\n",
            "Loss: 4.246415e-05, l1: 0.69985, l2: 0.31464\n",
            "Loss: 4.244580e-05, l1: 0.69991, l2: 0.31461\n",
            "Loss: 4.241503e-05, l1: 0.69992, l2: 0.31462\n",
            "Loss: 4.238029e-05, l1: 0.70005, l2: 0.31461\n",
            "Loss: 4.259513e-05, l1: 0.70068, l2: 0.31480\n",
            "Loss: 4.236330e-05, l1: 0.70019, l2: 0.31465\n",
            "Loss: 4.231132e-05, l1: 0.70019, l2: 0.31468\n",
            "Loss: 4.227676e-05, l1: 0.69989, l2: 0.31469\n",
            "Loss: 4.224506e-05, l1: 0.70016, l2: 0.31465\n",
            "Loss: 4.223053e-05, l1: 0.69985, l2: 0.31464\n",
            "Loss: 4.221475e-05, l1: 0.69940, l2: 0.31465\n",
            "Loss: 4.219998e-05, l1: 0.69891, l2: 0.31463\n",
            "Loss: 4.218089e-05, l1: 0.69788, l2: 0.31463\n",
            "Loss: 4.222609e-05, l1: 0.69625, l2: 0.31476\n",
            "Loss: 4.216773e-05, l1: 0.69735, l2: 0.31467\n",
            "Loss: 4.213796e-05, l1: 0.69695, l2: 0.31469\n",
            "Loss: 4.210389e-05, l1: 0.69677, l2: 0.31473\n",
            "Loss: 4.208514e-05, l1: 0.69714, l2: 0.31475\n",
            "Loss: 4.207791e-05, l1: 0.69717, l2: 0.31474\n",
            "Loss: 4.206397e-05, l1: 0.69719, l2: 0.31472\n",
            "Loss: 4.204850e-05, l1: 0.69725, l2: 0.31466\n",
            "Loss: 4.202786e-05, l1: 0.69734, l2: 0.31463\n",
            "Loss: 4.206269e-05, l1: 0.69693, l2: 0.31457\n",
            "Loss: 4.201232e-05, l1: 0.69719, l2: 0.31461\n",
            "Loss: 4.198021e-05, l1: 0.69696, l2: 0.31462\n",
            "Loss: 4.194471e-05, l1: 0.69681, l2: 0.31470\n",
            "Loss: 4.191016e-05, l1: 0.69625, l2: 0.31482\n",
            "Loss: 4.189422e-05, l1: 0.69632, l2: 0.31489\n",
            "Loss: 4.188030e-05, l1: 0.69666, l2: 0.31493\n",
            "Loss: 4.187117e-05, l1: 0.69691, l2: 0.31491\n",
            "Loss: 4.186011e-05, l1: 0.69725, l2: 0.31487\n",
            "Loss: 4.184955e-05, l1: 0.69744, l2: 0.31484\n",
            "Loss: 4.182917e-05, l1: 0.69737, l2: 0.31485\n",
            "Loss: 4.181298e-05, l1: 0.69728, l2: 0.31493\n",
            "Loss: 4.179181e-05, l1: 0.69662, l2: 0.31499\n",
            "Loss: 4.177850e-05, l1: 0.69667, l2: 0.31497\n",
            "Loss: 4.176332e-05, l1: 0.69699, l2: 0.31502\n",
            "Loss: 4.174057e-05, l1: 0.69722, l2: 0.31507\n",
            "Loss: 4.171381e-05, l1: 0.69752, l2: 0.31506\n",
            "Loss: 4.167893e-05, l1: 0.69799, l2: 0.31505\n",
            "Loss: 4.164305e-05, l1: 0.69803, l2: 0.31503\n",
            "Loss: 4.158242e-05, l1: 0.69810, l2: 0.31497\n",
            "Loss: 4.153345e-05, l1: 0.69762, l2: 0.31496\n",
            "Loss: 4.150354e-05, l1: 0.69765, l2: 0.31489\n",
            "Loss: 4.146474e-05, l1: 0.69682, l2: 0.31496\n",
            "Loss: 4.145606e-05, l1: 0.69675, l2: 0.31504\n",
            "Loss: 4.143282e-05, l1: 0.69683, l2: 0.31499\n",
            "Loss: 4.141557e-05, l1: 0.69689, l2: 0.31493\n",
            "Loss: 4.139484e-05, l1: 0.69716, l2: 0.31493\n",
            "Loss: 4.137948e-05, l1: 0.69722, l2: 0.31488\n",
            "Loss: 4.136502e-05, l1: 0.69720, l2: 0.31484\n",
            "Loss: 4.135952e-05, l1: 0.69727, l2: 0.31487\n",
            "Loss: 4.134001e-05, l1: 0.69714, l2: 0.31488\n",
            "Loss: 4.132967e-05, l1: 0.69695, l2: 0.31487\n",
            "Loss: 4.131403e-05, l1: 0.69723, l2: 0.31494\n",
            "Loss: 4.129711e-05, l1: 0.69721, l2: 0.31500\n",
            "Loss: 4.128080e-05, l1: 0.69761, l2: 0.31504\n",
            "Loss: 4.124912e-05, l1: 0.69785, l2: 0.31508\n",
            "Loss: 4.120927e-05, l1: 0.69834, l2: 0.31508\n",
            "Loss: 4.116724e-05, l1: 0.69880, l2: 0.31505\n",
            "Loss: 4.114090e-05, l1: 0.69894, l2: 0.31503\n",
            "Loss: 4.112494e-05, l1: 0.69900, l2: 0.31502\n",
            "Loss: 4.109478e-05, l1: 0.69940, l2: 0.31500\n",
            "Loss: 4.107316e-05, l1: 0.69940, l2: 0.31503\n",
            "Loss: 4.105384e-05, l1: 0.69975, l2: 0.31505\n",
            "Loss: 4.104186e-05, l1: 0.69976, l2: 0.31505\n",
            "Loss: 4.103088e-05, l1: 0.69984, l2: 0.31505\n",
            "Loss: 4.101547e-05, l1: 0.69982, l2: 0.31502\n",
            "Loss: 4.100614e-05, l1: 0.70023, l2: 0.31496\n",
            "Loss: 4.098460e-05, l1: 0.70032, l2: 0.31494\n",
            "Loss: 4.096018e-05, l1: 0.70068, l2: 0.31491\n",
            "Loss: 4.093949e-05, l1: 0.70121, l2: 0.31487\n",
            "Loss: 4.091226e-05, l1: 0.70190, l2: 0.31481\n",
            "Loss: 4.088311e-05, l1: 0.70251, l2: 0.31479\n",
            "Loss: 4.086537e-05, l1: 0.70291, l2: 0.31467\n",
            "Loss: 4.084780e-05, l1: 0.70271, l2: 0.31469\n",
            "Loss: 4.083395e-05, l1: 0.70234, l2: 0.31470\n",
            "Loss: 4.082211e-05, l1: 0.70211, l2: 0.31468\n",
            "Loss: 4.081193e-05, l1: 0.70187, l2: 0.31463\n",
            "Loss: 4.079639e-05, l1: 0.70194, l2: 0.31465\n",
            "Loss: 4.077979e-05, l1: 0.70212, l2: 0.31469\n",
            "Loss: 4.076275e-05, l1: 0.70220, l2: 0.31477\n",
            "Loss: 4.074758e-05, l1: 0.70257, l2: 0.31481\n",
            "Loss: 4.078719e-05, l1: 0.70443, l2: 0.31486\n",
            "Loss: 4.072973e-05, l1: 0.70324, l2: 0.31483\n",
            "Loss: 4.069771e-05, l1: 0.70360, l2: 0.31489\n",
            "Loss: 4.067020e-05, l1: 0.70455, l2: 0.31488\n",
            "Loss: 4.064501e-05, l1: 0.70522, l2: 0.31485\n",
            "Loss: 4.062655e-05, l1: 0.70607, l2: 0.31483\n",
            "Loss: 4.060737e-05, l1: 0.70663, l2: 0.31485\n",
            "Loss: 4.058639e-05, l1: 0.70712, l2: 0.31490\n",
            "Loss: 4.057385e-05, l1: 0.70752, l2: 0.31495\n",
            "Loss: 4.056644e-05, l1: 0.70732, l2: 0.31498\n",
            "Loss: 4.055802e-05, l1: 0.70744, l2: 0.31497\n",
            "Loss: 4.054741e-05, l1: 0.70745, l2: 0.31496\n",
            "Loss: 4.054126e-05, l1: 0.70746, l2: 0.31493\n",
            "Loss: 4.053372e-05, l1: 0.70769, l2: 0.31494\n",
            "Loss: 4.052535e-05, l1: 0.70789, l2: 0.31495\n",
            "Loss: 4.052306e-05, l1: 0.70797, l2: 0.31499\n",
            "Loss: 4.051681e-05, l1: 0.70790, l2: 0.31501\n",
            "Loss: 4.051414e-05, l1: 0.70785, l2: 0.31502\n",
            "Loss: 4.050858e-05, l1: 0.70758, l2: 0.31503\n",
            "Loss: 4.050398e-05, l1: 0.70764, l2: 0.31504\n",
            "Loss: 4.049265e-05, l1: 0.70783, l2: 0.31506\n",
            "Loss: 4.048178e-05, l1: 0.70813, l2: 0.31506\n",
            "Loss: 4.046726e-05, l1: 0.70858, l2: 0.31508\n",
            "Loss: 4.045189e-05, l1: 0.70883, l2: 0.31507\n",
            "Loss: 4.044548e-05, l1: 0.70955, l2: 0.31516\n",
            "Loss: 4.043477e-05, l1: 0.70920, l2: 0.31514\n",
            "Loss: 4.042947e-05, l1: 0.70912, l2: 0.31514\n",
            "Loss: 4.042251e-05, l1: 0.70932, l2: 0.31518\n",
            "Loss: 4.041374e-05, l1: 0.70975, l2: 0.31523\n",
            "Loss: 4.040554e-05, l1: 0.71035, l2: 0.31527\n",
            "Loss: 4.039553e-05, l1: 0.71080, l2: 0.31529\n",
            "Loss: 4.038311e-05, l1: 0.71127, l2: 0.31529\n",
            "Loss: 4.039105e-05, l1: 0.71217, l2: 0.31528\n",
            "Loss: 4.037442e-05, l1: 0.71165, l2: 0.31529\n",
            "Loss: 4.036197e-05, l1: 0.71199, l2: 0.31527\n",
            "Loss: 4.034711e-05, l1: 0.71261, l2: 0.31526\n",
            "Loss: 4.033911e-05, l1: 0.71268, l2: 0.31522\n",
            "Loss: 4.033246e-05, l1: 0.71306, l2: 0.31525\n",
            "Loss: 4.032889e-05, l1: 0.71311, l2: 0.31526\n",
            "Loss: 4.032550e-05, l1: 0.71324, l2: 0.31526\n",
            "Loss: 4.031927e-05, l1: 0.71360, l2: 0.31524\n",
            "Loss: 4.031029e-05, l1: 0.71435, l2: 0.31523\n",
            "Loss: 4.029775e-05, l1: 0.71540, l2: 0.31521\n",
            "Loss: 4.027827e-05, l1: 0.71672, l2: 0.31519\n",
            "Loss: 4.027185e-05, l1: 0.71789, l2: 0.31520\n",
            "Loss: 4.026071e-05, l1: 0.71807, l2: 0.31523\n",
            "Loss: 4.024928e-05, l1: 0.71902, l2: 0.31527\n",
            "Loss: 4.022889e-05, l1: 0.71972, l2: 0.31531\n",
            "Loss: 4.019605e-05, l1: 0.72074, l2: 0.31535\n",
            "Loss: 4.015764e-05, l1: 0.72258, l2: 0.31529\n",
            "Loss: 4.013617e-05, l1: 0.72138, l2: 0.31530\n",
            "Loss: 4.012045e-05, l1: 0.72193, l2: 0.31532\n",
            "Loss: 4.010894e-05, l1: 0.72154, l2: 0.31530\n",
            "Loss: 4.008438e-05, l1: 0.72097, l2: 0.31529\n",
            "Loss: 4.005665e-05, l1: 0.72013, l2: 0.31530\n",
            "Loss: 4.003456e-05, l1: 0.72019, l2: 0.31531\n",
            "Loss: 4.002717e-05, l1: 0.72039, l2: 0.31541\n",
            "Loss: 4.001072e-05, l1: 0.72068, l2: 0.31539\n",
            "Loss: 4.000210e-05, l1: 0.72117, l2: 0.31540\n",
            "Loss: 3.998994e-05, l1: 0.72195, l2: 0.31540\n",
            "Loss: 3.998003e-05, l1: 0.72256, l2: 0.31540\n",
            "Loss: 3.996926e-05, l1: 0.72382, l2: 0.31535\n",
            "Loss: 3.994885e-05, l1: 0.72414, l2: 0.31536\n",
            "Loss: 3.993403e-05, l1: 0.72399, l2: 0.31535\n",
            "Loss: 3.991613e-05, l1: 0.72418, l2: 0.31532\n",
            "Loss: 3.992414e-05, l1: 0.72450, l2: 0.31544\n",
            "Loss: 3.991283e-05, l1: 0.72430, l2: 0.31537\n",
            "Loss: 3.990299e-05, l1: 0.72483, l2: 0.31536\n",
            "Loss: 3.988594e-05, l1: 0.72561, l2: 0.31536\n",
            "Loss: 3.987095e-05, l1: 0.72641, l2: 0.31536\n",
            "Loss: 3.984238e-05, l1: 0.72710, l2: 0.31533\n",
            "Loss: 3.982262e-05, l1: 0.72820, l2: 0.31532\n",
            "Loss: 3.980127e-05, l1: 0.72857, l2: 0.31532\n",
            "Loss: 3.978277e-05, l1: 0.72951, l2: 0.31535\n",
            "Loss: 3.976020e-05, l1: 0.73045, l2: 0.31543\n",
            "Loss: 3.974340e-05, l1: 0.73224, l2: 0.31552\n",
            "Loss: 3.974052e-05, l1: 0.73265, l2: 0.31555\n",
            "Loss: 3.972707e-05, l1: 0.73171, l2: 0.31553\n",
            "Loss: 3.972034e-05, l1: 0.73213, l2: 0.31551\n",
            "Loss: 3.971470e-05, l1: 0.73225, l2: 0.31551\n",
            "Loss: 3.969798e-05, l1: 0.73251, l2: 0.31550\n",
            "Loss: 3.968720e-05, l1: 0.73224, l2: 0.31547\n",
            "Loss: 3.966977e-05, l1: 0.73190, l2: 0.31542\n",
            "Loss: 3.965310e-05, l1: 0.73097, l2: 0.31539\n",
            "Loss: 3.963669e-05, l1: 0.73092, l2: 0.31539\n",
            "Loss: 3.962406e-05, l1: 0.73111, l2: 0.31550\n",
            "Loss: 3.969747e-05, l1: 0.73105, l2: 0.31539\n",
            "Loss: 3.960049e-05, l1: 0.73109, l2: 0.31547\n",
            "Loss: 3.958340e-05, l1: 0.73141, l2: 0.31544\n",
            "Loss: 3.956699e-05, l1: 0.73142, l2: 0.31542\n",
            "Loss: 3.954599e-05, l1: 0.73183, l2: 0.31543\n",
            "Loss: 3.951916e-05, l1: 0.73170, l2: 0.31541\n",
            "Loss: 3.950803e-05, l1: 0.73133, l2: 0.31544\n",
            "Loss: 3.948251e-05, l1: 0.73210, l2: 0.31544\n",
            "Loss: 3.947033e-05, l1: 0.73119, l2: 0.31540\n",
            "Loss: 3.945008e-05, l1: 0.73085, l2: 0.31540\n",
            "Loss: 3.942595e-05, l1: 0.73020, l2: 0.31540\n",
            "Loss: 3.940982e-05, l1: 0.72980, l2: 0.31540\n",
            "Loss: 3.938532e-05, l1: 0.72894, l2: 0.31550\n",
            "Loss: 3.932941e-05, l1: 0.72906, l2: 0.31550\n",
            "Loss: 3.929598e-05, l1: 0.72933, l2: 0.31550\n",
            "Loss: 3.924740e-05, l1: 0.73030, l2: 0.31553\n",
            "Loss: 3.920768e-05, l1: 0.73078, l2: 0.31556\n",
            "Loss: 3.917098e-05, l1: 0.73155, l2: 0.31555\n",
            "Loss: 3.912281e-05, l1: 0.73189, l2: 0.31562\n",
            "Loss: 3.967767e-05, l1: 0.73920, l2: 0.31540\n",
            "Loss: 3.908620e-05, l1: 0.73340, l2: 0.31558\n",
            "Loss: 3.901731e-05, l1: 0.73426, l2: 0.31555\n",
            "Loss: 3.900985e-05, l1: 0.73675, l2: 0.31569\n",
            "Loss: 3.896441e-05, l1: 0.73553, l2: 0.31562\n",
            "Loss: 3.890046e-05, l1: 0.73647, l2: 0.31554\n",
            "Loss: 3.886477e-05, l1: 0.73679, l2: 0.31556\n",
            "Loss: 3.880719e-05, l1: 0.73638, l2: 0.31566\n",
            "Loss: 3.877516e-05, l1: 0.73792, l2: 0.31575\n",
            "Loss: 3.874456e-05, l1: 0.73806, l2: 0.31581\n",
            "Loss: 3.870988e-05, l1: 0.73861, l2: 0.31585\n",
            "Loss: 3.868419e-05, l1: 0.73913, l2: 0.31590\n",
            "Loss: 3.866998e-05, l1: 0.73914, l2: 0.31591\n",
            "Loss: 3.865519e-05, l1: 0.73940, l2: 0.31594\n",
            "Loss: 3.864709e-05, l1: 0.73959, l2: 0.31596\n",
            "Loss: 3.862175e-05, l1: 0.73973, l2: 0.31603\n",
            "Loss: 3.859722e-05, l1: 0.73997, l2: 0.31612\n",
            "Loss: 3.856636e-05, l1: 0.73960, l2: 0.31619\n",
            "Loss: 3.853501e-05, l1: 0.73931, l2: 0.31619\n",
            "Loss: 3.849769e-05, l1: 0.73892, l2: 0.31616\n",
            "Loss: 3.847178e-05, l1: 0.73886, l2: 0.31612\n",
            "Loss: 3.842561e-05, l1: 0.73941, l2: 0.31611\n",
            "Loss: 3.837127e-05, l1: 0.74043, l2: 0.31614\n",
            "Loss: 3.832623e-05, l1: 0.74148, l2: 0.31615\n",
            "Loss: 3.827009e-05, l1: 0.74270, l2: 0.31620\n",
            "Loss: 3.821456e-05, l1: 0.74289, l2: 0.31618\n",
            "Loss: 3.816363e-05, l1: 0.74266, l2: 0.31624\n",
            "Loss: 3.812652e-05, l1: 0.74300, l2: 0.31621\n",
            "Loss: 3.809762e-05, l1: 0.74314, l2: 0.31624\n",
            "Loss: 3.844217e-05, l1: 0.73637, l2: 0.31612\n",
            "Loss: 3.808490e-05, l1: 0.74204, l2: 0.31622\n",
            "Loss: 3.804232e-05, l1: 0.74334, l2: 0.31625\n",
            "Loss: 3.802037e-05, l1: 0.74313, l2: 0.31632\n",
            "Loss: 3.798759e-05, l1: 0.74320, l2: 0.31630\n",
            "Loss: 3.795140e-05, l1: 0.74350, l2: 0.31636\n",
            "Loss: 3.790705e-05, l1: 0.74405, l2: 0.31650\n",
            "Loss: 3.787495e-05, l1: 0.74453, l2: 0.31663\n",
            "Loss: 3.784256e-05, l1: 0.74438, l2: 0.31674\n",
            "Loss: 3.781630e-05, l1: 0.74470, l2: 0.31678\n",
            "Loss: 3.777598e-05, l1: 0.74456, l2: 0.31678\n",
            "Loss: 3.774104e-05, l1: 0.74483, l2: 0.31674\n",
            "Loss: 3.771041e-05, l1: 0.74476, l2: 0.31669\n",
            "Loss: 3.768956e-05, l1: 0.74454, l2: 0.31670\n",
            "Loss: 3.766723e-05, l1: 0.74393, l2: 0.31667\n",
            "Loss: 3.764041e-05, l1: 0.74320, l2: 0.31671\n",
            "Loss: 3.762454e-05, l1: 0.74240, l2: 0.31670\n",
            "Loss: 3.761255e-05, l1: 0.74230, l2: 0.31673\n",
            "Loss: 3.760338e-05, l1: 0.74174, l2: 0.31685\n",
            "Loss: 3.758472e-05, l1: 0.74178, l2: 0.31685\n",
            "Loss: 3.757492e-05, l1: 0.74199, l2: 0.31685\n",
            "Loss: 3.755730e-05, l1: 0.74174, l2: 0.31685\n",
            "Loss: 3.754570e-05, l1: 0.74192, l2: 0.31692\n",
            "Loss: 3.752721e-05, l1: 0.74129, l2: 0.31697\n",
            "Loss: 3.750174e-05, l1: 0.74060, l2: 0.31706\n",
            "Loss: 3.747571e-05, l1: 0.74020, l2: 0.31717\n",
            "Loss: 3.745857e-05, l1: 0.73953, l2: 0.31722\n",
            "Loss: 3.744558e-05, l1: 0.73951, l2: 0.31723\n",
            "Loss: 3.742934e-05, l1: 0.73923, l2: 0.31720\n",
            "Loss: 3.741320e-05, l1: 0.73892, l2: 0.31713\n",
            "Loss: 3.739931e-05, l1: 0.73798, l2: 0.31707\n",
            "Loss: 3.738904e-05, l1: 0.73750, l2: 0.31705\n",
            "Loss: 3.738040e-05, l1: 0.73728, l2: 0.31705\n",
            "Loss: 3.736942e-05, l1: 0.73736, l2: 0.31704\n",
            "Loss: 3.735868e-05, l1: 0.73793, l2: 0.31705\n",
            "Loss: 3.734784e-05, l1: 0.73796, l2: 0.31701\n",
            "Loss: 3.734029e-05, l1: 0.73814, l2: 0.31697\n",
            "Loss: 3.733371e-05, l1: 0.73815, l2: 0.31697\n",
            "Loss: 3.733322e-05, l1: 0.73832, l2: 0.31697\n",
            "Loss: 3.732169e-05, l1: 0.73811, l2: 0.31698\n",
            "Loss: 3.731429e-05, l1: 0.73806, l2: 0.31699\n",
            "Loss: 3.732949e-05, l1: 0.73815, l2: 0.31701\n",
            "Loss: 3.730856e-05, l1: 0.73809, l2: 0.31700\n",
            "Loss: 3.729875e-05, l1: 0.73825, l2: 0.31700\n",
            "Loss: 3.728779e-05, l1: 0.73865, l2: 0.31700\n",
            "Loss: 3.727006e-05, l1: 0.73946, l2: 0.31702\n",
            "Loss: 3.726182e-05, l1: 0.74096, l2: 0.31706\n",
            "Loss: 3.722968e-05, l1: 0.74076, l2: 0.31710\n",
            "Loss: 3.720392e-05, l1: 0.74108, l2: 0.31714\n",
            "Loss: 3.717343e-05, l1: 0.74127, l2: 0.31719\n",
            "Loss: 3.713748e-05, l1: 0.74178, l2: 0.31722\n",
            "Loss: 3.711289e-05, l1: 0.74180, l2: 0.31724\n",
            "Loss: 3.709691e-05, l1: 0.74259, l2: 0.31720\n",
            "Loss: 3.708892e-05, l1: 0.74206, l2: 0.31721\n",
            "Loss: 3.708503e-05, l1: 0.74191, l2: 0.31722\n",
            "Loss: 3.707208e-05, l1: 0.74104, l2: 0.31720\n",
            "Loss: 3.705775e-05, l1: 0.74068, l2: 0.31721\n",
            "Loss: 3.703746e-05, l1: 0.74036, l2: 0.31723\n",
            "Loss: 3.700369e-05, l1: 0.74029, l2: 0.31727\n",
            "Loss: 3.696920e-05, l1: 0.74077, l2: 0.31731\n",
            "Loss: 3.693964e-05, l1: 0.74186, l2: 0.31733\n",
            "Loss: 3.710226e-05, l1: 0.74399, l2: 0.31731\n",
            "Loss: 3.692838e-05, l1: 0.74230, l2: 0.31732\n",
            "Loss: 3.691428e-05, l1: 0.74197, l2: 0.31728\n",
            "Loss: 3.690717e-05, l1: 0.74204, l2: 0.31724\n",
            "Loss: 3.690301e-05, l1: 0.74185, l2: 0.31720\n",
            "Loss: 3.689436e-05, l1: 0.74143, l2: 0.31716\n",
            "Loss: 3.688602e-05, l1: 0.74102, l2: 0.31711\n",
            "Loss: 3.687456e-05, l1: 0.74078, l2: 0.31710\n",
            "Loss: 3.685282e-05, l1: 0.74048, l2: 0.31713\n",
            "Loss: 3.683499e-05, l1: 0.74060, l2: 0.31715\n",
            "Loss: 3.680775e-05, l1: 0.74071, l2: 0.31724\n",
            "Loss: 3.677743e-05, l1: 0.74097, l2: 0.31724\n",
            "Loss: 3.675195e-05, l1: 0.74114, l2: 0.31722\n",
            "Loss: 3.672860e-05, l1: 0.74140, l2: 0.31718\n",
            "Loss: 3.671079e-05, l1: 0.74069, l2: 0.31712\n",
            "Loss: 3.669623e-05, l1: 0.74062, l2: 0.31713\n",
            "Loss: 3.667975e-05, l1: 0.74019, l2: 0.31717\n",
            "Loss: 3.675569e-05, l1: 0.74023, l2: 0.31735\n",
            "Loss: 3.666834e-05, l1: 0.74020, l2: 0.31722\n",
            "Loss: 3.664656e-05, l1: 0.73937, l2: 0.31728\n",
            "Loss: 3.663441e-05, l1: 0.73918, l2: 0.31734\n",
            "Loss: 3.661324e-05, l1: 0.73949, l2: 0.31736\n",
            "Loss: 3.658654e-05, l1: 0.73927, l2: 0.31737\n",
            "Loss: 3.655580e-05, l1: 0.73936, l2: 0.31738\n",
            "Loss: 3.651328e-05, l1: 0.73915, l2: 0.31731\n",
            "Loss: 3.647381e-05, l1: 0.73892, l2: 0.31726\n",
            "Loss: 3.645421e-05, l1: 0.73955, l2: 0.31721\n",
            "Loss: 3.643448e-05, l1: 0.73977, l2: 0.31722\n",
            "Loss: 3.641991e-05, l1: 0.74020, l2: 0.31721\n",
            "Loss: 3.640051e-05, l1: 0.74095, l2: 0.31718\n",
            "Loss: 3.638342e-05, l1: 0.74169, l2: 0.31714\n",
            "Loss: 3.636291e-05, l1: 0.74240, l2: 0.31712\n",
            "Loss: 3.634805e-05, l1: 0.74247, l2: 0.31710\n",
            "Loss: 3.632953e-05, l1: 0.74273, l2: 0.31710\n",
            "Loss: 3.630920e-05, l1: 0.74256, l2: 0.31711\n",
            "Loss: 3.628082e-05, l1: 0.74223, l2: 0.31710\n",
            "Loss: 3.625337e-05, l1: 0.74214, l2: 0.31707\n",
            "Loss: 3.622319e-05, l1: 0.74276, l2: 0.31701\n",
            "Loss: 3.620697e-05, l1: 0.74266, l2: 0.31701\n",
            "Loss: 3.619711e-05, l1: 0.74323, l2: 0.31701\n",
            "Loss: 3.618970e-05, l1: 0.74326, l2: 0.31703\n",
            "Loss: 3.618082e-05, l1: 0.74297, l2: 0.31706\n",
            "Loss: 3.616967e-05, l1: 0.74299, l2: 0.31708\n",
            "Loss: 3.615629e-05, l1: 0.74238, l2: 0.31709\n",
            "Loss: 3.614034e-05, l1: 0.74235, l2: 0.31710\n",
            "Loss: 3.612849e-05, l1: 0.74230, l2: 0.31709\n",
            "Loss: 3.611517e-05, l1: 0.74238, l2: 0.31706\n",
            "Loss: 3.610801e-05, l1: 0.74243, l2: 0.31704\n",
            "Loss: 3.609409e-05, l1: 0.74267, l2: 0.31700\n",
            "Loss: 3.608346e-05, l1: 0.74239, l2: 0.31695\n",
            "Loss: 3.605387e-05, l1: 0.74217, l2: 0.31696\n",
            "Loss: 3.601953e-05, l1: 0.74174, l2: 0.31702\n",
            "Loss: 3.600710e-05, l1: 0.74155, l2: 0.31705\n",
            "Loss: 3.598724e-05, l1: 0.74173, l2: 0.31704\n",
            "Loss: 3.597709e-05, l1: 0.74032, l2: 0.31698\n",
            "Loss: 3.593897e-05, l1: 0.74116, l2: 0.31701\n",
            "Loss: 3.590349e-05, l1: 0.74220, l2: 0.31706\n",
            "Loss: 3.587140e-05, l1: 0.74221, l2: 0.31708\n",
            "Loss: 3.584899e-05, l1: 0.74236, l2: 0.31705\n",
            "Loss: 3.583596e-05, l1: 0.74202, l2: 0.31703\n",
            "Loss: 3.582443e-05, l1: 0.74239, l2: 0.31701\n",
            "Loss: 3.579718e-05, l1: 0.74222, l2: 0.31695\n",
            "Loss: 3.577071e-05, l1: 0.74322, l2: 0.31687\n",
            "Loss: 3.601108e-05, l1: 0.74176, l2: 0.31681\n",
            "Loss: 3.574955e-05, l1: 0.74290, l2: 0.31686\n",
            "Loss: 3.572342e-05, l1: 0.74204, l2: 0.31682\n",
            "Loss: 3.570756e-05, l1: 0.74162, l2: 0.31682\n",
            "Loss: 3.570038e-05, l1: 0.74151, l2: 0.31682\n",
            "Loss: 3.568183e-05, l1: 0.74135, l2: 0.31680\n",
            "Loss: 3.566634e-05, l1: 0.74108, l2: 0.31677\n",
            "Loss: 3.565094e-05, l1: 0.74131, l2: 0.31666\n",
            "Loss: 3.563819e-05, l1: 0.74152, l2: 0.31665\n",
            "Loss: 3.562593e-05, l1: 0.74168, l2: 0.31663\n",
            "Loss: 3.562085e-05, l1: 0.74181, l2: 0.31660\n",
            "Loss: 3.561469e-05, l1: 0.74172, l2: 0.31656\n",
            "Loss: 3.560383e-05, l1: 0.74173, l2: 0.31651\n",
            "Loss: 3.558202e-05, l1: 0.74151, l2: 0.31646\n",
            "Loss: 3.555845e-05, l1: 0.74167, l2: 0.31642\n",
            "Loss: 3.553224e-05, l1: 0.74202, l2: 0.31641\n",
            "Loss: 3.550638e-05, l1: 0.74304, l2: 0.31640\n",
            "Loss: 3.551123e-05, l1: 0.74273, l2: 0.31650\n",
            "Loss: 3.549814e-05, l1: 0.74290, l2: 0.31644\n",
            "Loss: 3.548470e-05, l1: 0.74354, l2: 0.31644\n",
            "Loss: 3.547008e-05, l1: 0.74407, l2: 0.31643\n",
            "Loss: 3.546066e-05, l1: 0.74463, l2: 0.31641\n",
            "Loss: 3.544480e-05, l1: 0.74505, l2: 0.31639\n",
            "Loss: 3.542410e-05, l1: 0.74561, l2: 0.31637\n",
            "Loss: 3.540728e-05, l1: 0.74599, l2: 0.31634\n",
            "Loss: 3.538604e-05, l1: 0.74617, l2: 0.31638\n",
            "Loss: 3.536943e-05, l1: 0.74598, l2: 0.31643\n",
            "Loss: 3.536243e-05, l1: 0.74580, l2: 0.31645\n",
            "Loss: 3.535952e-05, l1: 0.74562, l2: 0.31647\n",
            "Loss: 3.535930e-05, l1: 0.74586, l2: 0.31646\n",
            "Loss: 3.535742e-05, l1: 0.74594, l2: 0.31645\n",
            "Loss: 3.535475e-05, l1: 0.74598, l2: 0.31644\n",
            "Loss: 3.535287e-05, l1: 0.74583, l2: 0.31642\n",
            "Loss: 3.534977e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.535008e-05, l1: 0.74563, l2: 0.31643\n",
            "Loss: 3.535097e-05, l1: 0.74573, l2: 0.31643\n",
            "Loss: 3.535080e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534938e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534938e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.535089e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534946e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534938e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534938e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534935e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534935e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.573453e-05, l1: 0.74316, l2: 0.31662\n",
            "Loss: 3.534988e-05, l1: 0.74559, l2: 0.31644\n",
            "Loss: 3.534995e-05, l1: 0.74572, l2: 0.31643\n",
            "Loss: 3.535215e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.535078e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534935e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534935e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534935e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534935e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534935e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534935e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534935e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534935e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534935e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534935e-05, l1: 0.74576, l2: 0.31642\n",
            "Loss: 3.534935e-05, l1: 0.74576, l2: 0.31642\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.000035\n",
            "  Number of iterations: 2287\n",
            "  Number of functions evaluations: 2432\n",
            "Error u: 1.899961e-02\n",
            "Error l1: 25.42380%\n",
            "Error l2: 0.59238%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "########################### Noisy Data ###############################\n",
        "######################################################################\n",
        "noise = 0.01        \n",
        "u_train = u_train + noise*np.std(u_train)*np.random.randn(u_train.shape[0], u_train.shape[1])\n",
        "        \n",
        "model = PhysicsInformedNN(X_u_train, u_train, layers, lb, ub)\n",
        "model.train(2000)\n",
        "    \n",
        "u_pred, f_pred = model.predict(X_star)\n",
        "        \n",
        "lambda_1_value_noisy = model.sess.run(model.lambda_1)\n",
        "lambda_2_value_noisy = model.sess.run(model.lambda_2)\n",
        "lambda_2_value_noisy = np.exp(lambda_2_value_noisy)\n",
        "            \n",
        "error_lambda_1_noisy = np.abs(lambda_1_value_noisy - 1.0)*100\n",
        "error_lambda_2_noisy = np.abs(lambda_2_value_noisy - nu)/nu * 100\n",
        "    \n",
        "print('Error lambda_1: %f%%' % (error_lambda_1_noisy))\n",
        "print('Error lambda_2: %f%%' % (error_lambda_2_noisy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WSYpFgNogBy",
        "outputId": "907458df-555c-4b14-8fec-b9342bc73b46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "Loss: 1.118276e-03, l1: 0.70747, l2: 0.29716\n",
            "Loss: 1.110992e-03, l1: 0.71041, l2: 0.29612\n",
            "Loss: 1.100625e-03, l1: 0.71340, l2: 0.29593\n",
            "Loss: 1.066406e-03, l1: 0.72576, l2: 0.29727\n",
            "Loss: 1.023126e-03, l1: 0.74330, l2: 0.30085\n",
            "Loss: 9.777541e-04, l1: 0.75604, l2: 0.30498\n",
            "Loss: 9.179731e-04, l1: 0.77155, l2: 0.31328\n",
            "Loss: 9.033371e-04, l1: 0.78054, l2: 0.31757\n",
            "Loss: 8.981957e-04, l1: 0.77388, l2: 0.31775\n",
            "Loss: 8.942980e-04, l1: 0.77415, l2: 0.31719\n",
            "Loss: 8.913914e-04, l1: 0.77397, l2: 0.31609\n",
            "Loss: 8.860980e-04, l1: 0.77388, l2: 0.31508\n",
            "Loss: 8.748267e-04, l1: 0.77429, l2: 0.31245\n",
            "Loss: 8.628874e-04, l1: 0.77696, l2: 0.31266\n",
            "Loss: 8.538192e-04, l1: 0.77768, l2: 0.31042\n",
            "Loss: 8.466458e-04, l1: 0.77825, l2: 0.31191\n",
            "Loss: 8.358133e-04, l1: 0.77903, l2: 0.31376\n",
            "Loss: 8.257458e-04, l1: 0.77867, l2: 0.31494\n",
            "Loss: 7.994972e-04, l1: 0.77441, l2: 0.31572\n",
            "Loss: 7.818124e-04, l1: 0.76690, l2: 0.31434\n",
            "Loss: 7.725771e-04, l1: 0.76624, l2: 0.31387\n",
            "Loss: 7.683740e-04, l1: 0.76673, l2: 0.31289\n",
            "Loss: 7.641998e-04, l1: 0.76624, l2: 0.31236\n",
            "Loss: 7.533507e-04, l1: 0.76493, l2: 0.31210\n",
            "Loss: 7.398898e-04, l1: 0.76340, l2: 0.31223\n",
            "Loss: 7.095356e-04, l1: 0.76017, l2: 0.31263\n",
            "Loss: 6.815396e-04, l1: 0.74217, l2: 0.30662\n",
            "Loss: 6.628126e-04, l1: 0.74662, l2: 0.30895\n",
            "Loss: 6.551737e-04, l1: 0.74598, l2: 0.30821\n",
            "Loss: 6.502297e-04, l1: 0.74780, l2: 0.30921\n",
            "Loss: 6.489091e-04, l1: 0.74912, l2: 0.31043\n",
            "Loss: 6.485314e-04, l1: 0.74926, l2: 0.31042\n",
            "Loss: 6.480473e-04, l1: 0.74928, l2: 0.31047\n",
            "Loss: 6.472130e-04, l1: 0.74850, l2: 0.31023\n",
            "Loss: 6.455077e-04, l1: 0.74694, l2: 0.30978\n",
            "Loss: 6.423509e-04, l1: 0.74413, l2: 0.30897\n",
            "Loss: 6.361456e-04, l1: 0.74053, l2: 0.30804\n",
            "Loss: 6.279149e-04, l1: 0.73698, l2: 0.30730\n",
            "Loss: 6.193920e-04, l1: 0.73736, l2: 0.30818\n",
            "Loss: 6.100271e-04, l1: 0.73869, l2: 0.30966\n",
            "Loss: 6.040464e-04, l1: 0.74713, l2: 0.31230\n",
            "Loss: 6.021949e-04, l1: 0.74881, l2: 0.31262\n",
            "Loss: 6.016559e-04, l1: 0.75089, l2: 0.31299\n",
            "Loss: 6.011337e-04, l1: 0.75212, l2: 0.31332\n",
            "Loss: 6.008546e-04, l1: 0.75200, l2: 0.31322\n",
            "Loss: 6.004780e-04, l1: 0.75255, l2: 0.31320\n",
            "Loss: 5.996147e-04, l1: 0.75360, l2: 0.31314\n",
            "Loss: 5.975888e-04, l1: 0.75565, l2: 0.31284\n",
            "Loss: 5.951552e-04, l1: 0.75834, l2: 0.31326\n",
            "Loss: 5.902320e-04, l1: 0.75922, l2: 0.31324\n",
            "Loss: 5.809042e-04, l1: 0.75904, l2: 0.31405\n",
            "Loss: 5.729404e-04, l1: 0.75526, l2: 0.31341\n",
            "Loss: 5.732482e-04, l1: 0.76102, l2: 0.31587\n",
            "Loss: 5.693507e-04, l1: 0.75816, l2: 0.31465\n",
            "Loss: 5.728086e-04, l1: 0.75606, l2: 0.31606\n",
            "Loss: 5.665480e-04, l1: 0.75731, l2: 0.31521\n",
            "Loss: 5.652915e-04, l1: 0.75477, l2: 0.31491\n",
            "Loss: 5.648201e-04, l1: 0.75504, l2: 0.31464\n",
            "Loss: 5.645275e-04, l1: 0.75453, l2: 0.31453\n",
            "Loss: 5.643904e-04, l1: 0.75168, l2: 0.31344\n",
            "Loss: 5.637471e-04, l1: 0.75184, l2: 0.31371\n",
            "Loss: 5.634555e-04, l1: 0.75152, l2: 0.31365\n",
            "Loss: 5.629095e-04, l1: 0.75055, l2: 0.31346\n",
            "Loss: 5.628432e-04, l1: 0.74784, l2: 0.31200\n",
            "Loss: 5.624163e-04, l1: 0.74915, l2: 0.31271\n",
            "Loss: 5.608597e-04, l1: 0.74778, l2: 0.31260\n",
            "Loss: 5.571857e-04, l1: 0.74607, l2: 0.31290\n",
            "Loss: 5.488748e-04, l1: 0.74284, l2: 0.31364\n",
            "Loss: 5.371929e-04, l1: 0.74386, l2: 0.31669\n",
            "Loss: 5.623659e-04, l1: 0.73578, l2: 0.31785\n",
            "Loss: 5.319277e-04, l1: 0.74129, l2: 0.31706\n",
            "Loss: 5.187457e-04, l1: 0.74180, l2: 0.31823\n",
            "Loss: 5.557560e-04, l1: 0.75092, l2: 0.32329\n",
            "Loss: 5.142018e-04, l1: 0.74420, l2: 0.31956\n",
            "Loss: 5.083116e-04, l1: 0.74990, l2: 0.32162\n",
            "Loss: 5.057712e-04, l1: 0.74765, l2: 0.32230\n",
            "Loss: 5.041576e-04, l1: 0.74816, l2: 0.32219\n",
            "Loss: 5.034540e-04, l1: 0.74881, l2: 0.32243\n",
            "Loss: 5.030799e-04, l1: 0.74920, l2: 0.32290\n",
            "Loss: 5.026603e-04, l1: 0.74895, l2: 0.32312\n",
            "Loss: 5.018434e-04, l1: 0.74853, l2: 0.32351\n",
            "Loss: 5.009217e-04, l1: 0.74724, l2: 0.32338\n",
            "Loss: 4.996370e-04, l1: 0.74468, l2: 0.32298\n",
            "Loss: 4.984033e-04, l1: 0.74322, l2: 0.32263\n",
            "Loss: 4.973195e-04, l1: 0.74217, l2: 0.32195\n",
            "Loss: 5.019201e-04, l1: 0.74219, l2: 0.32007\n",
            "Loss: 4.965078e-04, l1: 0.74218, l2: 0.32142\n",
            "Loss: 4.952927e-04, l1: 0.74111, l2: 0.32082\n",
            "Loss: 4.939478e-04, l1: 0.73967, l2: 0.32105\n",
            "Loss: 4.932332e-04, l1: 0.73783, l2: 0.32097\n",
            "Loss: 4.929600e-04, l1: 0.73769, l2: 0.32153\n",
            "Loss: 4.928190e-04, l1: 0.73715, l2: 0.32159\n",
            "Loss: 4.924371e-04, l1: 0.73633, l2: 0.32148\n",
            "Loss: 4.914557e-04, l1: 0.73400, l2: 0.32112\n",
            "Loss: 4.903470e-04, l1: 0.73164, l2: 0.32074\n",
            "Loss: 4.882165e-04, l1: 0.72821, l2: 0.32028\n",
            "Loss: 4.849509e-04, l1: 0.71780, l2: 0.31810\n",
            "Loss: 4.806714e-04, l1: 0.71633, l2: 0.31845\n",
            "Loss: 4.727386e-04, l1: 0.70851, l2: 0.31890\n",
            "Loss: 4.825255e-04, l1: 0.70143, l2: 0.31839\n",
            "Loss: 4.706023e-04, l1: 0.70638, l2: 0.31874\n",
            "Loss: 4.679931e-04, l1: 0.70270, l2: 0.31925\n",
            "Loss: 4.667698e-04, l1: 0.69988, l2: 0.31915\n",
            "Loss: 4.656414e-04, l1: 0.69893, l2: 0.31968\n",
            "Loss: 4.645314e-04, l1: 0.69640, l2: 0.31993\n",
            "Loss: 4.635333e-04, l1: 0.69567, l2: 0.32021\n",
            "Loss: 4.635926e-04, l1: 0.69972, l2: 0.32036\n",
            "Loss: 4.628748e-04, l1: 0.69766, l2: 0.32028\n",
            "Loss: 4.619756e-04, l1: 0.69640, l2: 0.32018\n",
            "Loss: 4.612377e-04, l1: 0.69718, l2: 0.32008\n",
            "Loss: 4.607782e-04, l1: 0.69733, l2: 0.32014\n",
            "Loss: 4.605578e-04, l1: 0.69705, l2: 0.32017\n",
            "Loss: 4.604715e-04, l1: 0.69642, l2: 0.32008\n",
            "Loss: 4.603663e-04, l1: 0.69608, l2: 0.32003\n",
            "Loss: 4.601442e-04, l1: 0.69559, l2: 0.31995\n",
            "Loss: 4.595891e-04, l1: 0.69522, l2: 0.31982\n",
            "Loss: 4.581714e-04, l1: 0.69527, l2: 0.31973\n",
            "Loss: 4.562815e-04, l1: 0.69599, l2: 0.31963\n",
            "Loss: 4.539176e-04, l1: 0.69819, l2: 0.32020\n",
            "Loss: 4.514472e-04, l1: 0.70003, l2: 0.32110\n",
            "Loss: 4.496950e-04, l1: 0.70141, l2: 0.32180\n",
            "Loss: 4.481661e-04, l1: 0.70045, l2: 0.32254\n",
            "Loss: 4.465707e-04, l1: 0.69863, l2: 0.32264\n",
            "Loss: 4.419667e-04, l1: 0.68974, l2: 0.32269\n",
            "Loss: 4.354994e-04, l1: 0.67638, l2: 0.32256\n",
            "Loss: 4.279341e-04, l1: 0.64840, l2: 0.32265\n",
            "Loss: 4.406854e-04, l1: 0.63654, l2: 0.32163\n",
            "Loss: 4.202733e-04, l1: 0.64382, l2: 0.32226\n",
            "Loss: 4.441451e-04, l1: 0.65445, l2: 0.32211\n",
            "Loss: 4.153362e-04, l1: 0.64677, l2: 0.32222\n",
            "Loss: 4.078096e-04, l1: 0.63708, l2: 0.32151\n",
            "Loss: 4.041364e-04, l1: 0.62242, l2: 0.31975\n",
            "Loss: 3.979677e-04, l1: 0.62228, l2: 0.31997\n",
            "Loss: 3.937609e-04, l1: 0.62288, l2: 0.31986\n",
            "Loss: 3.895116e-04, l1: 0.60792, l2: 0.31951\n",
            "Loss: 3.854631e-04, l1: 0.60999, l2: 0.31996\n",
            "Loss: 3.837053e-04, l1: 0.60547, l2: 0.31946\n",
            "Loss: 3.823653e-04, l1: 0.59755, l2: 0.31950\n",
            "Loss: 3.808070e-04, l1: 0.59939, l2: 0.31926\n",
            "Loss: 3.801857e-04, l1: 0.59966, l2: 0.31924\n",
            "Loss: 3.792193e-04, l1: 0.59509, l2: 0.31886\n",
            "Loss: 3.782181e-04, l1: 0.59269, l2: 0.31903\n",
            "Loss: 3.770803e-04, l1: 0.59103, l2: 0.31885\n",
            "Loss: 3.757078e-04, l1: 0.58752, l2: 0.31940\n",
            "Loss: 3.748236e-04, l1: 0.57754, l2: 0.31888\n",
            "Loss: 3.743038e-04, l1: 0.58254, l2: 0.31914\n",
            "Loss: 3.722710e-04, l1: 0.57747, l2: 0.31922\n",
            "Loss: 3.708678e-04, l1: 0.56955, l2: 0.31977\n",
            "Loss: 3.697842e-04, l1: 0.57089, l2: 0.32019\n",
            "Loss: 3.711837e-04, l1: 0.56535, l2: 0.32040\n",
            "Loss: 3.692076e-04, l1: 0.56890, l2: 0.32026\n",
            "Loss: 3.689229e-04, l1: 0.56626, l2: 0.32012\n",
            "Loss: 3.682579e-04, l1: 0.56530, l2: 0.32015\n",
            "Loss: 3.681830e-04, l1: 0.56479, l2: 0.32023\n",
            "Loss: 3.678756e-04, l1: 0.56410, l2: 0.32041\n",
            "Loss: 3.676947e-04, l1: 0.56227, l2: 0.32047\n",
            "Loss: 3.674568e-04, l1: 0.56033, l2: 0.32069\n",
            "Loss: 3.672655e-04, l1: 0.55738, l2: 0.32086\n",
            "Loss: 3.670973e-04, l1: 0.55617, l2: 0.32066\n",
            "Loss: 3.669162e-04, l1: 0.55445, l2: 0.32065\n",
            "Loss: 3.666679e-04, l1: 0.55238, l2: 0.32054\n",
            "Loss: 3.664746e-04, l1: 0.55109, l2: 0.32029\n",
            "Loss: 3.664296e-04, l1: 0.55086, l2: 0.32028\n",
            "Loss: 3.662446e-04, l1: 0.54901, l2: 0.32028\n",
            "Loss: 3.660896e-04, l1: 0.55035, l2: 0.32021\n",
            "Loss: 3.659740e-04, l1: 0.55035, l2: 0.32010\n",
            "Loss: 3.658474e-04, l1: 0.55006, l2: 0.31992\n",
            "Loss: 3.656605e-04, l1: 0.54895, l2: 0.31956\n",
            "Loss: 3.652415e-04, l1: 0.54658, l2: 0.31892\n",
            "Loss: 3.647750e-04, l1: 0.54372, l2: 0.31866\n",
            "Loss: 3.642851e-04, l1: 0.54129, l2: 0.31852\n",
            "Loss: 3.637104e-04, l1: 0.53750, l2: 0.31863\n",
            "Loss: 3.632097e-04, l1: 0.53815, l2: 0.31911\n",
            "Loss: 3.626877e-04, l1: 0.53727, l2: 0.31934\n",
            "Loss: 3.623368e-04, l1: 0.53744, l2: 0.31947\n",
            "Loss: 3.617597e-04, l1: 0.53764, l2: 0.31969\n",
            "Loss: 3.608316e-04, l1: 0.53779, l2: 0.31968\n",
            "Loss: 3.598065e-04, l1: 0.53463, l2: 0.31937\n",
            "Loss: 3.593374e-04, l1: 0.53430, l2: 0.31904\n",
            "Loss: 3.592038e-04, l1: 0.53233, l2: 0.31903\n",
            "Loss: 3.590446e-04, l1: 0.53192, l2: 0.31906\n",
            "Loss: 3.588594e-04, l1: 0.53203, l2: 0.31938\n",
            "Loss: 3.583815e-04, l1: 0.53142, l2: 0.32016\n",
            "Loss: 3.579558e-04, l1: 0.53105, l2: 0.32081\n",
            "Loss: 3.575396e-04, l1: 0.52994, l2: 0.32109\n",
            "Loss: 3.571439e-04, l1: 0.53018, l2: 0.32113\n",
            "Loss: 3.568503e-04, l1: 0.52963, l2: 0.32092\n",
            "Loss: 3.566226e-04, l1: 0.52985, l2: 0.32069\n",
            "Loss: 3.563495e-04, l1: 0.53051, l2: 0.32058\n",
            "Loss: 3.559790e-04, l1: 0.53055, l2: 0.32046\n",
            "Loss: 3.555086e-04, l1: 0.53128, l2: 0.32035\n",
            "Loss: 3.546520e-04, l1: 0.53046, l2: 0.32030\n",
            "Loss: 3.539644e-04, l1: 0.53097, l2: 0.31968\n",
            "Loss: 3.534888e-04, l1: 0.52886, l2: 0.31916\n",
            "Loss: 3.530919e-04, l1: 0.52806, l2: 0.31895\n",
            "Loss: 3.527506e-04, l1: 0.52594, l2: 0.31881\n",
            "Loss: 3.522657e-04, l1: 0.52228, l2: 0.31861\n",
            "Loss: 3.516849e-04, l1: 0.51921, l2: 0.31844\n",
            "Loss: 3.511161e-04, l1: 0.51560, l2: 0.31813\n",
            "Loss: 3.510196e-04, l1: 0.51427, l2: 0.31827\n",
            "Loss: 3.507793e-04, l1: 0.51491, l2: 0.31820\n",
            "Loss: 3.508985e-04, l1: 0.51484, l2: 0.31844\n",
            "Loss: 3.505913e-04, l1: 0.51488, l2: 0.31831\n",
            "Loss: 3.501927e-04, l1: 0.51274, l2: 0.31832\n",
            "Loss: 3.498175e-04, l1: 0.51257, l2: 0.31853\n",
            "Loss: 3.493526e-04, l1: 0.51281, l2: 0.31838\n",
            "Loss: 3.486914e-04, l1: 0.51225, l2: 0.31816\n",
            "Loss: 3.481516e-04, l1: 0.51251, l2: 0.31782\n",
            "Loss: 3.477291e-04, l1: 0.51207, l2: 0.31746\n",
            "Loss: 3.471998e-04, l1: 0.51234, l2: 0.31716\n",
            "Loss: 3.465515e-04, l1: 0.51202, l2: 0.31677\n",
            "Loss: 3.458106e-04, l1: 0.51639, l2: 0.31640\n",
            "Loss: 3.446082e-04, l1: 0.51575, l2: 0.31616\n",
            "Loss: 3.434722e-04, l1: 0.51774, l2: 0.31656\n",
            "Loss: 3.422714e-04, l1: 0.52257, l2: 0.31728\n",
            "Loss: 3.412462e-04, l1: 0.52570, l2: 0.31802\n",
            "Loss: 3.553584e-04, l1: 0.52224, l2: 0.31476\n",
            "Loss: 3.401116e-04, l1: 0.52493, l2: 0.31729\n",
            "Loss: 3.378061e-04, l1: 0.52949, l2: 0.31869\n",
            "Loss: 3.354283e-04, l1: 0.53204, l2: 0.31913\n",
            "Loss: 3.346263e-04, l1: 0.53775, l2: 0.31880\n",
            "Loss: 3.336823e-04, l1: 0.53504, l2: 0.31896\n",
            "Loss: 3.321310e-04, l1: 0.53712, l2: 0.31845\n",
            "Loss: 3.313097e-04, l1: 0.53783, l2: 0.31804\n",
            "Loss: 3.301183e-04, l1: 0.54210, l2: 0.31790\n",
            "Loss: 3.295306e-04, l1: 0.54251, l2: 0.31864\n",
            "Loss: 3.293240e-04, l1: 0.54235, l2: 0.31854\n",
            "Loss: 3.289229e-04, l1: 0.54440, l2: 0.31866\n",
            "Loss: 3.286110e-04, l1: 0.54554, l2: 0.31875\n",
            "Loss: 3.281929e-04, l1: 0.54764, l2: 0.31902\n",
            "Loss: 3.279212e-04, l1: 0.54856, l2: 0.31921\n",
            "Loss: 3.276197e-04, l1: 0.54981, l2: 0.31931\n",
            "Loss: 3.274085e-04, l1: 0.55023, l2: 0.31922\n",
            "Loss: 3.272351e-04, l1: 0.55005, l2: 0.31918\n",
            "Loss: 3.269655e-04, l1: 0.55020, l2: 0.31925\n",
            "Loss: 3.265695e-04, l1: 0.54982, l2: 0.31946\n",
            "Loss: 3.259607e-04, l1: 0.54979, l2: 0.31973\n",
            "Loss: 3.250633e-04, l1: 0.54854, l2: 0.32013\n",
            "Loss: 3.238001e-04, l1: 0.54600, l2: 0.32053\n",
            "Loss: 3.222358e-04, l1: 0.54266, l2: 0.32120\n",
            "Loss: 3.213146e-04, l1: 0.53941, l2: 0.32093\n",
            "Loss: 3.195537e-04, l1: 0.53864, l2: 0.32046\n",
            "Loss: 3.187020e-04, l1: 0.53093, l2: 0.31991\n",
            "Loss: 3.162530e-04, l1: 0.53016, l2: 0.31978\n",
            "Loss: 3.153979e-04, l1: 0.52761, l2: 0.32020\n",
            "Loss: 3.146291e-04, l1: 0.52551, l2: 0.32100\n",
            "Loss: 3.140094e-04, l1: 0.52306, l2: 0.32110\n",
            "Loss: 3.132563e-04, l1: 0.52252, l2: 0.32100\n",
            "Loss: 3.119363e-04, l1: 0.51943, l2: 0.32097\n",
            "Loss: 3.113017e-04, l1: 0.51620, l2: 0.32084\n",
            "Loss: 3.103011e-04, l1: 0.51445, l2: 0.32082\n",
            "Loss: 3.095812e-04, l1: 0.50925, l2: 0.32037\n",
            "Loss: 3.089157e-04, l1: 0.50541, l2: 0.32006\n",
            "Loss: 3.084206e-04, l1: 0.50383, l2: 0.32003\n",
            "Loss: 3.080404e-04, l1: 0.50001, l2: 0.31987\n",
            "Loss: 3.076765e-04, l1: 0.50033, l2: 0.31972\n",
            "Loss: 3.079771e-04, l1: 0.49778, l2: 0.32002\n",
            "Loss: 3.075019e-04, l1: 0.49936, l2: 0.31983\n",
            "Loss: 3.072919e-04, l1: 0.49875, l2: 0.31982\n",
            "Loss: 3.071562e-04, l1: 0.49920, l2: 0.31984\n",
            "Loss: 3.069981e-04, l1: 0.49882, l2: 0.31962\n",
            "Loss: 3.067571e-04, l1: 0.49982, l2: 0.31968\n",
            "Loss: 3.065067e-04, l1: 0.49949, l2: 0.31949\n",
            "Loss: 3.061127e-04, l1: 0.49840, l2: 0.31943\n",
            "Loss: 3.057745e-04, l1: 0.49735, l2: 0.31945\n",
            "Loss: 3.053022e-04, l1: 0.49473, l2: 0.31942\n",
            "Loss: 3.047380e-04, l1: 0.49278, l2: 0.31950\n",
            "Loss: 3.043158e-04, l1: 0.49137, l2: 0.31937\n",
            "Loss: 3.040268e-04, l1: 0.49118, l2: 0.31922\n",
            "Loss: 3.038044e-04, l1: 0.48953, l2: 0.31883\n",
            "Loss: 3.036594e-04, l1: 0.49019, l2: 0.31843\n",
            "Loss: 3.034383e-04, l1: 0.48945, l2: 0.31836\n",
            "Loss: 3.032633e-04, l1: 0.48908, l2: 0.31833\n",
            "Loss: 3.029682e-04, l1: 0.48893, l2: 0.31827\n",
            "Loss: 3.024286e-04, l1: 0.49066, l2: 0.31841\n",
            "Loss: 3.019624e-04, l1: 0.49263, l2: 0.31844\n",
            "Loss: 3.015781e-04, l1: 0.49472, l2: 0.31868\n",
            "Loss: 3.012778e-04, l1: 0.49678, l2: 0.31900\n",
            "Loss: 3.008517e-04, l1: 0.49946, l2: 0.31934\n",
            "Loss: 3.005144e-04, l1: 0.50165, l2: 0.31940\n",
            "Loss: 3.001541e-04, l1: 0.50236, l2: 0.31921\n",
            "Loss: 2.999802e-04, l1: 0.50327, l2: 0.31914\n",
            "Loss: 2.998778e-04, l1: 0.50230, l2: 0.31901\n",
            "Loss: 2.997926e-04, l1: 0.50173, l2: 0.31902\n",
            "Loss: 2.997086e-04, l1: 0.50097, l2: 0.31913\n",
            "Loss: 2.996297e-04, l1: 0.49981, l2: 0.31915\n",
            "Loss: 2.995234e-04, l1: 0.49950, l2: 0.31915\n",
            "Loss: 2.992772e-04, l1: 0.49826, l2: 0.31877\n",
            "Loss: 2.990419e-04, l1: 0.49802, l2: 0.31891\n",
            "Loss: 2.986114e-04, l1: 0.49741, l2: 0.31854\n",
            "Loss: 2.977822e-04, l1: 0.49465, l2: 0.31821\n",
            "Loss: 2.962326e-04, l1: 0.49044, l2: 0.31756\n",
            "Loss: 2.952509e-04, l1: 0.48479, l2: 0.31729\n",
            "Loss: 2.933960e-04, l1: 0.48235, l2: 0.31702\n",
            "Loss: 2.923224e-04, l1: 0.47871, l2: 0.31712\n",
            "Loss: 2.916966e-04, l1: 0.47377, l2: 0.31740\n",
            "Loss: 2.912115e-04, l1: 0.47530, l2: 0.31801\n",
            "Loss: 2.903376e-04, l1: 0.47438, l2: 0.31791\n",
            "Loss: 2.891346e-04, l1: 0.47365, l2: 0.31809\n",
            "Loss: 2.880383e-04, l1: 0.47350, l2: 0.31880\n",
            "Loss: 2.875045e-04, l1: 0.47295, l2: 0.31929\n",
            "Loss: 2.873532e-04, l1: 0.47512, l2: 0.31949\n",
            "Loss: 2.870745e-04, l1: 0.47344, l2: 0.31918\n",
            "Loss: 2.869271e-04, l1: 0.47328, l2: 0.31888\n",
            "Loss: 2.867615e-04, l1: 0.47253, l2: 0.31870\n",
            "Loss: 2.865917e-04, l1: 0.47158, l2: 0.31845\n",
            "Loss: 2.862536e-04, l1: 0.46996, l2: 0.31851\n",
            "Loss: 2.858783e-04, l1: 0.46609, l2: 0.31859\n",
            "Loss: 2.856581e-04, l1: 0.46224, l2: 0.31878\n",
            "Loss: 2.853140e-04, l1: 0.46177, l2: 0.31882\n",
            "Loss: 2.849124e-04, l1: 0.45864, l2: 0.31864\n",
            "Loss: 2.844636e-04, l1: 0.45163, l2: 0.31839\n",
            "Loss: 2.837084e-04, l1: 0.45152, l2: 0.31834\n",
            "Loss: 2.830808e-04, l1: 0.44864, l2: 0.31849\n",
            "Loss: 2.839385e-04, l1: 0.43855, l2: 0.31885\n",
            "Loss: 2.826230e-04, l1: 0.44467, l2: 0.31863\n",
            "Loss: 2.820138e-04, l1: 0.44280, l2: 0.31905\n",
            "Loss: 2.817410e-04, l1: 0.44123, l2: 0.31916\n",
            "Loss: 2.816391e-04, l1: 0.43969, l2: 0.31933\n",
            "Loss: 2.813838e-04, l1: 0.43862, l2: 0.31917\n",
            "Loss: 2.812533e-04, l1: 0.43725, l2: 0.31906\n",
            "Loss: 2.810295e-04, l1: 0.43548, l2: 0.31880\n",
            "Loss: 2.808194e-04, l1: 0.43424, l2: 0.31870\n",
            "Loss: 2.809219e-04, l1: 0.42946, l2: 0.31885\n",
            "Loss: 2.807163e-04, l1: 0.43220, l2: 0.31876\n",
            "Loss: 2.805312e-04, l1: 0.43165, l2: 0.31896\n",
            "Loss: 2.802316e-04, l1: 0.43045, l2: 0.31914\n",
            "Loss: 2.797854e-04, l1: 0.42857, l2: 0.31954\n",
            "Loss: 2.796811e-04, l1: 0.42875, l2: 0.31958\n",
            "Loss: 2.791851e-04, l1: 0.42651, l2: 0.31941\n",
            "Loss: 2.790380e-04, l1: 0.42519, l2: 0.31919\n",
            "Loss: 2.788174e-04, l1: 0.42394, l2: 0.31885\n",
            "Loss: 2.784744e-04, l1: 0.42084, l2: 0.31827\n",
            "Loss: 2.783143e-04, l1: 0.42000, l2: 0.31765\n",
            "Loss: 2.777784e-04, l1: 0.41530, l2: 0.31750\n",
            "Loss: 2.774234e-04, l1: 0.41658, l2: 0.31804\n",
            "Loss: 2.768493e-04, l1: 0.41710, l2: 0.31908\n",
            "Loss: 2.765217e-04, l1: 0.41599, l2: 0.31904\n",
            "Loss: 2.760596e-04, l1: 0.41251, l2: 0.31859\n",
            "Loss: 2.756029e-04, l1: 0.41220, l2: 0.31817\n",
            "Loss: 2.752412e-04, l1: 0.40888, l2: 0.31800\n",
            "Loss: 2.758016e-04, l1: 0.40938, l2: 0.31808\n",
            "Loss: 2.748705e-04, l1: 0.40907, l2: 0.31803\n",
            "Loss: 2.745393e-04, l1: 0.40874, l2: 0.31827\n",
            "Loss: 2.741552e-04, l1: 0.40782, l2: 0.31819\n",
            "Loss: 2.738919e-04, l1: 0.40533, l2: 0.31815\n",
            "Loss: 2.736748e-04, l1: 0.40506, l2: 0.31815\n",
            "Loss: 2.734121e-04, l1: 0.40286, l2: 0.31798\n",
            "Loss: 2.730999e-04, l1: 0.40102, l2: 0.31789\n",
            "Loss: 2.725354e-04, l1: 0.39728, l2: 0.31760\n",
            "Loss: 2.722456e-04, l1: 0.39369, l2: 0.31750\n",
            "Loss: 2.717501e-04, l1: 0.39534, l2: 0.31750\n",
            "Loss: 2.712043e-04, l1: 0.39390, l2: 0.31735\n",
            "Loss: 2.704644e-04, l1: 0.39419, l2: 0.31743\n",
            "Loss: 2.695756e-04, l1: 0.39236, l2: 0.31710\n",
            "Loss: 2.688395e-04, l1: 0.39274, l2: 0.31702\n",
            "Loss: 2.682146e-04, l1: 0.39063, l2: 0.31669\n",
            "Loss: 2.680320e-04, l1: 0.39145, l2: 0.31667\n",
            "Loss: 2.678722e-04, l1: 0.39023, l2: 0.31678\n",
            "Loss: 2.675629e-04, l1: 0.39000, l2: 0.31674\n",
            "Loss: 2.672605e-04, l1: 0.38962, l2: 0.31658\n",
            "Loss: 2.666014e-04, l1: 0.38823, l2: 0.31613\n",
            "Loss: 2.657514e-04, l1: 0.38472, l2: 0.31559\n",
            "Loss: 2.657978e-04, l1: 0.38607, l2: 0.31572\n",
            "Loss: 2.653937e-04, l1: 0.38537, l2: 0.31565\n",
            "Loss: 2.652195e-04, l1: 0.38538, l2: 0.31546\n",
            "Loss: 2.650519e-04, l1: 0.38538, l2: 0.31539\n",
            "Loss: 2.648695e-04, l1: 0.38518, l2: 0.31546\n",
            "Loss: 2.646940e-04, l1: 0.38442, l2: 0.31549\n",
            "Loss: 2.643395e-04, l1: 0.38356, l2: 0.31575\n",
            "Loss: 2.635162e-04, l1: 0.38214, l2: 0.31661\n",
            "Loss: 2.647708e-04, l1: 0.37744, l2: 0.31760\n",
            "Loss: 2.629464e-04, l1: 0.38045, l2: 0.31696\n",
            "Loss: 2.616575e-04, l1: 0.37934, l2: 0.31725\n",
            "Loss: 2.592612e-04, l1: 0.37869, l2: 0.31785\n",
            "Loss: 2.707907e-04, l1: 0.37237, l2: 0.31637\n",
            "Loss: 2.580399e-04, l1: 0.37710, l2: 0.31748\n",
            "Loss: 2.577447e-04, l1: 0.37753, l2: 0.31705\n",
            "Loss: 2.548659e-04, l1: 0.37515, l2: 0.31646\n",
            "Loss: 2.537026e-04, l1: 0.37501, l2: 0.31642\n",
            "Loss: 2.523345e-04, l1: 0.37583, l2: 0.31607\n",
            "Loss: 2.515963e-04, l1: 0.37340, l2: 0.31524\n",
            "Loss: 2.502375e-04, l1: 0.37412, l2: 0.31534\n",
            "Loss: 2.491775e-04, l1: 0.37519, l2: 0.31583\n",
            "Loss: 2.487359e-04, l1: 0.37583, l2: 0.31600\n",
            "Loss: 2.481665e-04, l1: 0.37583, l2: 0.31606\n",
            "Loss: 2.478053e-04, l1: 0.37774, l2: 0.31638\n",
            "Loss: 2.474450e-04, l1: 0.37936, l2: 0.31662\n",
            "Loss: 2.468962e-04, l1: 0.38077, l2: 0.31680\n",
            "Loss: 2.458334e-04, l1: 0.38167, l2: 0.31672\n",
            "Loss: 2.446696e-04, l1: 0.38319, l2: 0.31618\n",
            "Loss: 2.429192e-04, l1: 0.38080, l2: 0.31512\n",
            "Loss: 2.414029e-04, l1: 0.37891, l2: 0.31434\n",
            "Loss: 2.403802e-04, l1: 0.37865, l2: 0.31406\n",
            "Loss: 2.397746e-04, l1: 0.38078, l2: 0.31414\n",
            "Loss: 2.388117e-04, l1: 0.38089, l2: 0.31466\n",
            "Loss: 2.383732e-04, l1: 0.38145, l2: 0.31502\n",
            "Loss: 2.374942e-04, l1: 0.38089, l2: 0.31609\n",
            "Loss: 2.370934e-04, l1: 0.38169, l2: 0.31607\n",
            "Loss: 2.366244e-04, l1: 0.38086, l2: 0.31569\n",
            "Loss: 2.359127e-04, l1: 0.38027, l2: 0.31540\n",
            "Loss: 2.350031e-04, l1: 0.38017, l2: 0.31518\n",
            "Loss: 2.339253e-04, l1: 0.38174, l2: 0.31511\n",
            "Loss: 2.330878e-04, l1: 0.38361, l2: 0.31572\n",
            "Loss: 2.320733e-04, l1: 0.38578, l2: 0.31636\n",
            "Loss: 2.316557e-04, l1: 0.38669, l2: 0.31687\n",
            "Loss: 2.315069e-04, l1: 0.38680, l2: 0.31692\n",
            "Loss: 2.312331e-04, l1: 0.38630, l2: 0.31667\n",
            "Loss: 2.310501e-04, l1: 0.38615, l2: 0.31665\n",
            "Loss: 2.306552e-04, l1: 0.38578, l2: 0.31662\n",
            "Loss: 2.302202e-04, l1: 0.38501, l2: 0.31662\n",
            "Loss: 2.298394e-04, l1: 0.38542, l2: 0.31674\n",
            "Loss: 2.294225e-04, l1: 0.38507, l2: 0.31698\n",
            "Loss: 2.288460e-04, l1: 0.38516, l2: 0.31734\n",
            "Loss: 2.284445e-04, l1: 0.38539, l2: 0.31773\n",
            "Loss: 2.279587e-04, l1: 0.38533, l2: 0.31785\n",
            "Loss: 2.274279e-04, l1: 0.38576, l2: 0.31777\n",
            "Loss: 2.270904e-04, l1: 0.38581, l2: 0.31772\n",
            "Loss: 2.264716e-04, l1: 0.38674, l2: 0.31768\n",
            "Loss: 2.258987e-04, l1: 0.38828, l2: 0.31744\n",
            "Loss: 2.258997e-04, l1: 0.38869, l2: 0.31761\n",
            "Loss: 2.257118e-04, l1: 0.38850, l2: 0.31753\n",
            "Loss: 2.254486e-04, l1: 0.38818, l2: 0.31773\n",
            "Loss: 2.250782e-04, l1: 0.38777, l2: 0.31798\n",
            "Loss: 2.246315e-04, l1: 0.38671, l2: 0.31807\n",
            "Loss: 2.242501e-04, l1: 0.38548, l2: 0.31821\n",
            "Loss: 2.235579e-04, l1: 0.38352, l2: 0.31810\n",
            "Loss: 2.230938e-04, l1: 0.38323, l2: 0.31818\n",
            "Loss: 2.225945e-04, l1: 0.38335, l2: 0.31833\n",
            "Loss: 2.223706e-04, l1: 0.38402, l2: 0.31840\n",
            "Loss: 2.220907e-04, l1: 0.38377, l2: 0.31835\n",
            "Loss: 2.218061e-04, l1: 0.38311, l2: 0.31822\n",
            "Loss: 2.215571e-04, l1: 0.38252, l2: 0.31829\n",
            "Loss: 2.212817e-04, l1: 0.38249, l2: 0.31806\n",
            "Loss: 2.208754e-04, l1: 0.38124, l2: 0.31807\n",
            "Loss: 2.203502e-04, l1: 0.38116, l2: 0.31785\n",
            "Loss: 2.196560e-04, l1: 0.38200, l2: 0.31768\n",
            "Loss: 2.190721e-04, l1: 0.38214, l2: 0.31764\n",
            "Loss: 2.194100e-04, l1: 0.38307, l2: 0.31844\n",
            "Loss: 2.188331e-04, l1: 0.38250, l2: 0.31795\n",
            "Loss: 2.184802e-04, l1: 0.38229, l2: 0.31808\n",
            "Loss: 2.183302e-04, l1: 0.38209, l2: 0.31796\n",
            "Loss: 2.182139e-04, l1: 0.38189, l2: 0.31790\n",
            "Loss: 2.180252e-04, l1: 0.38130, l2: 0.31761\n",
            "Loss: 2.177838e-04, l1: 0.38010, l2: 0.31717\n",
            "Loss: 2.173665e-04, l1: 0.37843, l2: 0.31674\n",
            "Loss: 2.168363e-04, l1: 0.37529, l2: 0.31616\n",
            "Loss: 2.161841e-04, l1: 0.37387, l2: 0.31598\n",
            "Loss: 2.154635e-04, l1: 0.37196, l2: 0.31640\n",
            "Loss: 2.152901e-04, l1: 0.37304, l2: 0.31683\n",
            "Loss: 2.148775e-04, l1: 0.37190, l2: 0.31693\n",
            "Loss: 2.144921e-04, l1: 0.37064, l2: 0.31671\n",
            "Loss: 2.141558e-04, l1: 0.36989, l2: 0.31660\n",
            "Loss: 2.131393e-04, l1: 0.36685, l2: 0.31616\n",
            "Loss: 2.122213e-04, l1: 0.36198, l2: 0.31595\n",
            "Loss: 2.109271e-04, l1: 0.35874, l2: 0.31593\n",
            "Loss: 2.101134e-04, l1: 0.35740, l2: 0.31633\n",
            "Loss: 2.093897e-04, l1: 0.35749, l2: 0.31635\n",
            "Loss: 2.088814e-04, l1: 0.35874, l2: 0.31685\n",
            "Loss: 2.086389e-04, l1: 0.35646, l2: 0.31714\n",
            "Loss: 2.078008e-04, l1: 0.35667, l2: 0.31750\n",
            "Loss: 2.072050e-04, l1: 0.35587, l2: 0.31742\n",
            "Loss: 2.063763e-04, l1: 0.35504, l2: 0.31783\n",
            "Loss: 2.058153e-04, l1: 0.35264, l2: 0.31825\n",
            "Loss: 2.047057e-04, l1: 0.35385, l2: 0.31798\n",
            "Loss: 2.040441e-04, l1: 0.35445, l2: 0.31737\n",
            "Loss: 2.029663e-04, l1: 0.35372, l2: 0.31699\n",
            "Loss: 2.020060e-04, l1: 0.35234, l2: 0.31680\n",
            "Loss: 2.012815e-04, l1: 0.35179, l2: 0.31667\n",
            "Loss: 1.999613e-04, l1: 0.34998, l2: 0.31635\n",
            "Loss: 1.993481e-04, l1: 0.34806, l2: 0.31614\n",
            "Loss: 1.990075e-04, l1: 0.34690, l2: 0.31606\n",
            "Loss: 1.987844e-04, l1: 0.34402, l2: 0.31617\n",
            "Loss: 1.980458e-04, l1: 0.34493, l2: 0.31641\n",
            "Loss: 1.976047e-04, l1: 0.34495, l2: 0.31642\n",
            "Loss: 1.968141e-04, l1: 0.34257, l2: 0.31655\n",
            "Loss: 1.963011e-04, l1: 0.33949, l2: 0.31637\n",
            "Loss: 1.959461e-04, l1: 0.33741, l2: 0.31641\n",
            "Loss: 1.955575e-04, l1: 0.33596, l2: 0.31617\n",
            "Loss: 1.957237e-04, l1: 0.33377, l2: 0.31623\n",
            "Loss: 1.953325e-04, l1: 0.33499, l2: 0.31620\n",
            "Loss: 1.950527e-04, l1: 0.33445, l2: 0.31609\n",
            "Loss: 1.947590e-04, l1: 0.33435, l2: 0.31615\n",
            "Loss: 1.945438e-04, l1: 0.33275, l2: 0.31589\n",
            "Loss: 1.942785e-04, l1: 0.33161, l2: 0.31583\n",
            "Loss: 1.936840e-04, l1: 0.32913, l2: 0.31586\n",
            "Loss: 1.930606e-04, l1: 0.32697, l2: 0.31596\n",
            "Loss: 1.930403e-04, l1: 0.32374, l2: 0.31616\n",
            "Loss: 1.928458e-04, l1: 0.32551, l2: 0.31605\n",
            "Loss: 1.925248e-04, l1: 0.32446, l2: 0.31627\n",
            "Loss: 1.922859e-04, l1: 0.32069, l2: 0.31611\n",
            "Loss: 1.919220e-04, l1: 0.32062, l2: 0.31605\n",
            "Loss: 1.917968e-04, l1: 0.31961, l2: 0.31585\n",
            "Loss: 1.916356e-04, l1: 0.31830, l2: 0.31560\n",
            "Loss: 1.914816e-04, l1: 0.31566, l2: 0.31530\n",
            "Loss: 1.913003e-04, l1: 0.31502, l2: 0.31501\n",
            "Loss: 1.911358e-04, l1: 0.31458, l2: 0.31519\n",
            "Loss: 1.910501e-04, l1: 0.31252, l2: 0.31536\n",
            "Loss: 1.909616e-04, l1: 0.31295, l2: 0.31557\n",
            "Loss: 1.908994e-04, l1: 0.31255, l2: 0.31561\n",
            "Loss: 1.908260e-04, l1: 0.31138, l2: 0.31566\n",
            "Loss: 1.907881e-04, l1: 0.31092, l2: 0.31576\n",
            "Loss: 1.907405e-04, l1: 0.31082, l2: 0.31587\n",
            "Loss: 1.906482e-04, l1: 0.30996, l2: 0.31603\n",
            "Loss: 1.904860e-04, l1: 0.30895, l2: 0.31615\n",
            "Loss: 1.904299e-04, l1: 0.30822, l2: 0.31627\n",
            "Loss: 1.903198e-04, l1: 0.30826, l2: 0.31621\n",
            "Loss: 1.902662e-04, l1: 0.30876, l2: 0.31614\n",
            "Loss: 1.901592e-04, l1: 0.30990, l2: 0.31613\n",
            "Loss: 1.900369e-04, l1: 0.31083, l2: 0.31639\n",
            "Loss: 1.900162e-04, l1: 0.31279, l2: 0.31641\n",
            "Loss: 1.898370e-04, l1: 0.31183, l2: 0.31640\n",
            "Loss: 1.899033e-04, l1: 0.31196, l2: 0.31603\n",
            "Loss: 1.896919e-04, l1: 0.31189, l2: 0.31623\n",
            "Loss: 1.894692e-04, l1: 0.31078, l2: 0.31631\n",
            "Loss: 1.892989e-04, l1: 0.30984, l2: 0.31637\n",
            "Loss: 1.891425e-04, l1: 0.30995, l2: 0.31625\n",
            "Loss: 1.890334e-04, l1: 0.31032, l2: 0.31606\n",
            "Loss: 1.889064e-04, l1: 0.31030, l2: 0.31595\n",
            "Loss: 1.887167e-04, l1: 0.31057, l2: 0.31588\n",
            "Loss: 1.884246e-04, l1: 0.31023, l2: 0.31627\n",
            "Loss: 1.880231e-04, l1: 0.31105, l2: 0.31648\n",
            "Loss: 1.875074e-04, l1: 0.31095, l2: 0.31701\n",
            "Loss: 1.871475e-04, l1: 0.30972, l2: 0.31729\n",
            "Loss: 1.869166e-04, l1: 0.31006, l2: 0.31758\n",
            "Loss: 1.867351e-04, l1: 0.30891, l2: 0.31757\n",
            "Loss: 1.866085e-04, l1: 0.30894, l2: 0.31732\n",
            "Loss: 1.864555e-04, l1: 0.30935, l2: 0.31738\n",
            "Loss: 1.863889e-04, l1: 0.30968, l2: 0.31746\n",
            "Loss: 1.863270e-04, l1: 0.31024, l2: 0.31739\n",
            "Loss: 1.862365e-04, l1: 0.31048, l2: 0.31733\n",
            "Loss: 1.861279e-04, l1: 0.31085, l2: 0.31731\n",
            "Loss: 1.860543e-04, l1: 0.31013, l2: 0.31718\n",
            "Loss: 1.859967e-04, l1: 0.30884, l2: 0.31713\n",
            "Loss: 1.859563e-04, l1: 0.30799, l2: 0.31699\n",
            "Loss: 1.859259e-04, l1: 0.30693, l2: 0.31696\n",
            "Loss: 1.858950e-04, l1: 0.30582, l2: 0.31700\n",
            "Loss: 1.858563e-04, l1: 0.30534, l2: 0.31694\n",
            "Loss: 1.858063e-04, l1: 0.30486, l2: 0.31692\n",
            "Loss: 1.857844e-04, l1: 0.30428, l2: 0.31711\n",
            "Loss: 1.857262e-04, l1: 0.30388, l2: 0.31706\n",
            "Loss: 1.856960e-04, l1: 0.30378, l2: 0.31707\n",
            "Loss: 1.856585e-04, l1: 0.30247, l2: 0.31704\n",
            "Loss: 1.856030e-04, l1: 0.30236, l2: 0.31703\n",
            "Loss: 1.854961e-04, l1: 0.30127, l2: 0.31695\n",
            "Loss: 1.853344e-04, l1: 0.29851, l2: 0.31671\n",
            "Loss: 1.851041e-04, l1: 0.29729, l2: 0.31642\n",
            "Loss: 1.852104e-04, l1: 0.29387, l2: 0.31622\n",
            "Loss: 1.849752e-04, l1: 0.29574, l2: 0.31633\n",
            "Loss: 1.846651e-04, l1: 0.29471, l2: 0.31625\n",
            "Loss: 1.844126e-04, l1: 0.29515, l2: 0.31642\n",
            "Loss: 1.843788e-04, l1: 0.29320, l2: 0.31655\n",
            "Loss: 1.842884e-04, l1: 0.29424, l2: 0.31649\n",
            "Loss: 1.841839e-04, l1: 0.29378, l2: 0.31670\n",
            "Loss: 1.841123e-04, l1: 0.29402, l2: 0.31689\n",
            "Loss: 1.840137e-04, l1: 0.29492, l2: 0.31716\n",
            "Loss: 1.838409e-04, l1: 0.29424, l2: 0.31717\n",
            "Loss: 1.836314e-04, l1: 0.29337, l2: 0.31718\n",
            "Loss: 1.835731e-04, l1: 0.29309, l2: 0.31701\n",
            "Loss: 1.835013e-04, l1: 0.29290, l2: 0.31688\n",
            "Loss: 1.834263e-04, l1: 0.29289, l2: 0.31683\n",
            "Loss: 1.833745e-04, l1: 0.29249, l2: 0.31684\n",
            "Loss: 1.833222e-04, l1: 0.29279, l2: 0.31689\n",
            "Loss: 1.832758e-04, l1: 0.29305, l2: 0.31692\n",
            "Loss: 1.832299e-04, l1: 0.29338, l2: 0.31698\n",
            "Loss: 1.831516e-04, l1: 0.29345, l2: 0.31693\n",
            "Loss: 1.830536e-04, l1: 0.29329, l2: 0.31680\n",
            "Loss: 1.829793e-04, l1: 0.29256, l2: 0.31628\n",
            "Loss: 1.828232e-04, l1: 0.29235, l2: 0.31635\n",
            "Loss: 1.826948e-04, l1: 0.29189, l2: 0.31640\n",
            "Loss: 1.825674e-04, l1: 0.29119, l2: 0.31642\n",
            "Loss: 1.824606e-04, l1: 0.29093, l2: 0.31639\n",
            "Loss: 1.824056e-04, l1: 0.29060, l2: 0.31647\n",
            "Loss: 1.823406e-04, l1: 0.29083, l2: 0.31648\n",
            "Loss: 1.822739e-04, l1: 0.29123, l2: 0.31657\n",
            "Loss: 1.821950e-04, l1: 0.29152, l2: 0.31657\n",
            "Loss: 1.821023e-04, l1: 0.29188, l2: 0.31645\n",
            "Loss: 1.819909e-04, l1: 0.29252, l2: 0.31634\n",
            "Loss: 1.818661e-04, l1: 0.29325, l2: 0.31609\n",
            "Loss: 1.818061e-04, l1: 0.29320, l2: 0.31601\n",
            "Loss: 1.817076e-04, l1: 0.29315, l2: 0.31602\n",
            "Loss: 1.816026e-04, l1: 0.29340, l2: 0.31601\n",
            "Loss: 1.815144e-04, l1: 0.29365, l2: 0.31606\n",
            "Loss: 1.813763e-04, l1: 0.29334, l2: 0.31600\n",
            "Loss: 1.813191e-04, l1: 0.29345, l2: 0.31593\n",
            "Loss: 1.812648e-04, l1: 0.29359, l2: 0.31590\n",
            "Loss: 1.811965e-04, l1: 0.29391, l2: 0.31585\n",
            "Loss: 1.811324e-04, l1: 0.29412, l2: 0.31583\n",
            "Loss: 1.810679e-04, l1: 0.29412, l2: 0.31580\n",
            "Loss: 1.810098e-04, l1: 0.29418, l2: 0.31570\n",
            "Loss: 1.809684e-04, l1: 0.29411, l2: 0.31574\n",
            "Loss: 1.809192e-04, l1: 0.29418, l2: 0.31581\n",
            "Loss: 1.808833e-04, l1: 0.29445, l2: 0.31585\n",
            "Loss: 1.808318e-04, l1: 0.29502, l2: 0.31597\n",
            "Loss: 1.807924e-04, l1: 0.29607, l2: 0.31576\n",
            "Loss: 1.807116e-04, l1: 0.29623, l2: 0.31583\n",
            "Loss: 1.805759e-04, l1: 0.29685, l2: 0.31581\n",
            "Loss: 1.803982e-04, l1: 0.29885, l2: 0.31576\n",
            "Loss: 1.802339e-04, l1: 0.30061, l2: 0.31569\n",
            "Loss: 1.800657e-04, l1: 0.30199, l2: 0.31541\n",
            "Loss: 1.800230e-04, l1: 0.30266, l2: 0.31530\n",
            "Loss: 1.799252e-04, l1: 0.30350, l2: 0.31544\n",
            "Loss: 1.798734e-04, l1: 0.30330, l2: 0.31553\n",
            "Loss: 1.796903e-04, l1: 0.30331, l2: 0.31579\n",
            "Loss: 1.794301e-04, l1: 0.30396, l2: 0.31615\n",
            "Loss: 1.790764e-04, l1: 0.30558, l2: 0.31617\n",
            "Loss: 1.786673e-04, l1: 0.30655, l2: 0.31603\n",
            "Loss: 1.785746e-04, l1: 0.31022, l2: 0.31555\n",
            "Loss: 1.784014e-04, l1: 0.30840, l2: 0.31579\n",
            "Loss: 1.781039e-04, l1: 0.30914, l2: 0.31550\n",
            "Loss: 1.776798e-04, l1: 0.31183, l2: 0.31535\n",
            "Loss: 1.775350e-04, l1: 0.31279, l2: 0.31513\n",
            "Loss: 1.773670e-04, l1: 0.31232, l2: 0.31524\n",
            "Loss: 1.767978e-04, l1: 0.31487, l2: 0.31527\n",
            "Loss: 1.762390e-04, l1: 0.31639, l2: 0.31547\n",
            "Loss: 1.759183e-04, l1: 0.31783, l2: 0.31560\n",
            "Loss: 1.756133e-04, l1: 0.31687, l2: 0.31563\n",
            "Loss: 1.753713e-04, l1: 0.31754, l2: 0.31560\n",
            "Loss: 1.754749e-04, l1: 0.32046, l2: 0.31591\n",
            "Loss: 1.752455e-04, l1: 0.31881, l2: 0.31573\n",
            "Loss: 1.750718e-04, l1: 0.32027, l2: 0.31621\n",
            "Loss: 1.748082e-04, l1: 0.32179, l2: 0.31630\n",
            "Loss: 1.746447e-04, l1: 0.32224, l2: 0.31615\n",
            "Loss: 1.744494e-04, l1: 0.32283, l2: 0.31603\n",
            "Loss: 1.742727e-04, l1: 0.32446, l2: 0.31586\n",
            "Loss: 1.740990e-04, l1: 0.32472, l2: 0.31574\n",
            "Loss: 1.739866e-04, l1: 0.32590, l2: 0.31573\n",
            "Loss: 1.736571e-04, l1: 0.32441, l2: 0.31568\n",
            "Loss: 1.733461e-04, l1: 0.32307, l2: 0.31558\n",
            "Loss: 1.735701e-04, l1: 0.32165, l2: 0.31554\n",
            "Loss: 1.730897e-04, l1: 0.32243, l2: 0.31556\n",
            "Loss: 1.729152e-04, l1: 0.32010, l2: 0.31582\n",
            "Loss: 1.731629e-04, l1: 0.31866, l2: 0.31561\n",
            "Loss: 1.727339e-04, l1: 0.31953, l2: 0.31573\n",
            "Loss: 1.728923e-04, l1: 0.31997, l2: 0.31552\n",
            "Loss: 1.725856e-04, l1: 0.31971, l2: 0.31565\n",
            "Loss: 1.725211e-04, l1: 0.31980, l2: 0.31565\n",
            "Loss: 1.724794e-04, l1: 0.32029, l2: 0.31570\n",
            "Loss: 1.723507e-04, l1: 0.31993, l2: 0.31556\n",
            "Loss: 1.722946e-04, l1: 0.31975, l2: 0.31551\n",
            "Loss: 1.722275e-04, l1: 0.31917, l2: 0.31546\n",
            "Loss: 1.721281e-04, l1: 0.31881, l2: 0.31491\n",
            "Loss: 1.720067e-04, l1: 0.31760, l2: 0.31522\n",
            "Loss: 1.718710e-04, l1: 0.31773, l2: 0.31523\n",
            "Loss: 1.717903e-04, l1: 0.31800, l2: 0.31518\n",
            "Loss: 1.716925e-04, l1: 0.31907, l2: 0.31537\n",
            "Loss: 1.716067e-04, l1: 0.31888, l2: 0.31551\n",
            "Loss: 1.715561e-04, l1: 0.31892, l2: 0.31560\n",
            "Loss: 1.714940e-04, l1: 0.31901, l2: 0.31567\n",
            "Loss: 1.713746e-04, l1: 0.31916, l2: 0.31581\n",
            "Loss: 1.712175e-04, l1: 0.31858, l2: 0.31576\n",
            "Loss: 1.710555e-04, l1: 0.31759, l2: 0.31572\n",
            "Loss: 1.708270e-04, l1: 0.31554, l2: 0.31548\n",
            "Loss: 1.709382e-04, l1: 0.31329, l2: 0.31516\n",
            "Loss: 1.707246e-04, l1: 0.31461, l2: 0.31535\n",
            "Loss: 1.706819e-04, l1: 0.31201, l2: 0.31513\n",
            "Loss: 1.705767e-04, l1: 0.31341, l2: 0.31525\n",
            "Loss: 1.704777e-04, l1: 0.31243, l2: 0.31513\n",
            "Loss: 1.704138e-04, l1: 0.31315, l2: 0.31516\n",
            "Loss: 1.703641e-04, l1: 0.31302, l2: 0.31517\n",
            "Loss: 1.703089e-04, l1: 0.31275, l2: 0.31521\n",
            "Loss: 1.702300e-04, l1: 0.31254, l2: 0.31520\n",
            "Loss: 1.701413e-04, l1: 0.31216, l2: 0.31515\n",
            "Loss: 1.700649e-04, l1: 0.31247, l2: 0.31504\n",
            "Loss: 1.699869e-04, l1: 0.31250, l2: 0.31497\n",
            "Loss: 1.698824e-04, l1: 0.31332, l2: 0.31493\n",
            "Loss: 1.697626e-04, l1: 0.31505, l2: 0.31497\n",
            "Loss: 1.696956e-04, l1: 0.31649, l2: 0.31514\n",
            "Loss: 1.696370e-04, l1: 0.31689, l2: 0.31515\n",
            "Loss: 1.695759e-04, l1: 0.31694, l2: 0.31512\n",
            "Loss: 1.694816e-04, l1: 0.31758, l2: 0.31506\n",
            "Loss: 1.693940e-04, l1: 0.31776, l2: 0.31504\n",
            "Loss: 1.693082e-04, l1: 0.31849, l2: 0.31500\n",
            "Loss: 1.692195e-04, l1: 0.31978, l2: 0.31497\n",
            "Loss: 1.690923e-04, l1: 0.32041, l2: 0.31498\n",
            "Loss: 1.689594e-04, l1: 0.32149, l2: 0.31503\n",
            "Loss: 1.688197e-04, l1: 0.32152, l2: 0.31521\n",
            "Loss: 1.687521e-04, l1: 0.32248, l2: 0.31529\n",
            "Loss: 1.686419e-04, l1: 0.32228, l2: 0.31532\n",
            "Loss: 1.685962e-04, l1: 0.32241, l2: 0.31536\n",
            "Loss: 1.685368e-04, l1: 0.32126, l2: 0.31549\n",
            "Loss: 1.684684e-04, l1: 0.32142, l2: 0.31547\n",
            "Loss: 1.684055e-04, l1: 0.32094, l2: 0.31534\n",
            "Loss: 1.683257e-04, l1: 0.32026, l2: 0.31525\n",
            "Loss: 1.682307e-04, l1: 0.31918, l2: 0.31512\n",
            "Loss: 1.681781e-04, l1: 0.31928, l2: 0.31518\n",
            "Loss: 1.681447e-04, l1: 0.31923, l2: 0.31515\n",
            "Loss: 1.680219e-04, l1: 0.31948, l2: 0.31525\n",
            "Loss: 1.679689e-04, l1: 0.31946, l2: 0.31525\n",
            "Loss: 1.678476e-04, l1: 0.31928, l2: 0.31525\n",
            "Loss: 1.677769e-04, l1: 0.31912, l2: 0.31526\n",
            "Loss: 1.676377e-04, l1: 0.31851, l2: 0.31524\n",
            "Loss: 1.674660e-04, l1: 0.31784, l2: 0.31530\n",
            "Loss: 1.672452e-04, l1: 0.31775, l2: 0.31545\n",
            "Loss: 1.673827e-04, l1: 0.31733, l2: 0.31572\n",
            "Loss: 1.671426e-04, l1: 0.31758, l2: 0.31556\n",
            "Loss: 1.670165e-04, l1: 0.31849, l2: 0.31572\n",
            "Loss: 1.669394e-04, l1: 0.31821, l2: 0.31572\n",
            "Loss: 1.668635e-04, l1: 0.31856, l2: 0.31575\n",
            "Loss: 1.667277e-04, l1: 0.31907, l2: 0.31571\n",
            "Loss: 1.666198e-04, l1: 0.31895, l2: 0.31575\n",
            "Loss: 1.665264e-04, l1: 0.31908, l2: 0.31570\n",
            "Loss: 1.663958e-04, l1: 0.31965, l2: 0.31552\n",
            "Loss: 1.662607e-04, l1: 0.32041, l2: 0.31531\n",
            "Loss: 1.661874e-04, l1: 0.32076, l2: 0.31510\n",
            "Loss: 1.662350e-04, l1: 0.32038, l2: 0.31480\n",
            "Loss: 1.661108e-04, l1: 0.32060, l2: 0.31497\n",
            "Loss: 1.660270e-04, l1: 0.32068, l2: 0.31503\n",
            "Loss: 1.659437e-04, l1: 0.32063, l2: 0.31505\n",
            "Loss: 1.658739e-04, l1: 0.32169, l2: 0.31506\n",
            "Loss: 1.657970e-04, l1: 0.32246, l2: 0.31514\n",
            "Loss: 1.657422e-04, l1: 0.32392, l2: 0.31512\n",
            "Loss: 1.657040e-04, l1: 0.32487, l2: 0.31521\n",
            "Loss: 1.657259e-04, l1: 0.32474, l2: 0.31521\n",
            "Loss: 1.656837e-04, l1: 0.32482, l2: 0.31521\n",
            "Loss: 1.656294e-04, l1: 0.32506, l2: 0.31516\n",
            "Loss: 1.655260e-04, l1: 0.32652, l2: 0.31507\n",
            "Loss: 1.654406e-04, l1: 0.32786, l2: 0.31515\n",
            "Loss: 1.653450e-04, l1: 0.32934, l2: 0.31523\n",
            "Loss: 1.652630e-04, l1: 0.32906, l2: 0.31525\n",
            "Loss: 1.652077e-04, l1: 0.32843, l2: 0.31521\n",
            "Loss: 1.651632e-04, l1: 0.32821, l2: 0.31512\n",
            "Loss: 1.651078e-04, l1: 0.32779, l2: 0.31501\n",
            "Loss: 1.649947e-04, l1: 0.32765, l2: 0.31486\n",
            "Loss: 1.648102e-04, l1: 0.32798, l2: 0.31480\n",
            "Loss: 1.646606e-04, l1: 0.32814, l2: 0.31471\n",
            "Loss: 1.645450e-04, l1: 0.32866, l2: 0.31478\n",
            "Loss: 1.645428e-04, l1: 0.33102, l2: 0.31480\n",
            "Loss: 1.644965e-04, l1: 0.32977, l2: 0.31479\n",
            "Loss: 1.644174e-04, l1: 0.33101, l2: 0.31481\n",
            "Loss: 1.643622e-04, l1: 0.33155, l2: 0.31479\n",
            "Loss: 1.642555e-04, l1: 0.33267, l2: 0.31462\n",
            "Loss: 1.641574e-04, l1: 0.33309, l2: 0.31443\n",
            "Loss: 1.640352e-04, l1: 0.33415, l2: 0.31417\n",
            "Loss: 1.639236e-04, l1: 0.33433, l2: 0.31405\n",
            "Loss: 1.639725e-04, l1: 0.33652, l2: 0.31382\n",
            "Loss: 1.638592e-04, l1: 0.33532, l2: 0.31395\n",
            "Loss: 1.637696e-04, l1: 0.33627, l2: 0.31395\n",
            "Loss: 1.636325e-04, l1: 0.33631, l2: 0.31396\n",
            "Loss: 1.634250e-04, l1: 0.33676, l2: 0.31409\n",
            "Loss: 1.633699e-04, l1: 0.33729, l2: 0.31394\n",
            "Loss: 1.632799e-04, l1: 0.33699, l2: 0.31402\n",
            "Loss: 1.629598e-04, l1: 0.33515, l2: 0.31406\n",
            "Loss: 1.627817e-04, l1: 0.33528, l2: 0.31412\n",
            "Loss: 1.626799e-04, l1: 0.33589, l2: 0.31409\n",
            "Loss: 1.626047e-04, l1: 0.33569, l2: 0.31408\n",
            "Loss: 1.625472e-04, l1: 0.33557, l2: 0.31411\n",
            "Loss: 1.624743e-04, l1: 0.33576, l2: 0.31412\n",
            "Loss: 1.623571e-04, l1: 0.33607, l2: 0.31414\n",
            "Loss: 1.621859e-04, l1: 0.33730, l2: 0.31403\n",
            "Loss: 1.620224e-04, l1: 0.33735, l2: 0.31393\n",
            "Loss: 1.618550e-04, l1: 0.33783, l2: 0.31384\n",
            "Loss: 1.616481e-04, l1: 0.33851, l2: 0.31369\n",
            "Loss: 1.613917e-04, l1: 0.33953, l2: 0.31376\n",
            "Loss: 1.610628e-04, l1: 0.34068, l2: 0.31392\n",
            "Loss: 1.607695e-04, l1: 0.34199, l2: 0.31398\n",
            "Loss: 1.603718e-04, l1: 0.34294, l2: 0.31413\n",
            "Loss: 1.599413e-04, l1: 0.34725, l2: 0.31447\n",
            "Loss: 1.595557e-04, l1: 0.34586, l2: 0.31453\n",
            "Loss: 1.588471e-04, l1: 0.34685, l2: 0.31446\n",
            "Loss: 1.587349e-04, l1: 0.34876, l2: 0.31430\n",
            "Loss: 1.581959e-04, l1: 0.34897, l2: 0.31442\n",
            "Loss: 1.582048e-04, l1: 0.34704, l2: 0.31437\n",
            "Loss: 1.579573e-04, l1: 0.34802, l2: 0.31440\n",
            "Loss: 1.575926e-04, l1: 0.34920, l2: 0.31443\n",
            "Loss: 1.578986e-04, l1: 0.35266, l2: 0.31440\n",
            "Loss: 1.571862e-04, l1: 0.35076, l2: 0.31441\n",
            "Loss: 1.570841e-04, l1: 0.35400, l2: 0.31474\n",
            "Loss: 1.568464e-04, l1: 0.35237, l2: 0.31458\n",
            "Loss: 1.564716e-04, l1: 0.35329, l2: 0.31466\n",
            "Loss: 1.566009e-04, l1: 0.35550, l2: 0.31500\n",
            "Loss: 1.561918e-04, l1: 0.35434, l2: 0.31482\n",
            "Loss: 1.559673e-04, l1: 0.35557, l2: 0.31496\n",
            "Loss: 1.554669e-04, l1: 0.35732, l2: 0.31535\n",
            "Loss: 1.555021e-04, l1: 0.36407, l2: 0.31555\n",
            "Loss: 1.550832e-04, l1: 0.36068, l2: 0.31545\n",
            "Loss: 1.546778e-04, l1: 0.36288, l2: 0.31535\n",
            "Loss: 1.545563e-04, l1: 0.36568, l2: 0.31536\n",
            "Loss: 1.542138e-04, l1: 0.36598, l2: 0.31504\n",
            "Loss: 1.540485e-04, l1: 0.36626, l2: 0.31479\n",
            "Loss: 1.538908e-04, l1: 0.36728, l2: 0.31462\n",
            "Loss: 1.537238e-04, l1: 0.36841, l2: 0.31467\n",
            "Loss: 1.536019e-04, l1: 0.37093, l2: 0.31465\n",
            "Loss: 1.532744e-04, l1: 0.37047, l2: 0.31478\n",
            "Loss: 1.530398e-04, l1: 0.37304, l2: 0.31506\n",
            "Loss: 1.527098e-04, l1: 0.37432, l2: 0.31551\n",
            "Loss: 1.523645e-04, l1: 0.37604, l2: 0.31562\n",
            "Loss: 1.521794e-04, l1: 0.37509, l2: 0.31553\n",
            "Loss: 1.519900e-04, l1: 0.37560, l2: 0.31569\n",
            "Loss: 1.518009e-04, l1: 0.37664, l2: 0.31579\n",
            "Loss: 1.515094e-04, l1: 0.37727, l2: 0.31580\n",
            "Loss: 1.513135e-04, l1: 0.38067, l2: 0.31577\n",
            "Loss: 1.509252e-04, l1: 0.38032, l2: 0.31552\n",
            "Loss: 1.507022e-04, l1: 0.38067, l2: 0.31554\n",
            "Loss: 1.504236e-04, l1: 0.38267, l2: 0.31549\n",
            "Loss: 1.501669e-04, l1: 0.38283, l2: 0.31540\n",
            "Loss: 1.497687e-04, l1: 0.38368, l2: 0.31531\n",
            "Loss: 1.494863e-04, l1: 0.38406, l2: 0.31540\n",
            "Loss: 1.498976e-04, l1: 0.38601, l2: 0.31552\n",
            "Loss: 1.494139e-04, l1: 0.38462, l2: 0.31544\n",
            "Loss: 1.493417e-04, l1: 0.38467, l2: 0.31557\n",
            "Loss: 1.492595e-04, l1: 0.38510, l2: 0.31560\n",
            "Loss: 1.491662e-04, l1: 0.38536, l2: 0.31565\n",
            "Loss: 1.489344e-04, l1: 0.38666, l2: 0.31583\n",
            "Loss: 1.488418e-04, l1: 0.38766, l2: 0.31608\n",
            "Loss: 1.485624e-04, l1: 0.38882, l2: 0.31611\n",
            "Loss: 1.483954e-04, l1: 0.38937, l2: 0.31597\n",
            "Loss: 1.482407e-04, l1: 0.39013, l2: 0.31589\n",
            "Loss: 1.481120e-04, l1: 0.39050, l2: 0.31581\n",
            "Loss: 1.479949e-04, l1: 0.39181, l2: 0.31575\n",
            "Loss: 1.478785e-04, l1: 0.39247, l2: 0.31562\n",
            "Loss: 1.477629e-04, l1: 0.39347, l2: 0.31559\n",
            "Loss: 1.476258e-04, l1: 0.39437, l2: 0.31553\n",
            "Loss: 1.474985e-04, l1: 0.39611, l2: 0.31546\n",
            "Loss: 1.473432e-04, l1: 0.39753, l2: 0.31549\n",
            "Loss: 1.472250e-04, l1: 0.39956, l2: 0.31553\n",
            "Loss: 1.471470e-04, l1: 0.39999, l2: 0.31558\n",
            "Loss: 1.471094e-04, l1: 0.40014, l2: 0.31556\n",
            "Loss: 1.470483e-04, l1: 0.40038, l2: 0.31553\n",
            "Loss: 1.469154e-04, l1: 0.40041, l2: 0.31548\n",
            "Loss: 1.466493e-04, l1: 0.40104, l2: 0.31533\n",
            "Loss: 1.463194e-04, l1: 0.40124, l2: 0.31545\n",
            "Loss: 1.460219e-04, l1: 0.40163, l2: 0.31579\n",
            "Loss: 1.458795e-04, l1: 0.40251, l2: 0.31603\n",
            "Loss: 1.457422e-04, l1: 0.40259, l2: 0.31607\n",
            "Loss: 1.456721e-04, l1: 0.40245, l2: 0.31607\n",
            "Loss: 1.456179e-04, l1: 0.40331, l2: 0.31601\n",
            "Loss: 1.455576e-04, l1: 0.40249, l2: 0.31604\n",
            "Loss: 1.454898e-04, l1: 0.40178, l2: 0.31611\n",
            "Loss: 1.454322e-04, l1: 0.40108, l2: 0.31610\n",
            "Loss: 1.454100e-04, l1: 0.40123, l2: 0.31607\n",
            "Loss: 1.453584e-04, l1: 0.40168, l2: 0.31606\n",
            "Loss: 1.452776e-04, l1: 0.40242, l2: 0.31605\n",
            "Loss: 1.451222e-04, l1: 0.40327, l2: 0.31603\n",
            "Loss: 1.449194e-04, l1: 0.40514, l2: 0.31612\n",
            "Loss: 1.445883e-04, l1: 0.40577, l2: 0.31597\n",
            "Loss: 1.443420e-04, l1: 0.40604, l2: 0.31595\n",
            "Loss: 1.441602e-04, l1: 0.40638, l2: 0.31594\n",
            "Loss: 1.441031e-04, l1: 0.40686, l2: 0.31597\n",
            "Loss: 1.440783e-04, l1: 0.40785, l2: 0.31602\n",
            "Loss: 1.440397e-04, l1: 0.40726, l2: 0.31603\n",
            "Loss: 1.440109e-04, l1: 0.40717, l2: 0.31605\n",
            "Loss: 1.440650e-04, l1: 0.40731, l2: 0.31628\n",
            "Loss: 1.439834e-04, l1: 0.40722, l2: 0.31614\n",
            "Loss: 1.439414e-04, l1: 0.40727, l2: 0.31625\n",
            "Loss: 1.439081e-04, l1: 0.40752, l2: 0.31632\n",
            "Loss: 1.438710e-04, l1: 0.40772, l2: 0.31634\n",
            "Loss: 1.438394e-04, l1: 0.40782, l2: 0.31633\n",
            "Loss: 1.437799e-04, l1: 0.40835, l2: 0.31633\n",
            "Loss: 1.436660e-04, l1: 0.40919, l2: 0.31627\n",
            "Loss: 1.435041e-04, l1: 0.41085, l2: 0.31626\n",
            "Loss: 1.432522e-04, l1: 0.41314, l2: 0.31644\n",
            "Loss: 1.430960e-04, l1: 0.41629, l2: 0.31636\n",
            "Loss: 1.429607e-04, l1: 0.41567, l2: 0.31630\n",
            "Loss: 1.428651e-04, l1: 0.41545, l2: 0.31647\n",
            "Loss: 1.426829e-04, l1: 0.41547, l2: 0.31660\n",
            "Loss: 1.427183e-04, l1: 0.41759, l2: 0.31663\n",
            "Loss: 1.426245e-04, l1: 0.41643, l2: 0.31662\n",
            "Loss: 1.425257e-04, l1: 0.41673, l2: 0.31668\n",
            "Loss: 1.424080e-04, l1: 0.41707, l2: 0.31671\n",
            "Loss: 1.423271e-04, l1: 0.41738, l2: 0.31678\n",
            "Loss: 1.422666e-04, l1: 0.41734, l2: 0.31679\n",
            "Loss: 1.422030e-04, l1: 0.41777, l2: 0.31678\n",
            "Loss: 1.421488e-04, l1: 0.41775, l2: 0.31674\n",
            "Loss: 1.421002e-04, l1: 0.41865, l2: 0.31673\n",
            "Loss: 1.420378e-04, l1: 0.41903, l2: 0.31670\n",
            "Loss: 1.419608e-04, l1: 0.41948, l2: 0.31670\n",
            "Loss: 1.419099e-04, l1: 0.42034, l2: 0.31668\n",
            "Loss: 1.418778e-04, l1: 0.42041, l2: 0.31670\n",
            "Loss: 1.418527e-04, l1: 0.42064, l2: 0.31671\n",
            "Loss: 1.418158e-04, l1: 0.42100, l2: 0.31672\n",
            "Loss: 1.417826e-04, l1: 0.42127, l2: 0.31676\n",
            "Loss: 1.417201e-04, l1: 0.42126, l2: 0.31678\n",
            "Loss: 1.416688e-04, l1: 0.42198, l2: 0.31686\n",
            "Loss: 1.416203e-04, l1: 0.42165, l2: 0.31676\n",
            "Loss: 1.415513e-04, l1: 0.42118, l2: 0.31676\n",
            "Loss: 1.414587e-04, l1: 0.42129, l2: 0.31669\n",
            "Loss: 1.413803e-04, l1: 0.42076, l2: 0.31675\n",
            "Loss: 1.412861e-04, l1: 0.42039, l2: 0.31666\n",
            "Loss: 1.412044e-04, l1: 0.42111, l2: 0.31661\n",
            "Loss: 1.411161e-04, l1: 0.42106, l2: 0.31656\n",
            "Loss: 1.409903e-04, l1: 0.42111, l2: 0.31648\n",
            "Loss: 1.408176e-04, l1: 0.42138, l2: 0.31635\n",
            "Loss: 1.407291e-04, l1: 0.42229, l2: 0.31612\n",
            "Loss: 1.405312e-04, l1: 0.42247, l2: 0.31601\n",
            "Loss: 1.403830e-04, l1: 0.42342, l2: 0.31590\n",
            "Loss: 1.401366e-04, l1: 0.42386, l2: 0.31586\n",
            "Loss: 1.399666e-04, l1: 0.42453, l2: 0.31569\n",
            "Loss: 1.398957e-04, l1: 0.42637, l2: 0.31552\n",
            "Loss: 1.397466e-04, l1: 0.42648, l2: 0.31554\n",
            "Loss: 1.396285e-04, l1: 0.42746, l2: 0.31545\n",
            "Loss: 1.394525e-04, l1: 0.42898, l2: 0.31531\n",
            "Loss: 1.392702e-04, l1: 0.43170, l2: 0.31516\n",
            "Loss: 1.392556e-04, l1: 0.43343, l2: 0.31492\n",
            "Loss: 1.391932e-04, l1: 0.43260, l2: 0.31504\n",
            "Loss: 1.391701e-04, l1: 0.43355, l2: 0.31510\n",
            "Loss: 1.389954e-04, l1: 0.43429, l2: 0.31497\n",
            "Loss: 1.388940e-04, l1: 0.43431, l2: 0.31492\n",
            "Loss: 1.387943e-04, l1: 0.43382, l2: 0.31494\n",
            "Loss: 1.387305e-04, l1: 0.43492, l2: 0.31489\n",
            "Loss: 1.386006e-04, l1: 0.43552, l2: 0.31492\n",
            "Loss: 1.383952e-04, l1: 0.43707, l2: 0.31504\n",
            "Loss: 1.382173e-04, l1: 0.43996, l2: 0.31497\n",
            "Loss: 1.380569e-04, l1: 0.44033, l2: 0.31518\n",
            "Loss: 1.379147e-04, l1: 0.43939, l2: 0.31507\n",
            "Loss: 1.377281e-04, l1: 0.43995, l2: 0.31496\n",
            "Loss: 1.375422e-04, l1: 0.43930, l2: 0.31503\n",
            "Loss: 1.374163e-04, l1: 0.43932, l2: 0.31510\n",
            "Loss: 1.372603e-04, l1: 0.43915, l2: 0.31516\n",
            "Loss: 1.369561e-04, l1: 0.44048, l2: 0.31521\n",
            "Loss: 1.366787e-04, l1: 0.44172, l2: 0.31504\n",
            "Loss: 1.365613e-04, l1: 0.44142, l2: 0.31514\n",
            "Loss: 1.363973e-04, l1: 0.44122, l2: 0.31504\n",
            "Loss: 1.362191e-04, l1: 0.44241, l2: 0.31494\n",
            "Loss: 1.359266e-04, l1: 0.44163, l2: 0.31499\n",
            "Loss: 1.357228e-04, l1: 0.44231, l2: 0.31506\n",
            "Loss: 1.354612e-04, l1: 0.44223, l2: 0.31514\n",
            "Loss: 1.353173e-04, l1: 0.44345, l2: 0.31510\n",
            "Loss: 1.353467e-04, l1: 0.44272, l2: 0.31526\n",
            "Loss: 1.352218e-04, l1: 0.44311, l2: 0.31518\n",
            "Loss: 1.352554e-04, l1: 0.44292, l2: 0.31528\n",
            "Loss: 1.351556e-04, l1: 0.44302, l2: 0.31522\n",
            "Loss: 1.350916e-04, l1: 0.44281, l2: 0.31524\n",
            "Loss: 1.349658e-04, l1: 0.44304, l2: 0.31524\n",
            "Loss: 1.348005e-04, l1: 0.44274, l2: 0.31526\n",
            "Loss: 1.346339e-04, l1: 0.44289, l2: 0.31522\n",
            "Loss: 1.345270e-04, l1: 0.44285, l2: 0.31521\n",
            "Loss: 1.344538e-04, l1: 0.44225, l2: 0.31520\n",
            "Loss: 1.344122e-04, l1: 0.44269, l2: 0.31516\n",
            "Loss: 1.343609e-04, l1: 0.44286, l2: 0.31513\n",
            "Loss: 1.342944e-04, l1: 0.44303, l2: 0.31504\n",
            "Loss: 1.342385e-04, l1: 0.44310, l2: 0.31490\n",
            "Loss: 1.341758e-04, l1: 0.44337, l2: 0.31488\n",
            "Loss: 1.341137e-04, l1: 0.44360, l2: 0.31482\n",
            "Loss: 1.340697e-04, l1: 0.44433, l2: 0.31475\n",
            "Loss: 1.340154e-04, l1: 0.44418, l2: 0.31475\n",
            "Loss: 1.339649e-04, l1: 0.44410, l2: 0.31466\n",
            "Loss: 1.338787e-04, l1: 0.44427, l2: 0.31452\n",
            "Loss: 1.337350e-04, l1: 0.44469, l2: 0.31430\n",
            "Loss: 1.335868e-04, l1: 0.44528, l2: 0.31406\n",
            "Loss: 1.334648e-04, l1: 0.44547, l2: 0.31393\n",
            "Loss: 1.332895e-04, l1: 0.44465, l2: 0.31414\n",
            "Loss: 1.331920e-04, l1: 0.44417, l2: 0.31420\n",
            "Loss: 1.331121e-04, l1: 0.44376, l2: 0.31424\n",
            "Loss: 1.330116e-04, l1: 0.44293, l2: 0.31426\n",
            "Loss: 1.328870e-04, l1: 0.44252, l2: 0.31424\n",
            "Loss: 1.326997e-04, l1: 0.44162, l2: 0.31422\n",
            "Loss: 1.324855e-04, l1: 0.44091, l2: 0.31417\n",
            "Loss: 1.323376e-04, l1: 0.44039, l2: 0.31421\n",
            "Loss: 1.322425e-04, l1: 0.44056, l2: 0.31421\n",
            "Loss: 1.321566e-04, l1: 0.44087, l2: 0.31422\n",
            "Loss: 1.320574e-04, l1: 0.44076, l2: 0.31427\n",
            "Loss: 1.318032e-04, l1: 0.44029, l2: 0.31439\n",
            "Loss: 1.316291e-04, l1: 0.43999, l2: 0.31458\n",
            "Loss: 1.315394e-04, l1: 0.43994, l2: 0.31454\n",
            "Loss: 1.314537e-04, l1: 0.43941, l2: 0.31459\n",
            "Loss: 1.313530e-04, l1: 0.43967, l2: 0.31464\n",
            "Loss: 1.312179e-04, l1: 0.44005, l2: 0.31485\n",
            "Loss: 1.311049e-04, l1: 0.44031, l2: 0.31510\n",
            "Loss: 1.310006e-04, l1: 0.44076, l2: 0.31539\n",
            "Loss: 1.308935e-04, l1: 0.44083, l2: 0.31560\n",
            "Loss: 1.308002e-04, l1: 0.44097, l2: 0.31572\n",
            "Loss: 1.306608e-04, l1: 0.44131, l2: 0.31586\n",
            "Loss: 1.305105e-04, l1: 0.44176, l2: 0.31592\n",
            "Loss: 1.304118e-04, l1: 0.44218, l2: 0.31583\n",
            "Loss: 1.302623e-04, l1: 0.44255, l2: 0.31578\n",
            "Loss: 1.301541e-04, l1: 0.44285, l2: 0.31591\n",
            "Loss: 1.300709e-04, l1: 0.44287, l2: 0.31576\n",
            "Loss: 1.300274e-04, l1: 0.44322, l2: 0.31580\n",
            "Loss: 1.299904e-04, l1: 0.44351, l2: 0.31588\n",
            "Loss: 1.299656e-04, l1: 0.44366, l2: 0.31598\n",
            "Loss: 1.299441e-04, l1: 0.44403, l2: 0.31611\n",
            "Loss: 1.299151e-04, l1: 0.44398, l2: 0.31622\n",
            "Loss: 1.298620e-04, l1: 0.44392, l2: 0.31632\n",
            "Loss: 1.297903e-04, l1: 0.44413, l2: 0.31645\n",
            "Loss: 1.329359e-04, l1: 0.43727, l2: 0.31696\n",
            "Loss: 1.297820e-04, l1: 0.44380, l2: 0.31647\n",
            "Loss: 1.297402e-04, l1: 0.44377, l2: 0.31643\n",
            "Loss: 1.297013e-04, l1: 0.44359, l2: 0.31635\n",
            "Loss: 1.296813e-04, l1: 0.44333, l2: 0.31634\n",
            "Loss: 1.296554e-04, l1: 0.44330, l2: 0.31634\n",
            "Loss: 1.296360e-04, l1: 0.44310, l2: 0.31636\n",
            "Loss: 1.295999e-04, l1: 0.44266, l2: 0.31629\n",
            "Loss: 1.295790e-04, l1: 0.44189, l2: 0.31644\n",
            "Loss: 1.295283e-04, l1: 0.44177, l2: 0.31634\n",
            "Loss: 1.294911e-04, l1: 0.44179, l2: 0.31631\n",
            "Loss: 1.294375e-04, l1: 0.44148, l2: 0.31632\n",
            "Loss: 1.293764e-04, l1: 0.44090, l2: 0.31635\n",
            "Loss: 1.293040e-04, l1: 0.44016, l2: 0.31632\n",
            "Loss: 1.292364e-04, l1: 0.43919, l2: 0.31628\n",
            "Loss: 1.291829e-04, l1: 0.43793, l2: 0.31612\n",
            "Loss: 1.291808e-04, l1: 0.43794, l2: 0.31596\n",
            "Loss: 1.291246e-04, l1: 0.43793, l2: 0.31604\n",
            "Loss: 1.290512e-04, l1: 0.43748, l2: 0.31600\n",
            "Loss: 1.289959e-04, l1: 0.43738, l2: 0.31605\n",
            "Loss: 1.289367e-04, l1: 0.43715, l2: 0.31587\n",
            "Loss: 1.289038e-04, l1: 0.43693, l2: 0.31585\n",
            "Loss: 1.288410e-04, l1: 0.43670, l2: 0.31585\n",
            "Loss: 1.287827e-04, l1: 0.43658, l2: 0.31584\n",
            "Loss: 1.287377e-04, l1: 0.43657, l2: 0.31580\n",
            "Loss: 1.287034e-04, l1: 0.43687, l2: 0.31562\n",
            "Loss: 1.286603e-04, l1: 0.43692, l2: 0.31557\n",
            "Loss: 1.286346e-04, l1: 0.43714, l2: 0.31548\n",
            "Loss: 1.286160e-04, l1: 0.43742, l2: 0.31540\n",
            "Loss: 1.285853e-04, l1: 0.43775, l2: 0.31528\n",
            "Loss: 1.285386e-04, l1: 0.43794, l2: 0.31508\n",
            "Loss: 1.284943e-04, l1: 0.43824, l2: 0.31492\n",
            "Loss: 1.284554e-04, l1: 0.43772, l2: 0.31482\n",
            "Loss: 1.284217e-04, l1: 0.43709, l2: 0.31477\n",
            "Loss: 1.283817e-04, l1: 0.43642, l2: 0.31477\n",
            "Loss: 1.283153e-04, l1: 0.43554, l2: 0.31473\n",
            "Loss: 1.284706e-04, l1: 0.43401, l2: 0.31451\n",
            "Loss: 1.282794e-04, l1: 0.43506, l2: 0.31466\n",
            "Loss: 1.281989e-04, l1: 0.43507, l2: 0.31460\n",
            "Loss: 1.281435e-04, l1: 0.43519, l2: 0.31455\n",
            "Loss: 1.281030e-04, l1: 0.43558, l2: 0.31453\n",
            "Loss: 1.280773e-04, l1: 0.43515, l2: 0.31450\n",
            "Loss: 1.280518e-04, l1: 0.43490, l2: 0.31450\n",
            "Loss: 1.280363e-04, l1: 0.43457, l2: 0.31451\n",
            "Loss: 1.280243e-04, l1: 0.43399, l2: 0.31451\n",
            "Loss: 1.280162e-04, l1: 0.43365, l2: 0.31451\n",
            "Loss: 1.280066e-04, l1: 0.43340, l2: 0.31451\n",
            "Loss: 1.279950e-04, l1: 0.43300, l2: 0.31450\n",
            "Loss: 1.279822e-04, l1: 0.43292, l2: 0.31458\n",
            "Loss: 1.279668e-04, l1: 0.43260, l2: 0.31455\n",
            "Loss: 1.279502e-04, l1: 0.43241, l2: 0.31455\n",
            "Loss: 1.279307e-04, l1: 0.43214, l2: 0.31456\n",
            "Loss: 1.279217e-04, l1: 0.43140, l2: 0.31462\n",
            "Loss: 1.278702e-04, l1: 0.43030, l2: 0.31438\n",
            "Loss: 1.278283e-04, l1: 0.43144, l2: 0.31459\n",
            "Loss: 1.277807e-04, l1: 0.43120, l2: 0.31459\n",
            "Loss: 1.277303e-04, l1: 0.43059, l2: 0.31455\n",
            "Loss: 1.276851e-04, l1: 0.43043, l2: 0.31456\n",
            "Loss: 1.276108e-04, l1: 0.43007, l2: 0.31468\n",
            "Loss: 1.275647e-04, l1: 0.43033, l2: 0.31469\n",
            "Loss: 1.275099e-04, l1: 0.42997, l2: 0.31471\n",
            "Loss: 1.274661e-04, l1: 0.42987, l2: 0.31468\n",
            "Loss: 1.274450e-04, l1: 0.42940, l2: 0.31464\n",
            "Loss: 1.274253e-04, l1: 0.42905, l2: 0.31461\n",
            "Loss: 1.273856e-04, l1: 0.42801, l2: 0.31458\n",
            "Loss: 1.273397e-04, l1: 0.42719, l2: 0.31453\n",
            "Loss: 1.272860e-04, l1: 0.42609, l2: 0.31452\n",
            "Loss: 1.272247e-04, l1: 0.42580, l2: 0.31460\n",
            "Loss: 1.271493e-04, l1: 0.42529, l2: 0.31458\n",
            "Loss: 1.270384e-04, l1: 0.42522, l2: 0.31461\n",
            "Loss: 1.269159e-04, l1: 0.42546, l2: 0.31461\n",
            "Loss: 1.269111e-04, l1: 0.42574, l2: 0.31453\n",
            "Loss: 1.268309e-04, l1: 0.42559, l2: 0.31457\n",
            "Loss: 1.266577e-04, l1: 0.42439, l2: 0.31442\n",
            "Loss: 1.264508e-04, l1: 0.42292, l2: 0.31423\n",
            "Loss: 1.263064e-04, l1: 0.42263, l2: 0.31426\n",
            "Loss: 1.261302e-04, l1: 0.42184, l2: 0.31429\n",
            "Loss: 1.259468e-04, l1: 0.42193, l2: 0.31433\n",
            "Loss: 1.258692e-04, l1: 0.42115, l2: 0.31466\n",
            "Loss: 1.256381e-04, l1: 0.42126, l2: 0.31477\n",
            "Loss: 1.254799e-04, l1: 0.42044, l2: 0.31461\n",
            "Loss: 1.252364e-04, l1: 0.41985, l2: 0.31452\n",
            "Loss: 1.249880e-04, l1: 0.41733, l2: 0.31454\n",
            "Loss: 1.252754e-04, l1: 0.41601, l2: 0.31404\n",
            "Loss: 1.248183e-04, l1: 0.41684, l2: 0.31435\n",
            "Loss: 1.248962e-04, l1: 0.41637, l2: 0.31432\n",
            "Loss: 1.247059e-04, l1: 0.41663, l2: 0.31434\n",
            "Loss: 1.245623e-04, l1: 0.41592, l2: 0.31444\n",
            "Loss: 1.244638e-04, l1: 0.41523, l2: 0.31437\n",
            "Loss: 1.244073e-04, l1: 0.41400, l2: 0.31397\n",
            "Loss: 1.243273e-04, l1: 0.41395, l2: 0.31403\n",
            "Loss: 1.242967e-04, l1: 0.41377, l2: 0.31410\n",
            "Loss: 1.242546e-04, l1: 0.41399, l2: 0.31411\n",
            "Loss: 1.241069e-04, l1: 0.41437, l2: 0.31412\n",
            "Loss: 1.239447e-04, l1: 0.41525, l2: 0.31413\n",
            "Loss: 1.237991e-04, l1: 0.41606, l2: 0.31430\n",
            "Loss: 1.236539e-04, l1: 0.41459, l2: 0.31420\n",
            "Loss: 1.234982e-04, l1: 0.41415, l2: 0.31429\n",
            "Loss: 1.233253e-04, l1: 0.41430, l2: 0.31448\n",
            "Loss: 1.231923e-04, l1: 0.41520, l2: 0.31480\n",
            "Loss: 1.230755e-04, l1: 0.41527, l2: 0.31481\n",
            "Loss: 1.229723e-04, l1: 0.41500, l2: 0.31475\n",
            "Loss: 1.228956e-04, l1: 0.41532, l2: 0.31476\n",
            "Loss: 1.228292e-04, l1: 0.41504, l2: 0.31472\n",
            "Loss: 1.227465e-04, l1: 0.41455, l2: 0.31474\n",
            "Loss: 1.225650e-04, l1: 0.41287, l2: 0.31480\n",
            "Loss: 1.224803e-04, l1: 0.41210, l2: 0.31487\n",
            "Loss: 1.224083e-04, l1: 0.41098, l2: 0.31493\n",
            "Loss: 1.223571e-04, l1: 0.41105, l2: 0.31491\n",
            "Loss: 1.223089e-04, l1: 0.41070, l2: 0.31489\n",
            "Loss: 1.222509e-04, l1: 0.41035, l2: 0.31482\n",
            "Loss: 1.222123e-04, l1: 0.41012, l2: 0.31479\n",
            "Loss: 1.221464e-04, l1: 0.40981, l2: 0.31480\n",
            "Loss: 1.220668e-04, l1: 0.40912, l2: 0.31482\n",
            "Loss: 1.220259e-04, l1: 0.40947, l2: 0.31495\n",
            "Loss: 1.219669e-04, l1: 0.40859, l2: 0.31494\n",
            "Loss: 1.219431e-04, l1: 0.40848, l2: 0.31490\n",
            "Loss: 1.219096e-04, l1: 0.40851, l2: 0.31486\n",
            "Loss: 1.218620e-04, l1: 0.40838, l2: 0.31479\n",
            "Loss: 1.217800e-04, l1: 0.40829, l2: 0.31467\n",
            "Loss: 1.216903e-04, l1: 0.40790, l2: 0.31462\n",
            "Loss: 1.216198e-04, l1: 0.40752, l2: 0.31467\n",
            "Loss: 1.215803e-04, l1: 0.40669, l2: 0.31474\n",
            "Loss: 1.215549e-04, l1: 0.40693, l2: 0.31477\n",
            "Loss: 1.215276e-04, l1: 0.40648, l2: 0.31476\n",
            "Loss: 1.215085e-04, l1: 0.40630, l2: 0.31478\n",
            "Loss: 1.214817e-04, l1: 0.40588, l2: 0.31485\n",
            "Loss: 1.214546e-04, l1: 0.40577, l2: 0.31493\n",
            "Loss: 1.214205e-04, l1: 0.40558, l2: 0.31503\n",
            "Loss: 1.214111e-04, l1: 0.40589, l2: 0.31512\n",
            "Loss: 1.214054e-04, l1: 0.40597, l2: 0.31518\n",
            "Loss: 1.213969e-04, l1: 0.40621, l2: 0.31520\n",
            "Loss: 1.213709e-04, l1: 0.40692, l2: 0.31525\n",
            "Loss: 1.213132e-04, l1: 0.40839, l2: 0.31541\n",
            "Loss: 1.212461e-04, l1: 0.40942, l2: 0.31543\n",
            "Loss: 1.211940e-04, l1: 0.40927, l2: 0.31548\n",
            "Loss: 1.211610e-04, l1: 0.40957, l2: 0.31545\n",
            "Loss: 1.211243e-04, l1: 0.40853, l2: 0.31533\n",
            "Loss: 1.210964e-04, l1: 0.40881, l2: 0.31538\n",
            "Loss: 1.210711e-04, l1: 0.40888, l2: 0.31548\n",
            "Loss: 1.210594e-04, l1: 0.40878, l2: 0.31548\n",
            "Loss: 1.210530e-04, l1: 0.40866, l2: 0.31547\n",
            "Loss: 1.210442e-04, l1: 0.40878, l2: 0.31548\n",
            "Loss: 1.210365e-04, l1: 0.40883, l2: 0.31548\n",
            "Loss: 1.210229e-04, l1: 0.40915, l2: 0.31552\n",
            "Loss: 1.210069e-04, l1: 0.40969, l2: 0.31561\n",
            "Loss: 1.209932e-04, l1: 0.41046, l2: 0.31565\n",
            "Loss: 1.209759e-04, l1: 0.41098, l2: 0.31574\n",
            "Loss: 1.209607e-04, l1: 0.41125, l2: 0.31573\n",
            "Loss: 1.209380e-04, l1: 0.41173, l2: 0.31568\n",
            "Loss: 1.213193e-04, l1: 0.41375, l2: 0.31601\n",
            "Loss: 1.209320e-04, l1: 0.41197, l2: 0.31572\n",
            "Loss: 1.209154e-04, l1: 0.41226, l2: 0.31569\n",
            "Loss: 1.208998e-04, l1: 0.41294, l2: 0.31568\n",
            "Loss: 1.208816e-04, l1: 0.41333, l2: 0.31564\n",
            "Loss: 1.208606e-04, l1: 0.41394, l2: 0.31563\n",
            "Loss: 1.208424e-04, l1: 0.41424, l2: 0.31556\n",
            "Loss: 1.208231e-04, l1: 0.41443, l2: 0.31552\n",
            "Loss: 1.207995e-04, l1: 0.41435, l2: 0.31547\n",
            "Loss: 1.207677e-04, l1: 0.41407, l2: 0.31536\n",
            "Loss: 1.207467e-04, l1: 0.41426, l2: 0.31533\n",
            "Loss: 1.207059e-04, l1: 0.41468, l2: 0.31528\n",
            "Loss: 1.207618e-04, l1: 0.41631, l2: 0.31508\n",
            "Loss: 1.206762e-04, l1: 0.41531, l2: 0.31520\n",
            "Loss: 1.206157e-04, l1: 0.41677, l2: 0.31507\n",
            "Loss: 1.205411e-04, l1: 0.41797, l2: 0.31509\n",
            "Loss: 1.204835e-04, l1: 0.41910, l2: 0.31515\n",
            "Loss: 1.205746e-04, l1: 0.42257, l2: 0.31534\n",
            "Loss: 1.204597e-04, l1: 0.42023, l2: 0.31521\n",
            "Loss: 1.204293e-04, l1: 0.42168, l2: 0.31523\n",
            "Loss: 1.203948e-04, l1: 0.42182, l2: 0.31537\n",
            "Loss: 1.203578e-04, l1: 0.42212, l2: 0.31535\n",
            "Loss: 1.203201e-04, l1: 0.42233, l2: 0.31533\n",
            "Loss: 1.202911e-04, l1: 0.42232, l2: 0.31530\n",
            "Loss: 1.202514e-04, l1: 0.42290, l2: 0.31538\n",
            "Loss: 1.201931e-04, l1: 0.42375, l2: 0.31539\n",
            "Loss: 1.201077e-04, l1: 0.42494, l2: 0.31528\n",
            "Loss: 1.200529e-04, l1: 0.42578, l2: 0.31529\n",
            "Loss: 1.200407e-04, l1: 0.42752, l2: 0.31525\n",
            "Loss: 1.200143e-04, l1: 0.42664, l2: 0.31527\n",
            "Loss: 1.199564e-04, l1: 0.42592, l2: 0.31515\n",
            "Loss: 1.198865e-04, l1: 0.42540, l2: 0.31512\n",
            "Loss: 1.198194e-04, l1: 0.42479, l2: 0.31513\n",
            "Loss: 1.197286e-04, l1: 0.42461, l2: 0.31506\n",
            "Loss: 1.195238e-04, l1: 0.42361, l2: 0.31482\n",
            "Loss: 1.195249e-04, l1: 0.42211, l2: 0.31442\n",
            "Loss: 1.193521e-04, l1: 0.42283, l2: 0.31461\n",
            "Loss: 1.192470e-04, l1: 0.42224, l2: 0.31447\n",
            "Loss: 1.191898e-04, l1: 0.42195, l2: 0.31461\n",
            "Loss: 1.191345e-04, l1: 0.42113, l2: 0.31459\n",
            "Loss: 1.190725e-04, l1: 0.42178, l2: 0.31457\n",
            "Loss: 1.190056e-04, l1: 0.42114, l2: 0.31457\n",
            "Loss: 1.188916e-04, l1: 0.42043, l2: 0.31461\n",
            "Loss: 1.187683e-04, l1: 0.42043, l2: 0.31471\n",
            "Loss: 1.186141e-04, l1: 0.42059, l2: 0.31486\n",
            "Loss: 1.186830e-04, l1: 0.42197, l2: 0.31496\n",
            "Loss: 1.185204e-04, l1: 0.42119, l2: 0.31490\n",
            "Loss: 1.183808e-04, l1: 0.42047, l2: 0.31479\n",
            "Loss: 1.182271e-04, l1: 0.42030, l2: 0.31447\n",
            "Loss: 1.180653e-04, l1: 0.42070, l2: 0.31438\n",
            "Loss: 1.178956e-04, l1: 0.42127, l2: 0.31410\n",
            "Loss: 1.178803e-04, l1: 0.42195, l2: 0.31366\n",
            "Loss: 1.177775e-04, l1: 0.42159, l2: 0.31389\n",
            "Loss: 1.176608e-04, l1: 0.42182, l2: 0.31378\n",
            "Loss: 1.174885e-04, l1: 0.42207, l2: 0.31387\n",
            "Loss: 1.173615e-04, l1: 0.42357, l2: 0.31389\n",
            "Loss: 1.171117e-04, l1: 0.42322, l2: 0.31412\n",
            "Loss: 1.170650e-04, l1: 0.42478, l2: 0.31416\n",
            "Loss: 1.168096e-04, l1: 0.42542, l2: 0.31433\n",
            "Loss: 1.165886e-04, l1: 0.42679, l2: 0.31442\n",
            "Loss: 1.163910e-04, l1: 0.42978, l2: 0.31439\n",
            "Loss: 1.163657e-04, l1: 0.43171, l2: 0.31440\n",
            "Loss: 1.163109e-04, l1: 0.43071, l2: 0.31440\n",
            "Loss: 1.162172e-04, l1: 0.43084, l2: 0.31436\n",
            "Loss: 1.161320e-04, l1: 0.43108, l2: 0.31425\n",
            "Loss: 1.160558e-04, l1: 0.43118, l2: 0.31426\n",
            "Loss: 1.158117e-04, l1: 0.43165, l2: 0.31431\n",
            "Loss: 1.155489e-04, l1: 0.43397, l2: 0.31413\n",
            "Loss: 1.152381e-04, l1: 0.43568, l2: 0.31446\n",
            "Loss: 1.150595e-04, l1: 0.43609, l2: 0.31480\n",
            "Loss: 1.148956e-04, l1: 0.43795, l2: 0.31474\n",
            "Loss: 1.147964e-04, l1: 0.43896, l2: 0.31458\n",
            "Loss: 1.147068e-04, l1: 0.43972, l2: 0.31452\n",
            "Loss: 1.146238e-04, l1: 0.44039, l2: 0.31447\n",
            "Loss: 1.145538e-04, l1: 0.44097, l2: 0.31450\n",
            "Loss: 1.144761e-04, l1: 0.44164, l2: 0.31445\n",
            "Loss: 1.143604e-04, l1: 0.44247, l2: 0.31436\n",
            "Loss: 1.142395e-04, l1: 0.44404, l2: 0.31422\n",
            "Loss: 1.141396e-04, l1: 0.44420, l2: 0.31410\n",
            "Loss: 1.140761e-04, l1: 0.44569, l2: 0.31413\n",
            "Loss: 1.140147e-04, l1: 0.44593, l2: 0.31415\n",
            "Loss: 1.139227e-04, l1: 0.44667, l2: 0.31421\n",
            "Loss: 1.138226e-04, l1: 0.44755, l2: 0.31425\n",
            "Loss: 1.135709e-04, l1: 0.44987, l2: 0.31435\n",
            "Loss: 1.134173e-04, l1: 0.45208, l2: 0.31440\n",
            "Loss: 1.131455e-04, l1: 0.45199, l2: 0.31445\n",
            "Loss: 1.129213e-04, l1: 0.45329, l2: 0.31447\n",
            "Loss: 1.127925e-04, l1: 0.45221, l2: 0.31469\n",
            "Loss: 1.126419e-04, l1: 0.45339, l2: 0.31462\n",
            "Loss: 1.125522e-04, l1: 0.45386, l2: 0.31468\n",
            "Loss: 1.124331e-04, l1: 0.45531, l2: 0.31490\n",
            "Loss: 1.123550e-04, l1: 0.45617, l2: 0.31508\n",
            "Loss: 1.123208e-04, l1: 0.45663, l2: 0.31505\n",
            "Loss: 1.123082e-04, l1: 0.45777, l2: 0.31508\n",
            "Loss: 1.122840e-04, l1: 0.45791, l2: 0.31508\n",
            "Loss: 1.123011e-04, l1: 0.45854, l2: 0.31512\n",
            "Loss: 1.122756e-04, l1: 0.45815, l2: 0.31510\n",
            "Loss: 1.122581e-04, l1: 0.45785, l2: 0.31505\n",
            "Loss: 1.122185e-04, l1: 0.45800, l2: 0.31500\n",
            "Loss: 1.121434e-04, l1: 0.45832, l2: 0.31491\n",
            "Loss: 1.120738e-04, l1: 0.45847, l2: 0.31492\n",
            "Loss: 1.119698e-04, l1: 0.45857, l2: 0.31496\n",
            "Loss: 1.118817e-04, l1: 0.45861, l2: 0.31521\n",
            "Loss: 1.117868e-04, l1: 0.45742, l2: 0.31522\n",
            "Loss: 1.117194e-04, l1: 0.45747, l2: 0.31530\n",
            "Loss: 1.115967e-04, l1: 0.45767, l2: 0.31548\n",
            "Loss: 1.114753e-04, l1: 0.45761, l2: 0.31568\n",
            "Loss: 1.113629e-04, l1: 0.45756, l2: 0.31574\n",
            "Loss: 1.112637e-04, l1: 0.45729, l2: 0.31582\n",
            "Loss: 1.112171e-04, l1: 0.45629, l2: 0.31569\n",
            "Loss: 1.111540e-04, l1: 0.45608, l2: 0.31582\n",
            "Loss: 1.111289e-04, l1: 0.45576, l2: 0.31582\n",
            "Loss: 1.111058e-04, l1: 0.45531, l2: 0.31579\n",
            "Loss: 1.110687e-04, l1: 0.45470, l2: 0.31575\n",
            "Loss: 1.110317e-04, l1: 0.45344, l2: 0.31565\n",
            "Loss: 1.109870e-04, l1: 0.45298, l2: 0.31560\n",
            "Loss: 1.109203e-04, l1: 0.45226, l2: 0.31559\n",
            "Loss: 1.108421e-04, l1: 0.45134, l2: 0.31556\n",
            "Loss: 1.107706e-04, l1: 0.45135, l2: 0.31552\n",
            "Loss: 1.107098e-04, l1: 0.45117, l2: 0.31557\n",
            "Loss: 1.106531e-04, l1: 0.45093, l2: 0.31559\n",
            "Loss: 1.105838e-04, l1: 0.45135, l2: 0.31553\n",
            "Loss: 1.104941e-04, l1: 0.45184, l2: 0.31549\n",
            "Loss: 1.103991e-04, l1: 0.45215, l2: 0.31539\n",
            "Loss: 1.103238e-04, l1: 0.45354, l2: 0.31541\n",
            "Loss: 1.103165e-04, l1: 0.45307, l2: 0.31544\n",
            "Loss: 1.102753e-04, l1: 0.45333, l2: 0.31542\n",
            "Loss: 1.102269e-04, l1: 0.45281, l2: 0.31541\n",
            "Loss: 1.101824e-04, l1: 0.45271, l2: 0.31546\n",
            "Loss: 1.101006e-04, l1: 0.45284, l2: 0.31550\n",
            "Loss: 1.100005e-04, l1: 0.45214, l2: 0.31551\n",
            "Loss: 1.099066e-04, l1: 0.45194, l2: 0.31550\n",
            "Loss: 1.098267e-04, l1: 0.45151, l2: 0.31542\n",
            "Loss: 1.097565e-04, l1: 0.45067, l2: 0.31539\n",
            "Loss: 1.097094e-04, l1: 0.45025, l2: 0.31535\n",
            "Loss: 1.096646e-04, l1: 0.44985, l2: 0.31525\n",
            "Loss: 1.096216e-04, l1: 0.44926, l2: 0.31518\n",
            "Loss: 1.095902e-04, l1: 0.44860, l2: 0.31514\n",
            "Loss: 1.095684e-04, l1: 0.44822, l2: 0.31514\n",
            "Loss: 1.095558e-04, l1: 0.44775, l2: 0.31518\n",
            "Loss: 1.095389e-04, l1: 0.44727, l2: 0.31522\n",
            "Loss: 1.095347e-04, l1: 0.44729, l2: 0.31547\n",
            "Loss: 1.095084e-04, l1: 0.44694, l2: 0.31538\n",
            "Loss: 1.095008e-04, l1: 0.44688, l2: 0.31535\n",
            "Loss: 1.094905e-04, l1: 0.44674, l2: 0.31535\n",
            "Loss: 1.094763e-04, l1: 0.44689, l2: 0.31531\n",
            "Loss: 1.094435e-04, l1: 0.44659, l2: 0.31533\n",
            "Loss: 1.094024e-04, l1: 0.44658, l2: 0.31535\n",
            "Loss: 1.093768e-04, l1: 0.44651, l2: 0.31536\n",
            "Loss: 1.093104e-04, l1: 0.44699, l2: 0.31533\n",
            "Loss: 1.092711e-04, l1: 0.44706, l2: 0.31531\n",
            "Loss: 1.092860e-04, l1: 0.44751, l2: 0.31549\n",
            "Loss: 1.091936e-04, l1: 0.44728, l2: 0.31540\n",
            "Loss: 1.091266e-04, l1: 0.44809, l2: 0.31536\n",
            "Loss: 1.090922e-04, l1: 0.44818, l2: 0.31534\n",
            "Loss: 1.090270e-04, l1: 0.44807, l2: 0.31532\n",
            "Loss: 1.089853e-04, l1: 0.44876, l2: 0.31536\n",
            "Loss: 1.089401e-04, l1: 0.44871, l2: 0.31535\n",
            "Loss: 1.088625e-04, l1: 0.44928, l2: 0.31527\n",
            "Loss: 1.088330e-04, l1: 0.44889, l2: 0.31523\n",
            "Loss: 1.088006e-04, l1: 0.44867, l2: 0.31521\n",
            "Loss: 1.087620e-04, l1: 0.44916, l2: 0.31521\n",
            "Loss: 1.087401e-04, l1: 0.44940, l2: 0.31527\n",
            "Loss: 1.087189e-04, l1: 0.44983, l2: 0.31535\n",
            "Loss: 1.086939e-04, l1: 0.45066, l2: 0.31541\n",
            "Loss: 1.086542e-04, l1: 0.45179, l2: 0.31548\n",
            "Loss: 1.085832e-04, l1: 0.45405, l2: 0.31559\n",
            "Loss: 1.085179e-04, l1: 0.45646, l2: 0.31580\n",
            "Loss: 1.084766e-04, l1: 0.45914, l2: 0.31593\n",
            "Loss: 1.083971e-04, l1: 0.45750, l2: 0.31578\n",
            "Loss: 1.083446e-04, l1: 0.45734, l2: 0.31583\n",
            "Loss: 1.082629e-04, l1: 0.45823, l2: 0.31590\n",
            "Loss: 1.081965e-04, l1: 0.46029, l2: 0.31600\n",
            "Loss: 1.081396e-04, l1: 0.45905, l2: 0.31599\n",
            "Loss: 1.080808e-04, l1: 0.45740, l2: 0.31589\n",
            "Loss: 1.080152e-04, l1: 0.45664, l2: 0.31584\n",
            "Loss: 1.079569e-04, l1: 0.45654, l2: 0.31576\n",
            "Loss: 1.078906e-04, l1: 0.45757, l2: 0.31565\n",
            "Loss: 1.078494e-04, l1: 0.45870, l2: 0.31558\n",
            "Loss: 1.078037e-04, l1: 0.45996, l2: 0.31545\n",
            "Loss: 1.077620e-04, l1: 0.46041, l2: 0.31554\n",
            "Loss: 1.077235e-04, l1: 0.46091, l2: 0.31559\n",
            "Loss: 1.076966e-04, l1: 0.46230, l2: 0.31564\n",
            "Loss: 1.076738e-04, l1: 0.46265, l2: 0.31558\n",
            "Loss: 1.076504e-04, l1: 0.46257, l2: 0.31550\n",
            "Loss: 1.076170e-04, l1: 0.46293, l2: 0.31534\n",
            "Loss: 1.075855e-04, l1: 0.46272, l2: 0.31520\n",
            "Loss: 1.075338e-04, l1: 0.46258, l2: 0.31501\n",
            "Loss: 1.074740e-04, l1: 0.46278, l2: 0.31495\n",
            "Loss: 1.074155e-04, l1: 0.46307, l2: 0.31484\n",
            "Loss: 1.073642e-04, l1: 0.46369, l2: 0.31478\n",
            "Loss: 1.073301e-04, l1: 0.46345, l2: 0.31473\n",
            "Loss: 1.073127e-04, l1: 0.46453, l2: 0.31471\n",
            "Loss: 1.072945e-04, l1: 0.46418, l2: 0.31474\n",
            "Loss: 1.072821e-04, l1: 0.46398, l2: 0.31474\n",
            "Loss: 1.072639e-04, l1: 0.46409, l2: 0.31472\n",
            "Loss: 1.072458e-04, l1: 0.46410, l2: 0.31470\n",
            "Loss: 1.072189e-04, l1: 0.46439, l2: 0.31470\n",
            "Loss: 1.071754e-04, l1: 0.46443, l2: 0.31474\n",
            "Loss: 1.071285e-04, l1: 0.46428, l2: 0.31484\n",
            "Loss: 1.070894e-04, l1: 0.46432, l2: 0.31491\n",
            "Loss: 1.070563e-04, l1: 0.46395, l2: 0.31495\n",
            "Loss: 1.070185e-04, l1: 0.46372, l2: 0.31495\n",
            "Loss: 1.069801e-04, l1: 0.46325, l2: 0.31492\n",
            "Loss: 1.069463e-04, l1: 0.46320, l2: 0.31487\n",
            "Loss: 1.069776e-04, l1: 0.46268, l2: 0.31481\n",
            "Loss: 1.069218e-04, l1: 0.46299, l2: 0.31484\n",
            "Loss: 1.068515e-04, l1: 0.46317, l2: 0.31479\n",
            "Loss: 1.067523e-04, l1: 0.46351, l2: 0.31457\n",
            "Loss: 1.066104e-04, l1: 0.46361, l2: 0.31460\n",
            "Loss: 1.063014e-04, l1: 0.46381, l2: 0.31475\n",
            "Loss: 1.061693e-04, l1: 0.46399, l2: 0.31518\n",
            "Loss: 1.057096e-04, l1: 0.46305, l2: 0.31508\n",
            "Loss: 1.053721e-04, l1: 0.46374, l2: 0.31480\n",
            "Loss: 1.051068e-04, l1: 0.46342, l2: 0.31487\n",
            "Loss: 1.049410e-04, l1: 0.46369, l2: 0.31493\n",
            "Loss: 1.048354e-04, l1: 0.46374, l2: 0.31498\n",
            "Loss: 1.047786e-04, l1: 0.46372, l2: 0.31512\n",
            "Loss: 1.047139e-04, l1: 0.46454, l2: 0.31518\n",
            "Loss: 1.046637e-04, l1: 0.46490, l2: 0.31513\n",
            "Loss: 1.046125e-04, l1: 0.46583, l2: 0.31501\n",
            "Loss: 1.045388e-04, l1: 0.46662, l2: 0.31496\n",
            "Loss: 1.044947e-04, l1: 0.46798, l2: 0.31501\n",
            "Loss: 1.043918e-04, l1: 0.46817, l2: 0.31496\n",
            "Loss: 1.043144e-04, l1: 0.46896, l2: 0.31493\n",
            "Loss: 1.044199e-04, l1: 0.46954, l2: 0.31469\n",
            "Loss: 1.041726e-04, l1: 0.46923, l2: 0.31482\n",
            "Loss: 1.040243e-04, l1: 0.46980, l2: 0.31492\n",
            "Loss: 1.038916e-04, l1: 0.46989, l2: 0.31487\n",
            "Loss: 1.042015e-04, l1: 0.46543, l2: 0.31466\n",
            "Loss: 1.038329e-04, l1: 0.46864, l2: 0.31481\n",
            "Loss: 1.037253e-04, l1: 0.46674, l2: 0.31479\n",
            "Loss: 1.038780e-04, l1: 0.46537, l2: 0.31461\n",
            "Loss: 1.036856e-04, l1: 0.46630, l2: 0.31473\n",
            "Loss: 1.036433e-04, l1: 0.46548, l2: 0.31473\n",
            "Loss: 1.035365e-04, l1: 0.46451, l2: 0.31461\n",
            "Loss: 1.034368e-04, l1: 0.46211, l2: 0.31443\n",
            "Loss: 1.032894e-04, l1: 0.45983, l2: 0.31431\n",
            "Loss: 1.031433e-04, l1: 0.45750, l2: 0.31432\n",
            "Loss: 1.030556e-04, l1: 0.45743, l2: 0.31436\n",
            "Loss: 1.029735e-04, l1: 0.45665, l2: 0.31437\n",
            "Loss: 1.028996e-04, l1: 0.45727, l2: 0.31437\n",
            "Loss: 1.028359e-04, l1: 0.45673, l2: 0.31434\n",
            "Loss: 1.027952e-04, l1: 0.45680, l2: 0.31433\n",
            "Loss: 1.027767e-04, l1: 0.45838, l2: 0.31437\n",
            "Loss: 1.027276e-04, l1: 0.45872, l2: 0.31437\n",
            "Loss: 1.026918e-04, l1: 0.45829, l2: 0.31436\n",
            "Loss: 1.026241e-04, l1: 0.45835, l2: 0.31434\n",
            "Loss: 1.025664e-04, l1: 0.45956, l2: 0.31426\n",
            "Loss: 1.024705e-04, l1: 0.45887, l2: 0.31432\n",
            "Loss: 1.024130e-04, l1: 0.45864, l2: 0.31432\n",
            "Loss: 1.023464e-04, l1: 0.45895, l2: 0.31429\n",
            "Loss: 1.022944e-04, l1: 0.45909, l2: 0.31422\n",
            "Loss: 1.022685e-04, l1: 0.45941, l2: 0.31417\n",
            "Loss: 1.021898e-04, l1: 0.45819, l2: 0.31405\n",
            "Loss: 1.021652e-04, l1: 0.45832, l2: 0.31404\n",
            "Loss: 1.021442e-04, l1: 0.45773, l2: 0.31402\n",
            "Loss: 1.021306e-04, l1: 0.45735, l2: 0.31398\n",
            "Loss: 1.021168e-04, l1: 0.45701, l2: 0.31397\n",
            "Loss: 1.021038e-04, l1: 0.45704, l2: 0.31400\n",
            "Loss: 1.020895e-04, l1: 0.45722, l2: 0.31404\n",
            "Loss: 1.020808e-04, l1: 0.45749, l2: 0.31411\n",
            "Loss: 1.020657e-04, l1: 0.45775, l2: 0.31417\n",
            "Loss: 1.020479e-04, l1: 0.45794, l2: 0.31427\n",
            "Loss: 1.020303e-04, l1: 0.45786, l2: 0.31433\n",
            "Loss: 1.020062e-04, l1: 0.45753, l2: 0.31437\n",
            "Loss: 1.019852e-04, l1: 0.45765, l2: 0.31463\n",
            "Loss: 1.019450e-04, l1: 0.45666, l2: 0.31458\n",
            "Loss: 1.019090e-04, l1: 0.45640, l2: 0.31455\n",
            "Loss: 1.018805e-04, l1: 0.45599, l2: 0.31455\n",
            "Loss: 1.018585e-04, l1: 0.45598, l2: 0.31463\n",
            "Loss: 1.018261e-04, l1: 0.45639, l2: 0.31472\n",
            "Loss: 1.017522e-04, l1: 0.45670, l2: 0.31483\n",
            "Loss: 1.016314e-04, l1: 0.45605, l2: 0.31492\n",
            "Loss: 1.017024e-04, l1: 0.45554, l2: 0.31516\n",
            "Loss: 1.015632e-04, l1: 0.45584, l2: 0.31502\n",
            "Loss: 1.014638e-04, l1: 0.45556, l2: 0.31500\n",
            "Loss: 1.013270e-04, l1: 0.45341, l2: 0.31496\n",
            "Loss: 1.012210e-04, l1: 0.45393, l2: 0.31500\n",
            "Loss: 1.010809e-04, l1: 0.45390, l2: 0.31494\n",
            "Loss: 1.007179e-04, l1: 0.45364, l2: 0.31500\n",
            "Loss: 1.082153e-04, l1: 0.44945, l2: 0.31575\n",
            "Loss: 1.005121e-04, l1: 0.45291, l2: 0.31513\n",
            "Loss: 1.007221e-04, l1: 0.45362, l2: 0.31524\n",
            "Loss: 1.001378e-04, l1: 0.45325, l2: 0.31519\n",
            "Loss: 9.985323e-05, l1: 0.45302, l2: 0.31485\n",
            "Loss: 9.955782e-05, l1: 0.45226, l2: 0.31468\n",
            "Loss: 9.939916e-05, l1: 0.45062, l2: 0.31460\n",
            "Loss: 9.931020e-05, l1: 0.45036, l2: 0.31448\n",
            "Loss: 9.915866e-05, l1: 0.44956, l2: 0.31432\n",
            "Loss: 9.912901e-05, l1: 0.44833, l2: 0.31414\n",
            "Loss: 9.901673e-05, l1: 0.44736, l2: 0.31408\n",
            "Loss: 9.897102e-05, l1: 0.44806, l2: 0.31424\n",
            "Loss: 9.889402e-05, l1: 0.44799, l2: 0.31418\n",
            "Loss: 9.885006e-05, l1: 0.44770, l2: 0.31422\n",
            "Loss: 9.878153e-05, l1: 0.44785, l2: 0.31428\n",
            "Loss: 9.863966e-05, l1: 0.44881, l2: 0.31451\n",
            "Loss: 9.887016e-05, l1: 0.44883, l2: 0.31453\n",
            "Loss: 9.858629e-05, l1: 0.44882, l2: 0.31452\n",
            "Loss: 9.847093e-05, l1: 0.44952, l2: 0.31467\n",
            "Loss: 9.836718e-05, l1: 0.44903, l2: 0.31461\n",
            "Loss: 9.824629e-05, l1: 0.44863, l2: 0.31444\n",
            "Loss: 9.811908e-05, l1: 0.44908, l2: 0.31442\n",
            "Loss: 9.795834e-05, l1: 0.44934, l2: 0.31444\n",
            "Loss: 9.779236e-05, l1: 0.45036, l2: 0.31452\n",
            "Loss: 9.774216e-05, l1: 0.45149, l2: 0.31459\n",
            "Loss: 9.763094e-05, l1: 0.45153, l2: 0.31464\n",
            "Loss: 9.757162e-05, l1: 0.45177, l2: 0.31469\n",
            "Loss: 9.746737e-05, l1: 0.45280, l2: 0.31478\n",
            "Loss: 9.741387e-05, l1: 0.45292, l2: 0.31477\n",
            "Loss: 9.733110e-05, l1: 0.45334, l2: 0.31474\n",
            "Loss: 9.716924e-05, l1: 0.45459, l2: 0.31450\n",
            "Loss: 9.711578e-05, l1: 0.45504, l2: 0.31416\n",
            "Loss: 9.724457e-05, l1: 0.45464, l2: 0.31411\n",
            "Loss: 9.704551e-05, l1: 0.45489, l2: 0.31414\n",
            "Loss: 9.704706e-05, l1: 0.45562, l2: 0.31431\n",
            "Loss: 9.698966e-05, l1: 0.45525, l2: 0.31423\n",
            "Loss: 9.697373e-05, l1: 0.45575, l2: 0.31430\n",
            "Loss: 9.695742e-05, l1: 0.45597, l2: 0.31436\n",
            "Loss: 9.693323e-05, l1: 0.45610, l2: 0.31440\n",
            "Loss: 9.689642e-05, l1: 0.45631, l2: 0.31444\n",
            "Loss: 9.684836e-05, l1: 0.45658, l2: 0.31448\n",
            "Loss: 9.682379e-05, l1: 0.45719, l2: 0.31444\n",
            "Loss: 9.680662e-05, l1: 0.45771, l2: 0.31445\n",
            "Loss: 9.679070e-05, l1: 0.45876, l2: 0.31451\n",
            "Loss: 9.677943e-05, l1: 0.45908, l2: 0.31453\n",
            "Loss: 9.676120e-05, l1: 0.45974, l2: 0.31457\n",
            "Loss: 9.673823e-05, l1: 0.45997, l2: 0.31460\n",
            "Loss: 9.670544e-05, l1: 0.46015, l2: 0.31458\n",
            "Loss: 9.665210e-05, l1: 0.46017, l2: 0.31454\n",
            "Loss: 9.657715e-05, l1: 0.46043, l2: 0.31453\n",
            "Loss: 9.640602e-05, l1: 0.46178, l2: 0.31451\n",
            "Loss: 9.631309e-05, l1: 0.46517, l2: 0.31477\n",
            "Loss: 9.618794e-05, l1: 0.46438, l2: 0.31466\n",
            "Loss: 9.617796e-05, l1: 0.46538, l2: 0.31456\n",
            "Loss: 9.612374e-05, l1: 0.46488, l2: 0.31461\n",
            "Loss: 9.606963e-05, l1: 0.46541, l2: 0.31462\n",
            "Loss: 9.602583e-05, l1: 0.46630, l2: 0.31463\n",
            "Loss: 9.599075e-05, l1: 0.46666, l2: 0.31463\n",
            "Loss: 9.591073e-05, l1: 0.46741, l2: 0.31464\n",
            "Loss: 9.584892e-05, l1: 0.46801, l2: 0.31458\n",
            "Loss: 9.592690e-05, l1: 0.46646, l2: 0.31478\n",
            "Loss: 9.581677e-05, l1: 0.46747, l2: 0.31465\n",
            "Loss: 9.575066e-05, l1: 0.46834, l2: 0.31484\n",
            "Loss: 9.567423e-05, l1: 0.46798, l2: 0.31482\n",
            "Loss: 9.557358e-05, l1: 0.46716, l2: 0.31486\n",
            "Loss: 9.549140e-05, l1: 0.46688, l2: 0.31496\n",
            "Loss: 9.537894e-05, l1: 0.46654, l2: 0.31519\n",
            "Loss: 9.530096e-05, l1: 0.46777, l2: 0.31549\n",
            "Loss: 9.515032e-05, l1: 0.46728, l2: 0.31550\n",
            "Loss: 9.506541e-05, l1: 0.46808, l2: 0.31556\n",
            "Loss: 9.498595e-05, l1: 0.46838, l2: 0.31560\n",
            "Loss: 9.492195e-05, l1: 0.46793, l2: 0.31561\n",
            "Loss: 9.480706e-05, l1: 0.46766, l2: 0.31566\n",
            "Loss: 9.472885e-05, l1: 0.46697, l2: 0.31568\n",
            "Loss: 9.462071e-05, l1: 0.46679, l2: 0.31576\n",
            "Loss: 9.453567e-05, l1: 0.46673, l2: 0.31594\n",
            "Loss: 9.441114e-05, l1: 0.46736, l2: 0.31597\n",
            "Loss: 9.420684e-05, l1: 0.46887, l2: 0.31598\n",
            "Loss: 9.405328e-05, l1: 0.46976, l2: 0.31607\n",
            "Loss: 9.396199e-05, l1: 0.47045, l2: 0.31612\n",
            "Loss: 9.390883e-05, l1: 0.46997, l2: 0.31608\n",
            "Loss: 9.384708e-05, l1: 0.46961, l2: 0.31596\n",
            "Loss: 9.383180e-05, l1: 0.46859, l2: 0.31577\n",
            "Loss: 9.377826e-05, l1: 0.46842, l2: 0.31572\n",
            "Loss: 9.374976e-05, l1: 0.46914, l2: 0.31584\n",
            "Loss: 9.372983e-05, l1: 0.46897, l2: 0.31582\n",
            "Loss: 9.369708e-05, l1: 0.46895, l2: 0.31585\n",
            "Loss: 9.368085e-05, l1: 0.46821, l2: 0.31573\n",
            "Loss: 9.365676e-05, l1: 0.46890, l2: 0.31585\n",
            "Loss: 9.364614e-05, l1: 0.46920, l2: 0.31588\n",
            "Loss: 9.363695e-05, l1: 0.46953, l2: 0.31590\n",
            "Loss: 9.362495e-05, l1: 0.46992, l2: 0.31587\n",
            "Loss: 9.361363e-05, l1: 0.46972, l2: 0.31585\n",
            "Loss: 9.358754e-05, l1: 0.46958, l2: 0.31579\n",
            "Loss: 9.356665e-05, l1: 0.46840, l2: 0.31565\n",
            "Loss: 9.353588e-05, l1: 0.46845, l2: 0.31564\n",
            "Loss: 9.343364e-05, l1: 0.46877, l2: 0.31555\n",
            "Loss: 9.339233e-05, l1: 0.46893, l2: 0.31550\n",
            "Loss: 9.335244e-05, l1: 0.46937, l2: 0.31550\n",
            "Loss: 9.342268e-05, l1: 0.47221, l2: 0.31557\n",
            "Loss: 9.334386e-05, l1: 0.47009, l2: 0.31552\n",
            "Loss: 9.332757e-05, l1: 0.47037, l2: 0.31554\n",
            "Loss: 9.331638e-05, l1: 0.47074, l2: 0.31559\n",
            "Loss: 9.330428e-05, l1: 0.47078, l2: 0.31559\n",
            "Loss: 9.327414e-05, l1: 0.47059, l2: 0.31558\n",
            "Loss: 9.324454e-05, l1: 0.47015, l2: 0.31554\n",
            "Loss: 9.321729e-05, l1: 0.46937, l2: 0.31541\n",
            "Loss: 9.319081e-05, l1: 0.46875, l2: 0.31535\n",
            "Loss: 9.317272e-05, l1: 0.46843, l2: 0.31532\n",
            "Loss: 9.317366e-05, l1: 0.46789, l2: 0.31525\n",
            "Loss: 9.315868e-05, l1: 0.46816, l2: 0.31528\n",
            "Loss: 9.314077e-05, l1: 0.46816, l2: 0.31532\n",
            "Loss: 9.312214e-05, l1: 0.46834, l2: 0.31537\n",
            "Loss: 9.308322e-05, l1: 0.46824, l2: 0.31543\n",
            "Loss: 9.305268e-05, l1: 0.46829, l2: 0.31550\n",
            "Loss: 9.302012e-05, l1: 0.46740, l2: 0.31545\n",
            "Loss: 9.299373e-05, l1: 0.46711, l2: 0.31540\n",
            "Loss: 9.296376e-05, l1: 0.46674, l2: 0.31533\n",
            "Loss: 9.294485e-05, l1: 0.46680, l2: 0.31533\n",
            "Loss: 9.292000e-05, l1: 0.46679, l2: 0.31534\n",
            "Loss: 9.289524e-05, l1: 0.46731, l2: 0.31539\n",
            "Loss: 9.286138e-05, l1: 0.46751, l2: 0.31541\n",
            "Loss: 9.283047e-05, l1: 0.46786, l2: 0.31542\n",
            "Loss: 9.280386e-05, l1: 0.46770, l2: 0.31541\n",
            "Loss: 9.277270e-05, l1: 0.46750, l2: 0.31544\n",
            "Loss: 9.272641e-05, l1: 0.46727, l2: 0.31549\n",
            "Loss: 9.266505e-05, l1: 0.46670, l2: 0.31582\n",
            "Loss: 9.259600e-05, l1: 0.46650, l2: 0.31590\n",
            "Loss: 9.253259e-05, l1: 0.46555, l2: 0.31590\n",
            "Loss: 9.249678e-05, l1: 0.46522, l2: 0.31603\n",
            "Loss: 9.246913e-05, l1: 0.46462, l2: 0.31596\n",
            "Loss: 9.245116e-05, l1: 0.46389, l2: 0.31595\n",
            "Loss: 9.242487e-05, l1: 0.46250, l2: 0.31590\n",
            "Loss: 9.241446e-05, l1: 0.46220, l2: 0.31588\n",
            "Loss: 9.240505e-05, l1: 0.46202, l2: 0.31586\n",
            "Loss: 9.239218e-05, l1: 0.46222, l2: 0.31584\n",
            "Loss: 9.237333e-05, l1: 0.46224, l2: 0.31584\n",
            "Loss: 9.235408e-05, l1: 0.46252, l2: 0.31589\n",
            "Loss: 9.233515e-05, l1: 0.46266, l2: 0.31594\n",
            "Loss: 9.231724e-05, l1: 0.46289, l2: 0.31601\n",
            "Loss: 9.229928e-05, l1: 0.46345, l2: 0.31600\n",
            "Loss: 9.227837e-05, l1: 0.46295, l2: 0.31599\n",
            "Loss: 9.225406e-05, l1: 0.46310, l2: 0.31600\n",
            "Loss: 9.222417e-05, l1: 0.46282, l2: 0.31598\n",
            "Loss: 9.218318e-05, l1: 0.46281, l2: 0.31600\n",
            "Loss: 9.214469e-05, l1: 0.46317, l2: 0.31611\n",
            "Loss: 9.210217e-05, l1: 0.46274, l2: 0.31613\n",
            "Loss: 9.204727e-05, l1: 0.46269, l2: 0.31617\n",
            "Loss: 9.198433e-05, l1: 0.46289, l2: 0.31623\n",
            "Loss: 9.190090e-05, l1: 0.46314, l2: 0.31618\n",
            "Loss: 9.180205e-05, l1: 0.46371, l2: 0.31619\n",
            "Loss: 9.163369e-05, l1: 0.46434, l2: 0.31617\n",
            "Loss: 9.150489e-05, l1: 0.46491, l2: 0.31625\n",
            "Loss: 9.161132e-05, l1: 0.46299, l2: 0.31536\n",
            "Loss: 9.138665e-05, l1: 0.46410, l2: 0.31588\n",
            "Loss: 9.117314e-05, l1: 0.46496, l2: 0.31612\n",
            "Loss: 9.085955e-05, l1: 0.46643, l2: 0.31607\n",
            "Loss: 9.045953e-05, l1: 0.46933, l2: 0.31605\n",
            "Loss: 9.003399e-05, l1: 0.47042, l2: 0.31550\n",
            "Loss: 8.976371e-05, l1: 0.46986, l2: 0.31490\n",
            "Loss: 8.938275e-05, l1: 0.47202, l2: 0.31467\n",
            "Loss: 8.921696e-05, l1: 0.47350, l2: 0.31472\n",
            "Loss: 8.907897e-05, l1: 0.47450, l2: 0.31461\n",
            "Loss: 8.893065e-05, l1: 0.47591, l2: 0.31448\n",
            "Loss: 8.885914e-05, l1: 0.47893, l2: 0.31438\n",
            "Loss: 8.882470e-05, l1: 0.48021, l2: 0.31439\n",
            "Loss: 8.874799e-05, l1: 0.47901, l2: 0.31440\n",
            "Loss: 8.872389e-05, l1: 0.47889, l2: 0.31433\n",
            "Loss: 8.866911e-05, l1: 0.47927, l2: 0.31431\n",
            "Loss: 8.863791e-05, l1: 0.47971, l2: 0.31425\n",
            "Loss: 8.862033e-05, l1: 0.48001, l2: 0.31419\n",
            "Loss: 8.860251e-05, l1: 0.48041, l2: 0.31416\n",
            "Loss: 8.857533e-05, l1: 0.48101, l2: 0.31414\n",
            "Loss: 8.854256e-05, l1: 0.48179, l2: 0.31413\n",
            "Loss: 8.851077e-05, l1: 0.48247, l2: 0.31412\n",
            "Loss: 8.847706e-05, l1: 0.48317, l2: 0.31408\n",
            "Loss: 8.844285e-05, l1: 0.48367, l2: 0.31408\n",
            "Loss: 8.840598e-05, l1: 0.48407, l2: 0.31402\n",
            "Loss: 8.835235e-05, l1: 0.48387, l2: 0.31394\n",
            "Loss: 8.830804e-05, l1: 0.48410, l2: 0.31398\n",
            "Loss: 8.827111e-05, l1: 0.48364, l2: 0.31402\n",
            "Loss: 8.823380e-05, l1: 0.48440, l2: 0.31413\n",
            "Loss: 8.820596e-05, l1: 0.48515, l2: 0.31424\n",
            "Loss: 8.816235e-05, l1: 0.48592, l2: 0.31425\n",
            "Loss: 8.810881e-05, l1: 0.48849, l2: 0.31441\n",
            "Loss: 8.823571e-05, l1: 0.49084, l2: 0.31442\n",
            "Loss: 8.805482e-05, l1: 0.48934, l2: 0.31442\n",
            "Loss: 8.794642e-05, l1: 0.48910, l2: 0.31423\n",
            "Loss: 8.784252e-05, l1: 0.49045, l2: 0.31401\n",
            "Loss: 8.777019e-05, l1: 0.49195, l2: 0.31385\n",
            "Loss: 8.763361e-05, l1: 0.49354, l2: 0.31395\n",
            "Loss: 8.752993e-05, l1: 0.49391, l2: 0.31402\n",
            "Loss: 8.729644e-05, l1: 0.49747, l2: 0.31419\n",
            "Loss: 8.729933e-05, l1: 0.49901, l2: 0.31458\n",
            "Loss: 8.714697e-05, l1: 0.49825, l2: 0.31439\n",
            "Loss: 8.709994e-05, l1: 0.50112, l2: 0.31452\n",
            "Loss: 8.701179e-05, l1: 0.49952, l2: 0.31444\n",
            "Loss: 8.709441e-05, l1: 0.50378, l2: 0.31455\n",
            "Loss: 8.687583e-05, l1: 0.50149, l2: 0.31449\n",
            "Loss: 8.661505e-05, l1: 0.50162, l2: 0.31453\n",
            "Loss: 8.643808e-05, l1: 0.50250, l2: 0.31468\n",
            "Loss: 8.642698e-05, l1: 0.50606, l2: 0.31485\n",
            "Loss: 8.630510e-05, l1: 0.50405, l2: 0.31475\n",
            "Loss: 8.616206e-05, l1: 0.50456, l2: 0.31483\n",
            "Loss: 8.601445e-05, l1: 0.50378, l2: 0.31475\n",
            "Loss: 8.589030e-05, l1: 0.50543, l2: 0.31468\n",
            "Loss: 8.574441e-05, l1: 0.50515, l2: 0.31448\n",
            "Loss: 8.556855e-05, l1: 0.50509, l2: 0.31452\n",
            "Loss: 8.526911e-05, l1: 0.50848, l2: 0.31470\n",
            "Loss: 8.505721e-05, l1: 0.50839, l2: 0.31485\n",
            "Loss: 8.483264e-05, l1: 0.50921, l2: 0.31491\n",
            "Loss: 8.471371e-05, l1: 0.51271, l2: 0.31515\n",
            "Loss: 8.462612e-05, l1: 0.51097, l2: 0.31503\n",
            "Loss: 8.442811e-05, l1: 0.51408, l2: 0.31514\n",
            "Loss: 8.416593e-05, l1: 0.51437, l2: 0.31487\n",
            "Loss: 8.407501e-05, l1: 0.51473, l2: 0.31472\n",
            "Loss: 8.390179e-05, l1: 0.51476, l2: 0.31482\n",
            "Loss: 8.375713e-05, l1: 0.51645, l2: 0.31486\n",
            "Loss: 8.353314e-05, l1: 0.51586, l2: 0.31479\n",
            "Loss: 8.340331e-05, l1: 0.51711, l2: 0.31481\n",
            "Loss: 8.339210e-05, l1: 0.51640, l2: 0.31478\n",
            "Loss: 8.331710e-05, l1: 0.51675, l2: 0.31480\n",
            "Loss: 8.329695e-05, l1: 0.51681, l2: 0.31486\n",
            "Loss: 8.322524e-05, l1: 0.51665, l2: 0.31483\n",
            "Loss: 8.319318e-05, l1: 0.51652, l2: 0.31481\n",
            "Loss: 8.311401e-05, l1: 0.51583, l2: 0.31475\n",
            "Loss: 8.306638e-05, l1: 0.51492, l2: 0.31464\n",
            "Loss: 8.317551e-05, l1: 0.50991, l2: 0.31474\n",
            "Loss: 8.303307e-05, l1: 0.51328, l2: 0.31467\n",
            "Loss: 8.299184e-05, l1: 0.51378, l2: 0.31466\n",
            "Loss: 8.295312e-05, l1: 0.51317, l2: 0.31469\n",
            "Loss: 8.292354e-05, l1: 0.51290, l2: 0.31477\n",
            "Loss: 8.288400e-05, l1: 0.51256, l2: 0.31489\n",
            "Loss: 8.278893e-05, l1: 0.51161, l2: 0.31525\n",
            "Loss: 8.275431e-05, l1: 0.51021, l2: 0.31535\n",
            "Loss: 8.265561e-05, l1: 0.51046, l2: 0.31532\n",
            "Loss: 8.260830e-05, l1: 0.51086, l2: 0.31522\n",
            "Loss: 8.256679e-05, l1: 0.51085, l2: 0.31505\n",
            "Loss: 8.253416e-05, l1: 0.51070, l2: 0.31496\n",
            "Loss: 8.251215e-05, l1: 0.51063, l2: 0.31490\n",
            "Loss: 8.249612e-05, l1: 0.51085, l2: 0.31490\n",
            "Loss: 8.247541e-05, l1: 0.51102, l2: 0.31491\n",
            "Loss: 8.245681e-05, l1: 0.51107, l2: 0.31494\n",
            "Loss: 8.243295e-05, l1: 0.51090, l2: 0.31498\n",
            "Loss: 8.241276e-05, l1: 0.51071, l2: 0.31500\n",
            "Loss: 8.239087e-05, l1: 0.51080, l2: 0.31507\n",
            "Loss: 8.235901e-05, l1: 0.51116, l2: 0.31515\n",
            "Loss: 8.232392e-05, l1: 0.51175, l2: 0.31526\n",
            "Loss: 8.228240e-05, l1: 0.51300, l2: 0.31539\n",
            "Loss: 8.224201e-05, l1: 0.51356, l2: 0.31543\n",
            "Loss: 8.220146e-05, l1: 0.51393, l2: 0.31543\n",
            "Loss: 8.213658e-05, l1: 0.51441, l2: 0.31537\n",
            "Loss: 8.205691e-05, l1: 0.51444, l2: 0.31530\n",
            "Loss: 8.193732e-05, l1: 0.51401, l2: 0.31521\n",
            "Loss: 8.183648e-05, l1: 0.51320, l2: 0.31510\n",
            "Loss: 8.178042e-05, l1: 0.51312, l2: 0.31500\n",
            "Loss: 8.170163e-05, l1: 0.51303, l2: 0.31496\n",
            "Loss: 8.158939e-05, l1: 0.51366, l2: 0.31486\n",
            "Loss: 8.154358e-05, l1: 0.51330, l2: 0.31476\n",
            "Loss: 8.144925e-05, l1: 0.51531, l2: 0.31489\n",
            "Loss: 8.138129e-05, l1: 0.51510, l2: 0.31488\n",
            "Loss: 8.132408e-05, l1: 0.51464, l2: 0.31486\n",
            "Loss: 8.127845e-05, l1: 0.51519, l2: 0.31485\n",
            "Loss: 8.121214e-05, l1: 0.51545, l2: 0.31491\n",
            "Loss: 8.111653e-05, l1: 0.51648, l2: 0.31494\n",
            "Loss: 8.103940e-05, l1: 0.51706, l2: 0.31500\n",
            "Loss: 8.095142e-05, l1: 0.51764, l2: 0.31502\n",
            "Loss: 8.084140e-05, l1: 0.51925, l2: 0.31504\n",
            "Loss: 8.070411e-05, l1: 0.51911, l2: 0.31512\n",
            "Loss: 8.056639e-05, l1: 0.51913, l2: 0.31518\n",
            "Loss: 8.050819e-05, l1: 0.52108, l2: 0.31521\n",
            "Loss: 8.042191e-05, l1: 0.52009, l2: 0.31525\n",
            "Loss: 8.037857e-05, l1: 0.52049, l2: 0.31518\n",
            "Loss: 8.034837e-05, l1: 0.52123, l2: 0.31517\n",
            "Loss: 8.030293e-05, l1: 0.52291, l2: 0.31516\n",
            "Loss: 8.025969e-05, l1: 0.52444, l2: 0.31520\n",
            "Loss: 8.020880e-05, l1: 0.52654, l2: 0.31525\n",
            "Loss: 8.015699e-05, l1: 0.52838, l2: 0.31533\n",
            "Loss: 8.011935e-05, l1: 0.52993, l2: 0.31537\n",
            "Loss: 8.010872e-05, l1: 0.53095, l2: 0.31552\n",
            "Loss: 8.007928e-05, l1: 0.53053, l2: 0.31550\n",
            "Loss: 8.005806e-05, l1: 0.53074, l2: 0.31546\n",
            "Loss: 8.002827e-05, l1: 0.53097, l2: 0.31550\n",
            "Loss: 7.999350e-05, l1: 0.53185, l2: 0.31558\n",
            "Loss: 7.996290e-05, l1: 0.53289, l2: 0.31563\n",
            "Loss: 7.993351e-05, l1: 0.53319, l2: 0.31563\n",
            "Loss: 7.990118e-05, l1: 0.53398, l2: 0.31564\n",
            "Loss: 7.987484e-05, l1: 0.53443, l2: 0.31561\n",
            "Loss: 7.984834e-05, l1: 0.53416, l2: 0.31571\n",
            "Loss: 7.984113e-05, l1: 0.53416, l2: 0.31578\n",
            "Loss: 7.991009e-05, l1: 0.53595, l2: 0.31610\n",
            "Loss: 7.982561e-05, l1: 0.53469, l2: 0.31587\n",
            "Loss: 7.981623e-05, l1: 0.53387, l2: 0.31585\n",
            "Loss: 7.980711e-05, l1: 0.53408, l2: 0.31583\n",
            "Loss: 7.979921e-05, l1: 0.53431, l2: 0.31582\n",
            "Loss: 7.979044e-05, l1: 0.53433, l2: 0.31580\n",
            "Loss: 7.977764e-05, l1: 0.53442, l2: 0.31574\n",
            "Loss: 7.975967e-05, l1: 0.53468, l2: 0.31576\n",
            "Loss: 7.974818e-05, l1: 0.53443, l2: 0.31573\n",
            "Loss: 7.973856e-05, l1: 0.53444, l2: 0.31572\n",
            "Loss: 7.973021e-05, l1: 0.53443, l2: 0.31569\n",
            "Loss: 7.972011e-05, l1: 0.53434, l2: 0.31567\n",
            "Loss: 7.970732e-05, l1: 0.53436, l2: 0.31565\n",
            "Loss: 7.969297e-05, l1: 0.53404, l2: 0.31565\n",
            "Loss: 7.966197e-05, l1: 0.53437, l2: 0.31571\n",
            "Loss: 7.962816e-05, l1: 0.53466, l2: 0.31577\n",
            "Loss: 7.958990e-05, l1: 0.53643, l2: 0.31590\n",
            "Loss: 7.956624e-05, l1: 0.53684, l2: 0.31594\n",
            "Loss: 7.955417e-05, l1: 0.53747, l2: 0.31595\n",
            "Loss: 7.954424e-05, l1: 0.53788, l2: 0.31594\n",
            "Loss: 7.952697e-05, l1: 0.53827, l2: 0.31595\n",
            "Loss: 7.950891e-05, l1: 0.53872, l2: 0.31602\n",
            "Loss: 7.949730e-05, l1: 0.53860, l2: 0.31602\n",
            "Loss: 7.949048e-05, l1: 0.53858, l2: 0.31600\n",
            "Loss: 7.947916e-05, l1: 0.53861, l2: 0.31596\n",
            "Loss: 7.946966e-05, l1: 0.53854, l2: 0.31584\n",
            "Loss: 7.946676e-05, l1: 0.53867, l2: 0.31578\n",
            "Loss: 7.945253e-05, l1: 0.53886, l2: 0.31579\n",
            "Loss: 7.944687e-05, l1: 0.53860, l2: 0.31577\n",
            "Loss: 7.944019e-05, l1: 0.53874, l2: 0.31574\n",
            "Loss: 7.943311e-05, l1: 0.53851, l2: 0.31570\n",
            "Loss: 7.942772e-05, l1: 0.53864, l2: 0.31573\n",
            "Loss: 7.942183e-05, l1: 0.53870, l2: 0.31577\n",
            "Loss: 7.941545e-05, l1: 0.53882, l2: 0.31584\n",
            "Loss: 7.941109e-05, l1: 0.53900, l2: 0.31588\n",
            "Loss: 7.940537e-05, l1: 0.53891, l2: 0.31591\n",
            "Loss: 7.939633e-05, l1: 0.53882, l2: 0.31595\n",
            "Loss: 7.938729e-05, l1: 0.53859, l2: 0.31594\n",
            "Loss: 7.936647e-05, l1: 0.53782, l2: 0.31590\n",
            "Loss: 7.935138e-05, l1: 0.53735, l2: 0.31587\n",
            "Loss: 7.933475e-05, l1: 0.53705, l2: 0.31586\n",
            "Loss: 7.931804e-05, l1: 0.53685, l2: 0.31583\n",
            "Loss: 7.930175e-05, l1: 0.53717, l2: 0.31584\n",
            "Loss: 7.927864e-05, l1: 0.53756, l2: 0.31585\n",
            "Loss: 7.925775e-05, l1: 0.53794, l2: 0.31588\n",
            "Loss: 7.921865e-05, l1: 0.53782, l2: 0.31586\n",
            "Loss: 7.915979e-05, l1: 0.53778, l2: 0.31587\n",
            "Loss: 7.913195e-05, l1: 0.53561, l2: 0.31576\n",
            "Loss: 7.908454e-05, l1: 0.53618, l2: 0.31579\n",
            "Loss: 7.905465e-05, l1: 0.53610, l2: 0.31567\n",
            "Loss: 7.902776e-05, l1: 0.53629, l2: 0.31566\n",
            "Loss: 7.901429e-05, l1: 0.53620, l2: 0.31565\n",
            "Loss: 7.899983e-05, l1: 0.53627, l2: 0.31561\n",
            "Loss: 7.898831e-05, l1: 0.53631, l2: 0.31551\n",
            "Loss: 7.898181e-05, l1: 0.53652, l2: 0.31552\n",
            "Loss: 7.896690e-05, l1: 0.53696, l2: 0.31557\n",
            "Loss: 7.896948e-05, l1: 0.53764, l2: 0.31559\n",
            "Loss: 7.895863e-05, l1: 0.53728, l2: 0.31558\n",
            "Loss: 7.894678e-05, l1: 0.53756, l2: 0.31561\n",
            "Loss: 7.893585e-05, l1: 0.53781, l2: 0.31563\n",
            "Loss: 7.892594e-05, l1: 0.53816, l2: 0.31564\n",
            "Loss: 7.890510e-05, l1: 0.53899, l2: 0.31563\n",
            "Loss: 7.889199e-05, l1: 0.53981, l2: 0.31563\n",
            "Loss: 7.888080e-05, l1: 0.54054, l2: 0.31563\n",
            "Loss: 7.887099e-05, l1: 0.54091, l2: 0.31565\n",
            "Loss: 7.885988e-05, l1: 0.54121, l2: 0.31567\n",
            "Loss: 7.884569e-05, l1: 0.54133, l2: 0.31568\n",
            "Loss: 7.883045e-05, l1: 0.54182, l2: 0.31570\n",
            "Loss: 7.880819e-05, l1: 0.54248, l2: 0.31573\n",
            "Loss: 7.879190e-05, l1: 0.54268, l2: 0.31586\n",
            "Loss: 7.875699e-05, l1: 0.54535, l2: 0.31576\n",
            "Loss: 7.879930e-05, l1: 0.54598, l2: 0.31564\n",
            "Loss: 7.870441e-05, l1: 0.54561, l2: 0.31571\n",
            "Loss: 7.864530e-05, l1: 0.54673, l2: 0.31578\n",
            "Loss: 7.857628e-05, l1: 0.54869, l2: 0.31587\n",
            "Loss: 7.852940e-05, l1: 0.55050, l2: 0.31592\n",
            "Loss: 7.848474e-05, l1: 0.55083, l2: 0.31596\n",
            "Loss: 7.844822e-05, l1: 0.55280, l2: 0.31597\n",
            "Loss: 7.841845e-05, l1: 0.55224, l2: 0.31598\n",
            "Loss: 7.839724e-05, l1: 0.55183, l2: 0.31599\n",
            "Loss: 7.836834e-05, l1: 0.55217, l2: 0.31600\n",
            "Loss: 7.831406e-05, l1: 0.55230, l2: 0.31600\n",
            "Loss: 7.830192e-05, l1: 0.55272, l2: 0.31615\n",
            "Loss: 7.828373e-05, l1: 0.55252, l2: 0.31608\n",
            "Loss: 7.822347e-05, l1: 0.55135, l2: 0.31612\n",
            "Loss: 7.815324e-05, l1: 0.55110, l2: 0.31612\n",
            "Loss: 7.804051e-05, l1: 0.55110, l2: 0.31609\n",
            "Loss: 7.816943e-05, l1: 0.55006, l2: 0.31633\n",
            "Loss: 7.797635e-05, l1: 0.55072, l2: 0.31618\n",
            "Loss: 7.798866e-05, l1: 0.55190, l2: 0.31616\n",
            "Loss: 7.790753e-05, l1: 0.55130, l2: 0.31617\n",
            "Loss: 7.792651e-05, l1: 0.55195, l2: 0.31614\n",
            "Loss: 7.785612e-05, l1: 0.55160, l2: 0.31615\n",
            "Loss: 7.783235e-05, l1: 0.55154, l2: 0.31616\n",
            "Loss: 7.780812e-05, l1: 0.55079, l2: 0.31612\n",
            "Loss: 7.779032e-05, l1: 0.55096, l2: 0.31612\n",
            "Loss: 7.776086e-05, l1: 0.55026, l2: 0.31609\n",
            "Loss: 7.775730e-05, l1: 0.54883, l2: 0.31591\n",
            "Loss: 7.772775e-05, l1: 0.54956, l2: 0.31600\n",
            "Loss: 7.768247e-05, l1: 0.54894, l2: 0.31587\n",
            "Loss: 7.763552e-05, l1: 0.54886, l2: 0.31586\n",
            "Loss: 7.758681e-05, l1: 0.54917, l2: 0.31587\n",
            "Loss: 7.756628e-05, l1: 0.55003, l2: 0.31586\n",
            "Loss: 7.750547e-05, l1: 0.54985, l2: 0.31592\n",
            "Loss: 7.746196e-05, l1: 0.54988, l2: 0.31602\n",
            "Loss: 7.736745e-05, l1: 0.55017, l2: 0.31615\n",
            "Loss: 7.728527e-05, l1: 0.55083, l2: 0.31631\n",
            "Loss: 7.722737e-05, l1: 0.55109, l2: 0.31632\n",
            "Loss: 7.715971e-05, l1: 0.55130, l2: 0.31630\n",
            "Loss: 7.711913e-05, l1: 0.55136, l2: 0.31623\n",
            "Loss: 7.708632e-05, l1: 0.55108, l2: 0.31624\n",
            "Loss: 7.702648e-05, l1: 0.55049, l2: 0.31621\n",
            "Loss: 7.695676e-05, l1: 0.54998, l2: 0.31623\n",
            "Loss: 7.689912e-05, l1: 0.54995, l2: 0.31630\n",
            "Loss: 7.677342e-05, l1: 0.54992, l2: 0.31637\n",
            "Loss: 7.668851e-05, l1: 0.54959, l2: 0.31635\n",
            "Loss: 7.662163e-05, l1: 0.54845, l2: 0.31620\n",
            "Loss: 7.659468e-05, l1: 0.54845, l2: 0.31610\n",
            "Loss: 7.655442e-05, l1: 0.54792, l2: 0.31609\n",
            "Loss: 7.652271e-05, l1: 0.54749, l2: 0.31606\n",
            "Loss: 7.648727e-05, l1: 0.54679, l2: 0.31596\n",
            "Loss: 7.644491e-05, l1: 0.54646, l2: 0.31586\n",
            "Loss: 7.641339e-05, l1: 0.54630, l2: 0.31580\n",
            "Loss: 7.637258e-05, l1: 0.54645, l2: 0.31576\n",
            "Loss: 7.631634e-05, l1: 0.54708, l2: 0.31574\n",
            "Loss: 7.627136e-05, l1: 0.54764, l2: 0.31559\n",
            "Loss: 7.622980e-05, l1: 0.54866, l2: 0.31547\n",
            "Loss: 7.619441e-05, l1: 0.54938, l2: 0.31536\n",
            "Loss: 7.617030e-05, l1: 0.54990, l2: 0.31526\n",
            "Loss: 7.615038e-05, l1: 0.55004, l2: 0.31522\n",
            "Loss: 7.612631e-05, l1: 0.55013, l2: 0.31524\n",
            "Loss: 7.609131e-05, l1: 0.55101, l2: 0.31526\n",
            "Loss: 7.608230e-05, l1: 0.55235, l2: 0.31524\n",
            "Loss: 7.606291e-05, l1: 0.55245, l2: 0.31525\n",
            "Loss: 7.605414e-05, l1: 0.55246, l2: 0.31522\n",
            "Loss: 7.604100e-05, l1: 0.55286, l2: 0.31519\n",
            "Loss: 7.602661e-05, l1: 0.55332, l2: 0.31516\n",
            "Loss: 7.601438e-05, l1: 0.55391, l2: 0.31517\n",
            "Loss: 7.599527e-05, l1: 0.55449, l2: 0.31522\n",
            "Loss: 7.597014e-05, l1: 0.55502, l2: 0.31524\n",
            "Loss: 7.593582e-05, l1: 0.55635, l2: 0.31529\n",
            "Loss: 7.590521e-05, l1: 0.55583, l2: 0.31527\n",
            "Loss: 7.587503e-05, l1: 0.55634, l2: 0.31519\n",
            "Loss: 7.585064e-05, l1: 0.55661, l2: 0.31517\n",
            "Loss: 7.582107e-05, l1: 0.55764, l2: 0.31518\n",
            "Loss: 7.578745e-05, l1: 0.55915, l2: 0.31526\n",
            "Loss: 7.576989e-05, l1: 0.56038, l2: 0.31535\n",
            "Loss: 7.575136e-05, l1: 0.56039, l2: 0.31534\n",
            "Loss: 7.574504e-05, l1: 0.55994, l2: 0.31527\n",
            "Loss: 7.573516e-05, l1: 0.56045, l2: 0.31527\n",
            "Loss: 7.572489e-05, l1: 0.56100, l2: 0.31526\n",
            "Loss: 7.571094e-05, l1: 0.56139, l2: 0.31523\n",
            "Loss: 7.569177e-05, l1: 0.56152, l2: 0.31520\n",
            "Loss: 7.567495e-05, l1: 0.56208, l2: 0.31517\n",
            "Loss: 7.564476e-05, l1: 0.56187, l2: 0.31515\n",
            "Loss: 7.562342e-05, l1: 0.56281, l2: 0.31527\n",
            "Loss: 7.559551e-05, l1: 0.56226, l2: 0.31522\n",
            "Loss: 7.558899e-05, l1: 0.56243, l2: 0.31517\n",
            "Loss: 7.558156e-05, l1: 0.56256, l2: 0.31518\n",
            "Loss: 7.555783e-05, l1: 0.56355, l2: 0.31520\n",
            "Loss: 7.552956e-05, l1: 0.56443, l2: 0.31523\n",
            "Loss: 7.550394e-05, l1: 0.56489, l2: 0.31525\n",
            "Loss: 7.548922e-05, l1: 0.56590, l2: 0.31527\n",
            "Loss: 7.547712e-05, l1: 0.56582, l2: 0.31529\n",
            "Loss: 7.546382e-05, l1: 0.56627, l2: 0.31529\n",
            "Loss: 7.544897e-05, l1: 0.56668, l2: 0.31532\n",
            "Loss: 7.543513e-05, l1: 0.56735, l2: 0.31535\n",
            "Loss: 7.542288e-05, l1: 0.56780, l2: 0.31537\n",
            "Loss: 7.540717e-05, l1: 0.56795, l2: 0.31538\n",
            "Loss: 7.538778e-05, l1: 0.56870, l2: 0.31534\n",
            "Loss: 7.536659e-05, l1: 0.57006, l2: 0.31529\n",
            "Loss: 7.534714e-05, l1: 0.57079, l2: 0.31522\n",
            "Loss: 7.537637e-05, l1: 0.57304, l2: 0.31519\n",
            "Loss: 7.533762e-05, l1: 0.57158, l2: 0.31521\n",
            "Loss: 7.531718e-05, l1: 0.57275, l2: 0.31521\n",
            "Loss: 7.529584e-05, l1: 0.57315, l2: 0.31523\n",
            "Loss: 7.527533e-05, l1: 0.57377, l2: 0.31521\n",
            "Loss: 7.525330e-05, l1: 0.57494, l2: 0.31518\n",
            "Loss: 7.526818e-05, l1: 0.57510, l2: 0.31510\n",
            "Loss: 7.524362e-05, l1: 0.57500, l2: 0.31515\n",
            "Loss: 7.522877e-05, l1: 0.57536, l2: 0.31513\n",
            "Loss: 7.521698e-05, l1: 0.57504, l2: 0.31514\n",
            "Loss: 7.520886e-05, l1: 0.57506, l2: 0.31514\n",
            "Loss: 7.520189e-05, l1: 0.57455, l2: 0.31514\n",
            "Loss: 7.519455e-05, l1: 0.57423, l2: 0.31515\n",
            "Loss: 7.518866e-05, l1: 0.57404, l2: 0.31516\n",
            "Loss: 7.517856e-05, l1: 0.57396, l2: 0.31515\n",
            "Loss: 7.516269e-05, l1: 0.57362, l2: 0.31517\n",
            "Loss: 7.514098e-05, l1: 0.57346, l2: 0.31511\n",
            "Loss: 7.511520e-05, l1: 0.57313, l2: 0.31511\n",
            "Loss: 7.509909e-05, l1: 0.57304, l2: 0.31502\n",
            "Loss: 7.508697e-05, l1: 0.57340, l2: 0.31505\n",
            "Loss: 7.507487e-05, l1: 0.57339, l2: 0.31510\n",
            "Loss: 7.506301e-05, l1: 0.57340, l2: 0.31513\n",
            "Loss: 7.503681e-05, l1: 0.57271, l2: 0.31518\n",
            "Loss: 7.499275e-05, l1: 0.57076, l2: 0.31526\n",
            "Loss: 7.496575e-05, l1: 0.56937, l2: 0.31520\n",
            "Loss: 7.495140e-05, l1: 0.56921, l2: 0.31517\n",
            "Loss: 7.493786e-05, l1: 0.56883, l2: 0.31513\n",
            "Loss: 7.489629e-05, l1: 0.56783, l2: 0.31505\n",
            "Loss: 7.484118e-05, l1: 0.56592, l2: 0.31501\n",
            "Loss: 7.479541e-05, l1: 0.56553, l2: 0.31494\n",
            "Loss: 7.473845e-05, l1: 0.56388, l2: 0.31484\n",
            "Loss: 7.469154e-05, l1: 0.56300, l2: 0.31483\n",
            "Loss: 7.461796e-05, l1: 0.56157, l2: 0.31477\n",
            "Loss: 7.457125e-05, l1: 0.56175, l2: 0.31483\n",
            "Loss: 7.454262e-05, l1: 0.56047, l2: 0.31493\n",
            "Loss: 7.451970e-05, l1: 0.56116, l2: 0.31494\n",
            "Loss: 7.449468e-05, l1: 0.56106, l2: 0.31491\n",
            "Loss: 7.446698e-05, l1: 0.56040, l2: 0.31487\n",
            "Loss: 7.441976e-05, l1: 0.55923, l2: 0.31484\n",
            "Loss: 7.437076e-05, l1: 0.55836, l2: 0.31477\n",
            "Loss: 7.431419e-05, l1: 0.55780, l2: 0.31472\n",
            "Loss: 7.427196e-05, l1: 0.55837, l2: 0.31461\n",
            "Loss: 7.423243e-05, l1: 0.55789, l2: 0.31446\n",
            "Loss: 7.420788e-05, l1: 0.55817, l2: 0.31435\n",
            "Loss: 7.419189e-05, l1: 0.55823, l2: 0.31427\n",
            "Loss: 7.417881e-05, l1: 0.55856, l2: 0.31424\n",
            "Loss: 7.415620e-05, l1: 0.55928, l2: 0.31423\n",
            "Loss: 7.417589e-05, l1: 0.56049, l2: 0.31426\n",
            "Loss: 7.413912e-05, l1: 0.55977, l2: 0.31424\n",
            "Loss: 7.410932e-05, l1: 0.56007, l2: 0.31426\n",
            "Loss: 7.406464e-05, l1: 0.56020, l2: 0.31426\n",
            "Loss: 7.403382e-05, l1: 0.55985, l2: 0.31434\n",
            "Loss: 7.399087e-05, l1: 0.55964, l2: 0.31429\n",
            "Loss: 7.394828e-05, l1: 0.55918, l2: 0.31425\n",
            "Loss: 7.389588e-05, l1: 0.55846, l2: 0.31426\n",
            "Loss: 7.383624e-05, l1: 0.55783, l2: 0.31432\n",
            "Loss: 7.380288e-05, l1: 0.55674, l2: 0.31434\n",
            "Loss: 7.379027e-05, l1: 0.55646, l2: 0.31437\n",
            "Loss: 7.377644e-05, l1: 0.55622, l2: 0.31434\n",
            "Loss: 7.376212e-05, l1: 0.55571, l2: 0.31428\n",
            "Loss: 7.374951e-05, l1: 0.55526, l2: 0.31427\n",
            "Loss: 7.373154e-05, l1: 0.55512, l2: 0.31429\n",
            "Loss: 7.371907e-05, l1: 0.55466, l2: 0.31437\n",
            "Loss: 7.369936e-05, l1: 0.55484, l2: 0.31439\n",
            "Loss: 7.367125e-05, l1: 0.55561, l2: 0.31445\n",
            "Loss: 7.365471e-05, l1: 0.55589, l2: 0.31451\n",
            "Loss: 7.363640e-05, l1: 0.55643, l2: 0.31458\n",
            "Loss: 7.362370e-05, l1: 0.55592, l2: 0.31468\n",
            "Loss: 7.360565e-05, l1: 0.55557, l2: 0.31465\n",
            "Loss: 7.362301e-05, l1: 0.55668, l2: 0.31460\n",
            "Loss: 7.359131e-05, l1: 0.55602, l2: 0.31463\n",
            "Loss: 7.357778e-05, l1: 0.55586, l2: 0.31463\n",
            "Loss: 7.354334e-05, l1: 0.55531, l2: 0.31465\n",
            "Loss: 7.351568e-05, l1: 0.55547, l2: 0.31471\n",
            "Loss: 7.347815e-05, l1: 0.55420, l2: 0.31476\n",
            "Loss: 7.344809e-05, l1: 0.55508, l2: 0.31481\n",
            "Loss: 7.342976e-05, l1: 0.55446, l2: 0.31484\n",
            "Loss: 7.342386e-05, l1: 0.55396, l2: 0.31485\n",
            "Loss: 7.342033e-05, l1: 0.55396, l2: 0.31487\n",
            "Loss: 7.341439e-05, l1: 0.55406, l2: 0.31491\n",
            "Loss: 7.340898e-05, l1: 0.55408, l2: 0.31494\n",
            "Loss: 7.339996e-05, l1: 0.55421, l2: 0.31495\n",
            "Loss: 7.338753e-05, l1: 0.55442, l2: 0.31497\n",
            "Loss: 7.337607e-05, l1: 0.55449, l2: 0.31496\n",
            "Loss: 7.336441e-05, l1: 0.55460, l2: 0.31496\n",
            "Loss: 7.335734e-05, l1: 0.55460, l2: 0.31489\n",
            "Loss: 7.334077e-05, l1: 0.55476, l2: 0.31493\n",
            "Loss: 7.331034e-05, l1: 0.55501, l2: 0.31494\n",
            "Loss: 7.327532e-05, l1: 0.55515, l2: 0.31502\n",
            "Loss: 7.323157e-05, l1: 0.55565, l2: 0.31505\n",
            "Loss: 7.318510e-05, l1: 0.55556, l2: 0.31514\n",
            "Loss: 7.312029e-05, l1: 0.55599, l2: 0.31520\n",
            "Loss: 7.306704e-05, l1: 0.55610, l2: 0.31524\n",
            "Loss: 7.300562e-05, l1: 0.55649, l2: 0.31524\n",
            "Loss: 7.294433e-05, l1: 0.55723, l2: 0.31526\n",
            "Loss: 7.288541e-05, l1: 0.55846, l2: 0.31536\n",
            "Loss: 7.286310e-05, l1: 0.56064, l2: 0.31564\n",
            "Loss: 7.284154e-05, l1: 0.56047, l2: 0.31572\n",
            "Loss: 7.278801e-05, l1: 0.56017, l2: 0.31553\n",
            "Loss: 7.276837e-05, l1: 0.56076, l2: 0.31560\n",
            "Loss: 7.274981e-05, l1: 0.56138, l2: 0.31569\n",
            "Loss: 7.273311e-05, l1: 0.56228, l2: 0.31575\n",
            "Loss: 7.271564e-05, l1: 0.56233, l2: 0.31573\n",
            "Loss: 7.270554e-05, l1: 0.56241, l2: 0.31569\n",
            "Loss: 7.269179e-05, l1: 0.56256, l2: 0.31567\n",
            "Loss: 7.266854e-05, l1: 0.56302, l2: 0.31565\n",
            "Loss: 7.264705e-05, l1: 0.56292, l2: 0.31560\n",
            "Loss: 7.265445e-05, l1: 0.56386, l2: 0.31559\n",
            "Loss: 7.263232e-05, l1: 0.56336, l2: 0.31559\n",
            "Loss: 7.261310e-05, l1: 0.56392, l2: 0.31561\n",
            "Loss: 7.259131e-05, l1: 0.56402, l2: 0.31560\n",
            "Loss: 7.257538e-05, l1: 0.56413, l2: 0.31557\n",
            "Loss: 7.255097e-05, l1: 0.56490, l2: 0.31555\n",
            "Loss: 7.249381e-05, l1: 0.56620, l2: 0.31551\n",
            "Loss: 7.263241e-05, l1: 0.56441, l2: 0.31548\n",
            "Loss: 7.247055e-05, l1: 0.56569, l2: 0.31550\n",
            "Loss: 7.242202e-05, l1: 0.56538, l2: 0.31542\n",
            "Loss: 7.240450e-05, l1: 0.56628, l2: 0.31523\n",
            "Loss: 7.238506e-05, l1: 0.56582, l2: 0.31533\n",
            "Loss: 7.234822e-05, l1: 0.56547, l2: 0.31516\n",
            "Loss: 7.230556e-05, l1: 0.56656, l2: 0.31522\n",
            "Loss: 7.222612e-05, l1: 0.56585, l2: 0.31531\n",
            "Loss: 7.211602e-05, l1: 0.56627, l2: 0.31551\n",
            "Loss: 7.205471e-05, l1: 0.56658, l2: 0.31596\n",
            "Loss: 7.231386e-05, l1: 0.56652, l2: 0.31627\n",
            "Loss: 7.200205e-05, l1: 0.56657, l2: 0.31605\n",
            "Loss: 7.195512e-05, l1: 0.56710, l2: 0.31580\n",
            "Loss: 7.188365e-05, l1: 0.56632, l2: 0.31575\n",
            "Loss: 7.181424e-05, l1: 0.56577, l2: 0.31586\n",
            "Loss: 7.172374e-05, l1: 0.56465, l2: 0.31587\n",
            "Loss: 7.165164e-05, l1: 0.56355, l2: 0.31589\n",
            "Loss: 7.159785e-05, l1: 0.56356, l2: 0.31590\n",
            "Loss: 7.155076e-05, l1: 0.56300, l2: 0.31584\n",
            "Loss: 7.150626e-05, l1: 0.56226, l2: 0.31575\n",
            "Loss: 7.149218e-05, l1: 0.56153, l2: 0.31589\n",
            "Loss: 7.146574e-05, l1: 0.56189, l2: 0.31582\n",
            "Loss: 7.144226e-05, l1: 0.56196, l2: 0.31590\n",
            "Loss: 7.142463e-05, l1: 0.56180, l2: 0.31594\n",
            "Loss: 7.140468e-05, l1: 0.56123, l2: 0.31595\n",
            "Loss: 7.137592e-05, l1: 0.56040, l2: 0.31593\n",
            "Loss: 7.134740e-05, l1: 0.55986, l2: 0.31593\n",
            "Loss: 7.133271e-05, l1: 0.55898, l2: 0.31594\n",
            "Loss: 7.131178e-05, l1: 0.55950, l2: 0.31590\n",
            "Loss: 7.129606e-05, l1: 0.55968, l2: 0.31589\n",
            "Loss: 7.126773e-05, l1: 0.55970, l2: 0.31584\n",
            "Loss: 7.117901e-05, l1: 0.55891, l2: 0.31566\n",
            "Loss: 7.109022e-05, l1: 0.55755, l2: 0.31554\n",
            "Loss: 7.100770e-05, l1: 0.55611, l2: 0.31547\n",
            "Loss: 7.094227e-05, l1: 0.55543, l2: 0.31560\n",
            "Loss: 7.090653e-05, l1: 0.55532, l2: 0.31568\n",
            "Loss: 7.088208e-05, l1: 0.55568, l2: 0.31580\n",
            "Loss: 7.086703e-05, l1: 0.55593, l2: 0.31585\n",
            "Loss: 7.084712e-05, l1: 0.55651, l2: 0.31585\n",
            "Loss: 7.083208e-05, l1: 0.55641, l2: 0.31581\n",
            "Loss: 7.081795e-05, l1: 0.55637, l2: 0.31571\n",
            "Loss: 7.078712e-05, l1: 0.55711, l2: 0.31565\n",
            "Loss: 7.076289e-05, l1: 0.55686, l2: 0.31563\n",
            "Loss: 7.073935e-05, l1: 0.55679, l2: 0.31567\n",
            "Loss: 7.072647e-05, l1: 0.55675, l2: 0.31572\n",
            "Loss: 7.071353e-05, l1: 0.55682, l2: 0.31578\n",
            "Loss: 7.070583e-05, l1: 0.55666, l2: 0.31581\n",
            "Loss: 7.069901e-05, l1: 0.55663, l2: 0.31581\n",
            "Loss: 7.068153e-05, l1: 0.55621, l2: 0.31580\n",
            "Loss: 7.066787e-05, l1: 0.55583, l2: 0.31572\n",
            "Loss: 7.064642e-05, l1: 0.55555, l2: 0.31570\n",
            "Loss: 7.061975e-05, l1: 0.55478, l2: 0.31563\n",
            "Loss: 7.059705e-05, l1: 0.55426, l2: 0.31552\n",
            "Loss: 7.057681e-05, l1: 0.55239, l2: 0.31541\n",
            "Loss: 7.054888e-05, l1: 0.55282, l2: 0.31543\n",
            "Loss: 7.053449e-05, l1: 0.55336, l2: 0.31545\n",
            "Loss: 7.052640e-05, l1: 0.55340, l2: 0.31547\n",
            "Loss: 7.051673e-05, l1: 0.55344, l2: 0.31547\n",
            "Loss: 7.050555e-05, l1: 0.55350, l2: 0.31544\n",
            "Loss: 7.048749e-05, l1: 0.55376, l2: 0.31540\n",
            "Loss: 7.045965e-05, l1: 0.55447, l2: 0.31534\n",
            "Loss: 7.042277e-05, l1: 0.55553, l2: 0.31531\n",
            "Loss: 7.045792e-05, l1: 0.55947, l2: 0.31517\n",
            "Loss: 7.039233e-05, l1: 0.55714, l2: 0.31525\n",
            "Loss: 7.034984e-05, l1: 0.55789, l2: 0.31529\n",
            "Loss: 7.029006e-05, l1: 0.55926, l2: 0.31535\n",
            "Loss: 7.024698e-05, l1: 0.55982, l2: 0.31538\n",
            "Loss: 7.020567e-05, l1: 0.56045, l2: 0.31529\n",
            "Loss: 7.018215e-05, l1: 0.56057, l2: 0.31522\n",
            "Loss: 7.011986e-05, l1: 0.56116, l2: 0.31504\n",
            "Loss: 7.002894e-05, l1: 0.56202, l2: 0.31491\n",
            "Loss: 6.987223e-05, l1: 0.56520, l2: 0.31470\n",
            "Loss: 6.973107e-05, l1: 0.56742, l2: 0.31468\n",
            "Loss: 7.003877e-05, l1: 0.56802, l2: 0.31482\n",
            "Loss: 6.965646e-05, l1: 0.56761, l2: 0.31473\n",
            "Loss: 6.969390e-05, l1: 0.56730, l2: 0.31504\n",
            "Loss: 6.957096e-05, l1: 0.56747, l2: 0.31487\n",
            "Loss: 6.951525e-05, l1: 0.56843, l2: 0.31496\n",
            "Loss: 6.943040e-05, l1: 0.57049, l2: 0.31504\n",
            "Loss: 6.933008e-05, l1: 0.57366, l2: 0.31523\n",
            "Loss: 6.916681e-05, l1: 0.57535, l2: 0.31511\n",
            "Loss: 6.914404e-05, l1: 0.57306, l2: 0.31495\n",
            "Loss: 6.905583e-05, l1: 0.57421, l2: 0.31503\n",
            "Loss: 6.908320e-05, l1: 0.57428, l2: 0.31459\n",
            "Loss: 6.888778e-05, l1: 0.57424, l2: 0.31481\n",
            "Loss: 6.883708e-05, l1: 0.57448, l2: 0.31471\n",
            "Loss: 6.903944e-05, l1: 0.57843, l2: 0.31472\n",
            "Loss: 6.867861e-05, l1: 0.57608, l2: 0.31471\n",
            "Loss: 9.206567e-05, l1: 0.58694, l2: 0.31520\n",
            "Loss: 6.859866e-05, l1: 0.57708, l2: 0.31476\n",
            "Loss: 6.858093e-05, l1: 0.57712, l2: 0.31514\n",
            "Loss: 6.848203e-05, l1: 0.57710, l2: 0.31496\n",
            "Loss: 6.832706e-05, l1: 0.57927, l2: 0.31503\n",
            "Loss: 6.822299e-05, l1: 0.58441, l2: 0.31527\n",
            "Loss: 6.823751e-05, l1: 0.58499, l2: 0.31568\n",
            "Loss: 6.804609e-05, l1: 0.58470, l2: 0.31547\n",
            "Loss: 6.790470e-05, l1: 0.58448, l2: 0.31548\n",
            "Loss: 6.776120e-05, l1: 0.58662, l2: 0.31550\n",
            "Loss: 6.762631e-05, l1: 0.59067, l2: 0.31550\n",
            "Loss: 6.751637e-05, l1: 0.59136, l2: 0.31547\n",
            "Loss: 6.774773e-05, l1: 0.59438, l2: 0.31556\n",
            "Loss: 6.743799e-05, l1: 0.59239, l2: 0.31550\n",
            "Loss: 6.731256e-05, l1: 0.59569, l2: 0.31544\n",
            "Loss: 6.718699e-05, l1: 0.59857, l2: 0.31534\n",
            "Loss: 6.702788e-05, l1: 0.60516, l2: 0.31533\n",
            "Loss: 6.696690e-05, l1: 0.60807, l2: 0.31542\n",
            "Loss: 6.741695e-05, l1: 0.61430, l2: 0.31536\n",
            "Loss: 6.685000e-05, l1: 0.61004, l2: 0.31540\n",
            "Loss: 6.672803e-05, l1: 0.61306, l2: 0.31556\n",
            "Loss: 6.670168e-05, l1: 0.60970, l2: 0.31551\n",
            "Loss: 6.663355e-05, l1: 0.60943, l2: 0.31549\n",
            "Loss: 6.659444e-05, l1: 0.61049, l2: 0.31552\n",
            "Loss: 6.657204e-05, l1: 0.61142, l2: 0.31550\n",
            "Loss: 6.654100e-05, l1: 0.61208, l2: 0.31546\n",
            "Loss: 6.650219e-05, l1: 0.61235, l2: 0.31539\n",
            "Loss: 6.647235e-05, l1: 0.61145, l2: 0.31527\n",
            "Loss: 6.644413e-05, l1: 0.61255, l2: 0.31543\n",
            "Loss: 6.638680e-05, l1: 0.61169, l2: 0.31537\n",
            "Loss: 6.636783e-05, l1: 0.61107, l2: 0.31540\n",
            "Loss: 6.633504e-05, l1: 0.61039, l2: 0.31541\n",
            "Loss: 6.704520e-05, l1: 0.61232, l2: 0.31624\n",
            "Loss: 6.632270e-05, l1: 0.61062, l2: 0.31551\n",
            "Loss: 6.627530e-05, l1: 0.60990, l2: 0.31554\n",
            "Loss: 6.620977e-05, l1: 0.60906, l2: 0.31559\n",
            "Loss: 6.615677e-05, l1: 0.60840, l2: 0.31560\n",
            "Loss: 6.613903e-05, l1: 0.60808, l2: 0.31582\n",
            "Loss: 6.609633e-05, l1: 0.60858, l2: 0.31577\n",
            "Loss: 6.607016e-05, l1: 0.60901, l2: 0.31572\n",
            "Loss: 6.602125e-05, l1: 0.60884, l2: 0.31569\n",
            "Loss: 6.593466e-05, l1: 0.60878, l2: 0.31565\n",
            "Loss: 6.584554e-05, l1: 0.60633, l2: 0.31554\n",
            "Loss: 6.579552e-05, l1: 0.60549, l2: 0.31545\n",
            "Loss: 6.576330e-05, l1: 0.60484, l2: 0.31541\n",
            "Loss: 6.572907e-05, l1: 0.60425, l2: 0.31539\n",
            "Loss: 6.567765e-05, l1: 0.60381, l2: 0.31534\n",
            "Loss: 6.559494e-05, l1: 0.60248, l2: 0.31532\n",
            "Loss: 6.552659e-05, l1: 0.60249, l2: 0.31534\n",
            "Loss: 6.547805e-05, l1: 0.60035, l2: 0.31534\n",
            "Loss: 6.542679e-05, l1: 0.60096, l2: 0.31541\n",
            "Loss: 6.539840e-05, l1: 0.60176, l2: 0.31542\n",
            "Loss: 6.536983e-05, l1: 0.60168, l2: 0.31544\n",
            "Loss: 6.534458e-05, l1: 0.60163, l2: 0.31542\n",
            "Loss: 6.531564e-05, l1: 0.60254, l2: 0.31536\n",
            "Loss: 6.528374e-05, l1: 0.60353, l2: 0.31538\n",
            "Loss: 6.523594e-05, l1: 0.60443, l2: 0.31534\n",
            "Loss: 6.518650e-05, l1: 0.60555, l2: 0.31536\n",
            "Loss: 6.515374e-05, l1: 0.60620, l2: 0.31549\n",
            "Loss: 6.511492e-05, l1: 0.60696, l2: 0.31554\n",
            "Loss: 6.508752e-05, l1: 0.60664, l2: 0.31554\n",
            "Loss: 6.506177e-05, l1: 0.60621, l2: 0.31555\n",
            "Loss: 6.503062e-05, l1: 0.60591, l2: 0.31552\n",
            "Loss: 6.499806e-05, l1: 0.60583, l2: 0.31552\n",
            "Loss: 6.496551e-05, l1: 0.60482, l2: 0.31535\n",
            "Loss: 6.490469e-05, l1: 0.60537, l2: 0.31536\n",
            "Loss: 6.487890e-05, l1: 0.60549, l2: 0.31531\n",
            "Loss: 6.484534e-05, l1: 0.60515, l2: 0.31522\n",
            "Loss: 6.482677e-05, l1: 0.60549, l2: 0.31520\n",
            "Loss: 6.481005e-05, l1: 0.60528, l2: 0.31515\n",
            "Loss: 6.479549e-05, l1: 0.60526, l2: 0.31511\n",
            "Loss: 6.477705e-05, l1: 0.60505, l2: 0.31510\n",
            "Loss: 6.474629e-05, l1: 0.60419, l2: 0.31509\n",
            "Loss: 6.470504e-05, l1: 0.60372, l2: 0.31509\n",
            "Loss: 6.464311e-05, l1: 0.60208, l2: 0.31515\n",
            "Loss: 6.461886e-05, l1: 0.59936, l2: 0.31523\n",
            "Loss: 6.456794e-05, l1: 0.59915, l2: 0.31525\n",
            "Loss: 6.461226e-05, l1: 0.59934, l2: 0.31519\n",
            "Loss: 6.454997e-05, l1: 0.59922, l2: 0.31523\n",
            "Loss: 6.452395e-05, l1: 0.59863, l2: 0.31524\n",
            "Loss: 6.449501e-05, l1: 0.59818, l2: 0.31520\n",
            "Loss: 6.445890e-05, l1: 0.59786, l2: 0.31520\n",
            "Loss: 6.443640e-05, l1: 0.59843, l2: 0.31530\n",
            "Loss: 6.442025e-05, l1: 0.59822, l2: 0.31535\n",
            "Loss: 6.440785e-05, l1: 0.59877, l2: 0.31537\n",
            "Loss: 6.439845e-05, l1: 0.59850, l2: 0.31537\n",
            "Loss: 6.439145e-05, l1: 0.59801, l2: 0.31541\n",
            "Loss: 6.438297e-05, l1: 0.59755, l2: 0.31549\n",
            "Loss: 6.437683e-05, l1: 0.59705, l2: 0.31554\n",
            "Loss: 6.437254e-05, l1: 0.59702, l2: 0.31558\n",
            "Loss: 6.436857e-05, l1: 0.59689, l2: 0.31559\n",
            "Loss: 6.436466e-05, l1: 0.59702, l2: 0.31558\n",
            "Loss: 6.436099e-05, l1: 0.59697, l2: 0.31559\n",
            "Loss: 6.435782e-05, l1: 0.59699, l2: 0.31558\n",
            "Loss: 6.435472e-05, l1: 0.59695, l2: 0.31560\n",
            "Loss: 6.434943e-05, l1: 0.59672, l2: 0.31564\n",
            "Loss: 6.434298e-05, l1: 0.59665, l2: 0.31564\n",
            "Loss: 6.432443e-05, l1: 0.59627, l2: 0.31561\n",
            "Loss: 6.431107e-05, l1: 0.59587, l2: 0.31562\n",
            "Loss: 6.429615e-05, l1: 0.59555, l2: 0.31557\n",
            "Loss: 6.428635e-05, l1: 0.59551, l2: 0.31558\n",
            "Loss: 6.428216e-05, l1: 0.59579, l2: 0.31557\n",
            "Loss: 6.428038e-05, l1: 0.59579, l2: 0.31557\n",
            "Loss: 6.427870e-05, l1: 0.59583, l2: 0.31556\n",
            "Loss: 6.427180e-05, l1: 0.59604, l2: 0.31554\n",
            "Loss: 6.426581e-05, l1: 0.59626, l2: 0.31552\n",
            "Loss: 6.426629e-05, l1: 0.59639, l2: 0.31558\n",
            "Loss: 6.426002e-05, l1: 0.59632, l2: 0.31555\n",
            "Loss: 6.424893e-05, l1: 0.59653, l2: 0.31552\n",
            "Loss: 6.424201e-05, l1: 0.59669, l2: 0.31555\n",
            "Loss: 6.423741e-05, l1: 0.59694, l2: 0.31555\n",
            "Loss: 6.422880e-05, l1: 0.59736, l2: 0.31554\n",
            "Loss: 6.422002e-05, l1: 0.59779, l2: 0.31550\n",
            "Loss: 6.421600e-05, l1: 0.59778, l2: 0.31548\n",
            "Loss: 6.421053e-05, l1: 0.59755, l2: 0.31547\n",
            "Loss: 6.419967e-05, l1: 0.59699, l2: 0.31545\n",
            "Loss: 6.419074e-05, l1: 0.59612, l2: 0.31546\n",
            "Loss: 6.417742e-05, l1: 0.59546, l2: 0.31543\n",
            "Loss: 6.417123e-05, l1: 0.59510, l2: 0.31544\n",
            "Loss: 6.416628e-05, l1: 0.59500, l2: 0.31545\n",
            "Loss: 6.416184e-05, l1: 0.59492, l2: 0.31544\n",
            "Loss: 6.415250e-05, l1: 0.59460, l2: 0.31543\n",
            "Loss: 6.413469e-05, l1: 0.59449, l2: 0.31535\n",
            "Loss: 6.411810e-05, l1: 0.59418, l2: 0.31529\n",
            "Loss: 6.410912e-05, l1: 0.59428, l2: 0.31524\n",
            "Loss: 6.410102e-05, l1: 0.59387, l2: 0.31523\n",
            "Loss: 6.409316e-05, l1: 0.59378, l2: 0.31523\n",
            "Loss: 6.407663e-05, l1: 0.59416, l2: 0.31520\n",
            "Loss: 6.405925e-05, l1: 0.59430, l2: 0.31515\n",
            "Loss: 6.403653e-05, l1: 0.59453, l2: 0.31510\n",
            "Loss: 6.401761e-05, l1: 0.59461, l2: 0.31509\n",
            "Loss: 6.401062e-05, l1: 0.59533, l2: 0.31511\n",
            "Loss: 6.399558e-05, l1: 0.59529, l2: 0.31515\n",
            "Loss: 6.398729e-05, l1: 0.59499, l2: 0.31516\n",
            "Loss: 6.398070e-05, l1: 0.59519, l2: 0.31518\n",
            "Loss: 6.396987e-05, l1: 0.59503, l2: 0.31520\n",
            "Loss: 6.396342e-05, l1: 0.59535, l2: 0.31518\n",
            "Loss: 6.397282e-05, l1: 0.59581, l2: 0.31512\n",
            "Loss: 6.396080e-05, l1: 0.59550, l2: 0.31516\n",
            "Loss: 6.394902e-05, l1: 0.59585, l2: 0.31512\n",
            "Loss: 6.394238e-05, l1: 0.59577, l2: 0.31510\n",
            "Loss: 6.392979e-05, l1: 0.59501, l2: 0.31507\n",
            "Loss: 6.392003e-05, l1: 0.59458, l2: 0.31508\n",
            "Loss: 6.390508e-05, l1: 0.59391, l2: 0.31505\n",
            "Loss: 6.387462e-05, l1: 0.59260, l2: 0.31496\n",
            "Loss: 6.388018e-05, l1: 0.59138, l2: 0.31489\n",
            "Loss: 6.386056e-05, l1: 0.59205, l2: 0.31493\n",
            "Loss: 6.384596e-05, l1: 0.59216, l2: 0.31488\n",
            "Loss: 6.382248e-05, l1: 0.59272, l2: 0.31482\n",
            "Loss: 6.380325e-05, l1: 0.59291, l2: 0.31483\n",
            "Loss: 6.376419e-05, l1: 0.59279, l2: 0.31486\n",
            "Loss: 6.374733e-05, l1: 0.59185, l2: 0.31508\n",
            "Loss: 6.367666e-05, l1: 0.59180, l2: 0.31506\n",
            "Loss: 6.360031e-05, l1: 0.59105, l2: 0.31505\n",
            "Loss: 6.348045e-05, l1: 0.58975, l2: 0.31515\n",
            "Loss: 6.333766e-05, l1: 0.58834, l2: 0.31529\n",
            "Loss: 6.832172e-05, l1: 0.57662, l2: 0.31506\n",
            "Loss: 6.332389e-05, l1: 0.58772, l2: 0.31528\n",
            "Loss: 6.325957e-05, l1: 0.58781, l2: 0.31529\n",
            "Loss: 6.322526e-05, l1: 0.58824, l2: 0.31526\n",
            "Loss: 6.319633e-05, l1: 0.58887, l2: 0.31524\n",
            "Loss: 6.318276e-05, l1: 0.58854, l2: 0.31521\n",
            "Loss: 6.315040e-05, l1: 0.58775, l2: 0.31516\n",
            "Loss: 6.310888e-05, l1: 0.58679, l2: 0.31508\n",
            "Loss: 6.306878e-05, l1: 0.58516, l2: 0.31516\n",
            "Loss: 6.303839e-05, l1: 0.58556, l2: 0.31521\n",
            "Loss: 6.297891e-05, l1: 0.58578, l2: 0.31524\n",
            "Loss: 6.295241e-05, l1: 0.58610, l2: 0.31539\n",
            "Loss: 6.291330e-05, l1: 0.58519, l2: 0.31554\n",
            "Loss: 6.289562e-05, l1: 0.58492, l2: 0.31558\n",
            "Loss: 6.287622e-05, l1: 0.58499, l2: 0.31560\n",
            "Loss: 6.284090e-05, l1: 0.58530, l2: 0.31563\n",
            "Loss: 6.281631e-05, l1: 0.58550, l2: 0.31551\n",
            "Loss: 6.277920e-05, l1: 0.58602, l2: 0.31549\n",
            "Loss: 6.275239e-05, l1: 0.58686, l2: 0.31548\n",
            "Loss: 6.272750e-05, l1: 0.58703, l2: 0.31538\n",
            "Loss: 6.271034e-05, l1: 0.58737, l2: 0.31543\n",
            "Loss: 6.268972e-05, l1: 0.58773, l2: 0.31551\n",
            "Loss: 6.266767e-05, l1: 0.58824, l2: 0.31558\n",
            "Loss: 6.263675e-05, l1: 0.58935, l2: 0.31563\n",
            "Loss: 6.261630e-05, l1: 0.59029, l2: 0.31570\n",
            "Loss: 6.259633e-05, l1: 0.59170, l2: 0.31572\n",
            "Loss: 6.257890e-05, l1: 0.59270, l2: 0.31574\n",
            "Loss: 6.255742e-05, l1: 0.59320, l2: 0.31572\n",
            "Loss: 6.254042e-05, l1: 0.59320, l2: 0.31569\n",
            "Loss: 6.252422e-05, l1: 0.59353, l2: 0.31570\n",
            "Loss: 6.251231e-05, l1: 0.59395, l2: 0.31572\n",
            "Loss: 6.250045e-05, l1: 0.59482, l2: 0.31576\n",
            "Loss: 6.249072e-05, l1: 0.59507, l2: 0.31578\n",
            "Loss: 6.247511e-05, l1: 0.59523, l2: 0.31578\n",
            "Loss: 6.244042e-05, l1: 0.59553, l2: 0.31575\n",
            "Loss: 6.242870e-05, l1: 0.59546, l2: 0.31576\n",
            "Loss: 6.240695e-05, l1: 0.59543, l2: 0.31572\n",
            "Loss: 6.239306e-05, l1: 0.59614, l2: 0.31574\n",
            "Loss: 6.237459e-05, l1: 0.59561, l2: 0.31579\n",
            "Loss: 6.235392e-05, l1: 0.59551, l2: 0.31581\n",
            "Loss: 6.232400e-05, l1: 0.59510, l2: 0.31580\n",
            "Loss: 6.233730e-05, l1: 0.59763, l2: 0.31570\n",
            "Loss: 6.230458e-05, l1: 0.59620, l2: 0.31576\n",
            "Loss: 6.227013e-05, l1: 0.59602, l2: 0.31571\n",
            "Loss: 6.223177e-05, l1: 0.59654, l2: 0.31565\n",
            "Loss: 6.219316e-05, l1: 0.59718, l2: 0.31556\n",
            "Loss: 6.215210e-05, l1: 0.59885, l2: 0.31555\n",
            "Loss: 6.212061e-05, l1: 0.59971, l2: 0.31557\n",
            "Loss: 6.209908e-05, l1: 0.60065, l2: 0.31557\n",
            "Loss: 6.208573e-05, l1: 0.60042, l2: 0.31553\n",
            "Loss: 6.206851e-05, l1: 0.60023, l2: 0.31549\n",
            "Loss: 6.204481e-05, l1: 0.59948, l2: 0.31540\n",
            "Loss: 6.202942e-05, l1: 0.59919, l2: 0.31539\n",
            "Loss: 6.201499e-05, l1: 0.59886, l2: 0.31540\n",
            "Loss: 6.200518e-05, l1: 0.59844, l2: 0.31543\n",
            "Loss: 6.200244e-05, l1: 0.59850, l2: 0.31546\n",
            "Loss: 6.199344e-05, l1: 0.59768, l2: 0.31549\n",
            "Loss: 6.198720e-05, l1: 0.59806, l2: 0.31547\n",
            "Loss: 6.198230e-05, l1: 0.59789, l2: 0.31545\n",
            "Loss: 6.197476e-05, l1: 0.59758, l2: 0.31543\n",
            "Loss: 6.196756e-05, l1: 0.59725, l2: 0.31542\n",
            "Loss: 6.196472e-05, l1: 0.59697, l2: 0.31534\n",
            "Loss: 6.195623e-05, l1: 0.59673, l2: 0.31540\n",
            "Loss: 6.194961e-05, l1: 0.59667, l2: 0.31541\n",
            "Loss: 6.194375e-05, l1: 0.59608, l2: 0.31549\n",
            "Loss: 6.193730e-05, l1: 0.59591, l2: 0.31544\n",
            "Loss: 6.193145e-05, l1: 0.59560, l2: 0.31542\n",
            "Loss: 6.192497e-05, l1: 0.59499, l2: 0.31544\n",
            "Loss: 6.192086e-05, l1: 0.59457, l2: 0.31547\n",
            "Loss: 6.190922e-05, l1: 0.59365, l2: 0.31546\n",
            "Loss: 6.191576e-05, l1: 0.59367, l2: 0.31565\n",
            "Loss: 6.189676e-05, l1: 0.59366, l2: 0.31554\n",
            "Loss: 6.188446e-05, l1: 0.59327, l2: 0.31555\n",
            "Loss: 6.186612e-05, l1: 0.59306, l2: 0.31556\n",
            "Loss: 6.185312e-05, l1: 0.59276, l2: 0.31554\n",
            "Loss: 6.183844e-05, l1: 0.59245, l2: 0.31554\n",
            "Loss: 6.182920e-05, l1: 0.59229, l2: 0.31554\n",
            "Loss: 6.182105e-05, l1: 0.59181, l2: 0.31553\n",
            "Loss: 6.181288e-05, l1: 0.59166, l2: 0.31554\n",
            "Loss: 6.180230e-05, l1: 0.59125, l2: 0.31555\n",
            "Loss: 6.178777e-05, l1: 0.59113, l2: 0.31554\n",
            "Loss: 6.177203e-05, l1: 0.59051, l2: 0.31554\n",
            "Loss: 6.176149e-05, l1: 0.59077, l2: 0.31549\n",
            "Loss: 6.175378e-05, l1: 0.59081, l2: 0.31545\n",
            "Loss: 6.174922e-05, l1: 0.59078, l2: 0.31543\n",
            "Loss: 6.174554e-05, l1: 0.59075, l2: 0.31540\n",
            "Loss: 6.174124e-05, l1: 0.59056, l2: 0.31539\n",
            "Loss: 6.173938e-05, l1: 0.59079, l2: 0.31539\n",
            "Loss: 6.173830e-05, l1: 0.59108, l2: 0.31540\n",
            "Loss: 6.173457e-05, l1: 0.59140, l2: 0.31539\n",
            "Loss: 6.173221e-05, l1: 0.59180, l2: 0.31541\n",
            "Loss: 6.172878e-05, l1: 0.59198, l2: 0.31536\n",
            "Loss: 6.172396e-05, l1: 0.59209, l2: 0.31531\n",
            "Loss: 6.172156e-05, l1: 0.59214, l2: 0.31528\n",
            "Loss: 6.171831e-05, l1: 0.59228, l2: 0.31529\n",
            "Loss: 6.171280e-05, l1: 0.59257, l2: 0.31530\n",
            "Loss: 6.170587e-05, l1: 0.59298, l2: 0.31531\n",
            "Loss: 6.170671e-05, l1: 0.59357, l2: 0.31538\n",
            "Loss: 6.169948e-05, l1: 0.59327, l2: 0.31534\n",
            "Loss: 6.168678e-05, l1: 0.59346, l2: 0.31535\n",
            "Loss: 6.166556e-05, l1: 0.59382, l2: 0.31536\n",
            "Loss: 6.164696e-05, l1: 0.59434, l2: 0.31537\n",
            "Loss: 6.162903e-05, l1: 0.59463, l2: 0.31540\n",
            "Loss: 6.162115e-05, l1: 0.59582, l2: 0.31538\n",
            "Loss: 6.160514e-05, l1: 0.59526, l2: 0.31537\n",
            "Loss: 6.159805e-05, l1: 0.59499, l2: 0.31535\n",
            "Loss: 6.158673e-05, l1: 0.59534, l2: 0.31535\n",
            "Loss: 6.157240e-05, l1: 0.59572, l2: 0.31538\n",
            "Loss: 6.156012e-05, l1: 0.59605, l2: 0.31541\n",
            "Loss: 6.153940e-05, l1: 0.59621, l2: 0.31547\n",
            "Loss: 6.153654e-05, l1: 0.59536, l2: 0.31555\n",
            "Loss: 6.151164e-05, l1: 0.59634, l2: 0.31553\n",
            "Loss: 6.149721e-05, l1: 0.59607, l2: 0.31554\n",
            "Loss: 6.147646e-05, l1: 0.59580, l2: 0.31551\n",
            "Loss: 6.145806e-05, l1: 0.59518, l2: 0.31552\n",
            "Loss: 6.144572e-05, l1: 0.59482, l2: 0.31550\n",
            "Loss: 6.143438e-05, l1: 0.59468, l2: 0.31552\n",
            "Loss: 6.142378e-05, l1: 0.59464, l2: 0.31552\n",
            "Loss: 6.140303e-05, l1: 0.59471, l2: 0.31551\n",
            "Loss: 6.138292e-05, l1: 0.59473, l2: 0.31551\n",
            "Loss: 6.135710e-05, l1: 0.59555, l2: 0.31548\n",
            "Loss: 6.140284e-05, l1: 0.59541, l2: 0.31571\n",
            "Loss: 6.135172e-05, l1: 0.59552, l2: 0.31554\n",
            "Loss: 6.133425e-05, l1: 0.59587, l2: 0.31551\n",
            "Loss: 6.132975e-05, l1: 0.59596, l2: 0.31547\n",
            "Loss: 6.132648e-05, l1: 0.59562, l2: 0.31546\n",
            "Loss: 6.132347e-05, l1: 0.59558, l2: 0.31547\n",
            "Loss: 6.131973e-05, l1: 0.59548, l2: 0.31546\n",
            "Loss: 6.131590e-05, l1: 0.59545, l2: 0.31544\n",
            "Loss: 6.131092e-05, l1: 0.59529, l2: 0.31541\n",
            "Loss: 6.130552e-05, l1: 0.59540, l2: 0.31540\n",
            "Loss: 6.130055e-05, l1: 0.59527, l2: 0.31541\n",
            "Loss: 6.129659e-05, l1: 0.59563, l2: 0.31547\n",
            "Loss: 6.131047e-05, l1: 0.59527, l2: 0.31553\n",
            "Loss: 6.129223e-05, l1: 0.59552, l2: 0.31549\n",
            "Loss: 6.128656e-05, l1: 0.59528, l2: 0.31547\n",
            "Loss: 6.128028e-05, l1: 0.59585, l2: 0.31545\n",
            "Loss: 6.127688e-05, l1: 0.59546, l2: 0.31550\n",
            "Loss: 6.127025e-05, l1: 0.59585, l2: 0.31551\n",
            "Loss: 6.126442e-05, l1: 0.59618, l2: 0.31550\n",
            "Loss: 6.125675e-05, l1: 0.59660, l2: 0.31549\n",
            "Loss: 6.124916e-05, l1: 0.59694, l2: 0.31547\n",
            "Loss: 6.123792e-05, l1: 0.59699, l2: 0.31544\n",
            "Loss: 6.122275e-05, l1: 0.59684, l2: 0.31539\n",
            "Loss: 6.121601e-05, l1: 0.59784, l2: 0.31539\n",
            "Loss: 6.119056e-05, l1: 0.59698, l2: 0.31534\n",
            "Loss: 6.117809e-05, l1: 0.59665, l2: 0.31535\n",
            "Loss: 6.116440e-05, l1: 0.59648, l2: 0.31534\n",
            "Loss: 6.114892e-05, l1: 0.59645, l2: 0.31531\n",
            "Loss: 6.113242e-05, l1: 0.59627, l2: 0.31524\n",
            "Loss: 6.111929e-05, l1: 0.59605, l2: 0.31517\n",
            "Loss: 6.110781e-05, l1: 0.59746, l2: 0.31510\n",
            "Loss: 6.108495e-05, l1: 0.59661, l2: 0.31509\n",
            "Loss: 6.106320e-05, l1: 0.59616, l2: 0.31507\n",
            "Loss: 6.103198e-05, l1: 0.59590, l2: 0.31509\n",
            "Loss: 6.100422e-05, l1: 0.59620, l2: 0.31514\n",
            "Loss: 6.096843e-05, l1: 0.59729, l2: 0.31517\n",
            "Loss: 6.093768e-05, l1: 0.59759, l2: 0.31520\n",
            "Loss: 6.089523e-05, l1: 0.59869, l2: 0.31521\n",
            "Loss: 6.083864e-05, l1: 0.59867, l2: 0.31518\n",
            "Loss: 6.081232e-05, l1: 0.59918, l2: 0.31497\n",
            "Loss: 6.079460e-05, l1: 0.59894, l2: 0.31507\n",
            "Loss: 6.075573e-05, l1: 0.59867, l2: 0.31498\n",
            "Loss: 6.073040e-05, l1: 0.59987, l2: 0.31498\n",
            "Loss: 6.071480e-05, l1: 0.60038, l2: 0.31500\n",
            "Loss: 6.069922e-05, l1: 0.60085, l2: 0.31500\n",
            "Loss: 6.067449e-05, l1: 0.60171, l2: 0.31493\n",
            "Loss: 6.063866e-05, l1: 0.60271, l2: 0.31497\n",
            "Loss: 6.061875e-05, l1: 0.60390, l2: 0.31502\n",
            "Loss: 6.058452e-05, l1: 0.60380, l2: 0.31497\n",
            "Loss: 6.056487e-05, l1: 0.60335, l2: 0.31503\n",
            "Loss: 6.054294e-05, l1: 0.60318, l2: 0.31507\n",
            "Loss: 6.051427e-05, l1: 0.60310, l2: 0.31513\n",
            "Loss: 6.048822e-05, l1: 0.60384, l2: 0.31517\n",
            "Loss: 6.045953e-05, l1: 0.60426, l2: 0.31516\n",
            "Loss: 6.041678e-05, l1: 0.60548, l2: 0.31511\n",
            "Loss: 6.038307e-05, l1: 0.60524, l2: 0.31502\n",
            "Loss: 6.031867e-05, l1: 0.60447, l2: 0.31507\n",
            "Loss: 6.026612e-05, l1: 0.60398, l2: 0.31510\n",
            "Loss: 6.018657e-05, l1: 0.60290, l2: 0.31511\n",
            "Loss: 6.011791e-05, l1: 0.60254, l2: 0.31515\n",
            "Loss: 6.009563e-05, l1: 0.60187, l2: 0.31515\n",
            "Loss: 6.007752e-05, l1: 0.60219, l2: 0.31515\n",
            "Loss: 6.003274e-05, l1: 0.60287, l2: 0.31515\n",
            "Loss: 5.999177e-05, l1: 0.60255, l2: 0.31518\n",
            "Loss: 5.995316e-05, l1: 0.60328, l2: 0.31521\n",
            "Loss: 5.990304e-05, l1: 0.60483, l2: 0.31525\n",
            "Loss: 5.981629e-05, l1: 0.60632, l2: 0.31529\n",
            "Loss: 5.966114e-05, l1: 0.60945, l2: 0.31520\n",
            "Loss: 5.975396e-05, l1: 0.61073, l2: 0.31510\n",
            "Loss: 5.957835e-05, l1: 0.60998, l2: 0.31516\n",
            "Loss: 5.947661e-05, l1: 0.61271, l2: 0.31493\n",
            "Loss: 5.941401e-05, l1: 0.61361, l2: 0.31489\n",
            "Loss: 5.939158e-05, l1: 0.61371, l2: 0.31490\n",
            "Loss: 5.936638e-05, l1: 0.61484, l2: 0.31490\n",
            "Loss: 5.934560e-05, l1: 0.61446, l2: 0.31487\n",
            "Loss: 5.933141e-05, l1: 0.61462, l2: 0.31483\n",
            "Loss: 5.931839e-05, l1: 0.61462, l2: 0.31481\n",
            "Loss: 5.930955e-05, l1: 0.61465, l2: 0.31476\n",
            "Loss: 5.929502e-05, l1: 0.61412, l2: 0.31478\n",
            "Loss: 5.928598e-05, l1: 0.61359, l2: 0.31474\n",
            "Loss: 5.928134e-05, l1: 0.61320, l2: 0.31472\n",
            "Loss: 5.928418e-05, l1: 0.61321, l2: 0.31469\n",
            "Loss: 5.927951e-05, l1: 0.61320, l2: 0.31471\n",
            "Loss: 5.927748e-05, l1: 0.61289, l2: 0.31473\n",
            "Loss: 5.927313e-05, l1: 0.61306, l2: 0.31472\n",
            "Loss: 5.926828e-05, l1: 0.61325, l2: 0.31473\n",
            "Loss: 5.926396e-05, l1: 0.61341, l2: 0.31473\n",
            "Loss: 5.925768e-05, l1: 0.61350, l2: 0.31474\n",
            "Loss: 5.925221e-05, l1: 0.61366, l2: 0.31474\n",
            "Loss: 5.924399e-05, l1: 0.61371, l2: 0.31472\n",
            "Loss: 5.923621e-05, l1: 0.61373, l2: 0.31469\n",
            "Loss: 5.922868e-05, l1: 0.61361, l2: 0.31468\n",
            "Loss: 5.921340e-05, l1: 0.61366, l2: 0.31470\n",
            "Loss: 5.918998e-05, l1: 0.61346, l2: 0.31475\n",
            "Loss: 5.916457e-05, l1: 0.61324, l2: 0.31481\n",
            "Loss: 5.913786e-05, l1: 0.61277, l2: 0.31487\n",
            "Loss: 5.911702e-05, l1: 0.61241, l2: 0.31489\n",
            "Loss: 5.910277e-05, l1: 0.61202, l2: 0.31490\n",
            "Loss: 5.909035e-05, l1: 0.61193, l2: 0.31485\n",
            "Loss: 5.907817e-05, l1: 0.61198, l2: 0.31478\n",
            "Loss: 5.907070e-05, l1: 0.61203, l2: 0.31473\n",
            "Loss: 5.905306e-05, l1: 0.61219, l2: 0.31468\n",
            "Loss: 5.908052e-05, l1: 0.61306, l2: 0.31455\n",
            "Loss: 5.904623e-05, l1: 0.61245, l2: 0.31464\n",
            "Loss: 5.902866e-05, l1: 0.61218, l2: 0.31463\n",
            "Loss: 5.901678e-05, l1: 0.61230, l2: 0.31465\n",
            "Loss: 5.900686e-05, l1: 0.61233, l2: 0.31468\n",
            "Loss: 5.899758e-05, l1: 0.61248, l2: 0.31469\n",
            "Loss: 5.898310e-05, l1: 0.61233, l2: 0.31470\n",
            "Loss: 5.896799e-05, l1: 0.61232, l2: 0.31469\n",
            "Loss: 5.895115e-05, l1: 0.61200, l2: 0.31470\n",
            "Loss: 5.893445e-05, l1: 0.61142, l2: 0.31472\n",
            "Loss: 5.892543e-05, l1: 0.61145, l2: 0.31476\n",
            "Loss: 5.891118e-05, l1: 0.61098, l2: 0.31475\n",
            "Loss: 5.889629e-05, l1: 0.61130, l2: 0.31487\n",
            "Loss: 5.887841e-05, l1: 0.61192, l2: 0.31480\n",
            "Loss: 5.886515e-05, l1: 0.61217, l2: 0.31474\n",
            "Loss: 5.884872e-05, l1: 0.61220, l2: 0.31477\n",
            "Loss: 5.882957e-05, l1: 0.61276, l2: 0.31475\n",
            "Loss: 5.879983e-05, l1: 0.61416, l2: 0.31473\n",
            "Loss: 5.878497e-05, l1: 0.61500, l2: 0.31473\n",
            "Loss: 5.877607e-05, l1: 0.61596, l2: 0.31470\n",
            "Loss: 5.877153e-05, l1: 0.61575, l2: 0.31471\n",
            "Loss: 5.876424e-05, l1: 0.61560, l2: 0.31472\n",
            "Loss: 5.875034e-05, l1: 0.61515, l2: 0.31472\n",
            "Loss: 5.873963e-05, l1: 0.61475, l2: 0.31474\n",
            "Loss: 5.872600e-05, l1: 0.61442, l2: 0.31476\n",
            "Loss: 5.877501e-05, l1: 0.61543, l2: 0.31501\n",
            "Loss: 5.871915e-05, l1: 0.61467, l2: 0.31483\n",
            "Loss: 5.869811e-05, l1: 0.61513, l2: 0.31485\n",
            "Loss: 5.866637e-05, l1: 0.61602, l2: 0.31486\n",
            "Loss: 5.863411e-05, l1: 0.61797, l2: 0.31488\n",
            "Loss: 5.861216e-05, l1: 0.61866, l2: 0.31489\n",
            "Loss: 5.859357e-05, l1: 0.61971, l2: 0.31484\n",
            "Loss: 5.868489e-05, l1: 0.61989, l2: 0.31471\n",
            "Loss: 5.858310e-05, l1: 0.61975, l2: 0.31481\n",
            "Loss: 5.855423e-05, l1: 0.62058, l2: 0.31476\n",
            "Loss: 5.854746e-05, l1: 0.62170, l2: 0.31475\n",
            "Loss: 5.851914e-05, l1: 0.62118, l2: 0.31474\n",
            "Loss: 5.850643e-05, l1: 0.62070, l2: 0.31480\n",
            "Loss: 5.848212e-05, l1: 0.62100, l2: 0.31484\n",
            "Loss: 5.845123e-05, l1: 0.62121, l2: 0.31486\n",
            "Loss: 5.842799e-05, l1: 0.62149, l2: 0.31484\n",
            "Loss: 5.841218e-05, l1: 0.62188, l2: 0.31483\n",
            "Loss: 5.840233e-05, l1: 0.62155, l2: 0.31484\n",
            "Loss: 5.839373e-05, l1: 0.62167, l2: 0.31484\n",
            "Loss: 5.838198e-05, l1: 0.62138, l2: 0.31485\n",
            "Loss: 5.836906e-05, l1: 0.62134, l2: 0.31485\n",
            "Loss: 5.836016e-05, l1: 0.62119, l2: 0.31485\n",
            "Loss: 5.834956e-05, l1: 0.62099, l2: 0.31484\n",
            "Loss: 5.833906e-05, l1: 0.62081, l2: 0.31482\n",
            "Loss: 5.833049e-05, l1: 0.62070, l2: 0.31480\n",
            "Loss: 5.831185e-05, l1: 0.61997, l2: 0.31482\n",
            "Loss: 5.829240e-05, l1: 0.61929, l2: 0.31484\n",
            "Loss: 5.826739e-05, l1: 0.61820, l2: 0.31484\n",
            "Loss: 5.824865e-05, l1: 0.61795, l2: 0.31486\n",
            "Loss: 5.822075e-05, l1: 0.61814, l2: 0.31488\n",
            "Loss: 5.819747e-05, l1: 0.61827, l2: 0.31486\n",
            "Loss: 5.817521e-05, l1: 0.61838, l2: 0.31485\n",
            "Loss: 5.815074e-05, l1: 0.61908, l2: 0.31480\n",
            "Loss: 5.813149e-05, l1: 0.61947, l2: 0.31478\n",
            "Loss: 5.811534e-05, l1: 0.62059, l2: 0.31475\n",
            "Loss: 5.810134e-05, l1: 0.62124, l2: 0.31475\n",
            "Loss: 5.808325e-05, l1: 0.62166, l2: 0.31477\n",
            "Loss: 5.806317e-05, l1: 0.62236, l2: 0.31481\n",
            "Loss: 5.804076e-05, l1: 0.62279, l2: 0.31489\n",
            "Loss: 5.803731e-05, l1: 0.62268, l2: 0.31496\n",
            "Loss: 5.802406e-05, l1: 0.62282, l2: 0.31495\n",
            "Loss: 5.801910e-05, l1: 0.62307, l2: 0.31494\n",
            "Loss: 5.800978e-05, l1: 0.62330, l2: 0.31492\n",
            "Loss: 5.799665e-05, l1: 0.62415, l2: 0.31488\n",
            "Loss: 5.797281e-05, l1: 0.62473, l2: 0.31485\n",
            "Loss: 5.794136e-05, l1: 0.62588, l2: 0.31474\n",
            "Loss: 5.792393e-05, l1: 0.62643, l2: 0.31473\n",
            "Loss: 5.791555e-05, l1: 0.62587, l2: 0.31470\n",
            "Loss: 5.789950e-05, l1: 0.62653, l2: 0.31467\n",
            "Loss: 5.788569e-05, l1: 0.62684, l2: 0.31465\n",
            "Loss: 5.787163e-05, l1: 0.62698, l2: 0.31463\n",
            "Loss: 5.786102e-05, l1: 0.62747, l2: 0.31460\n",
            "Loss: 5.784874e-05, l1: 0.62766, l2: 0.31459\n",
            "Loss: 5.783961e-05, l1: 0.62889, l2: 0.31450\n",
            "Loss: 5.782350e-05, l1: 0.62863, l2: 0.31454\n",
            "Loss: 5.781332e-05, l1: 0.62864, l2: 0.31457\n",
            "Loss: 5.778685e-05, l1: 0.62855, l2: 0.31465\n",
            "Loss: 5.772923e-05, l1: 0.62983, l2: 0.31468\n",
            "Loss: 5.765809e-05, l1: 0.63006, l2: 0.31473\n",
            "Loss: 5.759001e-05, l1: 0.62976, l2: 0.31483\n",
            "Loss: 5.754624e-05, l1: 0.63044, l2: 0.31489\n",
            "Loss: 5.754635e-05, l1: 0.63129, l2: 0.31499\n",
            "Loss: 5.751831e-05, l1: 0.63088, l2: 0.31494\n",
            "Loss: 5.747842e-05, l1: 0.62959, l2: 0.31504\n",
            "Loss: 5.744518e-05, l1: 0.62964, l2: 0.31503\n",
            "Loss: 5.741843e-05, l1: 0.63044, l2: 0.31505\n",
            "Loss: 5.740566e-05, l1: 0.63182, l2: 0.31503\n",
            "Loss: 5.736768e-05, l1: 0.63178, l2: 0.31504\n",
            "Loss: 5.733580e-05, l1: 0.63192, l2: 0.31505\n",
            "Loss: 5.729311e-05, l1: 0.63225, l2: 0.31507\n",
            "Loss: 5.727413e-05, l1: 0.63254, l2: 0.31510\n",
            "Loss: 5.725399e-05, l1: 0.63245, l2: 0.31509\n",
            "Loss: 5.723897e-05, l1: 0.63192, l2: 0.31507\n",
            "Loss: 5.722907e-05, l1: 0.63157, l2: 0.31505\n",
            "Loss: 5.722125e-05, l1: 0.63152, l2: 0.31501\n",
            "Loss: 5.721099e-05, l1: 0.63148, l2: 0.31498\n",
            "Loss: 5.720136e-05, l1: 0.63132, l2: 0.31500\n",
            "Loss: 5.718818e-05, l1: 0.63128, l2: 0.31503\n",
            "Loss: 5.717632e-05, l1: 0.63128, l2: 0.31506\n",
            "Loss: 5.716355e-05, l1: 0.63136, l2: 0.31507\n",
            "Loss: 5.715054e-05, l1: 0.63138, l2: 0.31505\n",
            "Loss: 5.714075e-05, l1: 0.63135, l2: 0.31502\n",
            "Loss: 5.713400e-05, l1: 0.63115, l2: 0.31497\n",
            "Loss: 5.712760e-05, l1: 0.63117, l2: 0.31496\n",
            "Loss: 5.712187e-05, l1: 0.63111, l2: 0.31497\n",
            "Loss: 5.711473e-05, l1: 0.63066, l2: 0.31496\n",
            "Loss: 5.713679e-05, l1: 0.62964, l2: 0.31512\n",
            "Loss: 5.711154e-05, l1: 0.63040, l2: 0.31500\n",
            "Loss: 5.710717e-05, l1: 0.63010, l2: 0.31498\n",
            "Loss: 5.709458e-05, l1: 0.62979, l2: 0.31499\n",
            "Loss: 5.708729e-05, l1: 0.62991, l2: 0.31500\n",
            "Loss: 5.707651e-05, l1: 0.62997, l2: 0.31503\n",
            "Loss: 5.706620e-05, l1: 0.63056, l2: 0.31507\n",
            "Loss: 5.750289e-05, l1: 0.63503, l2: 0.31506\n",
            "Loss: 5.706231e-05, l1: 0.63097, l2: 0.31507\n",
            "Loss: 5.705123e-05, l1: 0.63099, l2: 0.31508\n",
            "Loss: 5.704334e-05, l1: 0.63142, l2: 0.31510\n",
            "Loss: 5.703821e-05, l1: 0.63179, l2: 0.31510\n",
            "Loss: 5.703046e-05, l1: 0.63229, l2: 0.31512\n",
            "Loss: 5.702191e-05, l1: 0.63274, l2: 0.31511\n",
            "Loss: 5.701468e-05, l1: 0.63331, l2: 0.31511\n",
            "Loss: 5.700649e-05, l1: 0.63341, l2: 0.31508\n",
            "Loss: 5.699657e-05, l1: 0.63366, l2: 0.31506\n",
            "Loss: 5.698527e-05, l1: 0.63410, l2: 0.31505\n",
            "Loss: 5.702721e-05, l1: 0.63547, l2: 0.31506\n",
            "Loss: 5.698018e-05, l1: 0.63445, l2: 0.31505\n",
            "Loss: 5.697162e-05, l1: 0.63445, l2: 0.31508\n",
            "Loss: 5.696672e-05, l1: 0.63472, l2: 0.31511\n",
            "Loss: 5.696067e-05, l1: 0.63463, l2: 0.31516\n",
            "Loss: 5.695285e-05, l1: 0.63450, l2: 0.31521\n",
            "Loss: 5.694095e-05, l1: 0.63413, l2: 0.31524\n",
            "Loss: 5.693046e-05, l1: 0.63380, l2: 0.31524\n",
            "Loss: 5.692985e-05, l1: 0.63408, l2: 0.31517\n",
            "Loss: 5.692603e-05, l1: 0.63394, l2: 0.31520\n",
            "Loss: 5.692204e-05, l1: 0.63427, l2: 0.31520\n",
            "Loss: 5.691879e-05, l1: 0.63461, l2: 0.31518\n",
            "Loss: 5.691513e-05, l1: 0.63515, l2: 0.31518\n",
            "Loss: 5.691167e-05, l1: 0.63565, l2: 0.31519\n",
            "Loss: 5.690844e-05, l1: 0.63592, l2: 0.31519\n",
            "Loss: 5.690670e-05, l1: 0.63572, l2: 0.31520\n",
            "Loss: 5.690477e-05, l1: 0.63521, l2: 0.31522\n",
            "Loss: 5.690313e-05, l1: 0.63496, l2: 0.31522\n",
            "Loss: 5.689844e-05, l1: 0.63435, l2: 0.31524\n",
            "Loss: 5.689307e-05, l1: 0.63394, l2: 0.31525\n",
            "Loss: 5.688773e-05, l1: 0.63395, l2: 0.31526\n",
            "Loss: 5.687592e-05, l1: 0.63388, l2: 0.31525\n",
            "Loss: 5.686729e-05, l1: 0.63442, l2: 0.31523\n",
            "Loss: 5.685589e-05, l1: 0.63481, l2: 0.31519\n",
            "Loss: 5.684930e-05, l1: 0.63475, l2: 0.31516\n",
            "Loss: 5.684856e-05, l1: 0.63441, l2: 0.31517\n",
            "Loss: 5.684729e-05, l1: 0.63457, l2: 0.31517\n",
            "Loss: 5.684385e-05, l1: 0.63456, l2: 0.31514\n",
            "Loss: 5.683988e-05, l1: 0.63441, l2: 0.31514\n",
            "Loss: 5.683655e-05, l1: 0.63435, l2: 0.31515\n",
            "Loss: 5.683316e-05, l1: 0.63440, l2: 0.31517\n",
            "Loss: 5.682812e-05, l1: 0.63451, l2: 0.31520\n",
            "Loss: 5.682283e-05, l1: 0.63479, l2: 0.31522\n",
            "Loss: 5.681584e-05, l1: 0.63506, l2: 0.31522\n",
            "Loss: 5.680665e-05, l1: 0.63516, l2: 0.31519\n",
            "Loss: 5.679703e-05, l1: 0.63540, l2: 0.31519\n",
            "Loss: 5.678547e-05, l1: 0.63531, l2: 0.31514\n",
            "Loss: 5.677359e-05, l1: 0.63540, l2: 0.31506\n",
            "Loss: 5.676817e-05, l1: 0.63556, l2: 0.31504\n",
            "Loss: 5.675263e-05, l1: 0.63633, l2: 0.31498\n",
            "Loss: 5.673880e-05, l1: 0.63704, l2: 0.31497\n",
            "Loss: 5.688667e-05, l1: 0.63954, l2: 0.31480\n",
            "Loss: 5.673236e-05, l1: 0.63747, l2: 0.31494\n",
            "Loss: 5.671879e-05, l1: 0.63764, l2: 0.31498\n",
            "Loss: 5.670010e-05, l1: 0.63794, l2: 0.31502\n",
            "Loss: 5.668113e-05, l1: 0.63767, l2: 0.31506\n",
            "Loss: 5.665185e-05, l1: 0.63740, l2: 0.31509\n",
            "Loss: 5.662192e-05, l1: 0.63696, l2: 0.31508\n",
            "Loss: 5.659680e-05, l1: 0.63689, l2: 0.31502\n",
            "Loss: 5.658516e-05, l1: 0.63645, l2: 0.31497\n",
            "Loss: 5.657431e-05, l1: 0.63666, l2: 0.31494\n",
            "Loss: 5.656327e-05, l1: 0.63694, l2: 0.31494\n",
            "Loss: 5.654519e-05, l1: 0.63688, l2: 0.31498\n",
            "Loss: 5.653321e-05, l1: 0.63663, l2: 0.31502\n",
            "Loss: 5.651983e-05, l1: 0.63604, l2: 0.31506\n",
            "Loss: 5.650725e-05, l1: 0.63519, l2: 0.31509\n",
            "Loss: 5.649612e-05, l1: 0.63459, l2: 0.31509\n",
            "Loss: 5.648042e-05, l1: 0.63322, l2: 0.31515\n",
            "Loss: 5.647065e-05, l1: 0.63264, l2: 0.31516\n",
            "Loss: 5.643637e-05, l1: 0.63320, l2: 0.31517\n",
            "Loss: 5.640244e-05, l1: 0.63389, l2: 0.31517\n",
            "Loss: 5.632422e-05, l1: 0.63507, l2: 0.31517\n",
            "Loss: 5.622654e-05, l1: 0.63687, l2: 0.31515\n",
            "Loss: 5.618842e-05, l1: 0.63526, l2: 0.31513\n",
            "Loss: 5.608153e-05, l1: 0.63495, l2: 0.31516\n",
            "Loss: 5.601298e-05, l1: 0.63629, l2: 0.31502\n",
            "Loss: 5.589356e-05, l1: 0.63704, l2: 0.31477\n",
            "Loss: 5.578051e-05, l1: 0.63669, l2: 0.31470\n",
            "Loss: 5.588937e-05, l1: 0.63561, l2: 0.31472\n",
            "Loss: 5.570677e-05, l1: 0.63627, l2: 0.31471\n",
            "Loss: 5.561527e-05, l1: 0.63491, l2: 0.31486\n",
            "Loss: 5.554671e-05, l1: 0.63482, l2: 0.31497\n",
            "Loss: 5.548431e-05, l1: 0.63509, l2: 0.31501\n",
            "Loss: 5.543576e-05, l1: 0.63582, l2: 0.31502\n",
            "Loss: 5.529892e-05, l1: 0.63473, l2: 0.31508\n",
            "Loss: 5.520489e-05, l1: 0.63194, l2: 0.31508\n",
            "Loss: 5.535891e-05, l1: 0.63207, l2: 0.31510\n",
            "Loss: 5.509843e-05, l1: 0.63199, l2: 0.31509\n",
            "Loss: 5.523520e-05, l1: 0.63311, l2: 0.31509\n",
            "Loss: 5.503166e-05, l1: 0.63240, l2: 0.31509\n",
            "Loss: 5.490260e-05, l1: 0.63286, l2: 0.31504\n",
            "Loss: 5.487703e-05, l1: 0.63218, l2: 0.31499\n",
            "Loss: 5.483012e-05, l1: 0.63251, l2: 0.31501\n",
            "Loss: 5.479038e-05, l1: 0.63191, l2: 0.31496\n",
            "Loss: 5.474652e-05, l1: 0.63128, l2: 0.31495\n",
            "Loss: 5.470935e-05, l1: 0.63126, l2: 0.31497\n",
            "Loss: 5.465982e-05, l1: 0.63118, l2: 0.31502\n",
            "Loss: 5.459502e-05, l1: 0.63066, l2: 0.31506\n",
            "Loss: 5.457723e-05, l1: 0.62952, l2: 0.31507\n",
            "Loss: 5.455367e-05, l1: 0.62969, l2: 0.31506\n",
            "Loss: 5.454043e-05, l1: 0.62965, l2: 0.31509\n",
            "Loss: 5.452331e-05, l1: 0.62967, l2: 0.31513\n",
            "Loss: 5.450731e-05, l1: 0.62969, l2: 0.31513\n",
            "Loss: 5.449352e-05, l1: 0.62962, l2: 0.31511\n",
            "Loss: 5.447489e-05, l1: 0.63007, l2: 0.31510\n",
            "Loss: 5.445715e-05, l1: 0.63048, l2: 0.31507\n",
            "Loss: 5.444486e-05, l1: 0.63093, l2: 0.31509\n",
            "Loss: 5.443340e-05, l1: 0.63072, l2: 0.31508\n",
            "Loss: 5.441977e-05, l1: 0.63024, l2: 0.31507\n",
            "Loss: 5.440357e-05, l1: 0.62985, l2: 0.31506\n",
            "Loss: 5.438402e-05, l1: 0.62922, l2: 0.31503\n",
            "Loss: 5.436954e-05, l1: 0.62913, l2: 0.31494\n",
            "Loss: 5.436923e-05, l1: 0.62828, l2: 0.31496\n",
            "Loss: 5.436346e-05, l1: 0.62870, l2: 0.31495\n",
            "Loss: 5.435878e-05, l1: 0.62878, l2: 0.31494\n",
            "Loss: 5.435263e-05, l1: 0.62911, l2: 0.31492\n",
            "Loss: 5.434606e-05, l1: 0.62973, l2: 0.31486\n",
            "Loss: 5.433996e-05, l1: 0.62948, l2: 0.31485\n",
            "Loss: 5.433083e-05, l1: 0.62912, l2: 0.31483\n",
            "Loss: 5.432112e-05, l1: 0.62905, l2: 0.31482\n",
            "Loss: 5.430259e-05, l1: 0.62891, l2: 0.31484\n",
            "Loss: 5.429061e-05, l1: 0.62896, l2: 0.31486\n",
            "Loss: 5.427316e-05, l1: 0.62883, l2: 0.31488\n",
            "Loss: 5.425324e-05, l1: 0.62868, l2: 0.31491\n",
            "Loss: 5.423995e-05, l1: 0.62833, l2: 0.31489\n",
            "Loss: 5.423020e-05, l1: 0.62820, l2: 0.31487\n",
            "Loss: 5.422754e-05, l1: 0.62797, l2: 0.31486\n",
            "Loss: 5.422335e-05, l1: 0.62773, l2: 0.31485\n",
            "Loss: 5.421747e-05, l1: 0.62763, l2: 0.31486\n",
            "Loss: 5.421304e-05, l1: 0.62758, l2: 0.31488\n",
            "Loss: 5.421010e-05, l1: 0.62750, l2: 0.31491\n",
            "Loss: 5.420577e-05, l1: 0.62737, l2: 0.31493\n",
            "Loss: 5.419974e-05, l1: 0.62708, l2: 0.31495\n",
            "Loss: 5.419153e-05, l1: 0.62674, l2: 0.31497\n",
            "Loss: 5.420316e-05, l1: 0.62696, l2: 0.31493\n",
            "Loss: 5.418704e-05, l1: 0.62682, l2: 0.31496\n",
            "Loss: 5.417808e-05, l1: 0.62642, l2: 0.31496\n",
            "Loss: 5.417411e-05, l1: 0.62646, l2: 0.31492\n",
            "Loss: 5.416735e-05, l1: 0.62646, l2: 0.31492\n",
            "Loss: 5.416442e-05, l1: 0.62672, l2: 0.31493\n",
            "Loss: 5.416072e-05, l1: 0.62682, l2: 0.31493\n",
            "Loss: 5.415278e-05, l1: 0.62720, l2: 0.31494\n",
            "Loss: 5.414733e-05, l1: 0.62770, l2: 0.31494\n",
            "Loss: 5.413240e-05, l1: 0.62825, l2: 0.31495\n",
            "Loss: 5.412430e-05, l1: 0.62870, l2: 0.31491\n",
            "Loss: 5.411610e-05, l1: 0.62929, l2: 0.31489\n",
            "Loss: 5.411140e-05, l1: 0.62980, l2: 0.31485\n",
            "Loss: 5.410661e-05, l1: 0.62977, l2: 0.31486\n",
            "Loss: 5.410241e-05, l1: 0.62995, l2: 0.31488\n",
            "Loss: 5.409516e-05, l1: 0.63034, l2: 0.31491\n",
            "Loss: 5.408720e-05, l1: 0.63057, l2: 0.31495\n",
            "Loss: 5.407285e-05, l1: 0.63124, l2: 0.31497\n",
            "Loss: 5.405680e-05, l1: 0.63216, l2: 0.31500\n",
            "Loss: 5.404400e-05, l1: 0.63299, l2: 0.31501\n",
            "Loss: 5.403537e-05, l1: 0.63320, l2: 0.31500\n",
            "Loss: 5.402640e-05, l1: 0.63335, l2: 0.31500\n",
            "Loss: 5.401681e-05, l1: 0.63388, l2: 0.31499\n",
            "Loss: 5.402544e-05, l1: 0.63488, l2: 0.31502\n",
            "Loss: 5.401220e-05, l1: 0.63426, l2: 0.31500\n",
            "Loss: 5.400259e-05, l1: 0.63463, l2: 0.31500\n",
            "Loss: 5.399023e-05, l1: 0.63531, l2: 0.31500\n",
            "Loss: 5.397469e-05, l1: 0.63619, l2: 0.31499\n",
            "Loss: 5.397070e-05, l1: 0.63809, l2: 0.31499\n",
            "Loss: 5.395871e-05, l1: 0.63715, l2: 0.31499\n",
            "Loss: 5.393979e-05, l1: 0.63770, l2: 0.31499\n",
            "Loss: 5.391916e-05, l1: 0.63866, l2: 0.31499\n",
            "Loss: 5.391900e-05, l1: 0.63837, l2: 0.31499\n",
            "Loss: 5.391358e-05, l1: 0.63852, l2: 0.31499\n",
            "Loss: 5.391027e-05, l1: 0.63894, l2: 0.31500\n",
            "Loss: 5.390335e-05, l1: 0.63853, l2: 0.31500\n",
            "Loss: 5.389797e-05, l1: 0.63853, l2: 0.31499\n",
            "Loss: 5.389010e-05, l1: 0.63849, l2: 0.31499\n",
            "Loss: 5.387823e-05, l1: 0.63885, l2: 0.31497\n",
            "Loss: 5.386605e-05, l1: 0.63918, l2: 0.31497\n",
            "Loss: 5.385802e-05, l1: 0.63950, l2: 0.31497\n",
            "Loss: 5.384948e-05, l1: 0.63961, l2: 0.31503\n",
            "Loss: 5.383650e-05, l1: 0.63950, l2: 0.31501\n",
            "Loss: 5.383337e-05, l1: 0.63921, l2: 0.31501\n",
            "Loss: 5.382895e-05, l1: 0.63909, l2: 0.31503\n",
            "Loss: 5.382109e-05, l1: 0.63883, l2: 0.31506\n",
            "Loss: 5.381879e-05, l1: 0.63945, l2: 0.31509\n",
            "Loss: 5.380345e-05, l1: 0.63896, l2: 0.31512\n",
            "Loss: 5.379311e-05, l1: 0.63855, l2: 0.31512\n",
            "Loss: 5.377787e-05, l1: 0.63900, l2: 0.31513\n",
            "Loss: 5.377538e-05, l1: 0.63827, l2: 0.31521\n",
            "Loss: 5.375929e-05, l1: 0.63908, l2: 0.31517\n",
            "Loss: 5.374098e-05, l1: 0.63957, l2: 0.31515\n",
            "Loss: 5.370486e-05, l1: 0.64004, l2: 0.31512\n",
            "Loss: 5.365255e-05, l1: 0.64041, l2: 0.31510\n",
            "Loss: 5.359613e-05, l1: 0.64005, l2: 0.31502\n",
            "Loss: 5.353932e-05, l1: 0.64071, l2: 0.31501\n",
            "Loss: 5.356155e-05, l1: 0.63994, l2: 0.31505\n",
            "Loss: 5.351975e-05, l1: 0.64039, l2: 0.31503\n",
            "Loss: 5.350247e-05, l1: 0.64114, l2: 0.31501\n",
            "Loss: 5.348861e-05, l1: 0.64093, l2: 0.31503\n",
            "Loss: 5.347848e-05, l1: 0.64108, l2: 0.31502\n",
            "Loss: 5.346664e-05, l1: 0.64146, l2: 0.31496\n",
            "Loss: 5.345410e-05, l1: 0.64177, l2: 0.31486\n",
            "Loss: 5.344451e-05, l1: 0.64240, l2: 0.31480\n",
            "Loss: 5.343497e-05, l1: 0.64232, l2: 0.31480\n",
            "Loss: 5.341653e-05, l1: 0.64230, l2: 0.31479\n",
            "Loss: 5.340717e-05, l1: 0.64266, l2: 0.31479\n",
            "Loss: 5.383416e-05, l1: 0.64339, l2: 0.31469\n",
            "Loss: 5.339658e-05, l1: 0.64276, l2: 0.31477\n",
            "Loss: 5.338491e-05, l1: 0.64286, l2: 0.31478\n",
            "Loss: 5.335443e-05, l1: 0.64358, l2: 0.31478\n",
            "Loss: 5.331310e-05, l1: 0.64426, l2: 0.31480\n",
            "Loss: 5.321456e-05, l1: 0.64577, l2: 0.31478\n",
            "Loss: 5.310171e-05, l1: 0.64731, l2: 0.31497\n",
            "Loss: 5.302901e-05, l1: 0.64833, l2: 0.31504\n",
            "Loss: 5.289333e-05, l1: 0.64840, l2: 0.31510\n",
            "Loss: 5.285719e-05, l1: 0.64816, l2: 0.31508\n",
            "Loss: 5.287844e-05, l1: 0.65019, l2: 0.31505\n",
            "Loss: 5.282539e-05, l1: 0.64907, l2: 0.31506\n",
            "Loss: 5.279623e-05, l1: 0.64920, l2: 0.31511\n",
            "Loss: 5.275755e-05, l1: 0.64921, l2: 0.31518\n",
            "Loss: 5.268848e-05, l1: 0.65126, l2: 0.31535\n",
            "Loss: 5.276348e-05, l1: 0.65031, l2: 0.31535\n",
            "Loss: 5.264620e-05, l1: 0.65090, l2: 0.31535\n",
            "Loss: 5.259198e-05, l1: 0.65161, l2: 0.31532\n",
            "Loss: 5.256611e-05, l1: 0.65252, l2: 0.31530\n",
            "Loss: 5.256265e-05, l1: 0.65390, l2: 0.31536\n",
            "Loss: 5.254712e-05, l1: 0.65317, l2: 0.31533\n",
            "Loss: 5.254343e-05, l1: 0.65353, l2: 0.31540\n",
            "Loss: 5.252798e-05, l1: 0.65300, l2: 0.31540\n",
            "Loss: 5.252211e-05, l1: 0.65289, l2: 0.31541\n",
            "Loss: 5.251063e-05, l1: 0.65319, l2: 0.31542\n",
            "Loss: 5.249225e-05, l1: 0.65332, l2: 0.31549\n",
            "Loss: 5.247559e-05, l1: 0.65360, l2: 0.31553\n",
            "Loss: 5.245253e-05, l1: 0.65385, l2: 0.31561\n",
            "Loss: 5.242727e-05, l1: 0.65419, l2: 0.31570\n",
            "Loss: 5.242399e-05, l1: 0.65482, l2: 0.31582\n",
            "Loss: 5.238278e-05, l1: 0.65535, l2: 0.31575\n",
            "Loss: 5.237124e-05, l1: 0.65509, l2: 0.31571\n",
            "Loss: 5.235273e-05, l1: 0.65561, l2: 0.31570\n",
            "Loss: 5.231596e-05, l1: 0.65683, l2: 0.31569\n",
            "Loss: 5.228796e-05, l1: 0.65706, l2: 0.31565\n",
            "Loss: 5.228779e-05, l1: 0.65811, l2: 0.31572\n",
            "Loss: 5.226751e-05, l1: 0.65751, l2: 0.31568\n",
            "Loss: 5.224217e-05, l1: 0.65733, l2: 0.31568\n",
            "Loss: 5.222449e-05, l1: 0.65718, l2: 0.31569\n",
            "Loss: 5.220744e-05, l1: 0.65694, l2: 0.31571\n",
            "Loss: 5.218595e-05, l1: 0.65669, l2: 0.31577\n",
            "Loss: 5.216974e-05, l1: 0.65627, l2: 0.31582\n",
            "Loss: 5.215562e-05, l1: 0.65607, l2: 0.31586\n",
            "Loss: 5.214323e-05, l1: 0.65604, l2: 0.31582\n",
            "Loss: 5.212799e-05, l1: 0.65615, l2: 0.31582\n",
            "Loss: 5.211045e-05, l1: 0.65614, l2: 0.31577\n",
            "Loss: 5.210270e-05, l1: 0.65581, l2: 0.31572\n",
            "Loss: 5.209590e-05, l1: 0.65773, l2: 0.31555\n",
            "Loss: 5.206283e-05, l1: 0.65681, l2: 0.31563\n",
            "Loss: 5.205024e-05, l1: 0.65680, l2: 0.31568\n",
            "Loss: 5.203217e-05, l1: 0.65747, l2: 0.31568\n",
            "Loss: 5.201439e-05, l1: 0.65964, l2: 0.31573\n",
            "Loss: 5.198975e-05, l1: 0.65999, l2: 0.31568\n",
            "Loss: 5.198136e-05, l1: 0.66007, l2: 0.31567\n",
            "Loss: 5.197324e-05, l1: 0.66063, l2: 0.31571\n",
            "Loss: 5.196579e-05, l1: 0.66105, l2: 0.31577\n",
            "Loss: 5.195503e-05, l1: 0.66142, l2: 0.31582\n",
            "Loss: 5.192764e-05, l1: 0.66189, l2: 0.31595\n",
            "Loss: 5.190554e-05, l1: 0.66234, l2: 0.31602\n",
            "Loss: 5.188760e-05, l1: 0.66250, l2: 0.31604\n",
            "Loss: 5.187950e-05, l1: 0.66246, l2: 0.31602\n",
            "Loss: 5.187134e-05, l1: 0.66252, l2: 0.31597\n",
            "Loss: 5.186193e-05, l1: 0.66230, l2: 0.31593\n",
            "Loss: 5.185265e-05, l1: 0.66226, l2: 0.31591\n",
            "Loss: 5.184308e-05, l1: 0.66195, l2: 0.31592\n",
            "Loss: 5.183245e-05, l1: 0.66176, l2: 0.31599\n",
            "Loss: 5.182027e-05, l1: 0.66214, l2: 0.31605\n",
            "Loss: 5.180411e-05, l1: 0.66141, l2: 0.31606\n",
            "Loss: 5.179013e-05, l1: 0.66069, l2: 0.31606\n",
            "Loss: 5.177832e-05, l1: 0.66029, l2: 0.31609\n",
            "Loss: 5.176887e-05, l1: 0.66002, l2: 0.31607\n",
            "Loss: 5.175487e-05, l1: 0.66051, l2: 0.31610\n",
            "Loss: 5.174046e-05, l1: 0.66090, l2: 0.31611\n",
            "Loss: 5.172736e-05, l1: 0.66088, l2: 0.31616\n",
            "Loss: 5.171743e-05, l1: 0.66078, l2: 0.31611\n",
            "Loss: 5.171088e-05, l1: 0.66023, l2: 0.31609\n",
            "Loss: 5.170394e-05, l1: 0.66005, l2: 0.31605\n",
            "Loss: 5.169903e-05, l1: 0.65962, l2: 0.31603\n",
            "Loss: 5.169393e-05, l1: 0.65966, l2: 0.31603\n",
            "Loss: 5.168914e-05, l1: 0.65974, l2: 0.31605\n",
            "Loss: 5.168281e-05, l1: 0.65972, l2: 0.31606\n",
            "Loss: 5.167349e-05, l1: 0.65966, l2: 0.31610\n",
            "Loss: 5.166587e-05, l1: 0.65958, l2: 0.31611\n",
            "Loss: 5.165560e-05, l1: 0.65943, l2: 0.31611\n",
            "Loss: 5.164225e-05, l1: 0.65923, l2: 0.31608\n",
            "Loss: 5.162565e-05, l1: 0.65876, l2: 0.31604\n",
            "Loss: 5.161238e-05, l1: 0.65806, l2: 0.31597\n",
            "Loss: 5.159769e-05, l1: 0.65787, l2: 0.31597\n",
            "Loss: 5.158006e-05, l1: 0.65712, l2: 0.31597\n",
            "Loss: 5.157406e-05, l1: 0.65661, l2: 0.31598\n",
            "Loss: 5.155989e-05, l1: 0.65616, l2: 0.31599\n",
            "Loss: 5.155180e-05, l1: 0.65590, l2: 0.31600\n",
            "Loss: 5.153918e-05, l1: 0.65614, l2: 0.31604\n",
            "Loss: 5.152267e-05, l1: 0.65596, l2: 0.31606\n",
            "Loss: 5.150117e-05, l1: 0.65648, l2: 0.31608\n",
            "Loss: 5.147544e-05, l1: 0.65645, l2: 0.31605\n",
            "Loss: 5.145013e-05, l1: 0.65628, l2: 0.31600\n",
            "Loss: 5.143206e-05, l1: 0.65638, l2: 0.31595\n",
            "Loss: 5.140312e-05, l1: 0.65657, l2: 0.31588\n",
            "Loss: 5.137952e-05, l1: 0.65599, l2: 0.31579\n",
            "Loss: 5.136298e-05, l1: 0.65681, l2: 0.31579\n",
            "Loss: 5.134899e-05, l1: 0.65720, l2: 0.31581\n",
            "Loss: 5.133625e-05, l1: 0.65732, l2: 0.31580\n",
            "Loss: 5.131430e-05, l1: 0.65813, l2: 0.31577\n",
            "Loss: 5.129559e-05, l1: 0.65892, l2: 0.31576\n",
            "Loss: 5.128252e-05, l1: 0.65974, l2: 0.31578\n",
            "Loss: 5.127268e-05, l1: 0.66045, l2: 0.31576\n",
            "Loss: 5.125580e-05, l1: 0.66039, l2: 0.31574\n",
            "Loss: 5.124426e-05, l1: 0.66000, l2: 0.31574\n",
            "Loss: 5.123328e-05, l1: 0.66009, l2: 0.31571\n",
            "Loss: 5.122138e-05, l1: 0.66016, l2: 0.31569\n",
            "Loss: 5.121289e-05, l1: 0.66046, l2: 0.31564\n",
            "Loss: 5.165229e-05, l1: 0.66103, l2: 0.31589\n",
            "Loss: 5.121013e-05, l1: 0.66050, l2: 0.31566\n",
            "Loss: 5.121856e-05, l1: 0.65981, l2: 0.31564\n",
            "Loss: 5.120463e-05, l1: 0.66023, l2: 0.31565\n",
            "Loss: 5.119594e-05, l1: 0.66021, l2: 0.31567\n",
            "Loss: 5.118395e-05, l1: 0.66046, l2: 0.31573\n",
            "Loss: 5.118181e-05, l1: 0.66063, l2: 0.31574\n",
            "Loss: 5.117751e-05, l1: 0.66102, l2: 0.31575\n",
            "Loss: 5.117510e-05, l1: 0.66133, l2: 0.31576\n",
            "Loss: 5.116798e-05, l1: 0.66185, l2: 0.31576\n",
            "Loss: 5.115563e-05, l1: 0.66254, l2: 0.31576\n",
            "Loss: 5.120456e-05, l1: 0.66551, l2: 0.31572\n",
            "Loss: 5.114956e-05, l1: 0.66327, l2: 0.31575\n",
            "Loss: 5.113355e-05, l1: 0.66370, l2: 0.31575\n",
            "Loss: 5.111182e-05, l1: 0.66453, l2: 0.31577\n",
            "Loss: 5.109310e-05, l1: 0.66509, l2: 0.31576\n",
            "Loss: 5.107772e-05, l1: 0.66632, l2: 0.31580\n",
            "Loss: 5.106438e-05, l1: 0.66715, l2: 0.31580\n",
            "Loss: 5.105411e-05, l1: 0.66760, l2: 0.31575\n",
            "Loss: 5.104833e-05, l1: 0.66841, l2: 0.31577\n",
            "Loss: 5.104370e-05, l1: 0.66831, l2: 0.31576\n",
            "Loss: 5.104215e-05, l1: 0.66862, l2: 0.31577\n",
            "Loss: 5.103752e-05, l1: 0.66935, l2: 0.31580\n",
            "Loss: 5.103579e-05, l1: 0.67019, l2: 0.31583\n",
            "Loss: 5.102991e-05, l1: 0.66986, l2: 0.31584\n",
            "Loss: 5.102518e-05, l1: 0.66981, l2: 0.31584\n",
            "Loss: 5.101456e-05, l1: 0.66979, l2: 0.31583\n",
            "Loss: 5.101574e-05, l1: 0.66972, l2: 0.31579\n",
            "Loss: 5.101030e-05, l1: 0.66976, l2: 0.31581\n",
            "Loss: 5.100354e-05, l1: 0.66994, l2: 0.31580\n",
            "Loss: 5.099527e-05, l1: 0.67037, l2: 0.31577\n",
            "Loss: 5.098924e-05, l1: 0.67039, l2: 0.31574\n",
            "Loss: 5.097633e-05, l1: 0.67050, l2: 0.31567\n",
            "Loss: 5.102000e-05, l1: 0.67091, l2: 0.31557\n",
            "Loss: 5.097018e-05, l1: 0.67061, l2: 0.31565\n",
            "Loss: 5.095213e-05, l1: 0.66991, l2: 0.31560\n",
            "Loss: 5.093906e-05, l1: 0.66991, l2: 0.31559\n",
            "Loss: 5.091913e-05, l1: 0.66952, l2: 0.31560\n",
            "Loss: 5.090411e-05, l1: 0.66931, l2: 0.31561\n",
            "Loss: 5.088845e-05, l1: 0.66878, l2: 0.31564\n",
            "Loss: 5.087550e-05, l1: 0.66918, l2: 0.31566\n",
            "Loss: 5.086418e-05, l1: 0.66926, l2: 0.31569\n",
            "Loss: 5.085154e-05, l1: 0.66934, l2: 0.31569\n",
            "Loss: 5.082625e-05, l1: 0.66909, l2: 0.31566\n",
            "Loss: 5.080068e-05, l1: 0.66814, l2: 0.31560\n",
            "Loss: 5.078289e-05, l1: 0.66846, l2: 0.31568\n",
            "Loss: 5.075317e-05, l1: 0.66854, l2: 0.31570\n",
            "Loss: 5.072304e-05, l1: 0.66882, l2: 0.31574\n",
            "Loss: 5.068940e-05, l1: 0.67017, l2: 0.31584\n",
            "Loss: 5.066004e-05, l1: 0.67090, l2: 0.31591\n",
            "Loss: 5.064474e-05, l1: 0.67176, l2: 0.31596\n",
            "Loss: 5.063638e-05, l1: 0.67151, l2: 0.31596\n",
            "Loss: 5.062811e-05, l1: 0.67183, l2: 0.31598\n",
            "Loss: 5.061748e-05, l1: 0.67220, l2: 0.31598\n",
            "Loss: 5.060228e-05, l1: 0.67240, l2: 0.31595\n",
            "Loss: 5.058047e-05, l1: 0.67260, l2: 0.31587\n",
            "Loss: 5.058971e-05, l1: 0.67293, l2: 0.31582\n",
            "Loss: 5.056947e-05, l1: 0.67274, l2: 0.31585\n",
            "Loss: 5.055085e-05, l1: 0.67253, l2: 0.31578\n",
            "Loss: 5.053660e-05, l1: 0.67241, l2: 0.31575\n",
            "Loss: 5.052696e-05, l1: 0.67261, l2: 0.31577\n",
            "Loss: 5.051831e-05, l1: 0.67211, l2: 0.31579\n",
            "Loss: 5.050595e-05, l1: 0.67232, l2: 0.31581\n",
            "Loss: 5.048254e-05, l1: 0.67262, l2: 0.31585\n",
            "Loss: 5.046207e-05, l1: 0.67338, l2: 0.31580\n",
            "Loss: 5.043466e-05, l1: 0.67371, l2: 0.31579\n",
            "Loss: 5.041920e-05, l1: 0.67353, l2: 0.31571\n",
            "Loss: 5.041042e-05, l1: 0.67351, l2: 0.31569\n",
            "Loss: 5.040074e-05, l1: 0.67335, l2: 0.31571\n",
            "Loss: 5.038086e-05, l1: 0.67326, l2: 0.31573\n",
            "Loss: 5.035009e-05, l1: 0.67381, l2: 0.31572\n",
            "Loss: 5.031361e-05, l1: 0.67403, l2: 0.31573\n",
            "Loss: 5.029602e-05, l1: 0.67456, l2: 0.31555\n",
            "Loss: 5.024666e-05, l1: 0.67479, l2: 0.31556\n",
            "Loss: 5.019486e-05, l1: 0.67525, l2: 0.31549\n",
            "Loss: 5.011392e-05, l1: 0.67598, l2: 0.31534\n",
            "Loss: 5.062055e-05, l1: 0.67912, l2: 0.31505\n",
            "Loss: 5.009034e-05, l1: 0.67659, l2: 0.31528\n",
            "Loss: 4.999136e-05, l1: 0.67751, l2: 0.31508\n",
            "Loss: 4.994193e-05, l1: 0.67745, l2: 0.31502\n",
            "Loss: 4.992251e-05, l1: 0.67673, l2: 0.31511\n",
            "Loss: 4.987553e-05, l1: 0.67710, l2: 0.31509\n",
            "Loss: 4.985528e-05, l1: 0.67686, l2: 0.31509\n",
            "Loss: 4.981829e-05, l1: 0.67680, l2: 0.31511\n",
            "Loss: 4.977522e-05, l1: 0.67655, l2: 0.31515\n",
            "Loss: 4.989946e-05, l1: 0.67484, l2: 0.31527\n",
            "Loss: 4.975681e-05, l1: 0.67610, l2: 0.31518\n",
            "Loss: 4.973003e-05, l1: 0.67603, l2: 0.31513\n",
            "Loss: 4.969937e-05, l1: 0.67594, l2: 0.31507\n",
            "Loss: 4.967652e-05, l1: 0.67693, l2: 0.31509\n",
            "Loss: 4.964145e-05, l1: 0.67719, l2: 0.31505\n",
            "Loss: 4.963091e-05, l1: 0.67739, l2: 0.31501\n",
            "Loss: 4.961376e-05, l1: 0.67750, l2: 0.31505\n",
            "Loss: 4.959467e-05, l1: 0.67807, l2: 0.31507\n",
            "Loss: 4.958683e-05, l1: 0.67799, l2: 0.31507\n",
            "Loss: 4.957916e-05, l1: 0.67800, l2: 0.31509\n",
            "Loss: 4.957124e-05, l1: 0.67799, l2: 0.31511\n",
            "Loss: 4.956376e-05, l1: 0.67825, l2: 0.31513\n",
            "Loss: 4.955107e-05, l1: 0.67833, l2: 0.31514\n",
            "Loss: 4.953613e-05, l1: 0.67871, l2: 0.31517\n",
            "Loss: 4.952108e-05, l1: 0.67931, l2: 0.31516\n",
            "Loss: 4.951189e-05, l1: 0.67931, l2: 0.31519\n",
            "Loss: 4.950713e-05, l1: 0.67916, l2: 0.31520\n",
            "Loss: 4.949320e-05, l1: 0.67913, l2: 0.31527\n",
            "Loss: 4.948207e-05, l1: 0.67907, l2: 0.31531\n",
            "Loss: 4.946855e-05, l1: 0.67928, l2: 0.31537\n",
            "Loss: 4.945388e-05, l1: 0.67963, l2: 0.31539\n",
            "Loss: 4.944599e-05, l1: 0.67990, l2: 0.31538\n",
            "Loss: 4.943539e-05, l1: 0.68004, l2: 0.31533\n",
            "Loss: 4.942184e-05, l1: 0.67987, l2: 0.31526\n",
            "Loss: 4.940620e-05, l1: 0.67963, l2: 0.31524\n",
            "Loss: 4.938641e-05, l1: 0.67935, l2: 0.31521\n",
            "Loss: 4.935432e-05, l1: 0.67900, l2: 0.31519\n",
            "Loss: 4.932233e-05, l1: 0.67838, l2: 0.31517\n",
            "Loss: 4.930738e-05, l1: 0.67718, l2: 0.31513\n",
            "Loss: 4.927069e-05, l1: 0.67741, l2: 0.31511\n",
            "Loss: 4.925724e-05, l1: 0.67744, l2: 0.31512\n",
            "Loss: 4.924840e-05, l1: 0.67727, l2: 0.31509\n",
            "Loss: 4.924148e-05, l1: 0.67703, l2: 0.31508\n",
            "Loss: 4.923518e-05, l1: 0.67707, l2: 0.31505\n",
            "Loss: 4.922697e-05, l1: 0.67720, l2: 0.31505\n",
            "Loss: 4.934001e-05, l1: 0.67903, l2: 0.31480\n",
            "Loss: 4.922326e-05, l1: 0.67748, l2: 0.31501\n",
            "Loss: 4.920684e-05, l1: 0.67748, l2: 0.31499\n",
            "Loss: 4.920777e-05, l1: 0.67800, l2: 0.31496\n",
            "Loss: 4.919557e-05, l1: 0.67774, l2: 0.31498\n",
            "Loss: 4.917559e-05, l1: 0.67768, l2: 0.31492\n",
            "Loss: 4.914660e-05, l1: 0.67830, l2: 0.31487\n",
            "Loss: 4.912378e-05, l1: 0.67794, l2: 0.31487\n",
            "Loss: 4.911206e-05, l1: 0.67773, l2: 0.31489\n",
            "Loss: 4.910324e-05, l1: 0.67757, l2: 0.31492\n",
            "Loss: 4.909177e-05, l1: 0.67756, l2: 0.31494\n",
            "Loss: 4.906592e-05, l1: 0.67878, l2: 0.31497\n",
            "Loss: 4.919987e-05, l1: 0.68121, l2: 0.31530\n",
            "Loss: 4.904610e-05, l1: 0.67942, l2: 0.31506\n",
            "Loss: 4.902489e-05, l1: 0.67933, l2: 0.31506\n",
            "Loss: 4.900872e-05, l1: 0.67943, l2: 0.31504\n",
            "Loss: 4.898962e-05, l1: 0.67964, l2: 0.31500\n",
            "Loss: 4.897458e-05, l1: 0.67958, l2: 0.31496\n",
            "Loss: 4.896130e-05, l1: 0.67984, l2: 0.31492\n",
            "Loss: 4.894367e-05, l1: 0.67989, l2: 0.31489\n",
            "Loss: 4.892751e-05, l1: 0.68028, l2: 0.31490\n",
            "Loss: 4.891894e-05, l1: 0.68040, l2: 0.31492\n",
            "Loss: 4.890990e-05, l1: 0.68068, l2: 0.31492\n",
            "Loss: 4.889478e-05, l1: 0.68106, l2: 0.31491\n",
            "Loss: 4.887920e-05, l1: 0.68169, l2: 0.31490\n",
            "Loss: 4.886035e-05, l1: 0.68205, l2: 0.31487\n",
            "Loss: 4.884532e-05, l1: 0.68252, l2: 0.31491\n",
            "Loss: 4.883264e-05, l1: 0.68247, l2: 0.31485\n",
            "Loss: 4.882408e-05, l1: 0.68253, l2: 0.31485\n",
            "Loss: 4.881411e-05, l1: 0.68236, l2: 0.31483\n",
            "Loss: 4.880630e-05, l1: 0.68264, l2: 0.31480\n",
            "Loss: 4.879709e-05, l1: 0.68297, l2: 0.31479\n",
            "Loss: 4.879012e-05, l1: 0.68322, l2: 0.31473\n",
            "Loss: 4.878288e-05, l1: 0.68383, l2: 0.31470\n",
            "Loss: 4.877474e-05, l1: 0.68415, l2: 0.31469\n",
            "Loss: 4.875987e-05, l1: 0.68439, l2: 0.31471\n",
            "Loss: 4.874880e-05, l1: 0.68443, l2: 0.31474\n",
            "Loss: 4.873580e-05, l1: 0.68456, l2: 0.31475\n",
            "Loss: 4.871919e-05, l1: 0.68478, l2: 0.31480\n",
            "Loss: 4.870100e-05, l1: 0.68405, l2: 0.31472\n",
            "Loss: 4.867840e-05, l1: 0.68470, l2: 0.31466\n",
            "Loss: 4.865563e-05, l1: 0.68519, l2: 0.31462\n",
            "Loss: 4.863994e-05, l1: 0.68520, l2: 0.31455\n",
            "Loss: 4.863317e-05, l1: 0.68517, l2: 0.31452\n",
            "Loss: 4.862862e-05, l1: 0.68523, l2: 0.31451\n",
            "Loss: 4.862518e-05, l1: 0.68519, l2: 0.31453\n",
            "Loss: 4.862102e-05, l1: 0.68507, l2: 0.31456\n",
            "Loss: 4.861746e-05, l1: 0.68504, l2: 0.31458\n",
            "Loss: 4.861865e-05, l1: 0.68525, l2: 0.31462\n",
            "Loss: 4.861509e-05, l1: 0.68513, l2: 0.31460\n",
            "Loss: 4.863218e-05, l1: 0.68458, l2: 0.31469\n",
            "Loss: 4.861219e-05, l1: 0.68498, l2: 0.31462\n",
            "Loss: 4.860890e-05, l1: 0.68501, l2: 0.31463\n",
            "Loss: 4.860263e-05, l1: 0.68555, l2: 0.31463\n",
            "Loss: 4.859646e-05, l1: 0.68546, l2: 0.31462\n",
            "Loss: 4.858671e-05, l1: 0.68565, l2: 0.31461\n",
            "Loss: 4.857106e-05, l1: 0.68638, l2: 0.31461\n",
            "Loss: 4.855520e-05, l1: 0.68738, l2: 0.31461\n",
            "Loss: 4.853695e-05, l1: 0.68870, l2: 0.31461\n",
            "Loss: 4.851851e-05, l1: 0.68952, l2: 0.31461\n",
            "Loss: 4.849317e-05, l1: 0.69036, l2: 0.31464\n",
            "Loss: 4.846947e-05, l1: 0.69046, l2: 0.31467\n",
            "Loss: 4.844430e-05, l1: 0.69081, l2: 0.31475\n",
            "Loss: 4.841875e-05, l1: 0.69047, l2: 0.31480\n",
            "Loss: 4.839013e-05, l1: 0.69022, l2: 0.31491\n",
            "Loss: 4.837113e-05, l1: 0.68974, l2: 0.31496\n",
            "Loss: 4.836617e-05, l1: 0.69110, l2: 0.31493\n",
            "Loss: 4.834524e-05, l1: 0.69039, l2: 0.31494\n",
            "Loss: 4.831419e-05, l1: 0.69143, l2: 0.31491\n",
            "Loss: 4.829444e-05, l1: 0.69167, l2: 0.31488\n",
            "Loss: 4.826717e-05, l1: 0.69135, l2: 0.31484\n",
            "Loss: 4.823356e-05, l1: 0.69155, l2: 0.31481\n",
            "Loss: 4.817398e-05, l1: 0.69222, l2: 0.31473\n",
            "Loss: 4.813594e-05, l1: 0.69261, l2: 0.31466\n",
            "Loss: 4.809456e-05, l1: 0.69403, l2: 0.31468\n",
            "Loss: 4.806478e-05, l1: 0.69440, l2: 0.31470\n",
            "Loss: 4.802977e-05, l1: 0.69516, l2: 0.31473\n",
            "Loss: 4.798330e-05, l1: 0.69638, l2: 0.31484\n",
            "Loss: 4.795610e-05, l1: 0.69771, l2: 0.31485\n",
            "Loss: 4.789293e-05, l1: 0.69750, l2: 0.31491\n",
            "Loss: 4.785645e-05, l1: 0.69792, l2: 0.31494\n",
            "Loss: 4.783830e-05, l1: 0.69763, l2: 0.31487\n",
            "Loss: 4.782552e-05, l1: 0.69812, l2: 0.31487\n",
            "Loss: 4.782038e-05, l1: 0.69809, l2: 0.31487\n",
            "Loss: 4.781006e-05, l1: 0.69799, l2: 0.31485\n",
            "Loss: 4.779879e-05, l1: 0.69798, l2: 0.31484\n",
            "Loss: 4.778719e-05, l1: 0.69835, l2: 0.31484\n",
            "Loss: 4.777918e-05, l1: 0.69875, l2: 0.31487\n",
            "Loss: 4.776645e-05, l1: 0.69872, l2: 0.31488\n",
            "Loss: 4.775743e-05, l1: 0.69896, l2: 0.31486\n",
            "Loss: 4.774416e-05, l1: 0.69884, l2: 0.31489\n",
            "Loss: 4.772731e-05, l1: 0.69912, l2: 0.31491\n",
            "Loss: 4.770344e-05, l1: 0.69943, l2: 0.31494\n",
            "Loss: 4.768110e-05, l1: 0.69997, l2: 0.31496\n",
            "Loss: 4.765798e-05, l1: 0.70078, l2: 0.31502\n",
            "Loss: 4.763734e-05, l1: 0.70119, l2: 0.31499\n",
            "Loss: 4.761943e-05, l1: 0.70167, l2: 0.31501\n",
            "Loss: 4.759528e-05, l1: 0.70197, l2: 0.31501\n",
            "Loss: 4.757096e-05, l1: 0.70229, l2: 0.31501\n",
            "Loss: 4.753864e-05, l1: 0.70279, l2: 0.31501\n",
            "Loss: 4.751363e-05, l1: 0.70340, l2: 0.31507\n",
            "Loss: 4.748370e-05, l1: 0.70415, l2: 0.31514\n",
            "Loss: 4.744682e-05, l1: 0.70509, l2: 0.31521\n",
            "Loss: 4.742088e-05, l1: 0.70563, l2: 0.31526\n",
            "Loss: 4.738504e-05, l1: 0.70663, l2: 0.31532\n",
            "Loss: 4.734965e-05, l1: 0.70749, l2: 0.31546\n",
            "Loss: 4.731410e-05, l1: 0.70736, l2: 0.31550\n",
            "Loss: 4.727923e-05, l1: 0.70793, l2: 0.31558\n",
            "Loss: 4.722265e-05, l1: 0.70777, l2: 0.31560\n",
            "Loss: 4.714453e-05, l1: 0.70824, l2: 0.31567\n",
            "Loss: 4.708524e-05, l1: 0.70813, l2: 0.31562\n",
            "Loss: 4.703759e-05, l1: 0.70851, l2: 0.31561\n",
            "Loss: 4.700815e-05, l1: 0.70856, l2: 0.31555\n",
            "Loss: 4.698223e-05, l1: 0.70875, l2: 0.31554\n",
            "Loss: 4.695664e-05, l1: 0.70889, l2: 0.31553\n",
            "Loss: 4.690674e-05, l1: 0.70923, l2: 0.31553\n",
            "Loss: 4.688270e-05, l1: 0.70976, l2: 0.31555\n",
            "Loss: 4.685703e-05, l1: 0.71049, l2: 0.31557\n",
            "Loss: 4.682826e-05, l1: 0.71068, l2: 0.31558\n",
            "Loss: 4.682422e-05, l1: 0.71206, l2: 0.31557\n",
            "Loss: 4.681169e-05, l1: 0.71375, l2: 0.31551\n",
            "Loss: 4.676874e-05, l1: 0.71196, l2: 0.31549\n",
            "Loss: 4.675898e-05, l1: 0.71153, l2: 0.31549\n",
            "Loss: 4.673555e-05, l1: 0.71191, l2: 0.31546\n",
            "Loss: 4.671561e-05, l1: 0.71227, l2: 0.31545\n",
            "Loss: 4.670164e-05, l1: 0.71234, l2: 0.31545\n",
            "Loss: 4.667127e-05, l1: 0.71231, l2: 0.31547\n",
            "Loss: 4.666998e-05, l1: 0.71352, l2: 0.31545\n",
            "Loss: 4.665339e-05, l1: 0.71289, l2: 0.31546\n",
            "Loss: 4.662994e-05, l1: 0.71303, l2: 0.31547\n",
            "Loss: 4.659907e-05, l1: 0.71378, l2: 0.31547\n",
            "Loss: 4.658052e-05, l1: 0.71370, l2: 0.31548\n",
            "Loss: 4.655739e-05, l1: 0.71403, l2: 0.31548\n",
            "Loss: 4.653547e-05, l1: 0.71387, l2: 0.31551\n",
            "Loss: 4.651671e-05, l1: 0.71365, l2: 0.31558\n",
            "Loss: 4.650593e-05, l1: 0.71333, l2: 0.31562\n",
            "Loss: 4.649690e-05, l1: 0.71343, l2: 0.31564\n",
            "Loss: 4.648968e-05, l1: 0.71336, l2: 0.31563\n",
            "Loss: 4.648388e-05, l1: 0.71382, l2: 0.31567\n",
            "Loss: 4.647500e-05, l1: 0.71373, l2: 0.31560\n",
            "Loss: 4.646253e-05, l1: 0.71449, l2: 0.31559\n",
            "Loss: 4.644416e-05, l1: 0.71494, l2: 0.31556\n",
            "Loss: 4.641720e-05, l1: 0.71608, l2: 0.31551\n",
            "Loss: 4.639728e-05, l1: 0.71711, l2: 0.31551\n",
            "Loss: 4.637713e-05, l1: 0.71832, l2: 0.31553\n",
            "Loss: 4.636328e-05, l1: 0.71909, l2: 0.31554\n",
            "Loss: 4.635385e-05, l1: 0.71971, l2: 0.31557\n",
            "Loss: 4.634592e-05, l1: 0.72052, l2: 0.31558\n",
            "Loss: 4.633357e-05, l1: 0.72046, l2: 0.31559\n",
            "Loss: 4.631810e-05, l1: 0.72089, l2: 0.31557\n",
            "Loss: 4.628091e-05, l1: 0.72179, l2: 0.31552\n",
            "Loss: 4.625759e-05, l1: 0.72294, l2: 0.31553\n",
            "Loss: 4.623590e-05, l1: 0.72362, l2: 0.31554\n",
            "Loss: 4.622602e-05, l1: 0.72407, l2: 0.31554\n",
            "Loss: 4.621424e-05, l1: 0.72391, l2: 0.31554\n",
            "Loss: 4.619712e-05, l1: 0.72372, l2: 0.31555\n",
            "Loss: 4.617831e-05, l1: 0.72312, l2: 0.31554\n",
            "Loss: 4.616208e-05, l1: 0.72245, l2: 0.31553\n",
            "Loss: 4.619150e-05, l1: 0.72172, l2: 0.31557\n",
            "Loss: 4.615757e-05, l1: 0.72226, l2: 0.31554\n",
            "Loss: 4.614454e-05, l1: 0.72185, l2: 0.31553\n",
            "Loss: 4.613377e-05, l1: 0.72188, l2: 0.31553\n",
            "Loss: 4.611515e-05, l1: 0.72231, l2: 0.31557\n",
            "Loss: 4.609191e-05, l1: 0.72283, l2: 0.31565\n",
            "Loss: 4.606556e-05, l1: 0.72356, l2: 0.31574\n",
            "Loss: 4.604541e-05, l1: 0.72376, l2: 0.31579\n",
            "Loss: 4.602447e-05, l1: 0.72400, l2: 0.31577\n",
            "Loss: 4.600751e-05, l1: 0.72324, l2: 0.31567\n",
            "Loss: 4.599088e-05, l1: 0.72338, l2: 0.31562\n",
            "Loss: 4.597460e-05, l1: 0.72283, l2: 0.31553\n",
            "Loss: 4.595757e-05, l1: 0.72228, l2: 0.31551\n",
            "Loss: 4.601119e-05, l1: 0.72028, l2: 0.31549\n",
            "Loss: 4.595167e-05, l1: 0.72179, l2: 0.31551\n",
            "Loss: 4.593192e-05, l1: 0.72123, l2: 0.31555\n",
            "Loss: 4.591574e-05, l1: 0.72124, l2: 0.31560\n",
            "Loss: 4.589115e-05, l1: 0.72126, l2: 0.31568\n",
            "Loss: 4.589090e-05, l1: 0.72103, l2: 0.31563\n",
            "Loss: 4.588060e-05, l1: 0.72114, l2: 0.31566\n",
            "Loss: 4.585569e-05, l1: 0.72219, l2: 0.31568\n",
            "Loss: 4.583482e-05, l1: 0.72222, l2: 0.31565\n",
            "Loss: 4.580576e-05, l1: 0.72254, l2: 0.31555\n",
            "Loss: 4.579088e-05, l1: 0.72274, l2: 0.31551\n",
            "Loss: 4.578003e-05, l1: 0.72256, l2: 0.31549\n",
            "Loss: 4.577287e-05, l1: 0.72279, l2: 0.31548\n",
            "Loss: 4.576504e-05, l1: 0.72247, l2: 0.31547\n",
            "Loss: 4.575169e-05, l1: 0.72244, l2: 0.31545\n",
            "Loss: 4.590835e-05, l1: 0.72032, l2: 0.31526\n",
            "Loss: 4.574802e-05, l1: 0.72214, l2: 0.31542\n",
            "Loss: 4.573075e-05, l1: 0.72239, l2: 0.31537\n",
            "Loss: 4.571075e-05, l1: 0.72276, l2: 0.31532\n",
            "Loss: 4.568667e-05, l1: 0.72395, l2: 0.31519\n",
            "Loss: 4.566219e-05, l1: 0.72409, l2: 0.31524\n",
            "Loss: 4.564697e-05, l1: 0.72424, l2: 0.31523\n",
            "Loss: 4.563530e-05, l1: 0.72440, l2: 0.31526\n",
            "Loss: 4.562830e-05, l1: 0.72447, l2: 0.31526\n",
            "Loss: 4.562556e-05, l1: 0.72445, l2: 0.31526\n",
            "Loss: 4.561954e-05, l1: 0.72442, l2: 0.31524\n",
            "Loss: 4.561850e-05, l1: 0.72373, l2: 0.31524\n",
            "Loss: 4.561060e-05, l1: 0.72423, l2: 0.31524\n",
            "Loss: 4.560617e-05, l1: 0.72449, l2: 0.31525\n",
            "Loss: 4.559828e-05, l1: 0.72489, l2: 0.31529\n",
            "Loss: 4.558537e-05, l1: 0.72567, l2: 0.31534\n",
            "Loss: 4.556274e-05, l1: 0.72686, l2: 0.31540\n",
            "Loss: 4.553898e-05, l1: 0.72659, l2: 0.31544\n",
            "Loss: 4.550412e-05, l1: 0.72635, l2: 0.31543\n",
            "Loss: 4.548517e-05, l1: 0.72721, l2: 0.31545\n",
            "Loss: 4.546820e-05, l1: 0.72650, l2: 0.31542\n",
            "Loss: 4.545716e-05, l1: 0.72629, l2: 0.31542\n",
            "Loss: 4.544127e-05, l1: 0.72590, l2: 0.31543\n",
            "Loss: 4.543347e-05, l1: 0.72564, l2: 0.31542\n",
            "Loss: 4.542628e-05, l1: 0.72526, l2: 0.31542\n",
            "Loss: 4.542085e-05, l1: 0.72518, l2: 0.31542\n",
            "Loss: 4.540818e-05, l1: 0.72518, l2: 0.31541\n",
            "Loss: 4.539593e-05, l1: 0.72541, l2: 0.31543\n",
            "Loss: 4.537237e-05, l1: 0.72597, l2: 0.31542\n",
            "Loss: 4.535324e-05, l1: 0.72613, l2: 0.31550\n",
            "Loss: 4.533765e-05, l1: 0.72656, l2: 0.31553\n",
            "Loss: 4.532285e-05, l1: 0.72711, l2: 0.31555\n",
            "Loss: 4.530777e-05, l1: 0.72743, l2: 0.31559\n",
            "Loss: 4.528609e-05, l1: 0.72791, l2: 0.31557\n",
            "Loss: 4.526918e-05, l1: 0.72781, l2: 0.31558\n",
            "Loss: 4.525237e-05, l1: 0.72766, l2: 0.31559\n",
            "Loss: 4.523840e-05, l1: 0.72763, l2: 0.31556\n",
            "Loss: 4.522278e-05, l1: 0.72773, l2: 0.31554\n",
            "Loss: 4.520821e-05, l1: 0.72801, l2: 0.31551\n",
            "Loss: 4.518988e-05, l1: 0.72834, l2: 0.31548\n",
            "Loss: 4.521578e-05, l1: 0.72762, l2: 0.31525\n",
            "Loss: 4.518127e-05, l1: 0.72811, l2: 0.31540\n",
            "Loss: 4.516528e-05, l1: 0.72844, l2: 0.31537\n",
            "Loss: 4.514803e-05, l1: 0.72823, l2: 0.31532\n",
            "Loss: 4.513475e-05, l1: 0.72799, l2: 0.31530\n",
            "Loss: 4.511677e-05, l1: 0.72729, l2: 0.31528\n",
            "Loss: 4.509721e-05, l1: 0.72663, l2: 0.31527\n",
            "Loss: 4.507370e-05, l1: 0.72588, l2: 0.31530\n",
            "Loss: 4.520599e-05, l1: 0.72601, l2: 0.31511\n",
            "Loss: 4.505812e-05, l1: 0.72591, l2: 0.31525\n",
            "Loss: 4.502862e-05, l1: 0.72528, l2: 0.31526\n",
            "Loss: 4.500640e-05, l1: 0.72492, l2: 0.31541\n",
            "Loss: 4.498132e-05, l1: 0.72445, l2: 0.31539\n",
            "Loss: 4.496701e-05, l1: 0.72429, l2: 0.31535\n",
            "Loss: 4.495626e-05, l1: 0.72438, l2: 0.31535\n",
            "Loss: 4.494319e-05, l1: 0.72435, l2: 0.31537\n",
            "Loss: 4.492155e-05, l1: 0.72422, l2: 0.31540\n",
            "Loss: 4.490790e-05, l1: 0.72400, l2: 0.31540\n",
            "Loss: 4.489971e-05, l1: 0.72361, l2: 0.31542\n",
            "Loss: 4.489127e-05, l1: 0.72343, l2: 0.31538\n",
            "Loss: 4.488258e-05, l1: 0.72331, l2: 0.31535\n",
            "Loss: 4.487816e-05, l1: 0.72320, l2: 0.31534\n",
            "Loss: 4.487437e-05, l1: 0.72300, l2: 0.31534\n",
            "Loss: 4.486860e-05, l1: 0.72305, l2: 0.31536\n",
            "Loss: 4.486422e-05, l1: 0.72298, l2: 0.31537\n",
            "Loss: 4.485621e-05, l1: 0.72286, l2: 0.31535\n",
            "Loss: 4.484793e-05, l1: 0.72276, l2: 0.31529\n",
            "Loss: 4.484250e-05, l1: 0.72277, l2: 0.31526\n",
            "Loss: 4.483843e-05, l1: 0.72261, l2: 0.31521\n",
            "Loss: 4.483442e-05, l1: 0.72229, l2: 0.31519\n",
            "Loss: 4.482941e-05, l1: 0.72191, l2: 0.31518\n",
            "Loss: 4.482361e-05, l1: 0.72136, l2: 0.31519\n",
            "Loss: 4.481860e-05, l1: 0.72114, l2: 0.31528\n",
            "Loss: 4.480601e-05, l1: 0.72097, l2: 0.31527\n",
            "Loss: 4.478979e-05, l1: 0.72007, l2: 0.31524\n",
            "Loss: 4.478961e-05, l1: 0.72089, l2: 0.31535\n",
            "Loss: 4.477787e-05, l1: 0.72048, l2: 0.31529\n",
            "Loss: 4.475538e-05, l1: 0.71977, l2: 0.31530\n",
            "Loss: 4.482587e-05, l1: 0.71940, l2: 0.31556\n",
            "Loss: 4.474024e-05, l1: 0.71966, l2: 0.31538\n",
            "Loss: 4.470744e-05, l1: 0.71944, l2: 0.31538\n",
            "Loss: 4.468677e-05, l1: 0.72022, l2: 0.31544\n",
            "Loss: 4.465631e-05, l1: 0.72134, l2: 0.31546\n",
            "Loss: 4.462848e-05, l1: 0.72132, l2: 0.31546\n",
            "Loss: 4.460880e-05, l1: 0.72107, l2: 0.31543\n",
            "Loss: 4.458330e-05, l1: 0.71975, l2: 0.31536\n",
            "Loss: 4.456892e-05, l1: 0.71906, l2: 0.31537\n",
            "Loss: 4.455645e-05, l1: 0.71894, l2: 0.31537\n",
            "Loss: 4.454707e-05, l1: 0.71930, l2: 0.31538\n",
            "Loss: 4.453190e-05, l1: 0.71977, l2: 0.31539\n",
            "Loss: 4.450315e-05, l1: 0.72044, l2: 0.31542\n",
            "Loss: 4.446563e-05, l1: 0.72084, l2: 0.31547\n",
            "Loss: 4.442153e-05, l1: 0.72088, l2: 0.31553\n",
            "Loss: 4.437020e-05, l1: 0.72054, l2: 0.31559\n",
            "Loss: 4.433585e-05, l1: 0.72051, l2: 0.31564\n",
            "Loss: 4.431774e-05, l1: 0.71997, l2: 0.31565\n",
            "Loss: 4.429986e-05, l1: 0.72025, l2: 0.31568\n",
            "Loss: 4.428831e-05, l1: 0.72052, l2: 0.31569\n",
            "Loss: 4.426202e-05, l1: 0.72062, l2: 0.31579\n",
            "Loss: 4.436150e-05, l1: 0.71917, l2: 0.31584\n",
            "Loss: 4.424512e-05, l1: 0.72021, l2: 0.31580\n",
            "Loss: 4.421109e-05, l1: 0.72000, l2: 0.31588\n",
            "Loss: 4.416459e-05, l1: 0.71895, l2: 0.31600\n",
            "Loss: 4.414947e-05, l1: 0.71888, l2: 0.31601\n",
            "Loss: 4.413209e-05, l1: 0.71863, l2: 0.31598\n",
            "Loss: 4.412329e-05, l1: 0.71892, l2: 0.31596\n",
            "Loss: 4.411429e-05, l1: 0.71900, l2: 0.31595\n",
            "Loss: 4.410532e-05, l1: 0.71908, l2: 0.31597\n",
            "Loss: 4.412139e-05, l1: 0.71963, l2: 0.31597\n",
            "Loss: 4.409950e-05, l1: 0.71927, l2: 0.31597\n",
            "Loss: 4.408063e-05, l1: 0.71917, l2: 0.31603\n",
            "Loss: 4.406110e-05, l1: 0.71926, l2: 0.31608\n",
            "Loss: 4.403718e-05, l1: 0.71928, l2: 0.31613\n",
            "Loss: 4.404877e-05, l1: 0.71988, l2: 0.31620\n",
            "Loss: 4.402427e-05, l1: 0.71954, l2: 0.31616\n",
            "Loss: 4.397845e-05, l1: 0.72115, l2: 0.31622\n",
            "Loss: 4.393814e-05, l1: 0.72115, l2: 0.31617\n",
            "Loss: 4.388527e-05, l1: 0.72092, l2: 0.31610\n",
            "Loss: 4.385066e-05, l1: 0.72181, l2: 0.31614\n",
            "Loss: 4.382372e-05, l1: 0.72191, l2: 0.31614\n",
            "Loss: 4.382407e-05, l1: 0.72159, l2: 0.31641\n",
            "Loss: 4.380778e-05, l1: 0.72175, l2: 0.31627\n",
            "Loss: 4.379165e-05, l1: 0.72190, l2: 0.31620\n",
            "Loss: 4.377683e-05, l1: 0.72155, l2: 0.31621\n",
            "Loss: 4.376128e-05, l1: 0.72130, l2: 0.31623\n",
            "Loss: 4.374874e-05, l1: 0.72096, l2: 0.31620\n",
            "Loss: 4.373124e-05, l1: 0.72051, l2: 0.31619\n",
            "Loss: 4.371471e-05, l1: 0.71931, l2: 0.31616\n",
            "Loss: 4.369778e-05, l1: 0.71906, l2: 0.31618\n",
            "Loss: 4.368729e-05, l1: 0.71882, l2: 0.31619\n",
            "Loss: 4.367903e-05, l1: 0.71863, l2: 0.31619\n",
            "Loss: 4.366468e-05, l1: 0.71848, l2: 0.31622\n",
            "Loss: 4.365322e-05, l1: 0.71813, l2: 0.31625\n",
            "Loss: 4.364578e-05, l1: 0.71812, l2: 0.31627\n",
            "Loss: 4.364172e-05, l1: 0.71817, l2: 0.31629\n",
            "Loss: 4.363653e-05, l1: 0.71836, l2: 0.31636\n",
            "Loss: 4.363662e-05, l1: 0.71859, l2: 0.31632\n",
            "Loss: 4.363252e-05, l1: 0.71847, l2: 0.31634\n",
            "Loss: 4.362451e-05, l1: 0.71850, l2: 0.31635\n",
            "Loss: 4.361577e-05, l1: 0.71839, l2: 0.31637\n",
            "Loss: 4.360482e-05, l1: 0.71838, l2: 0.31641\n",
            "Loss: 4.359571e-05, l1: 0.71836, l2: 0.31650\n",
            "Loss: 4.368264e-05, l1: 0.71626, l2: 0.31647\n",
            "Loss: 4.358394e-05, l1: 0.71780, l2: 0.31650\n",
            "Loss: 4.356760e-05, l1: 0.71793, l2: 0.31646\n",
            "Loss: 4.354836e-05, l1: 0.71794, l2: 0.31645\n",
            "Loss: 4.352347e-05, l1: 0.71792, l2: 0.31649\n",
            "Loss: 4.350195e-05, l1: 0.71802, l2: 0.31655\n",
            "Loss: 4.347183e-05, l1: 0.71814, l2: 0.31665\n",
            "Loss: 4.344719e-05, l1: 0.71832, l2: 0.31670\n",
            "Loss: 4.352806e-05, l1: 0.71798, l2: 0.31683\n",
            "Loss: 4.343648e-05, l1: 0.71823, l2: 0.31674\n",
            "Loss: 4.341587e-05, l1: 0.71806, l2: 0.31678\n",
            "Loss: 4.338424e-05, l1: 0.71758, l2: 0.31674\n",
            "Loss: 4.336440e-05, l1: 0.71763, l2: 0.31671\n",
            "Loss: 4.333648e-05, l1: 0.71673, l2: 0.31669\n",
            "Loss: 4.330623e-05, l1: 0.71673, l2: 0.31666\n",
            "Loss: 4.326526e-05, l1: 0.71666, l2: 0.31670\n",
            "Loss: 4.323536e-05, l1: 0.71645, l2: 0.31671\n",
            "Loss: 4.322754e-05, l1: 0.71537, l2: 0.31665\n",
            "Loss: 4.320905e-05, l1: 0.71599, l2: 0.31668\n",
            "Loss: 4.320527e-05, l1: 0.71615, l2: 0.31670\n",
            "Loss: 4.320045e-05, l1: 0.71594, l2: 0.31668\n",
            "Loss: 4.319727e-05, l1: 0.71582, l2: 0.31668\n",
            "Loss: 4.318840e-05, l1: 0.71549, l2: 0.31669\n",
            "Loss: 4.317951e-05, l1: 0.71527, l2: 0.31671\n",
            "Loss: 4.315598e-05, l1: 0.71488, l2: 0.31673\n",
            "Loss: 4.312545e-05, l1: 0.71507, l2: 0.31677\n",
            "Loss: 4.309597e-05, l1: 0.71526, l2: 0.31682\n",
            "Loss: 4.307340e-05, l1: 0.71617, l2: 0.31680\n",
            "Loss: 4.305665e-05, l1: 0.71630, l2: 0.31679\n",
            "Loss: 4.304682e-05, l1: 0.71614, l2: 0.31679\n",
            "Loss: 4.303718e-05, l1: 0.71626, l2: 0.31678\n",
            "Loss: 4.302505e-05, l1: 0.71630, l2: 0.31680\n",
            "Loss: 4.301487e-05, l1: 0.71607, l2: 0.31683\n",
            "Loss: 4.300574e-05, l1: 0.71559, l2: 0.31690\n",
            "Loss: 4.299727e-05, l1: 0.71535, l2: 0.31692\n",
            "Loss: 4.298739e-05, l1: 0.71499, l2: 0.31694\n",
            "Loss: 4.297727e-05, l1: 0.71473, l2: 0.31691\n",
            "Loss: 4.305385e-05, l1: 0.71218, l2: 0.31705\n",
            "Loss: 4.297305e-05, l1: 0.71427, l2: 0.31694\n",
            "Loss: 4.296919e-05, l1: 0.71395, l2: 0.31692\n",
            "Loss: 4.295930e-05, l1: 0.71399, l2: 0.31691\n",
            "Loss: 4.295491e-05, l1: 0.71380, l2: 0.31690\n",
            "Loss: 4.296474e-05, l1: 0.71471, l2: 0.31693\n",
            "Loss: 4.295053e-05, l1: 0.71412, l2: 0.31691\n",
            "Loss: 4.293846e-05, l1: 0.71372, l2: 0.31690\n",
            "Loss: 4.292448e-05, l1: 0.71290, l2: 0.31683\n",
            "Loss: 4.291608e-05, l1: 0.71290, l2: 0.31684\n",
            "Loss: 4.290965e-05, l1: 0.71292, l2: 0.31683\n",
            "Loss: 4.289689e-05, l1: 0.71265, l2: 0.31675\n",
            "Loss: 4.288762e-05, l1: 0.71230, l2: 0.31671\n",
            "Loss: 4.287333e-05, l1: 0.71171, l2: 0.31666\n",
            "Loss: 4.286108e-05, l1: 0.71128, l2: 0.31665\n",
            "Loss: 4.285073e-05, l1: 0.71075, l2: 0.31666\n",
            "Loss: 4.284643e-05, l1: 0.71070, l2: 0.31670\n",
            "Loss: 4.283473e-05, l1: 0.71073, l2: 0.31672\n",
            "Loss: 4.282760e-05, l1: 0.71075, l2: 0.31675\n",
            "Loss: 4.281909e-05, l1: 0.71054, l2: 0.31678\n",
            "Loss: 4.280621e-05, l1: 0.71006, l2: 0.31683\n",
            "Loss: 4.278648e-05, l1: 0.70910, l2: 0.31686\n",
            "Loss: 4.275513e-05, l1: 0.70780, l2: 0.31686\n",
            "Loss: 4.273884e-05, l1: 0.70519, l2: 0.31675\n",
            "Loss: 4.271011e-05, l1: 0.70606, l2: 0.31677\n",
            "Loss: 4.269562e-05, l1: 0.70647, l2: 0.31680\n",
            "Loss: 4.267638e-05, l1: 0.70652, l2: 0.31672\n",
            "Loss: 4.266196e-05, l1: 0.70597, l2: 0.31666\n",
            "Loss: 4.263803e-05, l1: 0.70433, l2: 0.31655\n",
            "Loss: 4.262290e-05, l1: 0.70338, l2: 0.31653\n",
            "Loss: 4.260498e-05, l1: 0.70244, l2: 0.31652\n",
            "Loss: 4.258288e-05, l1: 0.70158, l2: 0.31652\n",
            "Loss: 4.274000e-05, l1: 0.70225, l2: 0.31671\n",
            "Loss: 4.257584e-05, l1: 0.70169, l2: 0.31656\n",
            "Loss: 4.255603e-05, l1: 0.70165, l2: 0.31655\n",
            "Loss: 4.253434e-05, l1: 0.70204, l2: 0.31655\n",
            "Loss: 4.251769e-05, l1: 0.70211, l2: 0.31661\n",
            "Loss: 4.249540e-05, l1: 0.70198, l2: 0.31659\n",
            "Loss: 4.247710e-05, l1: 0.69914, l2: 0.31655\n",
            "Loss: 4.244516e-05, l1: 0.69955, l2: 0.31652\n",
            "Loss: 4.243628e-05, l1: 0.70010, l2: 0.31651\n",
            "Loss: 4.241767e-05, l1: 0.69947, l2: 0.31650\n",
            "Loss: 4.239941e-05, l1: 0.69797, l2: 0.31648\n",
            "Loss: 4.238344e-05, l1: 0.69838, l2: 0.31648\n",
            "Loss: 4.236972e-05, l1: 0.69807, l2: 0.31645\n",
            "Loss: 4.234761e-05, l1: 0.69763, l2: 0.31640\n",
            "Loss: 4.231868e-05, l1: 0.69705, l2: 0.31629\n",
            "Loss: 4.233857e-05, l1: 0.69597, l2: 0.31616\n",
            "Loss: 4.229188e-05, l1: 0.69658, l2: 0.31623\n",
            "Loss: 4.225013e-05, l1: 0.69688, l2: 0.31617\n",
            "Loss: 4.221011e-05, l1: 0.69601, l2: 0.31611\n",
            "Loss: 4.217643e-05, l1: 0.69637, l2: 0.31613\n",
            "Loss: 4.214268e-05, l1: 0.69721, l2: 0.31622\n",
            "Loss: 4.210314e-05, l1: 0.69792, l2: 0.31631\n",
            "Loss: 4.203567e-05, l1: 0.69890, l2: 0.31642\n",
            "Loss: 4.198222e-05, l1: 0.69921, l2: 0.31640\n",
            "Loss: 4.194466e-05, l1: 0.70096, l2: 0.31639\n",
            "Loss: 4.187286e-05, l1: 0.69978, l2: 0.31628\n",
            "Loss: 4.183107e-05, l1: 0.69958, l2: 0.31620\n",
            "Loss: 4.178165e-05, l1: 0.70010, l2: 0.31616\n",
            "Loss: 4.171869e-05, l1: 0.70215, l2: 0.31612\n",
            "Loss: 4.166866e-05, l1: 0.70271, l2: 0.31613\n",
            "Loss: 4.165031e-05, l1: 0.70413, l2: 0.31613\n",
            "Loss: 4.163224e-05, l1: 0.71013, l2: 0.31614\n",
            "Loss: 4.156229e-05, l1: 0.70726, l2: 0.31614\n",
            "Loss: 4.152381e-05, l1: 0.70601, l2: 0.31602\n",
            "Loss: 4.146358e-05, l1: 0.70568, l2: 0.31599\n",
            "Loss: 4.141602e-05, l1: 0.70692, l2: 0.31602\n",
            "Loss: 4.137521e-05, l1: 0.70747, l2: 0.31601\n",
            "Loss: 4.132530e-05, l1: 0.70763, l2: 0.31599\n",
            "Loss: 4.129715e-05, l1: 0.70771, l2: 0.31602\n",
            "Loss: 4.128738e-05, l1: 0.70790, l2: 0.31606\n",
            "Loss: 4.127881e-05, l1: 0.70784, l2: 0.31607\n",
            "Loss: 4.126730e-05, l1: 0.70807, l2: 0.31605\n",
            "Loss: 4.125457e-05, l1: 0.70818, l2: 0.31601\n",
            "Loss: 4.147566e-05, l1: 0.70812, l2: 0.31587\n",
            "Loss: 4.124902e-05, l1: 0.70817, l2: 0.31599\n",
            "Loss: 4.123011e-05, l1: 0.70809, l2: 0.31595\n",
            "Loss: 4.120307e-05, l1: 0.70754, l2: 0.31589\n",
            "Loss: 4.118943e-05, l1: 0.70737, l2: 0.31586\n",
            "Loss: 4.117892e-05, l1: 0.70709, l2: 0.31583\n",
            "Loss: 4.117074e-05, l1: 0.70715, l2: 0.31584\n",
            "Loss: 4.115445e-05, l1: 0.70770, l2: 0.31584\n",
            "Loss: 4.114511e-05, l1: 0.70731, l2: 0.31585\n",
            "Loss: 4.112571e-05, l1: 0.70785, l2: 0.31584\n",
            "Loss: 4.109994e-05, l1: 0.70838, l2: 0.31580\n",
            "Loss: 4.107338e-05, l1: 0.70837, l2: 0.31579\n",
            "Loss: 4.104672e-05, l1: 0.70811, l2: 0.31578\n",
            "Loss: 4.102935e-05, l1: 0.70792, l2: 0.31577\n",
            "Loss: 4.101043e-05, l1: 0.70784, l2: 0.31576\n",
            "Loss: 4.099231e-05, l1: 0.70820, l2: 0.31571\n",
            "Loss: 4.097247e-05, l1: 0.70914, l2: 0.31568\n",
            "Loss: 4.095866e-05, l1: 0.70949, l2: 0.31562\n",
            "Loss: 4.094764e-05, l1: 0.71013, l2: 0.31558\n",
            "Loss: 4.093671e-05, l1: 0.71030, l2: 0.31558\n",
            "Loss: 4.092364e-05, l1: 0.71001, l2: 0.31561\n",
            "Loss: 4.091232e-05, l1: 0.70998, l2: 0.31565\n",
            "Loss: 4.089901e-05, l1: 0.70976, l2: 0.31569\n",
            "Loss: 4.088617e-05, l1: 0.70974, l2: 0.31569\n",
            "Loss: 4.088741e-05, l1: 0.70981, l2: 0.31563\n",
            "Loss: 4.087789e-05, l1: 0.70977, l2: 0.31566\n",
            "Loss: 4.086750e-05, l1: 0.71010, l2: 0.31563\n",
            "Loss: 4.086100e-05, l1: 0.71029, l2: 0.31557\n",
            "Loss: 4.085558e-05, l1: 0.71027, l2: 0.31554\n",
            "Loss: 4.086056e-05, l1: 0.71098, l2: 0.31556\n",
            "Loss: 4.084911e-05, l1: 0.71057, l2: 0.31555\n",
            "Loss: 4.084354e-05, l1: 0.71046, l2: 0.31557\n",
            "Loss: 4.083840e-05, l1: 0.71033, l2: 0.31558\n",
            "Loss: 4.083445e-05, l1: 0.71013, l2: 0.31559\n",
            "Loss: 4.082906e-05, l1: 0.71013, l2: 0.31560\n",
            "Loss: 4.082312e-05, l1: 0.71015, l2: 0.31557\n",
            "Loss: 4.081550e-05, l1: 0.70998, l2: 0.31554\n",
            "Loss: 4.080970e-05, l1: 0.70988, l2: 0.31550\n",
            "Loss: 4.080163e-05, l1: 0.70978, l2: 0.31544\n",
            "Loss: 4.081070e-05, l1: 0.70834, l2: 0.31538\n",
            "Loss: 4.079572e-05, l1: 0.70924, l2: 0.31541\n",
            "Loss: 4.079012e-05, l1: 0.70931, l2: 0.31541\n",
            "Loss: 4.078433e-05, l1: 0.70934, l2: 0.31542\n",
            "Loss: 4.077923e-05, l1: 0.70942, l2: 0.31546\n",
            "Loss: 4.077452e-05, l1: 0.70954, l2: 0.31546\n",
            "Loss: 4.076822e-05, l1: 0.70973, l2: 0.31546\n",
            "Loss: 4.076616e-05, l1: 0.70971, l2: 0.31542\n",
            "Loss: 4.076057e-05, l1: 0.71004, l2: 0.31543\n",
            "Loss: 4.075545e-05, l1: 0.70986, l2: 0.31541\n",
            "Loss: 4.075234e-05, l1: 0.70972, l2: 0.31538\n",
            "Loss: 4.074496e-05, l1: 0.70955, l2: 0.31534\n",
            "Loss: 4.073824e-05, l1: 0.70962, l2: 0.31525\n",
            "Loss: 4.073777e-05, l1: 0.70943, l2: 0.31521\n",
            "Loss: 4.073292e-05, l1: 0.70952, l2: 0.31523\n",
            "Loss: 4.071719e-05, l1: 0.70907, l2: 0.31522\n",
            "Loss: 4.069517e-05, l1: 0.70980, l2: 0.31522\n",
            "Loss: 4.066958e-05, l1: 0.70935, l2: 0.31527\n",
            "Loss: 4.063663e-05, l1: 0.70836, l2: 0.31538\n",
            "Loss: 4.061887e-05, l1: 0.70817, l2: 0.31536\n",
            "Loss: 4.059255e-05, l1: 0.70837, l2: 0.31535\n",
            "Loss: 4.057026e-05, l1: 0.70860, l2: 0.31532\n",
            "Loss: 4.055515e-05, l1: 0.70884, l2: 0.31529\n",
            "Loss: 4.054538e-05, l1: 0.70896, l2: 0.31527\n",
            "Loss: 4.055818e-05, l1: 0.70789, l2: 0.31524\n",
            "Loss: 4.054096e-05, l1: 0.70860, l2: 0.31526\n",
            "Loss: 4.053285e-05, l1: 0.70856, l2: 0.31526\n",
            "Loss: 4.052711e-05, l1: 0.70861, l2: 0.31529\n",
            "Loss: 4.052203e-05, l1: 0.70827, l2: 0.31528\n",
            "Loss: 4.051639e-05, l1: 0.70792, l2: 0.31529\n",
            "Loss: 4.051039e-05, l1: 0.70749, l2: 0.31526\n",
            "Loss: 4.050880e-05, l1: 0.70733, l2: 0.31522\n",
            "Loss: 4.050527e-05, l1: 0.70731, l2: 0.31522\n",
            "Loss: 4.050288e-05, l1: 0.70748, l2: 0.31524\n",
            "Loss: 4.049952e-05, l1: 0.70757, l2: 0.31526\n",
            "Loss: 4.049582e-05, l1: 0.70780, l2: 0.31529\n",
            "Loss: 4.049383e-05, l1: 0.70825, l2: 0.31528\n",
            "Loss: 4.049059e-05, l1: 0.70837, l2: 0.31531\n",
            "Loss: 4.048522e-05, l1: 0.70822, l2: 0.31531\n",
            "Loss: 4.047820e-05, l1: 0.70822, l2: 0.31531\n",
            "Loss: 4.047168e-05, l1: 0.70838, l2: 0.31532\n",
            "Loss: 4.046394e-05, l1: 0.70859, l2: 0.31532\n",
            "Loss: 4.044911e-05, l1: 0.70900, l2: 0.31533\n",
            "Loss: 4.046476e-05, l1: 0.70960, l2: 0.31534\n",
            "Loss: 4.044289e-05, l1: 0.70921, l2: 0.31533\n",
            "Loss: 4.042216e-05, l1: 0.70950, l2: 0.31540\n",
            "Loss: 4.040809e-05, l1: 0.70897, l2: 0.31539\n",
            "Loss: 4.040125e-05, l1: 0.70838, l2: 0.31539\n",
            "Loss: 4.039444e-05, l1: 0.70848, l2: 0.31537\n",
            "Loss: 4.039310e-05, l1: 0.70850, l2: 0.31536\n",
            "Loss: 4.038672e-05, l1: 0.70848, l2: 0.31533\n",
            "Loss: 4.038030e-05, l1: 0.70876, l2: 0.31529\n",
            "Loss: 4.037153e-05, l1: 0.70864, l2: 0.31525\n",
            "Loss: 4.035516e-05, l1: 0.70859, l2: 0.31522\n",
            "Loss: 4.032787e-05, l1: 0.70868, l2: 0.31519\n",
            "Loss: 4.028818e-05, l1: 0.70897, l2: 0.31514\n",
            "Loss: 4.023993e-05, l1: 0.70984, l2: 0.31504\n",
            "Loss: 4.021018e-05, l1: 0.71043, l2: 0.31492\n",
            "Loss: 4.015621e-05, l1: 0.70950, l2: 0.31501\n",
            "Loss: 4.013252e-05, l1: 0.70930, l2: 0.31496\n",
            "Loss: 4.011400e-05, l1: 0.70930, l2: 0.31492\n",
            "Loss: 4.008969e-05, l1: 0.70900, l2: 0.31489\n",
            "Loss: 4.004924e-05, l1: 0.70882, l2: 0.31486\n",
            "Loss: 4.001576e-05, l1: 0.70851, l2: 0.31485\n",
            "Loss: 3.999081e-05, l1: 0.70910, l2: 0.31484\n",
            "Loss: 3.996551e-05, l1: 0.70912, l2: 0.31487\n",
            "Loss: 3.994232e-05, l1: 0.70939, l2: 0.31487\n",
            "Loss: 3.990602e-05, l1: 0.70945, l2: 0.31486\n",
            "Loss: 3.987555e-05, l1: 0.71028, l2: 0.31482\n",
            "Loss: 3.984303e-05, l1: 0.70990, l2: 0.31479\n",
            "Loss: 3.981396e-05, l1: 0.70933, l2: 0.31471\n",
            "Loss: 3.979949e-05, l1: 0.70860, l2: 0.31471\n",
            "Loss: 3.978613e-05, l1: 0.70818, l2: 0.31469\n",
            "Loss: 3.977709e-05, l1: 0.70810, l2: 0.31474\n",
            "Loss: 3.976194e-05, l1: 0.70779, l2: 0.31474\n",
            "Loss: 3.974597e-05, l1: 0.70744, l2: 0.31476\n",
            "Loss: 3.972727e-05, l1: 0.70710, l2: 0.31478\n",
            "Loss: 3.971353e-05, l1: 0.70721, l2: 0.31479\n",
            "Loss: 3.969761e-05, l1: 0.70715, l2: 0.31482\n",
            "Loss: 3.969070e-05, l1: 0.70733, l2: 0.31478\n",
            "Loss: 3.967934e-05, l1: 0.70731, l2: 0.31479\n",
            "Loss: 3.967253e-05, l1: 0.70709, l2: 0.31482\n",
            "Loss: 3.966233e-05, l1: 0.70708, l2: 0.31486\n",
            "Loss: 3.964122e-05, l1: 0.70703, l2: 0.31496\n",
            "Loss: 3.963483e-05, l1: 0.70680, l2: 0.31506\n",
            "Loss: 3.961922e-05, l1: 0.70686, l2: 0.31506\n",
            "Loss: 3.960831e-05, l1: 0.70682, l2: 0.31506\n",
            "Loss: 3.959155e-05, l1: 0.70653, l2: 0.31508\n",
            "Loss: 3.957616e-05, l1: 0.70632, l2: 0.31509\n",
            "Loss: 3.955513e-05, l1: 0.70570, l2: 0.31514\n",
            "Loss: 3.953673e-05, l1: 0.70567, l2: 0.31514\n",
            "Loss: 3.962568e-05, l1: 0.70552, l2: 0.31519\n",
            "Loss: 3.952740e-05, l1: 0.70563, l2: 0.31515\n",
            "Loss: 3.950582e-05, l1: 0.70566, l2: 0.31515\n",
            "Loss: 3.948178e-05, l1: 0.70592, l2: 0.31514\n",
            "Loss: 3.946746e-05, l1: 0.70615, l2: 0.31516\n",
            "Loss: 3.945244e-05, l1: 0.70628, l2: 0.31524\n",
            "Loss: 3.944084e-05, l1: 0.70654, l2: 0.31527\n",
            "Loss: 3.943287e-05, l1: 0.70628, l2: 0.31529\n",
            "Loss: 3.942574e-05, l1: 0.70606, l2: 0.31531\n",
            "Loss: 3.943277e-05, l1: 0.70645, l2: 0.31524\n",
            "Loss: 3.942409e-05, l1: 0.70618, l2: 0.31529\n",
            "Loss: 3.941638e-05, l1: 0.70554, l2: 0.31534\n",
            "Loss: 3.940664e-05, l1: 0.70556, l2: 0.31532\n",
            "Loss: 3.939810e-05, l1: 0.70539, l2: 0.31529\n",
            "Loss: 3.939009e-05, l1: 0.70510, l2: 0.31529\n",
            "Loss: 3.937140e-05, l1: 0.70464, l2: 0.31530\n",
            "Loss: 3.934615e-05, l1: 0.70336, l2: 0.31535\n",
            "Loss: 3.933145e-05, l1: 0.70350, l2: 0.31540\n",
            "Loss: 3.929282e-05, l1: 0.70310, l2: 0.31544\n",
            "Loss: 3.927272e-05, l1: 0.70294, l2: 0.31554\n",
            "Loss: 3.925673e-05, l1: 0.70349, l2: 0.31557\n",
            "Loss: 3.924429e-05, l1: 0.70378, l2: 0.31558\n",
            "Loss: 3.922408e-05, l1: 0.70349, l2: 0.31566\n",
            "Loss: 3.927241e-05, l1: 0.70499, l2: 0.31592\n",
            "Loss: 3.920777e-05, l1: 0.70399, l2: 0.31575\n",
            "Loss: 3.919030e-05, l1: 0.70523, l2: 0.31568\n",
            "Loss: 3.917068e-05, l1: 0.70477, l2: 0.31567\n",
            "Loss: 3.916067e-05, l1: 0.70456, l2: 0.31567\n",
            "Loss: 3.915442e-05, l1: 0.70452, l2: 0.31566\n",
            "Loss: 3.925904e-05, l1: 0.70563, l2: 0.31544\n",
            "Loss: 3.915191e-05, l1: 0.70467, l2: 0.31563\n",
            "Loss: 3.913942e-05, l1: 0.70445, l2: 0.31564\n",
            "Loss: 3.912746e-05, l1: 0.70450, l2: 0.31566\n",
            "Loss: 3.911559e-05, l1: 0.70427, l2: 0.31568\n",
            "Loss: 3.909247e-05, l1: 0.70371, l2: 0.31572\n",
            "Loss: 3.907421e-05, l1: 0.70324, l2: 0.31572\n",
            "Loss: 3.906210e-05, l1: 0.70283, l2: 0.31574\n",
            "Loss: 3.904097e-05, l1: 0.70190, l2: 0.31576\n",
            "Loss: 3.902411e-05, l1: 0.70184, l2: 0.31573\n",
            "Loss: 3.900803e-05, l1: 0.70176, l2: 0.31571\n",
            "Loss: 3.898872e-05, l1: 0.70142, l2: 0.31574\n",
            "Loss: 3.897858e-05, l1: 0.70122, l2: 0.31575\n",
            "Loss: 3.895638e-05, l1: 0.70072, l2: 0.31577\n",
            "Loss: 3.893975e-05, l1: 0.70036, l2: 0.31574\n",
            "Loss: 3.893561e-05, l1: 0.69988, l2: 0.31576\n",
            "Loss: 3.893385e-05, l1: 0.70024, l2: 0.31565\n",
            "Loss: 3.892387e-05, l1: 0.70038, l2: 0.31567\n",
            "Loss: 3.891926e-05, l1: 0.69999, l2: 0.31572\n",
            "Loss: 3.891178e-05, l1: 0.70021, l2: 0.31571\n",
            "Loss: 3.890042e-05, l1: 0.70043, l2: 0.31570\n",
            "Loss: 3.888639e-05, l1: 0.70044, l2: 0.31569\n",
            "Loss: 3.887191e-05, l1: 0.70058, l2: 0.31569\n",
            "Loss: 3.886356e-05, l1: 0.69952, l2: 0.31572\n",
            "Loss: 3.883194e-05, l1: 0.69953, l2: 0.31572\n",
            "Loss: 3.880119e-05, l1: 0.69983, l2: 0.31575\n",
            "Loss: 3.877751e-05, l1: 0.69916, l2: 0.31575\n",
            "Loss: 3.875926e-05, l1: 0.69855, l2: 0.31575\n",
            "Loss: 3.876723e-05, l1: 0.69834, l2: 0.31568\n",
            "Loss: 3.875433e-05, l1: 0.69847, l2: 0.31572\n",
            "Loss: 3.874872e-05, l1: 0.69803, l2: 0.31571\n",
            "Loss: 3.874347e-05, l1: 0.69832, l2: 0.31571\n",
            "Loss: 3.874015e-05, l1: 0.69834, l2: 0.31570\n",
            "Loss: 3.873595e-05, l1: 0.69846, l2: 0.31567\n",
            "Loss: 3.873088e-05, l1: 0.69857, l2: 0.31563\n",
            "Loss: 3.873471e-05, l1: 0.69793, l2: 0.31566\n",
            "Loss: 3.872924e-05, l1: 0.69834, l2: 0.31564\n",
            "Loss: 3.872578e-05, l1: 0.69819, l2: 0.31563\n",
            "Loss: 3.872228e-05, l1: 0.69809, l2: 0.31563\n",
            "Loss: 3.871838e-05, l1: 0.69816, l2: 0.31562\n",
            "Loss: 3.871459e-05, l1: 0.69824, l2: 0.31560\n",
            "Loss: 3.871075e-05, l1: 0.69841, l2: 0.31558\n",
            "Loss: 3.870891e-05, l1: 0.69848, l2: 0.31558\n",
            "Loss: 3.870465e-05, l1: 0.69845, l2: 0.31557\n",
            "Loss: 3.869882e-05, l1: 0.69838, l2: 0.31558\n",
            "Loss: 3.869186e-05, l1: 0.69827, l2: 0.31558\n",
            "Loss: 3.868365e-05, l1: 0.69846, l2: 0.31556\n",
            "Loss: 3.867165e-05, l1: 0.69828, l2: 0.31555\n",
            "Loss: 3.865967e-05, l1: 0.69866, l2: 0.31547\n",
            "Loss: 3.864743e-05, l1: 0.69847, l2: 0.31546\n",
            "Loss: 3.864006e-05, l1: 0.69865, l2: 0.31540\n",
            "Loss: 3.863654e-05, l1: 0.69939, l2: 0.31535\n",
            "Loss: 3.863038e-05, l1: 0.69940, l2: 0.31535\n",
            "Loss: 3.862335e-05, l1: 0.69935, l2: 0.31536\n",
            "Loss: 3.861297e-05, l1: 0.69951, l2: 0.31536\n",
            "Loss: 3.860203e-05, l1: 0.69982, l2: 0.31536\n",
            "Loss: 3.859043e-05, l1: 0.70037, l2: 0.31533\n",
            "Loss: 3.857624e-05, l1: 0.70096, l2: 0.31530\n",
            "Loss: 3.856424e-05, l1: 0.70136, l2: 0.31529\n",
            "Loss: 3.855278e-05, l1: 0.70172, l2: 0.31526\n",
            "Loss: 3.854579e-05, l1: 0.70169, l2: 0.31524\n",
            "Loss: 3.853850e-05, l1: 0.70163, l2: 0.31522\n",
            "Loss: 3.853046e-05, l1: 0.70167, l2: 0.31519\n",
            "Loss: 3.867639e-05, l1: 0.70415, l2: 0.31517\n",
            "Loss: 3.852820e-05, l1: 0.70195, l2: 0.31519\n",
            "Loss: 3.851916e-05, l1: 0.70238, l2: 0.31518\n",
            "Loss: 3.851268e-05, l1: 0.70294, l2: 0.31518\n",
            "Loss: 3.851240e-05, l1: 0.70390, l2: 0.31520\n",
            "Loss: 3.850779e-05, l1: 0.70342, l2: 0.31519\n",
            "Loss: 3.869554e-05, l1: 0.70677, l2: 0.31522\n",
            "Loss: 3.850423e-05, l1: 0.70381, l2: 0.31519\n",
            "Loss: 3.849908e-05, l1: 0.70396, l2: 0.31522\n",
            "Loss: 3.848900e-05, l1: 0.70424, l2: 0.31530\n",
            "Loss: 3.847995e-05, l1: 0.70441, l2: 0.31534\n",
            "Loss: 3.845598e-05, l1: 0.70492, l2: 0.31540\n",
            "Loss: 3.841993e-05, l1: 0.70596, l2: 0.31545\n",
            "Loss: 3.837678e-05, l1: 0.70788, l2: 0.31541\n",
            "Loss: 3.834573e-05, l1: 0.70965, l2: 0.31543\n",
            "Loss: 3.831456e-05, l1: 0.70971, l2: 0.31538\n",
            "Loss: 3.829574e-05, l1: 0.71016, l2: 0.31537\n",
            "Loss: 3.827991e-05, l1: 0.71002, l2: 0.31541\n",
            "Loss: 3.826354e-05, l1: 0.71023, l2: 0.31547\n",
            "Loss: 3.824328e-05, l1: 0.71091, l2: 0.31556\n",
            "Loss: 3.823845e-05, l1: 0.71110, l2: 0.31561\n",
            "Loss: 3.821449e-05, l1: 0.71291, l2: 0.31570\n",
            "Loss: 3.819864e-05, l1: 0.71264, l2: 0.31564\n",
            "Loss: 3.817514e-05, l1: 0.71234, l2: 0.31557\n",
            "Loss: 3.815856e-05, l1: 0.71280, l2: 0.31555\n",
            "Loss: 3.823189e-05, l1: 0.71301, l2: 0.31549\n",
            "Loss: 3.815292e-05, l1: 0.71284, l2: 0.31554\n",
            "Loss: 3.812762e-05, l1: 0.71375, l2: 0.31553\n",
            "Loss: 3.811299e-05, l1: 0.71434, l2: 0.31558\n",
            "Loss: 3.809389e-05, l1: 0.71500, l2: 0.31565\n",
            "Loss: 3.809662e-05, l1: 0.71593, l2: 0.31575\n",
            "Loss: 3.808169e-05, l1: 0.71544, l2: 0.31570\n",
            "Loss: 3.806081e-05, l1: 0.71606, l2: 0.31573\n",
            "Loss: 3.803467e-05, l1: 0.71681, l2: 0.31575\n",
            "Loss: 3.803856e-05, l1: 0.71634, l2: 0.31586\n",
            "Loss: 3.802020e-05, l1: 0.71659, l2: 0.31580\n",
            "Loss: 3.800041e-05, l1: 0.71715, l2: 0.31578\n",
            "Loss: 3.797340e-05, l1: 0.71806, l2: 0.31576\n",
            "Loss: 3.794774e-05, l1: 0.71920, l2: 0.31574\n",
            "Loss: 3.792208e-05, l1: 0.72067, l2: 0.31575\n",
            "Loss: 3.789898e-05, l1: 0.72154, l2: 0.31578\n",
            "Loss: 3.787601e-05, l1: 0.72210, l2: 0.31581\n",
            "Loss: 3.786226e-05, l1: 0.72262, l2: 0.31584\n",
            "Loss: 3.783507e-05, l1: 0.72328, l2: 0.31585\n",
            "Loss: 3.819752e-05, l1: 0.72536, l2: 0.31614\n",
            "Loss: 3.783043e-05, l1: 0.72349, l2: 0.31588\n",
            "Loss: 3.779965e-05, l1: 0.72462, l2: 0.31588\n",
            "Loss: 3.777974e-05, l1: 0.72516, l2: 0.31588\n",
            "Loss: 3.775255e-05, l1: 0.72582, l2: 0.31586\n",
            "Loss: 3.773106e-05, l1: 0.72613, l2: 0.31588\n",
            "Loss: 3.770652e-05, l1: 0.72652, l2: 0.31591\n",
            "Loss: 3.768736e-05, l1: 0.72652, l2: 0.31598\n",
            "Loss: 3.767312e-05, l1: 0.72673, l2: 0.31607\n",
            "Loss: 3.766236e-05, l1: 0.72744, l2: 0.31609\n",
            "Loss: 3.765128e-05, l1: 0.72719, l2: 0.31614\n",
            "Loss: 3.764032e-05, l1: 0.72731, l2: 0.31615\n",
            "Loss: 3.762852e-05, l1: 0.72761, l2: 0.31616\n",
            "Loss: 3.761059e-05, l1: 0.72796, l2: 0.31618\n",
            "Loss: 3.759970e-05, l1: 0.72913, l2: 0.31616\n",
            "Loss: 3.758027e-05, l1: 0.72924, l2: 0.31619\n",
            "Loss: 3.756574e-05, l1: 0.72927, l2: 0.31620\n",
            "Loss: 3.755041e-05, l1: 0.72896, l2: 0.31619\n",
            "Loss: 3.754056e-05, l1: 0.72944, l2: 0.31619\n",
            "Loss: 3.752973e-05, l1: 0.72976, l2: 0.31619\n",
            "Loss: 3.751770e-05, l1: 0.72965, l2: 0.31618\n",
            "Loss: 3.750724e-05, l1: 0.73023, l2: 0.31618\n",
            "Loss: 3.749714e-05, l1: 0.73041, l2: 0.31619\n",
            "Loss: 3.749232e-05, l1: 0.73095, l2: 0.31618\n",
            "Loss: 3.748673e-05, l1: 0.73093, l2: 0.31618\n",
            "Loss: 3.747889e-05, l1: 0.73065, l2: 0.31617\n",
            "Loss: 3.747404e-05, l1: 0.73022, l2: 0.31614\n",
            "Loss: 3.746927e-05, l1: 0.72996, l2: 0.31611\n",
            "Loss: 3.746060e-05, l1: 0.72986, l2: 0.31608\n",
            "Loss: 3.744791e-05, l1: 0.72947, l2: 0.31600\n",
            "Loss: 3.743524e-05, l1: 0.72991, l2: 0.31598\n",
            "Loss: 3.741566e-05, l1: 0.73102, l2: 0.31596\n",
            "Loss: 3.739809e-05, l1: 0.73178, l2: 0.31593\n",
            "Loss: 3.743262e-05, l1: 0.73492, l2: 0.31615\n",
            "Loss: 3.738476e-05, l1: 0.73287, l2: 0.31601\n",
            "Loss: 3.736746e-05, l1: 0.73305, l2: 0.31600\n",
            "Loss: 3.734387e-05, l1: 0.73282, l2: 0.31601\n",
            "Loss: 3.732770e-05, l1: 0.73259, l2: 0.31611\n",
            "Loss: 3.729916e-05, l1: 0.73210, l2: 0.31604\n",
            "Loss: 3.728941e-05, l1: 0.73197, l2: 0.31604\n",
            "Loss: 3.727786e-05, l1: 0.73167, l2: 0.31603\n",
            "Loss: 3.726863e-05, l1: 0.73186, l2: 0.31606\n",
            "Loss: 3.725836e-05, l1: 0.73205, l2: 0.31607\n",
            "Loss: 3.724640e-05, l1: 0.73251, l2: 0.31610\n",
            "Loss: 3.723725e-05, l1: 0.73288, l2: 0.31608\n",
            "Loss: 3.723262e-05, l1: 0.73268, l2: 0.31606\n",
            "Loss: 3.722936e-05, l1: 0.73270, l2: 0.31607\n",
            "Loss: 3.723738e-05, l1: 0.73297, l2: 0.31603\n",
            "Loss: 3.722702e-05, l1: 0.73279, l2: 0.31606\n",
            "Loss: 3.722154e-05, l1: 0.73263, l2: 0.31605\n",
            "Loss: 3.721622e-05, l1: 0.73300, l2: 0.31607\n",
            "Loss: 3.720483e-05, l1: 0.73368, l2: 0.31610\n",
            "Loss: 3.719570e-05, l1: 0.73382, l2: 0.31611\n",
            "Loss: 3.716611e-05, l1: 0.73405, l2: 0.31608\n",
            "Loss: 3.712211e-05, l1: 0.73292, l2: 0.31604\n",
            "Loss: 3.726316e-05, l1: 0.73105, l2: 0.31591\n",
            "Loss: 3.710400e-05, l1: 0.73244, l2: 0.31601\n",
            "Loss: 3.708857e-05, l1: 0.73164, l2: 0.31596\n",
            "Loss: 3.706092e-05, l1: 0.73033, l2: 0.31594\n",
            "Loss: 3.704662e-05, l1: 0.73051, l2: 0.31594\n",
            "Loss: 3.701753e-05, l1: 0.73134, l2: 0.31596\n",
            "Loss: 3.699150e-05, l1: 0.73253, l2: 0.31599\n",
            "Loss: 3.696899e-05, l1: 0.73345, l2: 0.31599\n",
            "Loss: 3.695373e-05, l1: 0.73386, l2: 0.31601\n",
            "Loss: 3.694125e-05, l1: 0.73379, l2: 0.31602\n",
            "Loss: 3.692992e-05, l1: 0.73370, l2: 0.31600\n",
            "Loss: 3.691708e-05, l1: 0.73415, l2: 0.31600\n",
            "Loss: 3.690510e-05, l1: 0.73394, l2: 0.31598\n",
            "Loss: 3.688848e-05, l1: 0.73392, l2: 0.31595\n",
            "Loss: 3.687295e-05, l1: 0.73355, l2: 0.31590\n",
            "Loss: 3.685249e-05, l1: 0.73367, l2: 0.31584\n",
            "Loss: 3.682392e-05, l1: 0.73316, l2: 0.31575\n",
            "Loss: 3.691966e-05, l1: 0.73661, l2: 0.31543\n",
            "Loss: 3.680472e-05, l1: 0.73419, l2: 0.31566\n",
            "Loss: 3.677455e-05, l1: 0.73362, l2: 0.31564\n",
            "Loss: 3.674894e-05, l1: 0.73301, l2: 0.31560\n",
            "Loss: 3.672597e-05, l1: 0.73308, l2: 0.31564\n",
            "Loss: 3.671003e-05, l1: 0.73269, l2: 0.31565\n",
            "Loss: 3.668208e-05, l1: 0.73228, l2: 0.31569\n",
            "Loss: 3.666707e-05, l1: 0.73126, l2: 0.31572\n",
            "Loss: 3.665166e-05, l1: 0.73093, l2: 0.31569\n",
            "Loss: 3.663719e-05, l1: 0.73067, l2: 0.31565\n",
            "Loss: 3.662198e-05, l1: 0.73038, l2: 0.31559\n",
            "Loss: 3.661667e-05, l1: 0.73073, l2: 0.31557\n",
            "Loss: 3.660468e-05, l1: 0.73037, l2: 0.31557\n",
            "Loss: 3.659865e-05, l1: 0.73023, l2: 0.31557\n",
            "Loss: 3.659180e-05, l1: 0.72996, l2: 0.31556\n",
            "Loss: 3.658779e-05, l1: 0.72988, l2: 0.31555\n",
            "Loss: 3.658258e-05, l1: 0.72983, l2: 0.31554\n",
            "Loss: 3.657622e-05, l1: 0.73004, l2: 0.31555\n",
            "Loss: 3.656106e-05, l1: 0.73030, l2: 0.31554\n",
            "Loss: 3.654307e-05, l1: 0.73136, l2: 0.31556\n",
            "Loss: 3.652898e-05, l1: 0.73217, l2: 0.31551\n",
            "Loss: 3.651701e-05, l1: 0.73209, l2: 0.31551\n",
            "Loss: 3.650927e-05, l1: 0.73239, l2: 0.31551\n",
            "Loss: 3.650705e-05, l1: 0.73292, l2: 0.31549\n",
            "Loss: 3.650098e-05, l1: 0.73307, l2: 0.31548\n",
            "Loss: 3.649173e-05, l1: 0.73354, l2: 0.31547\n",
            "Loss: 3.648149e-05, l1: 0.73395, l2: 0.31544\n",
            "Loss: 3.647081e-05, l1: 0.73426, l2: 0.31541\n",
            "Loss: 3.646058e-05, l1: 0.73422, l2: 0.31536\n",
            "Loss: 3.661290e-05, l1: 0.73338, l2: 0.31528\n",
            "Loss: 3.645510e-05, l1: 0.73409, l2: 0.31535\n",
            "Loss: 3.644480e-05, l1: 0.73387, l2: 0.31535\n",
            "Loss: 3.643752e-05, l1: 0.73376, l2: 0.31532\n",
            "Loss: 3.643244e-05, l1: 0.73339, l2: 0.31533\n",
            "Loss: 3.642762e-05, l1: 0.73354, l2: 0.31534\n",
            "Loss: 3.642368e-05, l1: 0.73379, l2: 0.31535\n",
            "Loss: 3.641677e-05, l1: 0.73421, l2: 0.31534\n",
            "Loss: 3.641111e-05, l1: 0.73423, l2: 0.31533\n",
            "Loss: 3.640413e-05, l1: 0.73436, l2: 0.31533\n",
            "Loss: 3.639960e-05, l1: 0.73430, l2: 0.31533\n",
            "Loss: 3.639592e-05, l1: 0.73413, l2: 0.31534\n",
            "Loss: 3.639371e-05, l1: 0.73406, l2: 0.31535\n",
            "Loss: 3.639077e-05, l1: 0.73408, l2: 0.31536\n",
            "Loss: 3.638744e-05, l1: 0.73421, l2: 0.31538\n",
            "Loss: 3.638854e-05, l1: 0.73411, l2: 0.31540\n",
            "Loss: 3.638594e-05, l1: 0.73417, l2: 0.31539\n",
            "Loss: 3.638958e-05, l1: 0.73411, l2: 0.31547\n",
            "Loss: 3.638335e-05, l1: 0.73415, l2: 0.31542\n",
            "Loss: 3.638150e-05, l1: 0.73431, l2: 0.31541\n",
            "Loss: 3.640725e-05, l1: 0.73512, l2: 0.31543\n",
            "Loss: 3.637909e-05, l1: 0.73449, l2: 0.31542\n",
            "Loss: 3.637436e-05, l1: 0.73431, l2: 0.31540\n",
            "Loss: 3.636843e-05, l1: 0.73437, l2: 0.31538\n",
            "Loss: 3.636292e-05, l1: 0.73476, l2: 0.31538\n",
            "Loss: 3.636023e-05, l1: 0.73503, l2: 0.31536\n",
            "Loss: 3.635803e-05, l1: 0.73530, l2: 0.31537\n",
            "Loss: 3.635539e-05, l1: 0.73547, l2: 0.31537\n",
            "Loss: 3.635419e-05, l1: 0.73551, l2: 0.31537\n",
            "Loss: 3.635117e-05, l1: 0.73543, l2: 0.31538\n",
            "Loss: 3.634761e-05, l1: 0.73514, l2: 0.31540\n",
            "Loss: 3.634189e-05, l1: 0.73465, l2: 0.31541\n",
            "Loss: 3.633724e-05, l1: 0.73419, l2: 0.31541\n",
            "Loss: 3.633401e-05, l1: 0.73410, l2: 0.31538\n",
            "Loss: 3.632608e-05, l1: 0.73383, l2: 0.31539\n",
            "Loss: 3.635066e-05, l1: 0.73296, l2: 0.31537\n",
            "Loss: 3.632357e-05, l1: 0.73364, l2: 0.31539\n",
            "Loss: 3.631629e-05, l1: 0.73390, l2: 0.31537\n",
            "Loss: 3.630241e-05, l1: 0.73411, l2: 0.31532\n",
            "Loss: 3.629061e-05, l1: 0.73428, l2: 0.31530\n",
            "Loss: 3.626619e-05, l1: 0.73419, l2: 0.31527\n",
            "Loss: 3.624616e-05, l1: 0.73466, l2: 0.31522\n",
            "Loss: 3.632093e-05, l1: 0.73538, l2: 0.31543\n",
            "Loss: 3.623647e-05, l1: 0.73485, l2: 0.31528\n",
            "Loss: 3.621741e-05, l1: 0.73406, l2: 0.31527\n",
            "Loss: 3.620146e-05, l1: 0.73422, l2: 0.31527\n",
            "Loss: 3.619377e-05, l1: 0.73448, l2: 0.31529\n",
            "Loss: 3.619046e-05, l1: 0.73475, l2: 0.31529\n",
            "Loss: 3.618595e-05, l1: 0.73526, l2: 0.31529\n",
            "Loss: 3.617818e-05, l1: 0.73528, l2: 0.31528\n",
            "Loss: 3.616390e-05, l1: 0.73582, l2: 0.31525\n",
            "Loss: 3.614470e-05, l1: 0.73611, l2: 0.31529\n",
            "Loss: 3.613024e-05, l1: 0.73499, l2: 0.31532\n",
            "Loss: 3.610880e-05, l1: 0.73561, l2: 0.31534\n",
            "Loss: 3.609767e-05, l1: 0.73605, l2: 0.31537\n",
            "Loss: 3.608827e-05, l1: 0.73624, l2: 0.31542\n",
            "Loss: 3.607251e-05, l1: 0.73685, l2: 0.31548\n",
            "Loss: 3.605258e-05, l1: 0.73811, l2: 0.31556\n",
            "Loss: 3.604874e-05, l1: 0.73905, l2: 0.31565\n",
            "Loss: 3.603240e-05, l1: 0.73934, l2: 0.31563\n",
            "Loss: 3.602257e-05, l1: 0.73944, l2: 0.31561\n",
            "Loss: 3.599908e-05, l1: 0.73998, l2: 0.31558\n",
            "Loss: 3.596035e-05, l1: 0.74014, l2: 0.31556\n",
            "Loss: 3.589400e-05, l1: 0.74328, l2: 0.31554\n",
            "Loss: 3.580455e-05, l1: 0.74597, l2: 0.31561\n",
            "Loss: 3.592048e-05, l1: 0.75097, l2: 0.31569\n",
            "Loss: 3.575418e-05, l1: 0.74786, l2: 0.31564\n",
            "Loss: 3.567630e-05, l1: 0.74897, l2: 0.31577\n",
            "Loss: 3.562483e-05, l1: 0.75056, l2: 0.31589\n",
            "Loss: 3.560424e-05, l1: 0.75283, l2: 0.31611\n",
            "Loss: 3.558271e-05, l1: 0.75175, l2: 0.31600\n",
            "Loss: 3.555953e-05, l1: 0.75383, l2: 0.31611\n",
            "Loss: 3.556919e-05, l1: 0.75259, l2: 0.31618\n",
            "Loss: 3.551526e-05, l1: 0.75327, l2: 0.31614\n",
            "Loss: 3.552173e-05, l1: 0.75414, l2: 0.31615\n",
            "Loss: 3.547998e-05, l1: 0.75369, l2: 0.31614\n",
            "Loss: 3.547554e-05, l1: 0.75300, l2: 0.31607\n",
            "Loss: 3.545292e-05, l1: 0.75430, l2: 0.31609\n",
            "Loss: 3.541559e-05, l1: 0.75330, l2: 0.31611\n",
            "Loss: 3.539793e-05, l1: 0.75327, l2: 0.31612\n",
            "Loss: 3.537813e-05, l1: 0.75371, l2: 0.31616\n",
            "Loss: 3.536721e-05, l1: 0.75392, l2: 0.31614\n",
            "Loss: 3.535508e-05, l1: 0.75428, l2: 0.31616\n",
            "Loss: 3.533049e-05, l1: 0.75485, l2: 0.31616\n",
            "Loss: 3.538628e-05, l1: 0.75652, l2: 0.31617\n",
            "Loss: 3.531914e-05, l1: 0.75533, l2: 0.31616\n",
            "Loss: 3.528779e-05, l1: 0.75597, l2: 0.31614\n",
            "Loss: 3.527267e-05, l1: 0.75561, l2: 0.31612\n",
            "Loss: 3.527497e-05, l1: 0.75536, l2: 0.31614\n",
            "Loss: 3.526394e-05, l1: 0.75549, l2: 0.31613\n",
            "Loss: 3.525931e-05, l1: 0.75518, l2: 0.31615\n",
            "Loss: 3.525505e-05, l1: 0.75507, l2: 0.31614\n",
            "Loss: 3.524748e-05, l1: 0.75538, l2: 0.31615\n",
            "Loss: 3.523855e-05, l1: 0.75581, l2: 0.31617\n",
            "Loss: 3.523028e-05, l1: 0.75672, l2: 0.31619\n",
            "Loss: 3.522157e-05, l1: 0.75711, l2: 0.31619\n",
            "Loss: 3.521128e-05, l1: 0.75750, l2: 0.31620\n",
            "Loss: 3.520836e-05, l1: 0.75802, l2: 0.31620\n",
            "Loss: 3.520084e-05, l1: 0.75790, l2: 0.31619\n",
            "Loss: 3.519677e-05, l1: 0.75788, l2: 0.31619\n",
            "Loss: 3.519065e-05, l1: 0.75794, l2: 0.31621\n",
            "Loss: 3.518310e-05, l1: 0.75808, l2: 0.31624\n",
            "Loss: 3.516728e-05, l1: 0.75849, l2: 0.31632\n",
            "Loss: 3.515395e-05, l1: 0.75904, l2: 0.31638\n",
            "Loss: 3.514347e-05, l1: 0.76019, l2: 0.31648\n",
            "Loss: 3.514974e-05, l1: 0.75993, l2: 0.31650\n",
            "Loss: 3.513351e-05, l1: 0.76008, l2: 0.31649\n",
            "Loss: 3.511764e-05, l1: 0.76076, l2: 0.31649\n",
            "Loss: 3.509448e-05, l1: 0.76096, l2: 0.31644\n",
            "Loss: 3.507893e-05, l1: 0.76129, l2: 0.31643\n",
            "Loss: 3.506087e-05, l1: 0.76135, l2: 0.31641\n",
            "Loss: 3.504822e-05, l1: 0.76183, l2: 0.31645\n",
            "Loss: 3.503952e-05, l1: 0.76188, l2: 0.31647\n",
            "Loss: 3.503101e-05, l1: 0.76195, l2: 0.31649\n",
            "Loss: 3.502178e-05, l1: 0.76201, l2: 0.31649\n",
            "Loss: 3.500663e-05, l1: 0.76216, l2: 0.31647\n",
            "Loss: 3.504256e-05, l1: 0.76273, l2: 0.31638\n",
            "Loss: 3.499809e-05, l1: 0.76234, l2: 0.31644\n",
            "Loss: 3.496557e-05, l1: 0.76297, l2: 0.31639\n",
            "Loss: 3.494943e-05, l1: 0.76371, l2: 0.31640\n",
            "Loss: 3.493325e-05, l1: 0.76328, l2: 0.31634\n",
            "Loss: 3.492656e-05, l1: 0.76374, l2: 0.31632\n",
            "Loss: 3.492130e-05, l1: 0.76386, l2: 0.31633\n",
            "Loss: 3.490993e-05, l1: 0.76427, l2: 0.31634\n",
            "Loss: 3.489735e-05, l1: 0.76463, l2: 0.31634\n",
            "Loss: 3.487423e-05, l1: 0.76459, l2: 0.31627\n",
            "Loss: 3.484893e-05, l1: 0.76511, l2: 0.31626\n",
            "Loss: 3.482786e-05, l1: 0.76460, l2: 0.31625\n",
            "Loss: 3.481269e-05, l1: 0.76435, l2: 0.31624\n",
            "Loss: 3.480091e-05, l1: 0.76420, l2: 0.31625\n",
            "Loss: 3.478437e-05, l1: 0.76423, l2: 0.31624\n",
            "Loss: 3.481391e-05, l1: 0.76537, l2: 0.31635\n",
            "Loss: 3.477226e-05, l1: 0.76463, l2: 0.31628\n",
            "Loss: 3.475351e-05, l1: 0.76520, l2: 0.31628\n",
            "Loss: 3.472182e-05, l1: 0.76753, l2: 0.31633\n",
            "Loss: 3.469787e-05, l1: 0.76935, l2: 0.31633\n",
            "Loss: 3.467484e-05, l1: 0.77211, l2: 0.31635\n",
            "Loss: 3.465749e-05, l1: 0.77223, l2: 0.31635\n",
            "Loss: 3.464521e-05, l1: 0.77274, l2: 0.31629\n",
            "Loss: 3.462804e-05, l1: 0.77189, l2: 0.31627\n",
            "Loss: 3.461698e-05, l1: 0.77185, l2: 0.31627\n",
            "Loss: 3.459589e-05, l1: 0.77136, l2: 0.31623\n",
            "Loss: 3.457571e-05, l1: 0.77153, l2: 0.31625\n",
            "Loss: 3.455280e-05, l1: 0.77129, l2: 0.31623\n",
            "Loss: 3.451225e-05, l1: 0.77055, l2: 0.31621\n",
            "Loss: 3.448473e-05, l1: 0.76994, l2: 0.31624\n",
            "Loss: 3.446262e-05, l1: 0.76952, l2: 0.31630\n",
            "Loss: 3.444986e-05, l1: 0.76946, l2: 0.31632\n",
            "Loss: 3.443979e-05, l1: 0.76946, l2: 0.31632\n",
            "Loss: 3.442487e-05, l1: 0.76962, l2: 0.31633\n",
            "Loss: 3.441252e-05, l1: 0.76976, l2: 0.31634\n",
            "Loss: 3.439529e-05, l1: 0.77014, l2: 0.31636\n",
            "Loss: 3.437856e-05, l1: 0.77061, l2: 0.31636\n",
            "Loss: 3.436747e-05, l1: 0.77072, l2: 0.31637\n",
            "Loss: 3.436108e-05, l1: 0.77120, l2: 0.31639\n",
            "Loss: 3.435222e-05, l1: 0.77078, l2: 0.31637\n",
            "Loss: 3.444356e-05, l1: 0.77184, l2: 0.31652\n",
            "Loss: 3.434692e-05, l1: 0.77099, l2: 0.31640\n",
            "Loss: 3.433613e-05, l1: 0.77079, l2: 0.31637\n",
            "Loss: 3.432556e-05, l1: 0.77078, l2: 0.31636\n",
            "Loss: 3.430547e-05, l1: 0.77094, l2: 0.31635\n",
            "Loss: 3.428415e-05, l1: 0.77145, l2: 0.31638\n",
            "Loss: 3.428614e-05, l1: 0.77074, l2: 0.31631\n",
            "Loss: 3.427248e-05, l1: 0.77111, l2: 0.31635\n",
            "Loss: 3.425982e-05, l1: 0.77138, l2: 0.31634\n",
            "Loss: 3.424492e-05, l1: 0.77110, l2: 0.31633\n",
            "Loss: 3.423637e-05, l1: 0.77091, l2: 0.31631\n",
            "Loss: 3.422792e-05, l1: 0.77061, l2: 0.31631\n",
            "Loss: 3.421979e-05, l1: 0.77057, l2: 0.31631\n",
            "Loss: 3.421212e-05, l1: 0.77069, l2: 0.31633\n",
            "Loss: 3.420387e-05, l1: 0.77116, l2: 0.31633\n",
            "Loss: 3.419480e-05, l1: 0.77179, l2: 0.31632\n",
            "Loss: 3.418502e-05, l1: 0.77238, l2: 0.31630\n",
            "Loss: 3.416661e-05, l1: 0.77269, l2: 0.31627\n",
            "Loss: 3.425080e-05, l1: 0.77360, l2: 0.31631\n",
            "Loss: 3.415707e-05, l1: 0.77291, l2: 0.31628\n",
            "Loss: 3.413668e-05, l1: 0.77241, l2: 0.31624\n",
            "Loss: 3.411518e-05, l1: 0.77141, l2: 0.31616\n",
            "Loss: 3.411152e-05, l1: 0.77079, l2: 0.31617\n",
            "Loss: 3.410766e-05, l1: 0.77055, l2: 0.31612\n",
            "Loss: 3.410276e-05, l1: 0.77086, l2: 0.31613\n",
            "Loss: 3.409193e-05, l1: 0.77144, l2: 0.31613\n",
            "Loss: 3.407949e-05, l1: 0.77188, l2: 0.31612\n",
            "Loss: 3.405920e-05, l1: 0.77247, l2: 0.31610\n",
            "Loss: 3.405226e-05, l1: 0.77211, l2: 0.31610\n",
            "Loss: 3.403064e-05, l1: 0.77234, l2: 0.31609\n",
            "Loss: 3.402080e-05, l1: 0.77205, l2: 0.31611\n",
            "Loss: 3.401150e-05, l1: 0.77168, l2: 0.31612\n",
            "Loss: 3.400517e-05, l1: 0.77143, l2: 0.31614\n",
            "Loss: 3.399832e-05, l1: 0.77143, l2: 0.31614\n",
            "Loss: 3.399111e-05, l1: 0.77150, l2: 0.31613\n",
            "Loss: 3.399204e-05, l1: 0.77168, l2: 0.31613\n",
            "Loss: 3.398781e-05, l1: 0.77158, l2: 0.31613\n",
            "Loss: 3.398574e-05, l1: 0.77182, l2: 0.31614\n",
            "Loss: 3.398144e-05, l1: 0.77122, l2: 0.31614\n",
            "Loss: 3.397835e-05, l1: 0.77141, l2: 0.31615\n",
            "Loss: 3.397589e-05, l1: 0.77115, l2: 0.31615\n",
            "Loss: 3.397213e-05, l1: 0.77098, l2: 0.31615\n",
            "Loss: 3.396247e-05, l1: 0.77052, l2: 0.31617\n",
            "Loss: 3.395725e-05, l1: 0.77047, l2: 0.31617\n",
            "Loss: 3.395102e-05, l1: 0.77059, l2: 0.31615\n",
            "Loss: 3.394637e-05, l1: 0.76998, l2: 0.31611\n",
            "Loss: 3.393954e-05, l1: 0.76987, l2: 0.31609\n",
            "Loss: 3.393274e-05, l1: 0.76951, l2: 0.31605\n",
            "Loss: 3.392642e-05, l1: 0.76920, l2: 0.31601\n",
            "Loss: 3.391849e-05, l1: 0.76888, l2: 0.31597\n",
            "Loss: 3.390688e-05, l1: 0.76836, l2: 0.31593\n",
            "Loss: 3.412426e-05, l1: 0.76755, l2: 0.31574\n",
            "Loss: 3.390458e-05, l1: 0.76828, l2: 0.31591\n",
            "Loss: 3.389470e-05, l1: 0.76841, l2: 0.31590\n",
            "Loss: 3.388621e-05, l1: 0.76875, l2: 0.31591\n",
            "Loss: 3.388055e-05, l1: 0.76899, l2: 0.31592\n",
            "Loss: 3.387689e-05, l1: 0.76913, l2: 0.31593\n",
            "Loss: 3.387167e-05, l1: 0.76909, l2: 0.31593\n",
            "Loss: 3.386903e-05, l1: 0.76987, l2: 0.31599\n",
            "Loss: 3.386095e-05, l1: 0.76961, l2: 0.31597\n",
            "Loss: 3.385660e-05, l1: 0.76969, l2: 0.31597\n",
            "Loss: 3.385048e-05, l1: 0.77008, l2: 0.31599\n",
            "Loss: 3.385820e-05, l1: 0.76983, l2: 0.31604\n",
            "Loss: 3.384726e-05, l1: 0.76999, l2: 0.31601\n",
            "Loss: 3.384193e-05, l1: 0.77077, l2: 0.31605\n",
            "Loss: 3.383720e-05, l1: 0.77134, l2: 0.31608\n",
            "Loss: 3.383164e-05, l1: 0.77217, l2: 0.31609\n",
            "Loss: 3.387052e-05, l1: 0.77318, l2: 0.31629\n",
            "Loss: 3.382655e-05, l1: 0.77242, l2: 0.31614\n",
            "Loss: 3.381991e-05, l1: 0.77214, l2: 0.31612\n",
            "Loss: 3.381612e-05, l1: 0.77168, l2: 0.31616\n",
            "Loss: 3.381072e-05, l1: 0.77167, l2: 0.31611\n",
            "Loss: 3.380623e-05, l1: 0.77174, l2: 0.31613\n",
            "Loss: 3.380308e-05, l1: 0.77175, l2: 0.31614\n",
            "Loss: 3.379952e-05, l1: 0.77183, l2: 0.31616\n",
            "Loss: 3.379601e-05, l1: 0.77186, l2: 0.31617\n",
            "Loss: 3.379253e-05, l1: 0.77176, l2: 0.31616\n",
            "Loss: 3.378964e-05, l1: 0.77183, l2: 0.31615\n",
            "Loss: 3.378384e-05, l1: 0.77190, l2: 0.31614\n",
            "Loss: 3.377686e-05, l1: 0.77197, l2: 0.31617\n",
            "Loss: 3.376770e-05, l1: 0.77251, l2: 0.31621\n",
            "Loss: 3.377016e-05, l1: 0.77235, l2: 0.31628\n",
            "Loss: 3.376397e-05, l1: 0.77244, l2: 0.31624\n",
            "Loss: 3.376005e-05, l1: 0.77270, l2: 0.31625\n",
            "Loss: 3.375599e-05, l1: 0.77304, l2: 0.31626\n",
            "Loss: 3.375266e-05, l1: 0.77329, l2: 0.31626\n",
            "Loss: 3.374889e-05, l1: 0.77357, l2: 0.31626\n",
            "Loss: 3.374701e-05, l1: 0.77373, l2: 0.31627\n",
            "Loss: 3.374342e-05, l1: 0.77371, l2: 0.31629\n",
            "Loss: 3.373914e-05, l1: 0.77365, l2: 0.31628\n",
            "Loss: 3.373468e-05, l1: 0.77361, l2: 0.31628\n",
            "Loss: 3.372824e-05, l1: 0.77349, l2: 0.31628\n",
            "Loss: 3.372252e-05, l1: 0.77349, l2: 0.31628\n",
            "Loss: 3.371686e-05, l1: 0.77355, l2: 0.31628\n",
            "Loss: 3.371089e-05, l1: 0.77348, l2: 0.31627\n",
            "Loss: 3.370388e-05, l1: 0.77341, l2: 0.31623\n",
            "Loss: 3.369226e-05, l1: 0.77338, l2: 0.31623\n",
            "Loss: 3.368206e-05, l1: 0.77333, l2: 0.31623\n",
            "Loss: 3.366954e-05, l1: 0.77349, l2: 0.31626\n",
            "Loss: 3.365158e-05, l1: 0.77456, l2: 0.31630\n",
            "Loss: 3.363551e-05, l1: 0.77485, l2: 0.31633\n",
            "Loss: 3.361224e-05, l1: 0.77621, l2: 0.31637\n",
            "Loss: 3.361641e-05, l1: 0.77624, l2: 0.31638\n",
            "Loss: 3.360643e-05, l1: 0.77622, l2: 0.31637\n",
            "Loss: 3.358878e-05, l1: 0.77645, l2: 0.31633\n",
            "Loss: 3.357694e-05, l1: 0.77598, l2: 0.31631\n",
            "Loss: 3.356805e-05, l1: 0.77591, l2: 0.31630\n",
            "Loss: 3.356143e-05, l1: 0.77582, l2: 0.31630\n",
            "Loss: 3.355130e-05, l1: 0.77587, l2: 0.31631\n",
            "Loss: 3.354182e-05, l1: 0.77609, l2: 0.31632\n",
            "Loss: 3.356714e-05, l1: 0.77633, l2: 0.31633\n",
            "Loss: 3.353500e-05, l1: 0.77616, l2: 0.31633\n",
            "Loss: 3.350854e-05, l1: 0.77716, l2: 0.31637\n",
            "Loss: 3.348610e-05, l1: 0.77799, l2: 0.31640\n",
            "Loss: 3.344927e-05, l1: 0.77921, l2: 0.31641\n",
            "Loss: 3.347855e-05, l1: 0.77971, l2: 0.31635\n",
            "Loss: 3.344209e-05, l1: 0.77936, l2: 0.31639\n",
            "Loss: 3.341777e-05, l1: 0.78001, l2: 0.31638\n",
            "Loss: 3.338578e-05, l1: 0.78033, l2: 0.31634\n",
            "Loss: 3.341003e-05, l1: 0.78082, l2: 0.31622\n",
            "Loss: 3.337007e-05, l1: 0.78052, l2: 0.31629\n",
            "Loss: 3.333401e-05, l1: 0.77994, l2: 0.31624\n",
            "Loss: 3.330487e-05, l1: 0.77956, l2: 0.31622\n",
            "Loss: 3.329748e-05, l1: 0.77940, l2: 0.31625\n",
            "Loss: 3.328639e-05, l1: 0.77828, l2: 0.31624\n",
            "Loss: 3.327575e-05, l1: 0.77896, l2: 0.31626\n",
            "Loss: 3.326619e-05, l1: 0.77950, l2: 0.31627\n",
            "Loss: 3.325548e-05, l1: 0.78012, l2: 0.31630\n",
            "Loss: 3.324205e-05, l1: 0.78086, l2: 0.31633\n",
            "Loss: 3.323340e-05, l1: 0.78089, l2: 0.31635\n",
            "Loss: 3.322494e-05, l1: 0.78118, l2: 0.31635\n",
            "Loss: 3.322117e-05, l1: 0.78103, l2: 0.31634\n",
            "Loss: 3.321766e-05, l1: 0.78092, l2: 0.31632\n",
            "Loss: 3.321374e-05, l1: 0.78036, l2: 0.31629\n",
            "Loss: 3.320938e-05, l1: 0.78042, l2: 0.31627\n",
            "Loss: 3.320423e-05, l1: 0.78047, l2: 0.31626\n",
            "Loss: 3.319711e-05, l1: 0.78028, l2: 0.31623\n",
            "Loss: 3.319309e-05, l1: 0.78044, l2: 0.31623\n",
            "Loss: 3.318735e-05, l1: 0.78052, l2: 0.31623\n",
            "Loss: 3.318096e-05, l1: 0.78088, l2: 0.31623\n",
            "Loss: 3.317561e-05, l1: 0.78131, l2: 0.31624\n",
            "Loss: 3.317053e-05, l1: 0.78174, l2: 0.31624\n",
            "Loss: 3.316053e-05, l1: 0.78213, l2: 0.31623\n",
            "Loss: 3.342122e-05, l1: 0.78673, l2: 0.31615\n",
            "Loss: 3.315716e-05, l1: 0.78258, l2: 0.31622\n",
            "Loss: 3.315058e-05, l1: 0.78309, l2: 0.31619\n",
            "Loss: 3.314507e-05, l1: 0.78291, l2: 0.31619\n",
            "Loss: 3.314118e-05, l1: 0.78302, l2: 0.31620\n",
            "Loss: 3.313816e-05, l1: 0.78316, l2: 0.31621\n",
            "Loss: 3.313102e-05, l1: 0.78362, l2: 0.31622\n",
            "Loss: 3.312360e-05, l1: 0.78415, l2: 0.31623\n",
            "Loss: 3.311592e-05, l1: 0.78515, l2: 0.31628\n",
            "Loss: 3.377279e-05, l1: 0.78903, l2: 0.31613\n",
            "Loss: 3.311340e-05, l1: 0.78542, l2: 0.31627\n",
            "Loss: 3.310585e-05, l1: 0.78577, l2: 0.31627\n",
            "Loss: 3.308919e-05, l1: 0.78678, l2: 0.31628\n",
            "Loss: 3.307010e-05, l1: 0.78809, l2: 0.31628\n",
            "Loss: 3.304763e-05, l1: 0.78882, l2: 0.31626\n",
            "Loss: 3.303781e-05, l1: 0.78945, l2: 0.31623\n",
            "Loss: 3.303523e-05, l1: 0.78938, l2: 0.31622\n",
            "Loss: 3.302992e-05, l1: 0.78957, l2: 0.31624\n",
            "Loss: 3.302657e-05, l1: 0.78972, l2: 0.31625\n",
            "Loss: 3.302020e-05, l1: 0.79020, l2: 0.31628\n",
            "Loss: 3.301497e-05, l1: 0.79052, l2: 0.31629\n",
            "Loss: 3.300652e-05, l1: 0.79199, l2: 0.31630\n",
            "Loss: 3.307992e-05, l1: 0.79239, l2: 0.31631\n",
            "Loss: 3.299995e-05, l1: 0.79208, l2: 0.31630\n",
            "Loss: 3.298388e-05, l1: 0.79185, l2: 0.31627\n",
            "Loss: 3.296720e-05, l1: 0.79195, l2: 0.31623\n",
            "Loss: 3.295840e-05, l1: 0.79211, l2: 0.31623\n",
            "Loss: 3.294452e-05, l1: 0.79300, l2: 0.31625\n",
            "Loss: 3.293276e-05, l1: 0.79377, l2: 0.31626\n",
            "Loss: 3.291985e-05, l1: 0.79525, l2: 0.31627\n",
            "Loss: 3.290492e-05, l1: 0.79599, l2: 0.31627\n",
            "Loss: 3.289405e-05, l1: 0.79696, l2: 0.31625\n",
            "Loss: 3.288590e-05, l1: 0.79723, l2: 0.31623\n",
            "Loss: 3.288020e-05, l1: 0.79692, l2: 0.31620\n",
            "Loss: 3.287418e-05, l1: 0.79656, l2: 0.31618\n",
            "Loss: 3.302672e-05, l1: 0.78906, l2: 0.31615\n",
            "Loss: 3.287223e-05, l1: 0.79572, l2: 0.31618\n",
            "Loss: 3.286632e-05, l1: 0.79537, l2: 0.31617\n",
            "Loss: 3.286159e-05, l1: 0.79487, l2: 0.31616\n",
            "Loss: 3.285761e-05, l1: 0.79473, l2: 0.31614\n",
            "Loss: 3.285542e-05, l1: 0.79459, l2: 0.31613\n",
            "Loss: 3.285328e-05, l1: 0.79429, l2: 0.31609\n",
            "Loss: 3.291733e-05, l1: 0.79112, l2: 0.31593\n",
            "Loss: 3.285156e-05, l1: 0.79383, l2: 0.31607\n",
            "Loss: 3.284733e-05, l1: 0.79395, l2: 0.31606\n",
            "Loss: 3.284279e-05, l1: 0.79373, l2: 0.31604\n",
            "Loss: 3.283917e-05, l1: 0.79355, l2: 0.31603\n",
            "Loss: 3.283346e-05, l1: 0.79325, l2: 0.31602\n",
            "Loss: 3.283046e-05, l1: 0.79302, l2: 0.31598\n",
            "Loss: 3.283495e-05, l1: 0.79293, l2: 0.31596\n",
            "Loss: 3.282432e-05, l1: 0.79298, l2: 0.31597\n",
            "Loss: 3.282081e-05, l1: 0.79310, l2: 0.31597\n",
            "Loss: 3.281460e-05, l1: 0.79315, l2: 0.31598\n",
            "Loss: 3.280794e-05, l1: 0.79333, l2: 0.31602\n",
            "Loss: 3.280560e-05, l1: 0.79376, l2: 0.31599\n",
            "Loss: 3.279811e-05, l1: 0.79342, l2: 0.31599\n",
            "Loss: 3.279353e-05, l1: 0.79316, l2: 0.31598\n",
            "Loss: 3.278913e-05, l1: 0.79313, l2: 0.31597\n",
            "Loss: 3.278656e-05, l1: 0.79312, l2: 0.31595\n",
            "Loss: 3.282687e-05, l1: 0.79460, l2: 0.31592\n",
            "Loss: 3.278489e-05, l1: 0.79334, l2: 0.31595\n",
            "Loss: 3.277966e-05, l1: 0.79367, l2: 0.31593\n",
            "Loss: 3.277187e-05, l1: 0.79387, l2: 0.31592\n",
            "Loss: 3.276347e-05, l1: 0.79481, l2: 0.31593\n",
            "Loss: 3.275731e-05, l1: 0.79505, l2: 0.31595\n",
            "Loss: 3.275513e-05, l1: 0.79517, l2: 0.31597\n",
            "Loss: 3.275193e-05, l1: 0.79533, l2: 0.31597\n",
            "Loss: 3.274531e-05, l1: 0.79554, l2: 0.31596\n",
            "Loss: 3.273924e-05, l1: 0.79571, l2: 0.31594\n",
            "Loss: 3.273084e-05, l1: 0.79598, l2: 0.31590\n",
            "Loss: 3.273142e-05, l1: 0.79749, l2: 0.31580\n",
            "Loss: 3.272556e-05, l1: 0.79672, l2: 0.31585\n",
            "Loss: 3.280332e-05, l1: 0.79677, l2: 0.31571\n",
            "Loss: 3.272239e-05, l1: 0.79673, l2: 0.31583\n",
            "Loss: 3.271292e-05, l1: 0.79667, l2: 0.31580\n",
            "Loss: 3.269716e-05, l1: 0.79650, l2: 0.31575\n",
            "Loss: 3.268904e-05, l1: 0.79645, l2: 0.31574\n",
            "Loss: 3.268194e-05, l1: 0.79622, l2: 0.31571\n",
            "Loss: 3.274907e-05, l1: 0.79738, l2: 0.31581\n",
            "Loss: 3.267722e-05, l1: 0.79646, l2: 0.31573\n",
            "Loss: 3.266858e-05, l1: 0.79671, l2: 0.31573\n",
            "Loss: 3.265144e-05, l1: 0.79720, l2: 0.31575\n",
            "Loss: 3.264596e-05, l1: 0.79762, l2: 0.31575\n",
            "Loss: 3.263769e-05, l1: 0.79786, l2: 0.31574\n",
            "Loss: 3.262965e-05, l1: 0.79787, l2: 0.31573\n",
            "Loss: 3.263324e-05, l1: 0.79798, l2: 0.31572\n",
            "Loss: 3.262396e-05, l1: 0.79792, l2: 0.31573\n",
            "Loss: 3.261952e-05, l1: 0.79779, l2: 0.31573\n",
            "Loss: 3.261713e-05, l1: 0.79783, l2: 0.31572\n",
            "Loss: 3.261533e-05, l1: 0.79793, l2: 0.31570\n",
            "Loss: 3.261422e-05, l1: 0.79792, l2: 0.31569\n",
            "Loss: 3.261253e-05, l1: 0.79799, l2: 0.31568\n",
            "Loss: 3.261180e-05, l1: 0.79776, l2: 0.31566\n",
            "Loss: 3.261638e-05, l1: 0.79793, l2: 0.31566\n",
            "Loss: 3.261112e-05, l1: 0.79781, l2: 0.31566\n",
            "Loss: 3.260946e-05, l1: 0.79780, l2: 0.31566\n",
            "Loss: 3.260711e-05, l1: 0.79786, l2: 0.31566\n",
            "Loss: 3.260573e-05, l1: 0.79804, l2: 0.31566\n",
            "Loss: 3.260357e-05, l1: 0.79846, l2: 0.31566\n",
            "Loss: 3.260031e-05, l1: 0.79904, l2: 0.31565\n",
            "Loss: 3.259669e-05, l1: 0.79922, l2: 0.31564\n",
            "Loss: 3.259449e-05, l1: 0.79920, l2: 0.31563\n",
            "Loss: 3.259171e-05, l1: 0.79901, l2: 0.31561\n",
            "Loss: 3.258797e-05, l1: 0.79864, l2: 0.31558\n",
            "Loss: 3.258406e-05, l1: 0.79818, l2: 0.31556\n",
            "Loss: 3.257956e-05, l1: 0.79823, l2: 0.31554\n",
            "Loss: 3.257321e-05, l1: 0.79834, l2: 0.31552\n",
            "Loss: 3.256950e-05, l1: 0.79834, l2: 0.31550\n",
            "Loss: 3.256577e-05, l1: 0.79857, l2: 0.31549\n",
            "Loss: 3.256329e-05, l1: 0.79822, l2: 0.31549\n",
            "Loss: 3.256043e-05, l1: 0.79833, l2: 0.31549\n",
            "Loss: 3.255683e-05, l1: 0.79825, l2: 0.31549\n",
            "Loss: 3.255366e-05, l1: 0.79814, l2: 0.31548\n",
            "Loss: 3.254871e-05, l1: 0.79812, l2: 0.31546\n",
            "Loss: 3.254338e-05, l1: 0.79812, l2: 0.31543\n",
            "Loss: 3.254032e-05, l1: 0.79834, l2: 0.31540\n",
            "Loss: 3.253650e-05, l1: 0.79848, l2: 0.31539\n",
            "Loss: 3.253410e-05, l1: 0.79875, l2: 0.31536\n",
            "Loss: 3.253246e-05, l1: 0.79873, l2: 0.31536\n",
            "Loss: 3.252920e-05, l1: 0.79866, l2: 0.31537\n",
            "Loss: 3.252673e-05, l1: 0.79856, l2: 0.31537\n",
            "Loss: 3.252381e-05, l1: 0.79839, l2: 0.31536\n",
            "Loss: 3.251875e-05, l1: 0.79804, l2: 0.31534\n",
            "Loss: 3.251511e-05, l1: 0.79780, l2: 0.31533\n",
            "Loss: 3.251324e-05, l1: 0.79714, l2: 0.31530\n",
            "Loss: 3.251430e-05, l1: 0.79537, l2: 0.31527\n",
            "Loss: 3.250991e-05, l1: 0.79631, l2: 0.31528\n",
            "Loss: 3.250650e-05, l1: 0.79699, l2: 0.31533\n",
            "Loss: 3.250287e-05, l1: 0.79676, l2: 0.31533\n",
            "Loss: 3.250059e-05, l1: 0.79659, l2: 0.31533\n",
            "Loss: 3.249836e-05, l1: 0.79661, l2: 0.31532\n",
            "Loss: 3.249741e-05, l1: 0.79696, l2: 0.31531\n",
            "Loss: 3.249556e-05, l1: 0.79699, l2: 0.31531\n",
            "Loss: 3.249285e-05, l1: 0.79714, l2: 0.31532\n",
            "Loss: 3.248828e-05, l1: 0.79775, l2: 0.31534\n",
            "Loss: 3.248433e-05, l1: 0.79837, l2: 0.31536\n",
            "Loss: 3.249398e-05, l1: 0.80001, l2: 0.31543\n",
            "Loss: 3.248164e-05, l1: 0.79886, l2: 0.31538\n",
            "Loss: 3.247906e-05, l1: 0.79911, l2: 0.31538\n",
            "Loss: 3.247666e-05, l1: 0.79927, l2: 0.31538\n",
            "Loss: 3.247272e-05, l1: 0.79937, l2: 0.31537\n",
            "Loss: 3.246771e-05, l1: 0.79962, l2: 0.31536\n",
            "Loss: 3.246088e-05, l1: 0.79967, l2: 0.31533\n",
            "Loss: 3.248529e-05, l1: 0.80037, l2: 0.31528\n",
            "Loss: 3.245959e-05, l1: 0.79983, l2: 0.31532\n",
            "Loss: 3.245639e-05, l1: 0.79976, l2: 0.31533\n",
            "Loss: 3.245214e-05, l1: 0.79982, l2: 0.31536\n",
            "Loss: 3.244967e-05, l1: 0.79984, l2: 0.31538\n",
            "Loss: 3.244549e-05, l1: 0.80008, l2: 0.31540\n",
            "Loss: 3.244707e-05, l1: 0.80040, l2: 0.31541\n",
            "Loss: 3.244349e-05, l1: 0.80021, l2: 0.31541\n",
            "Loss: 3.244008e-05, l1: 0.80047, l2: 0.31543\n",
            "Loss: 3.243566e-05, l1: 0.80038, l2: 0.31545\n",
            "Loss: 3.243231e-05, l1: 0.80042, l2: 0.31547\n",
            "Loss: 3.242811e-05, l1: 0.80053, l2: 0.31548\n",
            "Loss: 3.242945e-05, l1: 0.79963, l2: 0.31556\n",
            "Loss: 3.242391e-05, l1: 0.80012, l2: 0.31552\n",
            "Loss: 3.241886e-05, l1: 0.80113, l2: 0.31560\n",
            "Loss: 3.240345e-05, l1: 0.80063, l2: 0.31557\n",
            "Loss: 3.239050e-05, l1: 0.80033, l2: 0.31557\n",
            "Loss: 3.237835e-05, l1: 0.80083, l2: 0.31564\n",
            "Loss: 3.241682e-05, l1: 0.79863, l2: 0.31575\n",
            "Loss: 3.237096e-05, l1: 0.80020, l2: 0.31567\n",
            "Loss: 3.236550e-05, l1: 0.80029, l2: 0.31569\n",
            "Loss: 3.235690e-05, l1: 0.80045, l2: 0.31573\n",
            "Loss: 3.235027e-05, l1: 0.80046, l2: 0.31575\n",
            "Loss: 3.233890e-05, l1: 0.80067, l2: 0.31575\n",
            "Loss: 3.233581e-05, l1: 0.79947, l2: 0.31576\n",
            "Loss: 3.232688e-05, l1: 0.79997, l2: 0.31574\n",
            "Loss: 3.231669e-05, l1: 0.80016, l2: 0.31573\n",
            "Loss: 3.229686e-05, l1: 0.80022, l2: 0.31570\n",
            "Loss: 3.227018e-05, l1: 0.80003, l2: 0.31569\n",
            "Loss: 3.223877e-05, l1: 0.79956, l2: 0.31571\n",
            "Loss: 3.235083e-05, l1: 0.80174, l2: 0.31566\n",
            "Loss: 3.223274e-05, l1: 0.79997, l2: 0.31570\n",
            "Loss: 3.220975e-05, l1: 0.79970, l2: 0.31573\n",
            "Loss: 3.219346e-05, l1: 0.79980, l2: 0.31576\n",
            "Loss: 3.217523e-05, l1: 0.80001, l2: 0.31578\n",
            "Loss: 3.215463e-05, l1: 0.80052, l2: 0.31577\n",
            "Loss: 3.214373e-05, l1: 0.79985, l2: 0.31573\n",
            "Loss: 3.212870e-05, l1: 0.79999, l2: 0.31572\n",
            "Loss: 3.211770e-05, l1: 0.79953, l2: 0.31571\n",
            "Loss: 3.211036e-05, l1: 0.79891, l2: 0.31571\n",
            "Loss: 3.209976e-05, l1: 0.79839, l2: 0.31573\n",
            "Loss: 3.209837e-05, l1: 0.79743, l2: 0.31576\n",
            "Loss: 3.209180e-05, l1: 0.79789, l2: 0.31575\n",
            "Loss: 3.236332e-05, l1: 0.79731, l2: 0.31613\n",
            "Loss: 3.208722e-05, l1: 0.79782, l2: 0.31579\n",
            "Loss: 3.207748e-05, l1: 0.79750, l2: 0.31580\n",
            "Loss: 3.206820e-05, l1: 0.79760, l2: 0.31580\n",
            "Loss: 3.205871e-05, l1: 0.79783, l2: 0.31580\n",
            "Loss: 3.204971e-05, l1: 0.79892, l2: 0.31585\n",
            "Loss: 3.201733e-05, l1: 0.79907, l2: 0.31580\n",
            "Loss: 3.197564e-05, l1: 0.79926, l2: 0.31586\n",
            "Loss: 3.192745e-05, l1: 0.79968, l2: 0.31594\n",
            "Loss: 3.187653e-05, l1: 0.80026, l2: 0.31601\n",
            "Loss: 3.182030e-05, l1: 0.80075, l2: 0.31608\n",
            "Loss: 3.178664e-05, l1: 0.80345, l2: 0.31596\n",
            "Loss: 3.175951e-05, l1: 0.80215, l2: 0.31602\n",
            "Loss: 3.176379e-05, l1: 0.80184, l2: 0.31603\n",
            "Loss: 3.170483e-05, l1: 0.80199, l2: 0.31602\n",
            "Loss: 3.165299e-05, l1: 0.80363, l2: 0.31594\n",
            "Loss: 3.156792e-05, l1: 0.80260, l2: 0.31589\n",
            "Loss: 3.151946e-05, l1: 0.80351, l2: 0.31583\n",
            "Loss: 3.145515e-05, l1: 0.80493, l2: 0.31579\n",
            "Loss: 3.140903e-05, l1: 0.80606, l2: 0.31577\n",
            "Loss: 3.134677e-05, l1: 0.80823, l2: 0.31578\n",
            "Loss: 3.131701e-05, l1: 0.80843, l2: 0.31584\n",
            "Loss: 3.128392e-05, l1: 0.80855, l2: 0.31585\n",
            "Loss: 3.127461e-05, l1: 0.80954, l2: 0.31583\n",
            "Loss: 3.126917e-05, l1: 0.81051, l2: 0.31583\n",
            "Loss: 3.125069e-05, l1: 0.81070, l2: 0.31583\n",
            "Loss: 3.124902e-05, l1: 0.81113, l2: 0.31584\n",
            "Loss: 3.123417e-05, l1: 0.81097, l2: 0.31585\n",
            "Loss: 3.122631e-05, l1: 0.81124, l2: 0.31584\n",
            "Loss: 3.121451e-05, l1: 0.81154, l2: 0.31584\n",
            "Loss: 3.120279e-05, l1: 0.81167, l2: 0.31584\n",
            "Loss: 3.119001e-05, l1: 0.81189, l2: 0.31586\n",
            "Loss: 3.117649e-05, l1: 0.81230, l2: 0.31591\n",
            "Loss: 3.117021e-05, l1: 0.81246, l2: 0.31595\n",
            "Loss: 3.116599e-05, l1: 0.81301, l2: 0.31597\n",
            "Loss: 3.116434e-05, l1: 0.81300, l2: 0.31597\n",
            "Loss: 3.116105e-05, l1: 0.81319, l2: 0.31599\n",
            "Loss: 3.115557e-05, l1: 0.81361, l2: 0.31603\n",
            "Loss: 3.114789e-05, l1: 0.81427, l2: 0.31605\n",
            "Loss: 3.113932e-05, l1: 0.81468, l2: 0.31610\n",
            "Loss: 3.112677e-05, l1: 0.81611, l2: 0.31608\n",
            "Loss: 3.111317e-05, l1: 0.81570, l2: 0.31603\n",
            "Loss: 3.109945e-05, l1: 0.81588, l2: 0.31602\n",
            "Loss: 3.109007e-05, l1: 0.81594, l2: 0.31603\n",
            "Loss: 3.107975e-05, l1: 0.81636, l2: 0.31606\n",
            "Loss: 3.107282e-05, l1: 0.81657, l2: 0.31608\n",
            "Loss: 3.106094e-05, l1: 0.81690, l2: 0.31612\n",
            "Loss: 3.105835e-05, l1: 0.81678, l2: 0.31613\n",
            "Loss: 3.106089e-05, l1: 0.81692, l2: 0.31607\n",
            "Loss: 3.104656e-05, l1: 0.81685, l2: 0.31610\n",
            "Loss: 3.103641e-05, l1: 0.81733, l2: 0.31616\n",
            "Loss: 3.102539e-05, l1: 0.81806, l2: 0.31608\n",
            "Loss: 3.101385e-05, l1: 0.81740, l2: 0.31604\n",
            "Loss: 3.100391e-05, l1: 0.81761, l2: 0.31608\n",
            "Loss: 3.099549e-05, l1: 0.81800, l2: 0.31609\n",
            "Loss: 3.098669e-05, l1: 0.81862, l2: 0.31607\n",
            "Loss: 3.097934e-05, l1: 0.81882, l2: 0.31608\n",
            "Loss: 3.096938e-05, l1: 0.81918, l2: 0.31606\n",
            "Loss: 3.095973e-05, l1: 0.81919, l2: 0.31607\n",
            "Loss: 3.094615e-05, l1: 0.81880, l2: 0.31609\n",
            "Loss: 3.093045e-05, l1: 0.81860, l2: 0.31606\n",
            "Loss: 3.091329e-05, l1: 0.81823, l2: 0.31607\n",
            "Loss: 3.089808e-05, l1: 0.81827, l2: 0.31606\n",
            "Loss: 3.088838e-05, l1: 0.81860, l2: 0.31605\n",
            "Loss: 3.088173e-05, l1: 0.81898, l2: 0.31605\n",
            "Loss: 3.087067e-05, l1: 0.81928, l2: 0.31606\n",
            "Loss: 3.085336e-05, l1: 0.81966, l2: 0.31610\n",
            "Loss: 3.083459e-05, l1: 0.81960, l2: 0.31613\n",
            "Loss: 3.080935e-05, l1: 0.81961, l2: 0.31620\n",
            "Loss: 3.078727e-05, l1: 0.81923, l2: 0.31620\n",
            "Loss: 3.076567e-05, l1: 0.81912, l2: 0.31618\n",
            "Loss: 3.075255e-05, l1: 0.81927, l2: 0.31614\n",
            "Loss: 3.074548e-05, l1: 0.81973, l2: 0.31612\n",
            "Loss: 3.079941e-05, l1: 0.81998, l2: 0.31607\n",
            "Loss: 3.074202e-05, l1: 0.81978, l2: 0.31611\n",
            "Loss: 3.073623e-05, l1: 0.82069, l2: 0.31609\n",
            "Loss: 3.072535e-05, l1: 0.82238, l2: 0.31613\n",
            "Loss: 3.071463e-05, l1: 0.82194, l2: 0.31614\n",
            "Loss: 3.070988e-05, l1: 0.82189, l2: 0.31615\n",
            "Loss: 3.070493e-05, l1: 0.82228, l2: 0.31615\n",
            "Loss: 3.069886e-05, l1: 0.82280, l2: 0.31616\n",
            "Loss: 3.068467e-05, l1: 0.82406, l2: 0.31618\n",
            "Loss: 3.066400e-05, l1: 0.82517, l2: 0.31624\n",
            "Loss: 3.064350e-05, l1: 0.82673, l2: 0.31630\n",
            "Loss: 3.063665e-05, l1: 0.82725, l2: 0.31636\n",
            "Loss: 3.062523e-05, l1: 0.82900, l2: 0.31639\n",
            "Loss: 3.061693e-05, l1: 0.82837, l2: 0.31638\n",
            "Loss: 3.060906e-05, l1: 0.82857, l2: 0.31638\n",
            "Loss: 3.059426e-05, l1: 0.82904, l2: 0.31640\n",
            "Loss: 3.060088e-05, l1: 0.83016, l2: 0.31643\n",
            "Loss: 3.058685e-05, l1: 0.82952, l2: 0.31641\n",
            "Loss: 3.057312e-05, l1: 0.82998, l2: 0.31647\n",
            "Loss: 3.055144e-05, l1: 0.83047, l2: 0.31658\n",
            "Loss: 3.054557e-05, l1: 0.82971, l2: 0.31659\n",
            "Loss: 3.053834e-05, l1: 0.82953, l2: 0.31656\n",
            "Loss: 3.053619e-05, l1: 0.82944, l2: 0.31655\n",
            "Loss: 3.053044e-05, l1: 0.82917, l2: 0.31652\n",
            "Loss: 3.052313e-05, l1: 0.82906, l2: 0.31649\n",
            "Loss: 3.051601e-05, l1: 0.82870, l2: 0.31647\n",
            "Loss: 3.053460e-05, l1: 0.82982, l2: 0.31648\n",
            "Loss: 3.050908e-05, l1: 0.82909, l2: 0.31647\n",
            "Loss: 3.050316e-05, l1: 0.82914, l2: 0.31648\n",
            "Loss: 3.049772e-05, l1: 0.82929, l2: 0.31651\n",
            "Loss: 3.048847e-05, l1: 0.82903, l2: 0.31649\n",
            "Loss: 3.047693e-05, l1: 0.82813, l2: 0.31644\n",
            "Loss: 3.057150e-05, l1: 0.82826, l2: 0.31623\n",
            "Loss: 3.047452e-05, l1: 0.82815, l2: 0.31641\n",
            "Loss: 3.137605e-05, l1: 0.82322, l2: 0.31611\n",
            "Loss: 3.047326e-05, l1: 0.82798, l2: 0.31640\n",
            "Loss: 3.046372e-05, l1: 0.82756, l2: 0.31638\n",
            "Loss: 3.044984e-05, l1: 0.82732, l2: 0.31634\n",
            "Loss: 3.043188e-05, l1: 0.82694, l2: 0.31630\n",
            "Loss: 3.042037e-05, l1: 0.82683, l2: 0.31614\n",
            "Loss: 3.039248e-05, l1: 0.82695, l2: 0.31616\n",
            "Loss: 3.037096e-05, l1: 0.82683, l2: 0.31617\n",
            "Loss: 3.035156e-05, l1: 0.82652, l2: 0.31612\n",
            "Loss: 3.033531e-05, l1: 0.82566, l2: 0.31607\n",
            "Loss: 3.031925e-05, l1: 0.82471, l2: 0.31602\n",
            "Loss: 3.030266e-05, l1: 0.82350, l2: 0.31598\n",
            "Loss: 3.030227e-05, l1: 0.82228, l2: 0.31587\n",
            "Loss: 3.029352e-05, l1: 0.82289, l2: 0.31592\n",
            "Loss: 3.027724e-05, l1: 0.82235, l2: 0.31594\n",
            "Loss: 3.025812e-05, l1: 0.82259, l2: 0.31596\n",
            "Loss: 3.022876e-05, l1: 0.82306, l2: 0.31599\n",
            "Loss: 3.022760e-05, l1: 0.82472, l2: 0.31600\n",
            "Loss: 3.021848e-05, l1: 0.82377, l2: 0.31599\n",
            "Loss: 3.019444e-05, l1: 0.82462, l2: 0.31596\n",
            "Loss: 3.016342e-05, l1: 0.82536, l2: 0.31596\n",
            "Loss: 3.022918e-05, l1: 0.82616, l2: 0.31582\n",
            "Loss: 3.015609e-05, l1: 0.82555, l2: 0.31592\n",
            "Loss: 3.013637e-05, l1: 0.82539, l2: 0.31589\n",
            "Loss: 3.011974e-05, l1: 0.82571, l2: 0.31590\n",
            "Loss: 3.010903e-05, l1: 0.82568, l2: 0.31591\n",
            "Loss: 3.010792e-05, l1: 0.82546, l2: 0.31592\n",
            "Loss: 3.010493e-05, l1: 0.82557, l2: 0.31591\n",
            "Loss: 3.010391e-05, l1: 0.82568, l2: 0.31591\n",
            "Loss: 3.009969e-05, l1: 0.82563, l2: 0.31591\n",
            "Loss: 3.009637e-05, l1: 0.82558, l2: 0.31590\n",
            "Loss: 3.008797e-05, l1: 0.82539, l2: 0.31587\n",
            "Loss: 3.011337e-05, l1: 0.82563, l2: 0.31589\n",
            "Loss: 3.008261e-05, l1: 0.82546, l2: 0.31587\n",
            "Loss: 3.007075e-05, l1: 0.82528, l2: 0.31584\n",
            "Loss: 3.004605e-05, l1: 0.82511, l2: 0.31580\n",
            "Loss: 3.002409e-05, l1: 0.82508, l2: 0.31581\n",
            "Loss: 3.000915e-05, l1: 0.82546, l2: 0.31583\n",
            "Loss: 2.999145e-05, l1: 0.82539, l2: 0.31587\n",
            "Loss: 2.998041e-05, l1: 0.82563, l2: 0.31590\n",
            "Loss: 3.010402e-05, l1: 0.82232, l2: 0.31571\n",
            "Loss: 2.997274e-05, l1: 0.82495, l2: 0.31586\n",
            "Loss: 2.994965e-05, l1: 0.82551, l2: 0.31592\n",
            "Loss: 2.994084e-05, l1: 0.82521, l2: 0.31589\n",
            "Loss: 2.991514e-05, l1: 0.82392, l2: 0.31581\n",
            "Loss: 2.998293e-05, l1: 0.82152, l2: 0.31556\n",
            "Loss: 2.991201e-05, l1: 0.82347, l2: 0.31576\n",
            "Loss: 2.989807e-05, l1: 0.82345, l2: 0.31576\n",
            "Loss: 2.988311e-05, l1: 0.82364, l2: 0.31579\n",
            "Loss: 2.986866e-05, l1: 0.82398, l2: 0.31583\n",
            "Loss: 2.986172e-05, l1: 0.82449, l2: 0.31586\n",
            "Loss: 2.987953e-05, l1: 0.82433, l2: 0.31603\n",
            "Loss: 2.985211e-05, l1: 0.82443, l2: 0.31592\n",
            "Loss: 2.984533e-05, l1: 0.82407, l2: 0.31589\n",
            "Loss: 2.983695e-05, l1: 0.82366, l2: 0.31586\n",
            "Loss: 2.982284e-05, l1: 0.82278, l2: 0.31581\n",
            "Loss: 2.980848e-05, l1: 0.82193, l2: 0.31578\n",
            "Loss: 2.981130e-05, l1: 0.82117, l2: 0.31570\n",
            "Loss: 2.980312e-05, l1: 0.82159, l2: 0.31575\n",
            "Loss: 2.979100e-05, l1: 0.82107, l2: 0.31577\n",
            "Loss: 2.978596e-05, l1: 0.82089, l2: 0.31577\n",
            "Loss: 2.977919e-05, l1: 0.82103, l2: 0.31580\n",
            "Loss: 2.977360e-05, l1: 0.82082, l2: 0.31581\n",
            "Loss: 2.976126e-05, l1: 0.82031, l2: 0.31582\n",
            "Loss: 2.975267e-05, l1: 0.81978, l2: 0.31580\n",
            "Loss: 2.974494e-05, l1: 0.81952, l2: 0.31580\n",
            "Loss: 2.973744e-05, l1: 0.81922, l2: 0.31578\n",
            "Loss: 2.973284e-05, l1: 0.81921, l2: 0.31578\n",
            "Loss: 2.972835e-05, l1: 0.81927, l2: 0.31580\n",
            "Loss: 2.972498e-05, l1: 0.81917, l2: 0.31582\n",
            "Loss: 2.972151e-05, l1: 0.81894, l2: 0.31583\n",
            "Loss: 2.971770e-05, l1: 0.81861, l2: 0.31586\n",
            "Loss: 2.971391e-05, l1: 0.81822, l2: 0.31586\n",
            "Loss: 2.971019e-05, l1: 0.81790, l2: 0.31587\n",
            "Loss: 2.970593e-05, l1: 0.81744, l2: 0.31585\n",
            "Loss: 2.970735e-05, l1: 0.81659, l2: 0.31586\n",
            "Loss: 2.970139e-05, l1: 0.81705, l2: 0.31586\n",
            "Loss: 2.969391e-05, l1: 0.81654, l2: 0.31584\n",
            "Loss: 2.968297e-05, l1: 0.81589, l2: 0.31586\n",
            "Loss: 2.967930e-05, l1: 0.81558, l2: 0.31586\n",
            "Loss: 2.967576e-05, l1: 0.81556, l2: 0.31592\n",
            "Loss: 2.967032e-05, l1: 0.81577, l2: 0.31589\n",
            "Loss: 2.967451e-05, l1: 0.81577, l2: 0.31590\n",
            "Loss: 2.966632e-05, l1: 0.81577, l2: 0.31590\n",
            "Loss: 2.965960e-05, l1: 0.81596, l2: 0.31592\n",
            "Loss: 2.965167e-05, l1: 0.81654, l2: 0.31598\n",
            "Loss: 2.964711e-05, l1: 0.81667, l2: 0.31598\n",
            "Loss: 2.964368e-05, l1: 0.81660, l2: 0.31598\n",
            "Loss: 2.963657e-05, l1: 0.81659, l2: 0.31597\n",
            "Loss: 2.963088e-05, l1: 0.81667, l2: 0.31596\n",
            "Loss: 2.961506e-05, l1: 0.81686, l2: 0.31593\n",
            "Loss: 2.960360e-05, l1: 0.81729, l2: 0.31592\n",
            "Loss: 2.971391e-05, l1: 0.81613, l2: 0.31573\n",
            "Loss: 2.959801e-05, l1: 0.81708, l2: 0.31589\n",
            "Loss: 2.958717e-05, l1: 0.81739, l2: 0.31589\n",
            "Loss: 2.957776e-05, l1: 0.81793, l2: 0.31592\n",
            "Loss: 2.970313e-05, l1: 0.81805, l2: 0.31579\n",
            "Loss: 2.957704e-05, l1: 0.81794, l2: 0.31591\n",
            "Loss: 2.957238e-05, l1: 0.81767, l2: 0.31592\n",
            "Loss: 2.956845e-05, l1: 0.81759, l2: 0.31592\n",
            "Loss: 2.956576e-05, l1: 0.81745, l2: 0.31592\n",
            "Loss: 2.956104e-05, l1: 0.81717, l2: 0.31592\n",
            "Loss: 2.955583e-05, l1: 0.81692, l2: 0.31594\n",
            "Loss: 2.954930e-05, l1: 0.81663, l2: 0.31594\n",
            "Loss: 2.957286e-05, l1: 0.81721, l2: 0.31600\n",
            "Loss: 2.954740e-05, l1: 0.81677, l2: 0.31596\n",
            "Loss: 2.954294e-05, l1: 0.81689, l2: 0.31596\n",
            "Loss: 2.953743e-05, l1: 0.81722, l2: 0.31597\n",
            "Loss: 2.952642e-05, l1: 0.81776, l2: 0.31597\n",
            "Loss: 2.951952e-05, l1: 0.81817, l2: 0.31595\n",
            "Loss: 2.951461e-05, l1: 0.81864, l2: 0.31595\n",
            "Loss: 2.951124e-05, l1: 0.81862, l2: 0.31593\n",
            "Loss: 2.950657e-05, l1: 0.81872, l2: 0.31598\n",
            "Loss: 2.950502e-05, l1: 0.81871, l2: 0.31598\n",
            "Loss: 2.949743e-05, l1: 0.81860, l2: 0.31600\n",
            "Loss: 2.949456e-05, l1: 0.81861, l2: 0.31601\n",
            "Loss: 2.949071e-05, l1: 0.81848, l2: 0.31602\n",
            "Loss: 2.948665e-05, l1: 0.81825, l2: 0.31601\n",
            "Loss: 2.948160e-05, l1: 0.81788, l2: 0.31601\n",
            "Loss: 2.947594e-05, l1: 0.81724, l2: 0.31599\n",
            "Loss: 2.946944e-05, l1: 0.81667, l2: 0.31598\n",
            "Loss: 2.946502e-05, l1: 0.81620, l2: 0.31597\n",
            "Loss: 2.946025e-05, l1: 0.81595, l2: 0.31598\n",
            "Loss: 2.945544e-05, l1: 0.81601, l2: 0.31600\n",
            "Loss: 2.945096e-05, l1: 0.81633, l2: 0.31604\n",
            "Loss: 2.944596e-05, l1: 0.81657, l2: 0.31603\n",
            "Loss: 2.944332e-05, l1: 0.81662, l2: 0.31603\n",
            "Loss: 2.943505e-05, l1: 0.81672, l2: 0.31604\n",
            "Loss: 2.943309e-05, l1: 0.81663, l2: 0.31605\n",
            "Loss: 2.942915e-05, l1: 0.81667, l2: 0.31607\n",
            "Loss: 2.942453e-05, l1: 0.81701, l2: 0.31613\n",
            "Loss: 2.942076e-05, l1: 0.81725, l2: 0.31615\n",
            "Loss: 2.941659e-05, l1: 0.81750, l2: 0.31617\n",
            "Loss: 2.941391e-05, l1: 0.81781, l2: 0.31621\n",
            "Loss: 2.941127e-05, l1: 0.81792, l2: 0.31623\n",
            "Loss: 2.940934e-05, l1: 0.81804, l2: 0.31623\n",
            "Loss: 2.942737e-05, l1: 0.81659, l2: 0.31632\n",
            "Loss: 2.940571e-05, l1: 0.81763, l2: 0.31626\n",
            "Loss: 2.940094e-05, l1: 0.81769, l2: 0.31625\n",
            "Loss: 2.940221e-05, l1: 0.81715, l2: 0.31621\n",
            "Loss: 2.939547e-05, l1: 0.81743, l2: 0.31623\n",
            "Loss: 2.938955e-05, l1: 0.81723, l2: 0.31623\n",
            "Loss: 2.938572e-05, l1: 0.81728, l2: 0.31624\n",
            "Loss: 2.937575e-05, l1: 0.81710, l2: 0.31627\n",
            "Loss: 2.936693e-05, l1: 0.81718, l2: 0.31630\n",
            "Loss: 2.935594e-05, l1: 0.81734, l2: 0.31635\n",
            "Loss: 2.934892e-05, l1: 0.81721, l2: 0.31638\n",
            "Loss: 2.934104e-05, l1: 0.81710, l2: 0.31642\n",
            "Loss: 2.933525e-05, l1: 0.81703, l2: 0.31645\n",
            "Loss: 2.933122e-05, l1: 0.81701, l2: 0.31646\n",
            "Loss: 2.932830e-05, l1: 0.81700, l2: 0.31646\n",
            "Loss: 3.001521e-05, l1: 0.82160, l2: 0.31696\n",
            "Loss: 2.932807e-05, l1: 0.81711, l2: 0.31647\n",
            "Loss: 2.932503e-05, l1: 0.81724, l2: 0.31645\n",
            "Loss: 2.932328e-05, l1: 0.81728, l2: 0.31644\n",
            "Loss: 2.931821e-05, l1: 0.81764, l2: 0.31644\n",
            "Loss: 2.932449e-05, l1: 0.81848, l2: 0.31653\n",
            "Loss: 2.931510e-05, l1: 0.81796, l2: 0.31647\n",
            "Loss: 2.930836e-05, l1: 0.81812, l2: 0.31647\n",
            "Loss: 2.929726e-05, l1: 0.81838, l2: 0.31648\n",
            "Loss: 2.929205e-05, l1: 0.81884, l2: 0.31651\n",
            "Loss: 2.928768e-05, l1: 0.81889, l2: 0.31652\n",
            "Loss: 2.928238e-05, l1: 0.81899, l2: 0.31653\n",
            "Loss: 2.928003e-05, l1: 0.81881, l2: 0.31653\n",
            "Loss: 2.928128e-05, l1: 0.81792, l2: 0.31649\n",
            "Loss: 2.927765e-05, l1: 0.81841, l2: 0.31651\n",
            "Loss: 2.927436e-05, l1: 0.81819, l2: 0.31651\n",
            "Loss: 2.926898e-05, l1: 0.81777, l2: 0.31651\n",
            "Loss: 2.926596e-05, l1: 0.81763, l2: 0.31651\n",
            "Loss: 2.926098e-05, l1: 0.81749, l2: 0.31653\n",
            "Loss: 2.925814e-05, l1: 0.81691, l2: 0.31655\n",
            "Loss: 2.924794e-05, l1: 0.81723, l2: 0.31659\n",
            "Loss: 2.924292e-05, l1: 0.81745, l2: 0.31659\n",
            "Loss: 2.923673e-05, l1: 0.81764, l2: 0.31660\n",
            "Loss: 2.923463e-05, l1: 0.81747, l2: 0.31666\n",
            "Loss: 2.922907e-05, l1: 0.81743, l2: 0.31665\n",
            "Loss: 2.922663e-05, l1: 0.81732, l2: 0.31665\n",
            "Loss: 2.922280e-05, l1: 0.81716, l2: 0.31665\n",
            "Loss: 2.921750e-05, l1: 0.81694, l2: 0.31666\n",
            "Loss: 2.921197e-05, l1: 0.81682, l2: 0.31670\n",
            "Loss: 2.921044e-05, l1: 0.81679, l2: 0.31674\n",
            "Loss: 2.920194e-05, l1: 0.81740, l2: 0.31674\n",
            "Loss: 2.919698e-05, l1: 0.81759, l2: 0.31674\n",
            "Loss: 2.918852e-05, l1: 0.81817, l2: 0.31675\n",
            "Loss: 2.918260e-05, l1: 0.81884, l2: 0.31677\n",
            "Loss: 2.917560e-05, l1: 0.81961, l2: 0.31679\n",
            "Loss: 2.916656e-05, l1: 0.82044, l2: 0.31680\n",
            "Loss: 2.916052e-05, l1: 0.82092, l2: 0.31682\n",
            "Loss: 2.915751e-05, l1: 0.82119, l2: 0.31683\n",
            "Loss: 2.915218e-05, l1: 0.82127, l2: 0.31684\n",
            "Loss: 2.917405e-05, l1: 0.82095, l2: 0.31689\n",
            "Loss: 2.914988e-05, l1: 0.82120, l2: 0.31685\n",
            "Loss: 2.914427e-05, l1: 0.82124, l2: 0.31686\n",
            "Loss: 2.914123e-05, l1: 0.82141, l2: 0.31686\n",
            "Loss: 2.913539e-05, l1: 0.82138, l2: 0.31686\n",
            "Loss: 2.912614e-05, l1: 0.82164, l2: 0.31688\n",
            "Loss: 2.911190e-05, l1: 0.82224, l2: 0.31692\n",
            "Loss: 2.909468e-05, l1: 0.82236, l2: 0.31695\n",
            "Loss: 2.908408e-05, l1: 0.82347, l2: 0.31698\n",
            "Loss: 2.907452e-05, l1: 0.82300, l2: 0.31695\n",
            "Loss: 2.906871e-05, l1: 0.82326, l2: 0.31695\n",
            "Loss: 2.906383e-05, l1: 0.82348, l2: 0.31695\n",
            "Loss: 2.905788e-05, l1: 0.82389, l2: 0.31696\n",
            "Loss: 2.905253e-05, l1: 0.82435, l2: 0.31698\n",
            "Loss: 2.904738e-05, l1: 0.82479, l2: 0.31702\n",
            "Loss: 2.904364e-05, l1: 0.82476, l2: 0.31703\n",
            "Loss: 2.904092e-05, l1: 0.82488, l2: 0.31705\n",
            "Loss: 2.903503e-05, l1: 0.82489, l2: 0.31706\n",
            "Loss: 2.903183e-05, l1: 0.82487, l2: 0.31707\n",
            "Loss: 2.902313e-05, l1: 0.82451, l2: 0.31707\n",
            "Loss: 2.901407e-05, l1: 0.82407, l2: 0.31703\n",
            "Loss: 2.929348e-05, l1: 0.82158, l2: 0.31730\n",
            "Loss: 2.900496e-05, l1: 0.82367, l2: 0.31707\n",
            "Loss: 2.899224e-05, l1: 0.82391, l2: 0.31707\n",
            "Loss: 2.898679e-05, l1: 0.82419, l2: 0.31706\n",
            "Loss: 2.897675e-05, l1: 0.82405, l2: 0.31705\n",
            "Loss: 2.897112e-05, l1: 0.82408, l2: 0.31705\n",
            "Loss: 2.895832e-05, l1: 0.82444, l2: 0.31707\n",
            "Loss: 2.894930e-05, l1: 0.82476, l2: 0.31709\n",
            "Loss: 2.893864e-05, l1: 0.82563, l2: 0.31716\n",
            "Loss: 2.892598e-05, l1: 0.82524, l2: 0.31714\n",
            "Loss: 2.891330e-05, l1: 0.82495, l2: 0.31712\n",
            "Loss: 2.891056e-05, l1: 0.82419, l2: 0.31707\n",
            "Loss: 2.890162e-05, l1: 0.82443, l2: 0.31709\n",
            "Loss: 2.889847e-05, l1: 0.82490, l2: 0.31710\n",
            "Loss: 2.889676e-05, l1: 0.82495, l2: 0.31709\n",
            "Loss: 2.889344e-05, l1: 0.82512, l2: 0.31710\n",
            "Loss: 2.889099e-05, l1: 0.82515, l2: 0.31709\n",
            "Loss: 2.888539e-05, l1: 0.82526, l2: 0.31713\n",
            "Loss: 2.888161e-05, l1: 0.82470, l2: 0.31710\n",
            "Loss: 2.887665e-05, l1: 0.82487, l2: 0.31711\n",
            "Loss: 2.887320e-05, l1: 0.82470, l2: 0.31710\n",
            "Loss: 2.886867e-05, l1: 0.82444, l2: 0.31708\n",
            "Loss: 2.886405e-05, l1: 0.82393, l2: 0.31705\n",
            "Loss: 2.885922e-05, l1: 0.82371, l2: 0.31702\n",
            "Loss: 2.886903e-05, l1: 0.82583, l2: 0.31699\n",
            "Loss: 2.885568e-05, l1: 0.82445, l2: 0.31701\n",
            "Loss: 2.884641e-05, l1: 0.82433, l2: 0.31695\n",
            "Loss: 2.884020e-05, l1: 0.82471, l2: 0.31696\n",
            "Loss: 2.882967e-05, l1: 0.82562, l2: 0.31699\n",
            "Loss: 2.882339e-05, l1: 0.82611, l2: 0.31702\n",
            "Loss: 2.881861e-05, l1: 0.82616, l2: 0.31703\n",
            "Loss: 2.881490e-05, l1: 0.82584, l2: 0.31704\n",
            "Loss: 2.881106e-05, l1: 0.82548, l2: 0.31704\n",
            "Loss: 2.880486e-05, l1: 0.82512, l2: 0.31703\n",
            "Loss: 2.879893e-05, l1: 0.82494, l2: 0.31703\n",
            "Loss: 2.879264e-05, l1: 0.82526, l2: 0.31702\n",
            "Loss: 2.878795e-05, l1: 0.82516, l2: 0.31698\n",
            "Loss: 2.878144e-05, l1: 0.82588, l2: 0.31700\n",
            "Loss: 2.877513e-05, l1: 0.82588, l2: 0.31698\n",
            "Loss: 2.877067e-05, l1: 0.82577, l2: 0.31696\n",
            "Loss: 2.876637e-05, l1: 0.82580, l2: 0.31694\n",
            "Loss: 2.876340e-05, l1: 0.82625, l2: 0.31689\n",
            "Loss: 2.875588e-05, l1: 0.82688, l2: 0.31686\n",
            "Loss: 2.875110e-05, l1: 0.82679, l2: 0.31689\n",
            "Loss: 2.874712e-05, l1: 0.82732, l2: 0.31690\n",
            "Loss: 2.874184e-05, l1: 0.82794, l2: 0.31689\n",
            "Loss: 2.873675e-05, l1: 0.82862, l2: 0.31688\n",
            "Loss: 2.876717e-05, l1: 0.83023, l2: 0.31704\n",
            "Loss: 2.873628e-05, l1: 0.82889, l2: 0.31691\n",
            "Loss: 2.876623e-05, l1: 0.82962, l2: 0.31695\n",
            "Loss: 2.873117e-05, l1: 0.82909, l2: 0.31692\n",
            "Loss: 2.872188e-05, l1: 0.82974, l2: 0.31692\n",
            "Loss: 2.870559e-05, l1: 0.82926, l2: 0.31693\n",
            "Loss: 2.868566e-05, l1: 0.82915, l2: 0.31699\n",
            "Loss: 2.867013e-05, l1: 0.82934, l2: 0.31705\n",
            "Loss: 2.865415e-05, l1: 0.83078, l2: 0.31710\n",
            "Loss: 2.864284e-05, l1: 0.83144, l2: 0.31712\n",
            "Loss: 2.863211e-05, l1: 0.83185, l2: 0.31713\n",
            "Loss: 2.862065e-05, l1: 0.83280, l2: 0.31714\n",
            "Loss: 2.861136e-05, l1: 0.83300, l2: 0.31716\n",
            "Loss: 2.860505e-05, l1: 0.83283, l2: 0.31714\n",
            "Loss: 2.859715e-05, l1: 0.83211, l2: 0.31713\n",
            "Loss: 2.859075e-05, l1: 0.83183, l2: 0.31711\n",
            "Loss: 2.858286e-05, l1: 0.83185, l2: 0.31704\n",
            "Loss: 2.858091e-05, l1: 0.83203, l2: 0.31697\n",
            "Loss: 2.857398e-05, l1: 0.83194, l2: 0.31700\n",
            "Loss: 2.856797e-05, l1: 0.83231, l2: 0.31701\n",
            "Loss: 2.856012e-05, l1: 0.83288, l2: 0.31702\n",
            "Loss: 2.855111e-05, l1: 0.83300, l2: 0.31700\n",
            "Loss: 2.853564e-05, l1: 0.83274, l2: 0.31701\n",
            "Loss: 2.851895e-05, l1: 0.83185, l2: 0.31699\n",
            "Loss: 2.852411e-05, l1: 0.83081, l2: 0.31697\n",
            "Loss: 2.850551e-05, l1: 0.83136, l2: 0.31698\n",
            "Loss: 2.848649e-05, l1: 0.83061, l2: 0.31700\n",
            "Loss: 2.847020e-05, l1: 0.83072, l2: 0.31700\n",
            "Loss: 2.845562e-05, l1: 0.83158, l2: 0.31701\n",
            "Loss: 2.844376e-05, l1: 0.83246, l2: 0.31700\n",
            "Loss: 2.843334e-05, l1: 0.83291, l2: 0.31699\n",
            "Loss: 2.842083e-05, l1: 0.83319, l2: 0.31697\n",
            "Loss: 2.840711e-05, l1: 0.83339, l2: 0.31699\n",
            "Loss: 2.838855e-05, l1: 0.83290, l2: 0.31702\n",
            "Loss: 2.836634e-05, l1: 0.83303, l2: 0.31707\n",
            "Loss: 2.833600e-05, l1: 0.83334, l2: 0.31716\n",
            "Loss: 2.832128e-05, l1: 0.83503, l2: 0.31721\n",
            "Loss: 2.830819e-05, l1: 0.83526, l2: 0.31718\n",
            "Loss: 2.829956e-05, l1: 0.83568, l2: 0.31717\n",
            "Loss: 2.828913e-05, l1: 0.83594, l2: 0.31719\n",
            "Loss: 2.827565e-05, l1: 0.83616, l2: 0.31719\n",
            "Loss: 2.827106e-05, l1: 0.83604, l2: 0.31731\n",
            "Loss: 2.824265e-05, l1: 0.83709, l2: 0.31727\n",
            "Loss: 2.823020e-05, l1: 0.83755, l2: 0.31728\n",
            "Loss: 2.822206e-05, l1: 0.83833, l2: 0.31731\n",
            "Loss: 2.821528e-05, l1: 0.83857, l2: 0.31733\n",
            "Loss: 2.820617e-05, l1: 0.83950, l2: 0.31739\n",
            "Loss: 2.819185e-05, l1: 0.83954, l2: 0.31742\n",
            "Loss: 2.817882e-05, l1: 0.83912, l2: 0.31741\n",
            "Loss: 2.816592e-05, l1: 0.83876, l2: 0.31742\n",
            "Loss: 2.816154e-05, l1: 0.83874, l2: 0.31742\n",
            "Loss: 2.815438e-05, l1: 0.83907, l2: 0.31743\n",
            "Loss: 2.814946e-05, l1: 0.83924, l2: 0.31743\n",
            "Loss: 2.813817e-05, l1: 0.83979, l2: 0.31745\n",
            "Loss: 2.812321e-05, l1: 0.84026, l2: 0.31747\n",
            "Loss: 2.816640e-05, l1: 0.84164, l2: 0.31747\n",
            "Loss: 2.811597e-05, l1: 0.84065, l2: 0.31747\n",
            "Loss: 2.808839e-05, l1: 0.84068, l2: 0.31749\n",
            "Loss: 2.807008e-05, l1: 0.84054, l2: 0.31749\n",
            "Loss: 2.805728e-05, l1: 0.84038, l2: 0.31747\n",
            "Loss: 2.803922e-05, l1: 0.84029, l2: 0.31746\n",
            "Loss: 2.799828e-05, l1: 0.84055, l2: 0.31748\n",
            "Loss: 2.794478e-05, l1: 0.84155, l2: 0.31755\n",
            "Loss: 2.790097e-05, l1: 0.84322, l2: 0.31761\n",
            "Loss: 2.788431e-05, l1: 0.84413, l2: 0.31771\n",
            "Loss: 2.787240e-05, l1: 0.84425, l2: 0.31770\n",
            "Loss: 2.786483e-05, l1: 0.84435, l2: 0.31770\n",
            "Loss: 2.784426e-05, l1: 0.84437, l2: 0.31768\n",
            "Loss: 2.783105e-05, l1: 0.84466, l2: 0.31768\n",
            "Loss: 2.781983e-05, l1: 0.84483, l2: 0.31768\n",
            "Loss: 2.780529e-05, l1: 0.84566, l2: 0.31768\n",
            "Loss: 2.778882e-05, l1: 0.84573, l2: 0.31770\n",
            "Loss: 2.775484e-05, l1: 0.84641, l2: 0.31773\n",
            "Loss: 2.772643e-05, l1: 0.84694, l2: 0.31773\n",
            "Loss: 2.769968e-05, l1: 0.84789, l2: 0.31776\n",
            "Loss: 2.768594e-05, l1: 0.84791, l2: 0.31776\n",
            "Loss: 2.766741e-05, l1: 0.84803, l2: 0.31779\n",
            "Loss: 2.765364e-05, l1: 0.84829, l2: 0.31780\n",
            "Loss: 2.764024e-05, l1: 0.84823, l2: 0.31782\n",
            "Loss: 2.763150e-05, l1: 0.84748, l2: 0.31784\n",
            "Loss: 2.762231e-05, l1: 0.84755, l2: 0.31788\n",
            "Loss: 2.760678e-05, l1: 0.84766, l2: 0.31790\n",
            "Loss: 2.758151e-05, l1: 0.84776, l2: 0.31796\n",
            "Loss: 2.756300e-05, l1: 0.84908, l2: 0.31801\n",
            "Loss: 2.754438e-05, l1: 0.84944, l2: 0.31802\n",
            "Loss: 2.751436e-05, l1: 0.85042, l2: 0.31805\n",
            "Loss: 2.748357e-05, l1: 0.85251, l2: 0.31812\n",
            "Loss: 2.744189e-05, l1: 0.85277, l2: 0.31811\n",
            "Loss: 2.740742e-05, l1: 0.85287, l2: 0.31812\n",
            "Loss: 2.737590e-05, l1: 0.85382, l2: 0.31819\n",
            "Loss: 2.735643e-05, l1: 0.85369, l2: 0.31819\n",
            "Loss: 2.739080e-05, l1: 0.85228, l2: 0.31825\n",
            "Loss: 2.734441e-05, l1: 0.85322, l2: 0.31821\n",
            "Loss: 2.731303e-05, l1: 0.85422, l2: 0.31827\n",
            "Loss: 2.728385e-05, l1: 0.85552, l2: 0.31833\n",
            "Loss: 2.729708e-05, l1: 0.85777, l2: 0.31848\n",
            "Loss: 2.726955e-05, l1: 0.85649, l2: 0.31840\n",
            "Loss: 2.724527e-05, l1: 0.85730, l2: 0.31844\n",
            "Loss: 2.722969e-05, l1: 0.85791, l2: 0.31844\n",
            "Loss: 2.721509e-05, l1: 0.85820, l2: 0.31845\n",
            "Loss: 2.720226e-05, l1: 0.85783, l2: 0.31844\n",
            "Loss: 2.719227e-05, l1: 0.85826, l2: 0.31846\n",
            "Loss: 2.717982e-05, l1: 0.85830, l2: 0.31847\n",
            "Loss: 2.716158e-05, l1: 0.85902, l2: 0.31850\n",
            "Loss: 2.717780e-05, l1: 0.85903, l2: 0.31852\n",
            "Loss: 2.715266e-05, l1: 0.85902, l2: 0.31851\n",
            "Loss: 2.713835e-05, l1: 0.85937, l2: 0.31853\n",
            "Loss: 2.710527e-05, l1: 0.86053, l2: 0.31861\n",
            "Loss: 2.708136e-05, l1: 0.86159, l2: 0.31865\n",
            "Loss: 2.704498e-05, l1: 0.86275, l2: 0.31873\n",
            "Loss: 2.700643e-05, l1: 0.86328, l2: 0.31870\n",
            "Loss: 2.697595e-05, l1: 0.86447, l2: 0.31872\n",
            "Loss: 2.693759e-05, l1: 0.86425, l2: 0.31870\n",
            "Loss: 2.692172e-05, l1: 0.86510, l2: 0.31878\n",
            "Loss: 2.695827e-05, l1: 0.86399, l2: 0.31877\n",
            "Loss: 2.690125e-05, l1: 0.86470, l2: 0.31878\n",
            "Loss: 2.688767e-05, l1: 0.86580, l2: 0.31878\n",
            "Loss: 2.687721e-05, l1: 0.86543, l2: 0.31877\n",
            "Loss: 2.686795e-05, l1: 0.86543, l2: 0.31877\n",
            "Loss: 2.685786e-05, l1: 0.86552, l2: 0.31878\n",
            "Loss: 2.685014e-05, l1: 0.86502, l2: 0.31879\n",
            "Loss: 2.684901e-05, l1: 0.86512, l2: 0.31869\n",
            "Loss: 2.684357e-05, l1: 0.86507, l2: 0.31874\n",
            "Loss: 2.683634e-05, l1: 0.86509, l2: 0.31873\n",
            "Loss: 2.681657e-05, l1: 0.86486, l2: 0.31869\n",
            "Loss: 2.679569e-05, l1: 0.86460, l2: 0.31867\n",
            "Loss: 2.676281e-05, l1: 0.86472, l2: 0.31862\n",
            "Loss: 2.672785e-05, l1: 0.86450, l2: 0.31859\n",
            "Loss: 2.669064e-05, l1: 0.86525, l2: 0.31856\n",
            "Loss: 2.666172e-05, l1: 0.86577, l2: 0.31853\n",
            "Loss: 2.664643e-05, l1: 0.86638, l2: 0.31849\n",
            "Loss: 2.662614e-05, l1: 0.86606, l2: 0.31842\n",
            "Loss: 2.660645e-05, l1: 0.86568, l2: 0.31832\n",
            "Loss: 2.659002e-05, l1: 0.86546, l2: 0.31826\n",
            "Loss: 2.656565e-05, l1: 0.86560, l2: 0.31823\n",
            "Loss: 2.652184e-05, l1: 0.86578, l2: 0.31813\n",
            "Loss: 2.647830e-05, l1: 0.86624, l2: 0.31812\n",
            "Loss: 2.633888e-05, l1: 0.86625, l2: 0.31797\n",
            "Loss: 2.626855e-05, l1: 0.86623, l2: 0.31778\n",
            "Loss: 2.632775e-05, l1: 0.86693, l2: 0.31758\n",
            "Loss: 2.624880e-05, l1: 0.86646, l2: 0.31771\n",
            "Loss: 2.622343e-05, l1: 0.86695, l2: 0.31763\n",
            "Loss: 2.621120e-05, l1: 0.86736, l2: 0.31756\n",
            "Loss: 2.620452e-05, l1: 0.86734, l2: 0.31757\n",
            "Loss: 2.619763e-05, l1: 0.86769, l2: 0.31758\n",
            "Loss: 2.617735e-05, l1: 0.86871, l2: 0.31760\n",
            "Loss: 2.616232e-05, l1: 0.86912, l2: 0.31758\n",
            "Loss: 2.614274e-05, l1: 0.86959, l2: 0.31758\n",
            "Loss: 2.612539e-05, l1: 0.86902, l2: 0.31750\n",
            "Loss: 2.610120e-05, l1: 0.86803, l2: 0.31746\n",
            "Loss: 2.606533e-05, l1: 0.86696, l2: 0.31742\n",
            "Loss: 2.603965e-05, l1: 0.86595, l2: 0.31742\n",
            "Loss: 2.601809e-05, l1: 0.86613, l2: 0.31742\n",
            "Loss: 2.599161e-05, l1: 0.86497, l2: 0.31736\n",
            "Loss: 2.594766e-05, l1: 0.86480, l2: 0.31748\n",
            "Loss: 2.591720e-05, l1: 0.86629, l2: 0.31747\n",
            "Loss: 2.588777e-05, l1: 0.86674, l2: 0.31746\n",
            "Loss: 2.587562e-05, l1: 0.86648, l2: 0.31743\n",
            "Loss: 2.585946e-05, l1: 0.86628, l2: 0.31739\n",
            "Loss: 2.583301e-05, l1: 0.86614, l2: 0.31734\n",
            "Loss: 2.581334e-05, l1: 0.86571, l2: 0.31734\n",
            "Loss: 2.583370e-05, l1: 0.86575, l2: 0.31746\n",
            "Loss: 2.579666e-05, l1: 0.86572, l2: 0.31739\n",
            "Loss: 2.576147e-05, l1: 0.86597, l2: 0.31739\n",
            "Loss: 2.574405e-05, l1: 0.86629, l2: 0.31737\n",
            "Loss: 2.571725e-05, l1: 0.86718, l2: 0.31731\n",
            "Loss: 2.569745e-05, l1: 0.86695, l2: 0.31726\n",
            "Loss: 2.566852e-05, l1: 0.86704, l2: 0.31724\n",
            "Loss: 2.564716e-05, l1: 0.86637, l2: 0.31719\n",
            "Loss: 2.626289e-05, l1: 0.86453, l2: 0.31715\n",
            "Loss: 2.563438e-05, l1: 0.86614, l2: 0.31718\n",
            "Loss: 2.561415e-05, l1: 0.86578, l2: 0.31720\n",
            "Loss: 2.560767e-05, l1: 0.86545, l2: 0.31724\n",
            "Loss: 2.559583e-05, l1: 0.86527, l2: 0.31724\n",
            "Loss: 2.558980e-05, l1: 0.86500, l2: 0.31723\n",
            "Loss: 2.557732e-05, l1: 0.86453, l2: 0.31721\n",
            "Loss: 2.557231e-05, l1: 0.86431, l2: 0.31711\n",
            "Loss: 2.554533e-05, l1: 0.86348, l2: 0.31711\n",
            "Loss: 2.552337e-05, l1: 0.86287, l2: 0.31710\n",
            "Loss: 2.548638e-05, l1: 0.86146, l2: 0.31701\n",
            "Loss: 2.546998e-05, l1: 0.86064, l2: 0.31699\n",
            "Loss: 2.545377e-05, l1: 0.85973, l2: 0.31688\n",
            "Loss: 2.544055e-05, l1: 0.85964, l2: 0.31689\n",
            "Loss: 2.542981e-05, l1: 0.85925, l2: 0.31691\n",
            "Loss: 2.542093e-05, l1: 0.85900, l2: 0.31690\n",
            "Loss: 2.540957e-05, l1: 0.85899, l2: 0.31690\n",
            "Loss: 2.539795e-05, l1: 0.85892, l2: 0.31686\n",
            "Loss: 2.542478e-05, l1: 0.85826, l2: 0.31688\n",
            "Loss: 2.538553e-05, l1: 0.85868, l2: 0.31687\n",
            "Loss: 2.537436e-05, l1: 0.85908, l2: 0.31687\n",
            "Loss: 2.536823e-05, l1: 0.85913, l2: 0.31687\n",
            "Loss: 2.536587e-05, l1: 0.85910, l2: 0.31687\n",
            "Loss: 2.536338e-05, l1: 0.85899, l2: 0.31688\n",
            "Loss: 2.535852e-05, l1: 0.85890, l2: 0.31690\n",
            "Loss: 2.535250e-05, l1: 0.85887, l2: 0.31691\n",
            "Loss: 2.534170e-05, l1: 0.85880, l2: 0.31692\n",
            "Loss: 2.533444e-05, l1: 0.85892, l2: 0.31693\n",
            "Loss: 2.532816e-05, l1: 0.85849, l2: 0.31693\n",
            "Loss: 2.538066e-05, l1: 0.86158, l2: 0.31691\n",
            "Loss: 2.532324e-05, l1: 0.85916, l2: 0.31692\n",
            "Loss: 2.531776e-05, l1: 0.85912, l2: 0.31692\n",
            "Loss: 2.530722e-05, l1: 0.85907, l2: 0.31691\n",
            "Loss: 2.530308e-05, l1: 0.85869, l2: 0.31690\n",
            "Loss: 2.529535e-05, l1: 0.85865, l2: 0.31689\n",
            "Loss: 2.528880e-05, l1: 0.85846, l2: 0.31687\n",
            "Loss: 2.528402e-05, l1: 0.85818, l2: 0.31685\n",
            "Loss: 2.528177e-05, l1: 0.85782, l2: 0.31683\n",
            "Loss: 2.527778e-05, l1: 0.85730, l2: 0.31679\n",
            "Loss: 2.527589e-05, l1: 0.85698, l2: 0.31676\n",
            "Loss: 2.527464e-05, l1: 0.85675, l2: 0.31675\n",
            "Loss: 2.527318e-05, l1: 0.85674, l2: 0.31673\n",
            "Loss: 2.527257e-05, l1: 0.85669, l2: 0.31674\n",
            "Loss: 2.528025e-05, l1: 0.85626, l2: 0.31672\n",
            "Loss: 2.527103e-05, l1: 0.85658, l2: 0.31674\n",
            "Loss: 2.526743e-05, l1: 0.85620, l2: 0.31676\n",
            "Loss: 2.526399e-05, l1: 0.85599, l2: 0.31677\n",
            "Loss: 2.525715e-05, l1: 0.85551, l2: 0.31677\n",
            "Loss: 2.525170e-05, l1: 0.85543, l2: 0.31675\n",
            "Loss: 2.524375e-05, l1: 0.85554, l2: 0.31672\n",
            "Loss: 2.523690e-05, l1: 0.85596, l2: 0.31669\n",
            "Loss: 2.522968e-05, l1: 0.85643, l2: 0.31669\n",
            "Loss: 2.522452e-05, l1: 0.85685, l2: 0.31670\n",
            "Loss: 2.522195e-05, l1: 0.85683, l2: 0.31672\n",
            "Loss: 2.521855e-05, l1: 0.85679, l2: 0.31675\n",
            "Loss: 2.521703e-05, l1: 0.85658, l2: 0.31675\n",
            "Loss: 2.521616e-05, l1: 0.85651, l2: 0.31674\n",
            "Loss: 2.521531e-05, l1: 0.85650, l2: 0.31674\n",
            "Loss: 2.522343e-05, l1: 0.85728, l2: 0.31672\n",
            "Loss: 2.521485e-05, l1: 0.85661, l2: 0.31674\n",
            "Loss: 2.521443e-05, l1: 0.85669, l2: 0.31674\n",
            "Loss: 2.521314e-05, l1: 0.85684, l2: 0.31676\n",
            "Loss: 2.521190e-05, l1: 0.85689, l2: 0.31676\n",
            "Loss: 2.521012e-05, l1: 0.85693, l2: 0.31675\n",
            "Loss: 2.520838e-05, l1: 0.85698, l2: 0.31674\n",
            "Loss: 2.520403e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520420e-05, l1: 0.85703, l2: 0.31671\n",
            "Loss: 2.520425e-05, l1: 0.85696, l2: 0.31671\n",
            "Loss: 2.520566e-05, l1: 0.85693, l2: 0.31671\n",
            "Loss: 2.520473e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520415e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520403e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520403e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520418e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520403e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520403e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520403e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520403e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520403e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520410e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520403e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520403e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520410e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520403e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520403e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520403e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520403e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.520362e-05, l1: 0.85703, l2: 0.31671\n",
            "Loss: 2.520269e-05, l1: 0.85695, l2: 0.31671\n",
            "Loss: 2.520108e-05, l1: 0.85692, l2: 0.31671\n",
            "Loss: 2.519959e-05, l1: 0.85701, l2: 0.31673\n",
            "Loss: 2.519819e-05, l1: 0.85705, l2: 0.31674\n",
            "Loss: 2.519681e-05, l1: 0.85719, l2: 0.31676\n",
            "Loss: 2.519276e-05, l1: 0.85738, l2: 0.31679\n",
            "Loss: 2.518874e-05, l1: 0.85768, l2: 0.31681\n",
            "Loss: 2.518043e-05, l1: 0.85814, l2: 0.31683\n",
            "Loss: 2.517465e-05, l1: 0.85843, l2: 0.31686\n",
            "Loss: 2.519107e-05, l1: 0.85938, l2: 0.31682\n",
            "Loss: 2.517307e-05, l1: 0.85867, l2: 0.31685\n",
            "Loss: 2.517138e-05, l1: 0.85845, l2: 0.31684\n",
            "Loss: 2.517041e-05, l1: 0.85836, l2: 0.31684\n",
            "Loss: 2.517034e-05, l1: 0.85830, l2: 0.31684\n",
            "Loss: 2.517002e-05, l1: 0.85833, l2: 0.31685\n",
            "Loss: 2.516862e-05, l1: 0.85840, l2: 0.31685\n",
            "Loss: 2.516777e-05, l1: 0.85845, l2: 0.31686\n",
            "Loss: 2.516696e-05, l1: 0.85850, l2: 0.31686\n",
            "Loss: 2.516949e-05, l1: 0.85852, l2: 0.31691\n",
            "Loss: 2.516614e-05, l1: 0.85850, l2: 0.31688\n",
            "Loss: 2.516694e-05, l1: 0.85939, l2: 0.31692\n",
            "Loss: 2.516446e-05, l1: 0.85891, l2: 0.31690\n",
            "Loss: 2.516298e-05, l1: 0.85875, l2: 0.31688\n",
            "Loss: 2.515978e-05, l1: 0.85846, l2: 0.31686\n",
            "Loss: 2.515701e-05, l1: 0.85838, l2: 0.31686\n",
            "Loss: 2.515005e-05, l1: 0.85805, l2: 0.31684\n",
            "Loss: 2.514275e-05, l1: 0.85790, l2: 0.31684\n",
            "Loss: 2.514112e-05, l1: 0.85682, l2: 0.31674\n",
            "Loss: 2.513241e-05, l1: 0.85716, l2: 0.31681\n",
            "Loss: 2.512804e-05, l1: 0.85740, l2: 0.31684\n",
            "Loss: 2.512269e-05, l1: 0.85753, l2: 0.31685\n",
            "Loss: 2.512015e-05, l1: 0.85721, l2: 0.31682\n",
            "Loss: 2.511633e-05, l1: 0.85772, l2: 0.31683\n",
            "Loss: 2.511391e-05, l1: 0.85784, l2: 0.31682\n",
            "Loss: 2.511144e-05, l1: 0.85786, l2: 0.31682\n",
            "Loss: 2.511086e-05, l1: 0.85778, l2: 0.31682\n",
            "Loss: 2.510992e-05, l1: 0.85788, l2: 0.31684\n",
            "Loss: 2.510803e-05, l1: 0.85803, l2: 0.31687\n",
            "Loss: 2.510636e-05, l1: 0.85832, l2: 0.31689\n",
            "Loss: 2.511018e-05, l1: 0.85911, l2: 0.31697\n",
            "Loss: 2.510536e-05, l1: 0.85856, l2: 0.31692\n",
            "Loss: 2.510325e-05, l1: 0.85879, l2: 0.31693\n",
            "Loss: 2.510166e-05, l1: 0.85903, l2: 0.31692\n",
            "Loss: 2.510033e-05, l1: 0.85900, l2: 0.31690\n",
            "Loss: 2.509811e-05, l1: 0.85897, l2: 0.31689\n",
            "Loss: 2.509584e-05, l1: 0.85889, l2: 0.31689\n",
            "Loss: 2.509330e-05, l1: 0.85886, l2: 0.31692\n",
            "Loss: 2.509856e-05, l1: 0.85955, l2: 0.31696\n",
            "Loss: 2.509329e-05, l1: 0.85902, l2: 0.31693\n",
            "Loss: 2.509037e-05, l1: 0.85900, l2: 0.31696\n",
            "Loss: 2.508877e-05, l1: 0.85910, l2: 0.31699\n",
            "Loss: 2.508632e-05, l1: 0.85909, l2: 0.31700\n",
            "Loss: 2.508478e-05, l1: 0.85903, l2: 0.31700\n",
            "Loss: 2.508456e-05, l1: 0.85898, l2: 0.31699\n",
            "Loss: 2.508266e-05, l1: 0.85905, l2: 0.31698\n",
            "Loss: 2.508176e-05, l1: 0.85920, l2: 0.31700\n",
            "Loss: 2.508137e-05, l1: 0.85937, l2: 0.31700\n",
            "Loss: 2.508039e-05, l1: 0.85959, l2: 0.31701\n",
            "Loss: 2.507827e-05, l1: 0.85970, l2: 0.31702\n",
            "Loss: 2.507778e-05, l1: 0.85972, l2: 0.31702\n",
            "Loss: 2.508839e-05, l1: 0.85989, l2: 0.31702\n",
            "Loss: 2.507847e-05, l1: 0.85974, l2: 0.31702\n",
            "Loss: 2.507830e-05, l1: 0.85972, l2: 0.31702\n",
            "Loss: 2.507825e-05, l1: 0.85972, l2: 0.31702\n",
            "Loss: 2.507778e-05, l1: 0.85972, l2: 0.31702\n",
            "Loss: 2.507778e-05, l1: 0.85972, l2: 0.31702\n",
            "Loss: 2.507778e-05, l1: 0.85972, l2: 0.31702\n",
            "Loss: 2.507778e-05, l1: 0.85972, l2: 0.31702\n",
            "Loss: 2.507778e-05, l1: 0.85972, l2: 0.31702\n",
            "Loss: 2.507778e-05, l1: 0.85972, l2: 0.31702\n",
            "Loss: 2.507778e-05, l1: 0.85972, l2: 0.31702\n",
            "Loss: 2.507778e-05, l1: 0.85972, l2: 0.31702\n",
            "Loss: 2.507778e-05, l1: 0.85972, l2: 0.31702\n",
            "Loss: 2.507778e-05, l1: 0.85972, l2: 0.31702\n",
            "Loss: 2.507778e-05, l1: 0.85972, l2: 0.31702\n",
            "Loss: 2.507778e-05, l1: 0.85972, l2: 0.31702\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.000025\n",
            "  Number of iterations: 4706\n",
            "  Number of functions evaluations: 5068\n",
            "Error lambda_1: 14.028299%\n",
            "Error lambda_2: 0.405516%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "######################################################################\n",
        "############################# Plotting ###############################\n",
        "######################################################################    \n",
        "    \n",
        "fig, ax = newfig(1.0, 1.4)\n",
        "ax.axis('off')\n",
        "    \n",
        "####### Row 0: u(t,x) ##################    \n",
        "gs0 = gridspec.GridSpec(1, 2)\n",
        "gs0.update(top=1-0.06, bottom=1-1.0/3.0+0.06, left=0.15, right=0.85, wspace=0)\n",
        "ax = plt.subplot(gs0[:, :])\n",
        "    \n",
        "h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
        "                  extent=[t.min(), t.max(), x.min(), x.max()], \n",
        "                  origin='lower', aspect='auto')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(h, cax=cax)\n",
        "    \n",
        "ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 2, clip_on = False)\n",
        "    \n",
        "line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    \n",
        "ax.set_xlabel('$t$')\n",
        "ax.set_ylabel('$x$')\n",
        "ax.legend(loc='upper center', bbox_to_anchor=(1.0, -0.125), ncol=5, frameon=False)\n",
        "ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "    \n",
        "####### Row 1: u(t,x) slices ##################    \n",
        "gs1 = gridspec.GridSpec(1, 3)\n",
        "gs1.update(top=1-1.0/3.0-0.1, bottom=1.0-2.0/3.0, left=0.1, right=0.9, wspace=0.5)\n",
        "    \n",
        "ax = plt.subplot(gs1[0, 0])\n",
        "ax.plot(x,Exact[25,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$u(t,x)$')    \n",
        "ax.set_title('$t = 0.25$', fontsize = 10)\n",
        "ax.axis('square')\n",
        "ax.set_xlim([-1.1,1.1])\n",
        "ax.set_ylim([-1.1,1.1])\n",
        "    \n",
        "ax = plt.subplot(gs1[0, 1])\n",
        "ax.plot(x,Exact[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$u(t,x)$')\n",
        "ax.axis('square')\n",
        "ax.set_xlim([-1.1,1.1])\n",
        "ax.set_ylim([-1.1,1.1])\n",
        "ax.set_title('$t = 0.50$', fontsize = 10)\n",
        "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
        "    \n",
        "ax = plt.subplot(gs1[0, 2])\n",
        "ax.plot(x,Exact[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$u(t,x)$')\n",
        "ax.axis('square')\n",
        "ax.set_xlim([-1.1,1.1])\n",
        "ax.set_ylim([-1.1,1.1])    \n",
        "ax.set_title('$t = 0.75$', fontsize = 10)\n",
        "    \n",
        "####### Row 3: Identified PDE ##################    \n",
        "gs2 = gridspec.GridSpec(1, 3)\n",
        "gs2.update(top=1.0-2.0/3.0, bottom=0, left=0.0, right=1.0, wspace=0.0)\n",
        "    \n",
        "ax = plt.subplot(gs2[:, :])\n",
        "ax.axis('off')\n",
        "s1 = r'$\\begin{tabular}{ |c|c| }  \\hline Correct PDE & $u_t + u u_x - 0.31831 u_{xx} = 0$ \\\\  \\hline Identified PDE (clean data) & '\n",
        "s2 = r'$u_t + %.5f u u_x - %.7f u_{xx} = 0$ \\\\  \\hline ' % (lambda_1_value, lambda_2_value)\n",
        "s3 = r'Identified PDE (1\\% noise) & '\n",
        "s4 = r'$u_t + %.5f u u_x - %.7f u_{xx} = 0$  \\\\  \\hline ' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "s5 = r'\\end{tabular}$'\n",
        "s = s1+s2+s3+s4+s5\n",
        "ax.text(0.1,0.1,s)\n",
        "        \n",
        "savefig('./Burgers_identification')  \n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "wQJocGkFn0j4",
        "outputId": "e18cc8b2-132b-4e22-bcd8-aecae075c2b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "findfont: Font family ['serif'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 388.543x336.186 with 6 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAFdCAYAAAApPOubAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3wVZb7/3zOnzjmThNBSKcJKLyEBQkIUZZW7d9e7d5uuBXsvWAERcm0XVAJiXRUQFXvf4roFWWx0SAi9SSeFHpLTy8zvj2dmMim4ctf7uj/1fF6vvM7JMzPPPDPnnO9nvl3SdZ0UUkghhRRS+J9C/r9eQAoppJBCCt9tpIgkhRRSSCGFfwkpIkkhhRRSSOFfQopIUkghhRRS+JeQIpIUUkghhRT+JaSIJIUfFCRJOk+SpA7/wvEdJEkq/DbXlEIK33WkiCSFHwxMAtF1vcH4v5ckSTeczhzGsb3+F5aXQgrfWaSIJIUfEm7QdX2x7f/zgLX/g3mqJEn6zbe0phRS+M4jRSQpfK9gahmm+UmSpLm2zb1t+xUCNwK9TmXqkiTpN5IkTTZeZ9o0mt3A+f97V5FCCt8tpIgkhe8bTFLo2Oq1BXRdrwJ267r+vmnqskOSpF66rr8PmNveabVfu/OmkMIPESkiSeF7BYMginRdXyxJ0nnAJ+3tZ2gXx79mnt3G2yJgsTGvHac8NoUUfmhIEUkK30eY2kIhsFaSpPac48OBT+wRWHYTl228l67rDalIrRRSODVSRJLC9xFrDG0EBGG0pz3spq15qtL2/jzDof6Jba4UUkihHUip6r8p/FAgSdINuq7P+5rtvWwmra+bpxdQaPhQUkjhB4+URpLCDwnv/pOw3W+aqJgikRRSsOE7TyRGpvF5kiRNbmfcDN1M2bdTMJMJG04V7tuOQ70NDG3kn2otKaTwQ4Lz/3oB/yoMR+hahGPVjhuAecb2mcA/FRIpfP/RKiHxf3J8ikRSSKEVvvMayddghC3uP1XSIoUUUkjhfwnfeY3kG+K0i/QZpjIVCOi6XvHtL+lfw//v6/s28F26RvtajaF21/1/cU3tnfO7dG9T+P8f34uoLcPmfYP9B2H8UN7XdX23JElzdV2/sdUxNyDMX7j83qLMft3FOOJ+nNhxkFhTGIfHhbdjGpIslDdd05BkGTU7s8X+dgTqT7TZzz7W3jyni6baYwTqTqDmZJKW2+lrz/3PkEsGtZxsd45vY63fBO2tu71rNPeLB6O4/J5/eY2B+hP0ye7Jjvq9xJrCaJqGLMt0PDP3lOtqD/a1Au1+NgDHdtQQawrjTlPwpPtOe93fdD32/XRNa7Me+3r75vailpP/9Hv7dWPfFN/WfMd31lrHmJ/V/3QdTTXHjuq63sXc9hNJ0o+exlyV8Hdd139y2ov4HuH7opFcBJwvSZIZSfMbYB5wgyRJu4G5rQ8wwkDnSZI02ZnmL8r71XkMnDge2SCG3/e/iFhTDVpSI1h3nLTeeZx58Y+pmvEqhdOuYORD1wCwftabxANhXKpC0eSLAVj1wMusmf4aI8ovp+Shq8R850/kwJJ1dBs7jNzSgaya/jrF5eOt7QsHXEUiFMXp83D11pfbXKDcirBWV7xLLBDGrSqMnHyRNb70/oWsnP4GJeWXctbDV36jmzdTGse9+iJWGXPWLN/C/iXVlJRfCsCK6W9SWn4pblWxzjlq8oXfaO5virfOm8K+JdX0GFvAJYsfA2BlxXvEAmHqK3eQU3QmblVh3fy/0rCrDm+mSqDuBKPLL+Hg8i3sW7KeHmOHcplx7D/DC/2vIx6KEQ/HWLt2LWX/dSn7PtvAwaWbyS8byBVfzAbg8/tfZdn0txhdfgljHr4CGa399f/sATJ7C4LoMWawdZ9KJ//G2h5rCqMlkgD4u3Ygo0dX9i5ZT8+xQxm/+JE2cy6veL/NPJ/d/xpLp79NWfnFnPPw5e3uJ6Pz6nnTrLmdHifR3hE8aV4u/fghAJZVvE8sEMGtell878s8oH/c4pgrFs8A4NP7X+fL6W9zVvnFnPvw+FOO2ecbbazVPgYQC0Q4sHwre5es56zyi3Gr3jZj5nyngjnnhmOfcnLvIbqVDeTqL2Z+k4+8xXpigYh1DV9Of3uffb+jksRa7zcXjVI43vkb7/w9xfeCSExSsA1VtHr9OowL1x9j398rCcTd6KEgDr+PpC4Zc4udkgmd2rVf0bm0gNq1X3E8pgDQ2Jhg86OvMfC+azgeF2MJJY3BU68moSg0JMSPqGHvYetVc7vJGj2Eg2t30pj0ABALxQgeOIIrw89n//UaTlWhYKIQ5NWz3yQZCONUFYZNugSAqO4goTvQdQchzWVdjOT3M3za5eBXCGhuAGRJXMRHF0wh3hTGlabwH38WAldGBwkiupNwIMrq6W/SbewwRpaPR1bF9Zjvw4Ewq6a/SXH5eCK6+OqsnfUO8UCYQ5U7yCrqg0tVGD7pty3OeyqsqXjHEoAaxv1GImG47oZPFvMsvX8hy6a/wajyy9CSurEfjCq/DIeqoBv768jEcLSZu9hGtCbioRhNB47gzvAD4FR9uNJ85JUNInikgU/vfw23quBUfZSUX4pLVVoIbJNITbJLRBMcWLqZ0vJL0ZCtv4SxnmhThINLN+PJ8JMIx0jvkYVO87Usq/jAmrvEmDsaiLBs+tuMLr8EzbjG2sqvyC8bSG3lV9ZY6/004z6a9zMeTXJg6WZ6jh1q3eeSVg8C5jjAyX2HWXL/67hVBZeqUFZ+MbWVX7UZc9k+t12L1lkkZF+/SXoAS6e/TWbvHLoZ609G4+xdsp7M3jmUGcRiR3vkZBKA0jGN9G5dCB1pUybtlHPYycOteq3XNnBIkOb+2nlbIBz/5vt+T/G9IJJvA7GkTNOJGPVPzSf3zpvRdCMOQZJw5+Wgu9x4Bw9m7+y5KGd0Y9GPb8bh9yFJOpklhRxau52GqPhSdrv9WmvexrgQFt7uuTTtrsHbPZf0gkFsfWwBA6ZcQyAhvrDxcAxnmp9EMELVjFfJOmc4P7rrKgBCjTE2Pfoqg6deTSAp9t+3qJL6T9eSfW4Rfe++wjrf/s83kGgK40xT6HuPGDe1mUhjhEPLNpI1eggRzfbRyxDSXNSt3Ul22RBwuyl44PoW90eWdNbNeouiaVeAX7GIJNwUpXLG6+SUDWbV9NcZPu1yYroQnnYlqnr2W5bmVjhJCJZIIMqa6W8wovxyuo0bQXbpIPGDN47/4wX3EW8KEzrSwMjy8ThUhcz+3VHzu+BOUxj10NWAEII5pQNxqQoJ43OLBKIW6S2veJ94IIxb9TLCICenz0Naty44fYLIiyZfjIZELBCmdvlmVkx/k1Hll1Fm0+qEtifGTbKLBCKsnP4m3ccOY1T5ZThVhUggzMrpb1JSfqklaF1pCnllgwgdaaBwwn/iVhX2f76BvLJByB43kUCEFdPfoqT8UhLIyOhsfe9L0rp1Yet7X1raZXZRH5YbGqI1t+qj1CA7c+yMcUXklQ7ArSrsWSQS9hv2HeZTgwzaEolsHbP5rc9YOv1teowt4LLFjwJCM1tq08yaj2v5UZukGA+EqKv8yiAI8UBSVn4xBw3tw3wPkNGjq6Vd2fU9OxE1X6vSZh47CZowSd++35b3viS9Wxc2v/clmb1yLBNjG8gSKK624ymcEikigUVy564/do44hwiQefMEog4fck4e7N2P7PMTq6nDX1pK1JVO1u23cmTha4T3HMCdn0eX3/ycmiefJ71sFBsfmovD76P7hGusyWVZ/MQ0p4cOowrRnB4S3jR6TbqBhKLQGBOCrPs1F/JVxXyU7rmE99eS0GUCcUEaSSWNvvdeh6YoVFe8RSIYomlfvdimy4SSzV/6aGOEo8vX02V0AZGk+Hi3Pv4aiaAQyF1GD0VWfdYxWx9/DaaeRWXF23QoHMDGR15myNSrLKLZNPsNEsEQLlVh8MTLrfNEjF+85PdRMPVKjlRto2DqleBXLCJYP/tNEoYmte3Fj2naVUNa71wG3XMZAPVrd5BdNoT6tTv42Z+bzRMxQyrFmiLULd1ITtkQCh+8DhmdoYaWtm7WWyy9fyEuVWHYJDEmSzqrZ71NPBDmcOUORpRfjkNViAbCrJn+OiPLx1tEc/mWhS2+BAldZs+iSg4uWUdG71yKy8fjVBXe/1m5pcWd3F1HWreubH/vC4vEnKqP4vLLcKuKRVJrKt6h2CAVk3Dyxwy1NI4Rk3+LjE40EGGloWm5VIVR5ZdRX7mDL+5/FbeqoHTpwPGlm8grG2SRi0tVLA3JFKCmaXNVxbt8bhxr18J0IK90ADXLt7Bs+luUll/aQrvi3p+gIVnHHFy+lYZddeJ7ewqyam1q7TWuiHyDuGKBsKUhnW2QzoqK99CRkD0uRpdfgktVLOKqq9xpERxgrcul+qx9W8PhcbUgqdbYvaiqlbaj4O/SgQNLN9OtbCCxprD1vg3k09RIUkgRia7rFXLfoTMj/3EHAG63RhIg6kDpP5Looj9A40liCYlw2IkWdVimFE12EnWm0/GWCYTXVXJgzgt0vu02GoIea36TSGLhJE0rq0gbXULm9cLv73ToNEbEfglPGt3uvomjf/ob6cVFaE4PjVHxZc665XrLTLTn0WfZM3sByhnd6FAiiGnDrDdIBsI4VAX8fjJLhhE6fJzKBxbgUBW0YJQdM1+i773X0f+/bgIglBDnPfjJGpgqXh0eF51LCzhcucMimkhThC2PvcLA+66xiMmOPne39cNENEMDaoqy8ZGFDJ56NVpCMI+W0C2S6ljYn/WPvMJQG3HZBZSsKmSNHsKJbfv4wzm341QVfvLRLDF3IMq6Ga8xbNqVFjmgi/VWzXiN3LGFJHUJWZeQ/T6Kpl2BZCM56xzG+RK6bJmD1B7ZFD14LbKks/6Fj2jaW09az2zS8rtQu3QjuWWDLcGuI8xHGpK1jv2fb7A0qWgggltViAcirJr+BsXl49F0sb8gIUFYwhwFiWicldPfoLj8Mo5vO4A73cfxbQfQjHOYfjiARKv7FTW0o1Hll7V4SjcJbnXFu4bm5iUaCLNi+pt0H1sA9wpBbxJJz3FF5Bqk0JqsoKXWYMJOXCsr3mujIUUDEZYbJHaWTaMB+OL+V1k2/U1Glwuz7bKv0XxMM16PsUPRkdCR2jULNuwTpuTwiYC1X/BIA2nduhA0zGHptvctvxQpjeR08YMnEgASMtJRN/E/Pk000QReP9IldwKgk44jFkBX/IROBIgtfBpHURmuIcORfH7k396MDMiO50gbPIK400djsPlL6HQYgiopWa+BsNh+fP5ctFAI2ecj+xYh4E+sWk/jshWoo0sIRcXHU/fci2jBkDCledPIv+tmmtaso2HpSrrdfRORk1H2z5lH97tvYtBbLwCw/lfXsbNiPplnF9NpbAlnTLwBTfERiotzm8QUNDSb4L568i78CTsr5tN5zEg2PDQPh98HPpU+914HPoWNs98gEQjTsG4LmYX9cfp99DHManZ/yNJf3kmiKcSJ6m0o+VnseX8J6f164svPwqkqxDQhzA9XbqfL6KEcqdzeTAYGZHR+/Mc5APxt7C3UL11P1uih1n6y38fQqVch+xUqZ71NIhDGpXqRDQ1p19uLqV1SRe7YIn769yeaP2pdzF1t05aYcg4JXSbv/BFklQyyBKCmS8QagwDEGoM41B7klA0mdLiBlfe/jMsgiLUzhEkvocvIkk68KUzt0o2o3bqyevrrjCi/HJfqY0T55ThVr80f1PwXD4RZPf0N8g3/lMvwRYT3niS9Zzaa3tJ8Y/qm7OY6l6pQbGg37Zl7TJ+TjM7qincZVX4Z2976FIA9iyqtecxXgJUV7xIPhNpoOe3Nb6I9DcmlKlbARmu4jW0uw9yXXzaIusqv2j1HXeVX5JcN4uS+w+xbst4ItthqBWqYRJLRoysNu+rwpPssYkrL62wFZeSXDrDGl01/q+VJHBKoKY3kdJAiEsCZkOhw1Mmxyk9JbP8cZ/8xKOPuEhvH3k3MI56Hon9+Cn57D0mvH+ni2wA4euvF6OEgkuJHffx1dKCxqVmoOp3ivbN4DOrgEUg+H4GQ8bTfGKHh+d/R4eYJ1lj0QI31ahJO+GSUo88+T9cJt+JQfWhJmXDtIfwjh9OwbgsdSkeQe+fN6IqP3U+8QjIYIrzfME1oEtk3C3+HLOlEDL/gwWcXkAyGrOdZT7dcdJ+fMybeQP0Hf+Xo56vpePZIRv5pnnXsjhnP8VXFi2SWDGPbYwv40eTriSUd1nYT8aYwx5ZX40zzEz54iE6lwyj58Glrv4Sxa4dhAyxfkTmPCft8DtVnmeRMEjKf6jVdom7xasNfNJxxf3sKgPoVm2naXYOuCzOYSRqDJ16GjE6sKUL1I68KcxxCMA6ZeJl1TnONnQr6ULukkk4FZ/LvH4nYjbUPLmDtjFcpmnYFhyt3kFM2hEOVO6z1OFQfOWVDCB8+wfBpl+P0KxRMFE/b62a9xfL7X8GdJkhoTSuisfuQNs7/GADJIbcRqrFAmNVG5J9JMkWTmrUVzWZ5EqQTssxqmhG0bv5Bs1YFzYEKHlVh76K17F9STfexBS0Ipj2Y2lF70X/2CMLWGs2+zzdY/orsojOtKMH2kF10Jsunv0mH3rkW4dhhXoPD4ybf8EmNLr/EIDDzHkq4VYXR5ZdQV7kTIFeSpMlW+oCU0khOFykiARxx6HDEydHDB8TAoQNI7z2DHg0S21+F44xhSB4/3l/cZR0TaxA/mvDer+DwfvSu3Wk8Kb58Tlfzr9jtFj8b528mWF/jQFBsjzvT8F17B3Gnn1BECEgpuxvs34+U3Y1QRHw8SbdK5s0TSLp9NH36JeGVy3Hm5RNcvZbOt91GxrU3W+fbM/5ygstX4OjQAf/I4WguN5G4mPvQ8/NJGpqNFoxQ8+RcMspGAZB+dhmJpE5Sk61INU2XiCSaiUJX/PSceCNN1Zs5Y+IN4POxfc6rJIMh6v/wdzydO+FQFSS/j8ySYZxcvxVvXjbhI8fbJZzjVVvpVDqMY1XbLIIwt8vobJ/zKolAGB2JzmcNF850TWgksUCEzY++LKLl1u8Q863fYWks2ecV03nUYFyGzX7jI6+Qfe5wYoEILr+C7PczZOpVHK7cDggBP9hGJOYacs8bQddRg4S/w9A4DlduJ7tsCIcqt9OlqB/rZiwkd2wRqx54GZfqtQjHmkfSLeEZC0SonPFaSxJau50LbD4ikwQGXHcBiWC4XQ3D2Y6GY0el4StyqQr7Fq21fD+xQMQYq+SAMQbQY9xwNF1ClnT2LlrLgSXVdBtbAJb2JLU4T2sfCdDCjGUPQHCpihXdZoar24+PNYWpMXxBbpsPaIUV/r2TbCP8u65yJ/llgzi6ZR8Nu2rpMbagRWCBCZNw7KY0HcnazzRJHt9RA5ADjMOM8kxpJKeNFJEAjqRE+jEZxd+D+IndeNXuuE+EOPrFTJTupYQ+riBz7L2ox8XtavzHE8jJAJJHRcKBDkg48DUJYZhwNv9Iwh4h2CRX83OYpaX86nZAPBUGAmK7Y8Q5eAeOQPL5CYXF+VyX3IbTKbY3vPs2AMlAgIybbifp9lH3u/mWiUzTjB++phFcvRZfSSmRmJgn2hjh8DOmZqOSdfuthDduFGvWJPRQiNonXyC9bBSdfnEBDr+PmI1Icm5p1mxM7Jv5DPsen4cjXSW0cx/e7rnkX3MRyUAIyeXm+BerRGCB1rYaT1rBQL6qmM+Zk69n25xXrRDnM+8ST6/Rpgg7Zi6gU+kwtj62gH5Trm1h2uo/5Vpkv4JuSF5d063z9Lmr2eS29XERnn105QY2PvIyg+67miEP3ADAkn+fAEDNJ2vof48IJtgy+3USwRBOv49BRoCBSQaaLtHJ8O0UTL0Sh1+hYOqVHFqxiXUzFjJs2pWsm92sAQ2deGkLs5RJQocrt9OlqC9VhmZjmufsId5DJ11qCVytldzWdePPJuDt4d3JaIKDS6rIHzvMEv9aUmOVEXRgIr1HFoAVsi3W2vzk3mPccHJLB3KocgfL7l9omdK+zrRlBg5sf+9zDny2HneaQjIatzSbkZMvanG824hoc6cplp8KhNa1Yvqb5JUNYoURBZeMxjm4dBMORQj6k/sOtdGuAOoNwqkXGgdAi9ynL+5/leXT38STqZpDPayNspwiktNEikgAOQHpR2WyOp1PRpcSHE4/yQTkjbiPYzs/wJ8/msTeatQGIVTDJ0Oc/EKQS3rx1ejRoNBYTorbaZrCIn95Clc8IHwuv55gnS9haCyxPzwNkSB4/cgOHT0sclic46egAw0vPoseDqJtX4+z/xAknx8pOx8O7MPRZyDK9ZMACLwwm8D8Z1CvvwPPqDG4hg4n9Nc/ojU2oukQiRrmII9Kx1smoHl8kNTRNIlkVHjdY00RHD6VrhNuxakqZBnmsH1Pz0cLhnCqCjm3XCful12GKCr5d91M/StvGjfTQawxwv458+hwVjE97rkRFB+xpEEANhKq/fATPHnZ1Px+ETm/+Dd2zZrPjyZfb5HB8aqtZJYMo3H7HjqWDON45TZrW+87r7Lm2TbnNePccjPRSKYAljjTCAhY+ss76VxawLGqbZZwt4etmmM1i1dzyDCVDZg43poHxJO4w+9jyNSrjBwWrGgk02cTawqz/pGFFEy9so1vo7OhwQybdiUOVTFevcQDYSvZtcUxUkvT3LBJlyCjEw+EWTvjNYZPu9zaP9YUps4IBpDdLmuCbuOGk106iMOV2+k3/nycqkK3cSPIMQgCYM2sdyzTWPdxw8kpHYjblhO04oFXrCTa1tfUOl/INIFtef0f1CzdRHrPbDJ65Rj3WWoT9dXNFtEWM0KnR5VfxqHKnVbIdMkp/CsYIdtm4IA5T5ZhIrOHYK+qeNfwKymWX2bLW58SPREAaE5KTDnbTxspIgEcCQn1uMyg7MlEVEPIK+J1V0Ri78ZHyC+cSu0rvyQZD5AIHaFr2RRkVDJG2sxdhm/EHRFf3OTJEOFFs/D/dDLuQLMPwCSSUFOI5AeP4/j1RDSHjv7uHBIX30MibOy76nOo/hKyupFctQTH+LtwFJ6Lq/9IJMVPxDCHRTdvwFkwkujmDfieEkI1smkjrk5ZaA4PsbgQrupVzSawQ9ddKkxk3cWDmO7xk9QEuUiabGki8aYwh595jqzbb22hnZhoWL6aZDAEkkxacZEICPD5yb/rZpyqQv5tIqdm3UU3kQwIQhryzvMAaLEY0Zp6vN1zkfw+zph4A5LPZ5FFesFAds+aR2ZJIcdXVLUgmd1PvWxFqmUM6cPRz9aQMaSPtd0ykdnWmjmsP1sfW0B/m2aT9eNR1uum2W+QCIQI7hP+JR2sMafqE59pMITTr1gazfqH5rPxkVcYMvUqhhq5N5tmv2ERjSnEzECFo0aYtMOvMNgIg5YlnfWz37TIxS5oNV1qSzKS8BsVTbsChyqCDZKBEOHDDeSUDcapKuSNKSC7ROTWFEy85JTJoX84fyIg8pJMkjKh02yuqq/cQW7ZYIt4TJhOf3siqnlNkkMcKzmkFpFg0NJZHw2EWWWEQbsNbcatCi2mZukmuo8tYPTDVxlrksgtHUj1c38iGY4BumUOq1m+xSKPeoOEql/4mP2fbWijFV28WJgSXarC51MW1AGLbIsHf0ojOR2kiAShkajHJf6x4wJiNOF0qGRmjSGRCBA6WcUZA6fiTKo0hgMEDi0jPWs0vYeIUhORRpvJykg+jHkNopBVOpx3LxIqPhuRNHw6Bz0aRK/8I44+JUg71uMcNBp+NRHN6ccZNjKW6w2fTTAAF99D0ulHq1qGHg4gKSqRi4TDnx8VkHj1CVxX3EUsZoQmR2Mk1q3GOXw0x+bPRQ8FSWzbgHvAECSfj1iNcOqbckO96mZO/u5xTjz/LB1vmWCRj+710+nW20DxkWhHq0gEwgRXVyKnp9G0qhJ1dAmaLkwxmiZZxyQCIZpWVZJeXNQ81hS0Xk3COfDMAnbMeA6nqiAb5NJYvYVek25A9ivW0/C+lz8kvOcgyhn5dL/q13QYWSDCaI3tK391u5X/Yjr6TZ/M8aqtbHv8NWs7QJ+7r2Dzw3PZ+thLdD1nON0v+jcjKits+WIANj8qTGPmeY5WbqPr6KEcrdzeKhpLQtcly++QCIRZ/8gr5JxbZIWjmnk2LtXbwtGvCVupBYfqY9i0K3GqXiva7IhhGtONz6DK8LuMeMiWw2QjhdZaROvP0doPiZgRBGA3gWUV9WG1Maa1Mj+ZTv8W8+gSmX26oeZ0xpWmUDTp4lOSmdsWbTbc5tA3EyntN8OMCKtdvpn9S6pJ75HVIrzZ9IGYTnuH10XN0k14MlWyhv2ozbmLJ1/E51MW1LYoXClLcBolUlJIEQkAchJ8DRJHm1YS007gljPpqA5n5/4ZDOhezpk9HgSgZtcreJVuJIJH8AYNU0ey2fZvEonTyKjzFUy0SCUWbCYcRyBE46IKXL1LiO9Ygfrvk/GcJzSbhEuDsNgv3rk7Wv1e5J6DcVw0VYytXgRbVqEPGGWRhr51AwwqJrF1Q/OYVeJFItEUIvrKUzgLRhKY/xTKNXcg5+STPLAPOSdfrC8uo3tU0m+8nfDGDRx+8glkn4+O1wktRpZ1YkbEl9PRfC2Sz49vxAgiO3ca5xOhrPVPPU/OHbeQMHw28aPHcOXlENq5mz2PPovD78M/sD8nl67EP6ifRS7Hlqyg4ctVdDirmILfvwgIckkGw2i6xFdPvkIyECJ+QhSZ1JOaENx6s+AGaNq+h/D+WpTuuZb/pWnnfkJ7DtLlnBHEA2G2zxR+FxCCz+H30W/KtbhUhb53X4GMzrY5rzFgyjUiFBoYeN81HKvayvqH5uP0K3Qs7M/mR18i69zhVD84H5eqWFFkaq884sEwLr/CkcrtdB09lKZ99dR9WsnQqVcBWHk0phaywdBcnKrCkImXIUvNSZgA7/S7hKZdNbgzVQ78bRWF067AqSoUTruCw5XbWf3AS0aS5iWWwG/PNLZulqg0ILuFCOh2/nD+9LMpJAIi/0U48ps1qkOn0EjM8fpW4yDIxzSHtdZc/ln5HKCNFmOHw+Mir2wQDk+zCcqe67K64l1Kyi9l5WPvAJCIxFo45ZsxyXwAACAASURBVFfZatW1QUojOW18n/uRfGPIGngDYH23dVASKkOyy1ESKt6AhDcg0a3rhUTCB+jW9UJrzBu0/Rlj7oj4O7Z0DscX/TcNn83BG5KtP5es0vHcKThcKhnn34vToRL/01PE3nuEUMVFxN95lMQfnsbT/8d4fz4JT/8f445KuKOScPD3GyVeozJSVEbvXQCbVqH3LiDy+u8Iz69Ad7hxjL8LqfAcdI+K64q7QFHxXHUnulfFOeIcvFffiat4DACJhIzvyptRb5qIs/9QGp5/hnhThERSaudPtv7y579E9zffxlcwFN+IEUhuN3j9dJ1wK4ENmzhQ8Qw1v1uAMzuHeE0dst9HzZPPEw+EyRgzmrw7b6bDmDIRzqu3rKWsaRKaJlGz8AP2zp5LzcIPSATC7Jk9DyQZT142sttNIhBm16x5JAJhax4cRhScw8GRf6xkZ8V8Yib5IJz1fe69jhNVokzH9jmv8qO7rqRf+c2cedeVVnixpV0gtJaB/3UjmcMEeSSCYZx+RWgrOmx69GXigXCz3yWpsfGRl4kHw3Qq6sfhZesB6Grkzpi+FqcqcnQqH1xAzSdrqH5kIYmAeJowr8fy6SRNEpcMU5jPclAnY3GqZrxK3LgPJhKBMJUzXm2e09A61s54ja5FfQEYNukS4gGR/6J06cCIB6+xwpABuhb1pXbpRroW9W2hkWQV9aF26UayivpYSZP2cibFRk5MPBBm1fTXibdzXTEjWTNmbGsPrefOKupDzdJNZBX1aXf/kZMvYvTDV5FhBBOk5XamePJFnPXwlRRPvog9iypZMf1Nm9ZjgyyB1/XN/1L47mskZgl5RPvT3Wa7VKMl6nvAWmDm13W2kzRwhyDXMYqo3IRLTmO4v7lzb8TwfXj0NAZ0L8epC3KxY83S/yCuN+F0pjHgp38E4Oj6BUSaduPJ6EX2iHusfbNHivemtgJwZMnDNCyeibu3iBJL+8m9qL+YZm2PGTVJ5Hves8YSUXF81KXChRPB5UcLBOCdOeiX3I18mXDay04haly2aLLkO8+gayAZGkMiIWE+V+heP/7r7kD3+pvNWZpO40svoIWDOFWFDteKBMqT80RSpRaNEVqzhk633tYsJKJxDj39O7pMuI3YQWFKSzQFyb7jFiSfj643m857HaMoLhlnl6EWFeJKU9oITy2hIft89LjnRg59+Bciew6QeXaxZQKT/T7rmPwrfy38GarC0SUrAHBlZtDzhotxqorlrN8x4zmxLpsQswvheCDMNsOvYoYjn1i3jf5TrsXhV+h79+VWZFjnkiE4/Aqy20WX0QWc3L6XLqOHcrRyG1lnFzLovqvZ+84iDi9bT/a5w61z6LpEIhhiwyOvkNY7j6zRQzlStZ31s99s9itNvAxNl8joJ2qNOVWFogeFNlX54ALWzXiVtN55ZJcN4YgR0mxeh0NVjHDj7ax54CWcqiKON3wsJlyqQk7ZYMKHGyzNBiARDHO4cruV5wLNPg6n6rMSKO3QkCicdLFlXvvDBVPJa6XR2At+FpePb1NAMWb4TorLL2sztxkZdqoSKWZ17Mw+efS75FwrS99cT+O+QwAcrt4FrfNIZAl8345G8m3Ip+8CvvNEwte31P2xrUtiu5AkabJKDpWBCs5gDCE5gEtSccaa93GHxY9maOdJ1ljEMF+Z27RYgJMnlpHZqcxytqMlrVdn/NThkgAOp9BSQnWVZJx/L5LT3+IYTT718fGkJLK8khK6xw8X3YPu8aOZ2fTvP4MeDpL4qhqpz1AkxY8UDRF/9UkcRWUABBc+h+xAVD9WffhvFNeqacYTsCyRDIVomvc0zm49CH72KbLPh2fQYBqefwalpJSOt0xAUnwkg0GO/e5ZfKWldL7tNiTFhysvj9i+/fgG9if77juNuQ1is+nFubca5CLrVsirr08vPLnZOFSf5Us5ubqayJ4D6DpWbTNZaj7m+NK1FpHIbheZJYU4VIU+024R5zZPbZis7CRkj/g6YfOrZBb2t0hl4P03tnCI97Vl+CeCYTY/+hJdRhdwZFk1g+67mgH3CB/C3neETzewr45aWyJl7nkjRV7Lio3UG6Yv4VdZ2ML0lXP2MOEjqdrG2gcW4EoTpDBsmghBrl1SSeG0K1pk7ptVpNc+uIBKI9zYaQjg2s+rYYowf5m5LKsfeMmKCKtbsZmaJVVk9M61tBc77GTRHkzC6Wr4WDJ65/LemLtwpSktTF9mOwVNb77/pu9EhB6/0qKeGTSH/JrRWGYF6uborzdaFN60t15I75FFw6463Ok+IsebchBNvowvxbdHJPyL8um7gu8DkYywOcpat9S9SJIkgLXmk0A7GBegjj3JT+hGKSuT0yl1lbcgEqNAL1sPzCKuBXDJKmf2NgStUQLFJat07FiG06EiG/zhT++PW83H4UzDGWsmgtrKx9GMsOCuo4R24khIaEmQdAk5CVJSIvj3J6zQYuXf72yzcPPcUiRA/MPZuH41Efcl94k1u3RRjAlIrv0M1n+JntUNVi9BuvRuHH4/jvF3oW9ZI+YKhUhsXkOycinO4aNRxhsCVzPXrYPiQ73+DsJ/+YBo5WrchSJ6LOOm23H6FTKvE1pKw4IX6HjLBJyqQucbRHSTJIGvqIiTH3/Mjt9cKkxLr863rsUsA2OFGWvN9yu9ZKRFCvufeYlkMERgyw7ceTlE6w6160hOBkI0rKyiQ0khssvFiRVVKGfks33685YQNecEOPOuK9n5xEIrYfPMu64UxBSLc2z5OrqcMwKnkbtyYt1WNj88F6fNl2KHae46XrWVgfddY50DwN8jh8DuGtQeObYjmo+X3W7L3AUw1PYeYPuLH9G0uwZ3hzRq/rbKcMIrxrFOK/IrHgizzoj0sjvoTZ+Kae7KKRsCiERJk6xcqsLwaZe30DLCxxtZM/018scWArSo5KwhUTXrbRIBEbxgz7A3cahyB3llgzm6eQ8nd9WSVza4hemrPZiksez+V9poJvakSdHf5w3yygZZ5OFuR2Oxk4vpL9n23hcguloWWTtKEnhOSzR2liRpre3/eUZrC/jX5dN3At8HIrHDaqlrqIrzACRJmgucqkPimeaYG5XRznLcuoqcaN7XJIZEMsD6I9Mp6FJujZmvZw/5M0aLEmKGtjKy9CMrjDiStAmbSIC6NY+SXXKfdbweDXD0y8fw9ijlxJKZdDx3Cjh0Ti6eSYfz7kU2BKtsKAjBvz9JItkkfCVuFfcvJoHbT/L3z0A0gO7z4/ilSHhMWhfiQLr0biTFj/PiW8W2d54V27x+tPqDYqyuxiIQSyGRbWaxQ/XgchHfupGMV9+1tptP+R2NopT2MetzicUIrVmLb8TwZgLQhFCvf+o5PD27c2LxZzj9PotAAmvXcdKoKwZwYM4LONLTiB2rw9Mtr8X8+55+iWQwTHDnHjx52cSOHMeb2xWA+ImT7Jo1j05jRgJw7PPVyIoX/usp/lH4K3J/OY6dFS+K2mLmem1zm3XFtvz3C1YYcWu01k7srwA55xXTxci4B+hSMhinXyEeDFthxAUPXH9KZ3SzjwQKpl5pkYKZXW/CdMCb283w4eFGMUqzJYCZ2W8nKzMh0lpzyUB2vP0PYiLfgnggbDVuqzIy6OuWb+bgkqoWkV4t7ks0Ts3SjXg7pgkSSWsZLtwePvzZVKv4ZXEbM1bLciejDM3FJA/T8b664l2W3r/Qyh0xtxcbyYk1y7dwYvtBFbBVWpVAOS2N5Kiu68P/+W7fXD591/B9IJI1kiT1Mj4Yy85oEMW7hurYsfVB9g6JKjkzezOO0UwmZuR4RGz7msLeJasUdCnHJas2IrE/DZ9axd/y8c9JJgI4nCpq97PJG3EfusvffA63SpezphCsr6LTOVOQXH50JyJ82N18Pgzfnh4NEPnLLJT/mIznt/dZ84R/P4PEB7ORBp9N0kh2pOBc6DcSye9DulAkRppmJdclt1mvWuVnJGv24jAiuezQNInI8i+Ir1kGsgO0BHjbaQp0CiSDIY4++yyuHt3xjRhumZRMBDdswj9yOOHtO4ju3U9acRHJYIiaJ5/H27M7acVFBNZvJqN0BN3uvom6l0WhPckhtzpPmL2z59JhVCENK6voNekGHH4fHYoLqHv/ryQamlrsryfFjU2GojSs20LHkmHUfPiJuCeqgsPtolPpMFuCHxz8YDFKfhYHPlzMwPtb/v5Nf0kiGOZ41VY6FvbHpSqWact8tROFjG7lnjht98Wee9K5sB8u1UtG/+7487sQPnLC2s9u2jKTHYsevNbSlKpnv2mRSmvkjikAWpKHGdFlRn+Z9yIeaO7fYfpLTFLJH1vYrq/EhOmT8GSmceHnT7TY9ocLploZ+fljhlp1weK20ilmHomJr4vosqM9E5fAqX+ruiQRc39rovF/JJ++a/g+EEmLlrqGE8tstTvc+P/eUx2s63pFrjR8ZoljEho6mqPtPubYkM7CAb/haAXrah/A6VBJOnUSyQBOh0qvfpPaHmwgmQjQWL+M9OzRX3sxvjPOotNZdwNweMWcNmswIXlUlP+YjOTxt9zgUXH+eiKJZR+gb/wCBp8NheeIa92w3CowiUEgdjhHjMExaDgO1d9mmzip+Wq8kZsXVXfj1WihILLPj7+4GC0UwuFX6HSDELQOv48uE27D4VPoetMNxlHGE7usow4ZRJ2hkbj6nYnD78Ph95F3580tNBLTR+L0+ywzlB0Ov9KiHpjD7+OMO0TvkPo//F3U/qo9RLfxvyCzeCi7nngZgNiJBjIL+7Nj5ot0LB3Gjpkv0vfe6+gwbADbZ75ohQnLko63SyZHl1fTubRA1BozEhb73S3Kqdh9JJsffYlB911trc9OIJtnvy5qafnbF4Zm7knW6KFWSRbTR7Lr7cVUPyK0kLzzR4i5DdOWS/W2CCM+1dymvwRa5pzs/2QtNUuqyDPMWGa9r1EPX91mnqpZb1sE0p5Jy0R6jyxO7qoFRJa8PYGxbuUWoicCItejqI9lxjKbgblszafsnS/NQpBme+n0nlns+esauo8dBggSsWspdpjhv0b4cIuERE2WiJyeRvJ1+Jfk03cF33kiMRi9dUtd8//F32gOqVlQm/6QVbEKyx8y2CEIpPqEGNt94i0CsV1kZYwls2MJ2/bNoN8Z0yyfhV3om+9ll0pa9mhkl0oyGaB2zaNkld5nbW/avZjQns9Qep1D5jmCSLR4gJOLZ5JxfvP3TDNMTMq/32FlyCdsQsDxS6FxJHaugvo9IqY5GoR3HoesbrD2H+gFZ4lM+nCQ5M71sPIfJN5+Ft8VwtwVe+tZwvMrkHx+1CuFr0SWdbwlZ+MZOpzE1g24Bw5GVpoJJ777KxI1B3Hm5aMNHszx556h8223WYKzy42CPFo8idvf+33k3HGL5SORJaj9ncgjkT0uut19E06/zzpGknTrz8wzcaqKRRpmbIIs6ex+6iWSgTB6NE6kpp7MkmFW1FbN26LCrqdLRxxGSPDJdVvoe+911tN1vynXttAUnGk+OpcW4EzzkQyE2PLYS/h75VH7l6WW0OsyuoDIkeMMuu9qnKqPLY+/bvkQBhplVxLBsNVIDGCDkVNiXqNTVVo0DXOqCjWfrKHu00pkr/iiNu2rt0xbdk3kz/92l1FGX5BBrUEMhYaGYUZtffXepzAd/nzBveSNKSAeCFtN0wCrFMuI8uamZt8UzeX9Fatm17a3lrBq+ut0M4R9PBAmEWl2SLpVr2XG+tXHoo/9mop3LGf7XqPYZLexw6yy9sL/MohjW8wqJzp7F1Wyf8k6uo8d1kITMQnTLKtSUn4pe/66pkVC4repkXwb8um7gO88kXwb0GUs/0bCsJTuO7GImsgS8rxj6asITSMaCrCpfjouRyYAgeg+OrnPp8+PpiE7VIuEEm7xZd23eTZRAjicfvr+4o/W+Q6sn012yX3CL2GQj+ku0OXmEip4/aSPuxc8fmssuOhJywHv+rnwgYT/8hREA+BRxXyRILjc8Nt7hGlr8zIYWAz7ReilBBAJknz9CeQhxeJckUCzHyQcJPzSU/iuvcMak2XIuEYkJwYXPocWCiHJevMxRt4GDofQRG69DYffh2xYnkzheGTePLRgCNnvI7hyleizoir0fc0sV2/sL+toIWHayjiruPneGc72xjXraPhyFT3uuRFJgr2z54qKxO0gaeSZKGfkk1kyDKfqs0qsJAIiu152yC1aFptrXvbLOwQBpPnod8/lyOic/ftm08y2OaIg5I7n3yO4uwZ/jxzUXnkcWVZN1rnDGfLADaIEykPz2fToywyeahAdOi6/Ypmz6r9YR9booex5fwlAi5L3dtR8IoIjJJtFtdkf4m2zv93w2rSv3gr/FdtEMAEIgW6SRnrvXFFqxePkSNV2cssGs/GFP1HzWbXQEsYUWKSYMDLb7b6RP15wH4mmMIG6Y5zcVdsiKmvbW+L6GvcdsnJLMnrnouZ0xJXWMirL1D5ql2/hwJJ1hrNdt9Zu4sSOgzTsqsOpuK0kxWTU7KOutxtVZi+hAvSVJOljXdd/BoZG4kklJJ4OUkSCEN6RNPHeJBStUbw2Jvex5pgwY0keP/17TGP/obeJJ0+g+HvQY9BEax6rPtf2WSQTQY589TaRpt2k551LJ3dzHolpuop5dWLGl1zp+2O8PYsJ11Vx7JP/RvL40RygO3Riu78k9nEAyeMnGQ8Q/WgWnv+chGSQixYPoH0wG/nCiWhJHd57HC65G/kKQ5N5PYD2xhxIy4SueXCsVgj5K+9E27EBAIfqbyYNv8gjkXx+q1KxXXvQw0FOvvAMHW6eYDXu8vTsiatrV2SfD0kSgi64aiV6KGg07hJ1qPRQkENPP0f2HbcQqKpGO9mIIyOd+udeNKKofOTdJhzCwQ2bSC8uInqglgMGaQDsnzOXzLOL6TnxRhx+hYZla+kwqpDG6i0tNBHz1akq/Gjy9eL1TvHEv2368+yseJHO5wizUM+rf2ld31dPLLTKpyQDIY4ZZqzWAkmWdAbcMx5Z0tk5930A4kbZFxBC3NIu/AqDp17NscptbHhoHi5VYcik5iikusWrOLRsPQ6vm/WPvEJarzyGTry0jdPd4XGSXTaEE1v2kgzHSOuRxTCj10n17DdZ++ACXKpCt/NHkFMyyCKN7JJB1K/YROWMVxk+TWgXJmmA8IEcrhSkcXzLXhp31ZI/tpCmffWc3FWLw+uyukPuX7SGg0vWkT92GD3GDbdMW+b9ObF1P4176/FkqlZUlpkzYiK9R1YL7aO9XidmZFZG7xzLPHXGuOHkGcUmTSe6ZgSyyG5RDsXct3VpeTvMEipp3bqACP21wn91SSLiSSUang5+8EQiSdJkxZnDyngFQzpPtrSJrp3H0TGzlKNNy9lUM51+Z0zjzIEPioO+UolKAZxO1SryCM2axPG6xTQe/BSHWwRpaA6dmLc52sYqm2JLSPT/mwjvjS36bxr/MhP/TyejAeG/VuA8s4TYRxV4/nMSSb8f568nkvT40TwGkfh88Nt70Lw+JIeOfokR3muQQGJnNdLgYvS92+BwDdKQYvyGySr65u8AoQFE3ngOPRTEqfpImyCIzyyHIss6DQteQAuFiG3eSMdbJiD7fBb5+IYO5sgzz9Jlwm0El35JcPkKXN3yCHz2BVm332rN41IVcu+8GYdfafG0bGof3e++CaesIcs66QUD2Pe4II3s3/zUEopnTLwBp9rs+9gVCrFr1jxBFrKGHbKkW2XphVDWkSUR4mo3XwltRFxLMhhim9FwyzRjudKUNkJdlnQ+/c+7SQRCJMNRANwd0nC4XXQdPRTZ7bKEq9nrZP1D862yKNY89kKJxltd09j4uPBz7H5vCUrXTFyqQlej9Hzu2EKybUQhSzpJIzrLrLnVmvj+fMG95JQNtiK1co3oKYCff/wYqx54mTXTXyOtZzaR402AjmZEiSVjCVzpPo5v20+XISKKVUI002qjBRkBEN6O6ZYm8sH5kziwZB3eTmmG1uA8ZaMsc74mo11utCFgbTOjsUy/yKjyy3B4nKR160L4WBN5ZYM4VLmDCz+e3mZee1kUs9CjLfzXOokmSURdKSI5HfzgiQRQw4k6Qq4AoQ66pVX0zBGahr5rFmpOCbpTJZRhmKwOvkxCC+Fw+Ij4NZLxIA6Xny6lQvhGAsJWq8sync+eguxWifibf2wmqdS/+CvLTJV+p3ii1fx+vD+fhObxk3TouH8xieSedTh+PZGE4oPfNDvJE0aPEtmpozt0JKeO+1Lh5xCahNguDRhC9JUnkfN7IPfui+TzWZpGLCKeoKVIEFnWaXzxabzFoyEiNIlOZn95p4YUCdLwvEg0lA2zlqmROFWFrNtvRfYrSKYfQ3aQc8ctyH4Fp0E43SY0h8wGVq4mGQjhUH24VEWQiKqIuSWdpvWbyRhVSLT2kFHmEJsPxExHo4XGYZqszL4m7YXRypLeJkTXKTUT0K4XP8CZ5uerFz+k/52XWc5mc1+7vyMZCHFk2XpcGSrJcBS1Rw5aLMbhZevJObfIOqY5Amur4e9oNkPJkk7+uBFklw6ySMMe1uvK8HNyxwHUntnkjCmwwnbNziGyJMw3btVr5H94WT/rzRaRV7KkkzW8rxW2C7TIC1k36y3cqpeR5eM5VLmD/uPPw6UqHPx8PWn5XTi6eQ+xEwG6lg22/B12LcSOwdf/zIq8ar7/hglX06lZuslomtV+gywT6T260rCrFneazyKN1Ubr30OVO43S8l7S8jqzf0k1nkzVqhbcHux+EbMfvEdV+GzKgibgc3M/XZKIulNEcjpIEQkEPN5sEh38VJ2sINbQhNOpklsoiKRL1j2WlhIwuh0m9BCx4EFcaflEHE0cXvEYXcumEOggQknNHk6yrwPKr0SZk/rPHkePimZY3p/eAUDs8Hb0o/uROnen4dMnIBpA8/lxXiRKm8Q/ekokcgwtRb9IONGdRoMs7d1ncEQDIks9HiT+5hM4r7gLr0FSsbeeRQ8FkXx+XOk+nNfdQXxrc/Vfr0es9fgnHwFPEvnkIzJ+fSGZN08gWr2Wky88Tadbb8PtEvs5HeIpvuuEWwlVVXH02WfJuv1Wjs8XWopLVci5V5BcvayRMWKYZaYCkA1BbRfsQ995rs2YeK8hS6IVr1lGfs/slhqHvYy8LIEu6TiMKrs7K0SUVXvaCbQUXu3leji9HkJHG/BlZJEMhths+DZMga0Fg2x69BUjcdBH1uihhI+cYMCtv7HqZgEcXrmJ6gfn41QVkkaWuukQF2hej2meGvFgc5a+metRPUcUHow3hgzyEL4N00xlXo8ZqitLOqseeNlykpvXZpquDlduJ3/MUEaWj6d2+WYxdyDMqIeubiPYRxiRVQsHXI1H9RE60tCq6GJbIpDaGTOLLJoOcalVT5L20HPccPJKB1BfuZOB43+MW/USC4Ss3iP/DDJ6i86MHrVt33ijvleLzHZdkog6U6LxdPCDv1u6rleoXYpmdh59N/vWPMTBqkfILb6Pnbsq0OJBZJff8mkcWjUHLRYgoUVwZOSjuxQaj1biOaOU49s/IKzqSB4/UpducHw3mqxz9B/C3xFe8Qr6oT1IWWeQMEJvdafDeo1rTfCh8G3oqhDeUjKA9u4c5MvuRvEbAt3QQoLVnxpZ6GXgduEsGAlfVROafBl6KIh29BDJA/tIu+EOHD4fmkMnmYwSmP8UHW6eYBGJq3Mn6zXnVuHHODp3LurwQmSfwokFc62M89Dq1WjBEIljRw3zlBctGKT+qedF/xFDO+lpaA0Hn11AzayncPh91lhL0sAas2sSvQ0/hjvNy5mTr6f294voWDqMxnVbLHLQgyF2VogQXSSdHTNFgmDN70WOx8EPFzPIVsbEfu72tBQ76Th8Hnz5WTh8Htyq6RBX2DL7dZLBEHvfX0LW6KEcq9pK7phhbar1bp/3e2LHG5HdTqoN8nClKVZobnu+FrNC7+HK7XQt6otb9VJkEEP9ik3ULKmic8GPOPjJGqtkiZnLUT37rRaZ5qZ2InwXzeezl4I3TVJ/uEBUlT5cucNKLjRLjdgr9fa58GwrLLdy1tstKuea780oqritv4hVRiaaoGbpJjr0zqXglp/jVhVLu7Afa4fZ0dA0SQFteo+Ull9Kr3FF5BuEY7bktUdnmS13z374ijbnMK6hjpRp61/CD55IAJIuneM5SWIdfXQ8dwpRj49koomGL2bi/dE5BNY0CUe3K0BgcQXuvmNw/qhYjCUCRP80C0efEpr+NhP3LyahF52Lc9AIEn9fQPijCsg+A3QhuHU9STRdpM07Lhhv5XXIso5++V04/Aoe1ehamKGgX3Unkk/B5xNjph9DN/rLOxw6nsGDaZz7NOk33k7wzx+SrDmInJ5B5s0TkH1eiDTRMLe59pXsU/C6DWIybOTONAW30yAXp0bSoeFwamjBEHVPC6LQQ0ECq0VPkV73CTKseXYB3e++icCGjdTOfgqHvzkEl3CQfY/Po9ekG3A72mokdq3i2JKVHPt8NZ3PGSHKjhgahi7p+PK6cuSzNfSfci17nnqZRCDMyeqt9J9yLU7Vy5Evq+hcWkDDui0oXTI5sqyaLqMLcEoasqS3G3q75Of3NDes+tvyFsL915tEt8fWAr/qwRdZ/8hCssuGUL90PcOmXUkyGLbIwtRYMvv1QM3vSvjwCXrf9mtcqpfaz9eJEu2HT5AMhHGr3hZJgMlAiMoZwj9x4G+ryB9bSNFkkZdhNyXtXyQqcaT3yLL8D78/f6IVEmvmZrT0XYhXt60kiWz4ipJREXqbjMaIB0JWqRFRA+uyNnWvPEYdK5MogBbvzX1bt9o115Deo6sl0N8+716r0VR7RGJ+BnHDJGUng5UV75FvONPtLXRNrLT1e7drIW2j2to+VOiSRMyREo2ngx/83ZIkabKcnsWB9bMhDZIJDcmjoTkUPP85ifjOVUQWzcT1q4kkAIk/dwAAIABJREFUD1Qj9RtF/MR+Yh9/LqKk0oSjO7n0jzCwmNjBKtyPGm1n/27UkgocxzGwCD07B0nxk2YQSdSjoSfF+dKM7oVC4xDb5Rubs6adDjGWjDdx4sVnUEaVovzHz40oKZ1Ot96G7PMSdsokAUdmBt0mi/Dgo/Pmkn3HLTj8Pqtd7qHnXyAZDJFZKqKWBr4xl/rn55IMhjjy4cdE9h6gw1nFdDy3lB733IhT9eBKU8gYVYhTVfC6xHrMNra7Hvkdu2bNpbeNNEyNwqF6cTsESbWI/jK0in5TrrWZncDtSCKjc+QfKzj82VpcHTMsouhY2J+tj4n+Hw5JwyHpdC7sa4XWHjMaTTlVBbdRDsA0ReWcW2RpV8lAiMPL1pM1WtSasvtI2vWrIDSkwmlXWDWrBEFUk1M2hKOV26w5fmYUP7QLrS1z/0jT3nrcGX4qZ7zawuQk7pXCiPLL2fjcHwARqmseby8lIqGTVzqAQ5U7WPXAy20yydvTwOxJfKOtnAqxrdFwaDftO8xhw/wUOtJgRT6Z8xW30+vDrNYrOhI2F1YcZex74LP1Vma62Zfd7B8i27qzS7QV8HaYbXHtJqnW5NH6+HggxPLpbzG6/BLGPCx8QitszvYS4/j2TFuaJBFxpjSS08EPnkgAVWs8RMAtelXw+8fh4nuQrxShs/p7zyAPG46mKLA3gr5tJVJuT1xX3IWkePFdIeo/hZUk0VeexHv1nTj+9BR6KEjcIZ535A4dyJn3inVCWRIx7o1aIw0vizDa5NvPoIVC6GpzNngLM5Dhd4l28BpObR85Rhn2Qy/MR3NqyC6N7PEXkgyGcKk+VMU4j6FhOB0aPrdBUpEAB54UEVEAR+bORQqHODBnHt7uecb5oc/dzRFPu2TdKnToNbSXXU++IuphrRdJfE7Vg9cpzjHgnuYkNlkyiMT2g/emeURRQ7+X3PNG0rVE1KByy0nxdG9KGk3j6PJqss8djkf1WlVyNz0qkvk8aYpR3NDLuI9m2c4jNBJPmpdh067kq7cXU/dpJblji3CleckuG2IJ4m9CJMPbydxOBkKsnSGc1pVG6C3QxtQkG5FMktPRxuQkozNykhC+9cs3cWDJOtJ7ZFmmJruJyRToopCh0Brs5ULMtZt1qlq3mG395G/260jvkUVWUR9WTn+DkvJLOcsyA329D8Sc78v7F1pag3ldnjSFfINEsovOtExM5nZ7o6n2sLLiPcv0dc7XkMEKQ/uoq9xJjmHaqqvcSX7ZQOoqd1rz7V5Uyb4l6/l/7L13fBVl2v//ntPmlAklAaSFAAmQ0EIvIbRQRBBQFEVXd3V33V1dy1qICAkqYAvY1t21rN3dBaWKNCmhSFVCLwkQIHSpgZyclpOZ3x/3zJxzksDqPvv89vG7XK8XrzncM/c9Jedcn/lcNSkr3Zxbk2lLkyT814HkR8l1IAGvlNAAZz3xdiX96jEkt0xcAxHO6VUqwVqJ5A4TsmsEAYtVw+2uxOIOI817E9Xno+LLv2Nt1JjK1QuRGjY0+6HXufceLG43deIi2bvGj72ijhP50d9j8TjxrltL2YbN1MrsRa0/6CU99NyK8l17UNLbY/W4Sf5DVCtVHZAuBMsoefNdnTm4qLSplG3ewulAGVbFjSXg4+hr7xHfvweWgBer4sJZy0lK9gOcmr0UgNI1G2kwqJeZ2Z10103YFBcn3vrAzKmw+P0U5QlfhAEWxz6eR/nhEzjia1Gvayo2SaX49Y/NSCejtpRRf8rmiZiX0sffHfM8IiIYSdMh3WjYux3Fs1ZSUVqGRdLoopt7ds74B40y2mNTnEioaJKKVVLZ9+pnZja1YToySnec3bSbsuKTSGgk9k83lTT8cyAx96FREKXg5Tjhizi9cS/fTfuMnroD2zA1GQAhIpmqdghUq60fDQoh3dTUK+dnMdcHItqoaoFCIcK8Fl2nqvz0BUAkAVZ9c28xtEvM1njzN46LdlYbLODo8gJK8neQlNXJVMg1ObLvWDzVXGdT3mz65NzF6YIDfKPnfxiBA9JVkgaP6Oepk9zIvIaawCDk9bNh2kwSM9uxYdpMMnPG0bhrCuunzaJ5Vjrros4HBgMSz7NP9m2snvBhbGY7EhWW66rxx8j1pwVYLRpxngrq/eY3UZnYomxj2dbVlG/chNKnNwlZfVB7pePduo3L7/yRRo89hLdgG2XrN2OpFUfl6Yu4e3bFYlPxA55mjUjNfTBmPYA9d/2OynIfofMXueGWG7E6Kgjo5iCbRaWOW4DO+VAZx954D2ezxpTmf0N8/x7UGh/JIDYUnn/XHuIzOuPftYe6XdIonvE+CRmdODLjPRG9VEu0kL24eRfF098jbcKv6DBZZIGXfbfdPK+h2Atf+0z4DyyqnlMhzEaXtwuz0eXt+3Bb9cxhvehh2Bdg70sf0migqEB7enUBjQZ2jXTZ85WzW/clOPXSytcyZ1gkjW46aMhxTsK6X8GhMxubqIyGDZUKvWe5Eda6TWcIqg6AxjU019+ARbFBH1tf0Et1TIBdM4Q5siZnsyEiqc4Xk2ltFBP8Lu9zHQAihSwlIgAVa4qpDiDG8+gdddyWKBOS8awMx3Ph7HW469fBEScUfNVn6T9XKnIrzpVSW++9UTvphmrHGefrXYOfwYLGjr8uobT4NHWSG5GRfXuNxwAx+2piDcZ27eRP2aCbnABT8VtqeCYG8/GeusCGaTOpm9yI2kkN9H0RMJAVJ5k54zhdcIjMnHEmmGXmjOPExv2snzaLzJxxtBzahaYZaf+00KOKRMBynZH8GPmPAYkkSbU0Tbvyb1jnah3IahyvQZTwuXO41cuc+d19Zl5Dly9Eot5xm0o54LCqtM8WiurImx+hZnTEqtgpPSlKr6s+H84mDVEvnqfJvaNpkNGB0u37OPva6yKLXA9NtSkuAocO4ys5ha22wtEZ75I64Vc0HdqDhhkduLR9PydeeROb4kap7aDthF9S8oWoJ2e3qNSRA9VuwFd8VPS4aNmEJgPS6TDxfo7OWUWDPulc2b7PNPesGPUUN/RJ58qOvSh6w5XEId3MrTEm+bzseUkofZfuF7ApDryHjnGl+CS1kpuYQBKf1oxaifW5uO8owUCoWiivARquOJnuOfdytkD0O49W8P8sDNQwn4jjDL+HAIKeOffgjHPpHfZEfZueOT+jcGY+J/K3kZjVyVTi0et8m/cFvXJ+xqmN+wAIe30AMc7maCZgQaPSW84WPfTUUPA2XZlFK+ITa3eaSXeWq7xt/xCJVe46i9Udz3GJ9Tm5fg9NM9uZ1xAtaWP7mgrbobhMBRrNEAxz0EtLbhSgVc3voOqJiRC4WGYq7uShnUnMSNXXq37uCq+PDbryrrr/TMFBEjPbcabgIEn9O8Qo/qpile0kRpmn1ErVHLPpzxYgM/u2qz7DDXlzSMxI0wFeM1mQuP9Ata6MoEdtWWqo3vovyL9BP/0k5D/JSJ6RJOlzTdN2SJLUGdA0TdvxL6xztQ5k1+pMFi1dbR4Xwd27sPp9XNy8k/p90mnoEYl6LpcFe590bC4LDd3CjNrwmcgP7uibHwFgsVkJnDxD+sT76DxBKKyvb3yMA6+8T6OBXbmhd3v2vvIJnSb+AqtN7y1iteiNiexAmLA1TPmho5z5eiONs7rQdEh3wtYw8a2bkHpXFjbFRS2bMLkZ4aI2xYWkd2KU1Ep6Py2uzWkJm8lnilUARONuraqNZejHi60AB3ecQ7fjO+g+PnKvhe+KemHBi5fZ/tz72BUXY5eIDOJohy5A04w0Dsxey5cDHsEe5+L2xS8A8MXgp/lu2mc0y+pc4xuuIf9M+ToVWVfmMj1rWOfMxr1cLj4tnPeRjiymGOfenDdbX08olIycu81IH1mRY+Y6FaepmCNKt7oibdw1hQ3TZpKUlW46oIGr2vZlxWlez8a8OdVCa08XHKJR1xQcigunIpOZM46Cd5ZQK7E+vnOlbNYZQPRxxlu6Q3GSoSvajXlzTDNPhdfPhmmzqN1c+EiOLC+gTxWFbEHDFR9H4JIXV3zcVRS3GNuQN8dUzLLipK9+7qp/x8pgBcfX76V5VnqN61R9jt9Mm4UrPg53vdrYZJs51jfn6pWGq17PwCmCxa+e/LeYuVdbR0MiKP3bGMn/VD/9JOQ/CSRbgZaSJB3WNG27JElZ/+I6V+tAdq3OZNFSEC73D2/WvSXfFxzAkdkee5yDhnYBGraKAKc27KRZVmca2MurTXbWchG6eAW7y0Hnp8biUGwcfu1jQl4//mOibLZdqqR2LZuu+Gx0eWBYtdj7byZ/wncv/INa+g/bhsqZFVs4lr+DOsmNSeyWjEMKU8ciGIm1vIwtLwjnZf20RGo3rYcjzkUtiwAaj+LQbdYOFCl01TFDFClkKjaH4qL/FBHOuSnvH+ZYvbSm1GqagPf0RbZM+xt9cu7CqUeY2VBRdVOToZBOrdnB8fV7SMxsh1MHKeMN1YLKtryZNeYjVAWYaOVq7LOimv8chKkqNtlmvrnaqO7oN6Rf9q0x2+oSARILqs4wVHPNmsSpyPTNGcfxjfvZMG2mqaw26IrLmBvW39z75owz35D3zFzLpeLTNM9KB+Bo/k6cdRWKl26leVY6P18pAHmvflzd5EYcXr6No/k7qd38BoqXbqVvzjhTeQoR920c1zwrneShnembM449M82E7pi39D76c+7ywI2iD8lVstjX580l5PWze+Y6LhWfpkVWOr9YGV2eRIs57rLelyTaL2LscyiuGHCRFSf9cu7k+MZCjuTvpF/OnTj0sZpAKloqvH6+mfY5/XLujDj/o+Zu/2gFtRLrsW/2N9XmakBQ+vcwEv7n+uknIf9JIGkJlAJ5kiS1AFYA+f/DNev80PGoDok3OGu5aaDAXYvGmz2m8/M+Jej1c36HoNXlJadorInIrvzpXxL0+pEVF43TGpPQNB45zsntU4QyWjZ5FuumzSElqwPd7uqDrDgZmH2Tee6X0x6lwhfC7nYwInsEAHUVK4NyxrJz9gaaZ6YhyxaObxHVer2nzrFx2j/E/rx/EPT6uVBQTFbOWGTFxqjFE6PuTCRuDcu++Zpja/JmEvQGOFlwiBeWDGNb3kxKlu/gcP4uWmZ1ZEj2KABKlm81x1oP7WTO6XxXX2TFjkKw2nEn1+4gWBbgQuEJkjLbIsc5+S7vC4JePw7ZxoCcO5AVF0FvOeunfcGAHL1+kv7ZWQUY1KjjjHWObSzkcP6uGo8HSOzakjVXWw+Jb/LmRkwbT4+IMQ9F7+sbpdjCunLqn3NnjeYkQ/pnjzHXScpINU1u/XPuxKHI5lynIptjIX3tOs0NH0C0ktTMMWOu0ZBLq6w0jw1d8dEsUyTm1XR9hhK/XPK9eY1ndLORXbZxePk2juTvokVWR3O/sY2+jmip8PpZF3XdVavtGr+nkH5c3eRGNMtsi1W2mwASDRQ1gcr6vLmmKe1aZqxocSguHTQiZrPouVvfWcKV4+dx1vUANJYkKdtQ7CoSQX4UI7lWq91o+cH66acm/0kgOaxp2lzgrwCSJI35J8dfTWrsQHaNcSDSIREguUtz7WePDoRgxGVjv3yZRS99Rf2kevguemmYGE+DCmEvtun7bnlmJOmZKQTKgzg9srk/3mVh1MTROD0yw58SQKGGfebaanmAyycuEt80gfiwYDljnhgKgFOrYPELCxgx6RbO7z+O76IXh9PB0CduRvZY2be8gKL8vbTJascdz94CwLJXviDoDSIrMkPHj6r2gFQzXiVKyrysfmEe8c3rA+Jt1fgy2FBRNAEQVl0hWVFRveWsnjaXoTm3Mfx58caqahX6fs3cVpT5KFlfSIvMVB5Z+zwAS5+dxZppc0nJ6oBNf6PfNns9dRLrsXf2enrcn8XgnNuRFQdOKlCx8MGIaQTL/HjPXWZQzlhkRSbo9bFm2mxSsjqYYzWZrlyKUwdaJxvy5prA319nHpVeH2unzSYrRw8DjVrD2Dcw544YhexSZAbm3IEcBQbr8uYR9AbE22527Fd44FVZjlpt/7q8eQzIuYNTBcV0umcAsq4AkzJSOVVQTOOuyciKy7wXm2zXQdpFi/7tScpIZdfMdRxbv4+WWR1j7rmvfl11kxpwqfgMdZMamMreKLdeGay4Zl7HpyOmENTDie9d/Kw5fqrgEM0y21J+7rIOirE+h2g20D/nTnbNXMux9ftokdXRBKEWWR3NuQbg9I9iEv1qALOrgb0hNc2JFqOwpN4LpREwFL1PiIZE4Mepxmu12v2X9NNPTf5jQKJp2lxJkpprmnZU95Ek/4tLXasDmTl+rQVsaiUNvaUAqHrYVn27xr1PDqFox3FuHNsFl8dBA58AmpPfHaJ975ac/O4QFaFKdqw7QKd+rfnF7/sB8POH+5lrq0FhIpvzxkoTcJwuO/Wa1sXhshEfEkAydcyfCHgDXD5Xxu0TRuB0WkhscwP1G9fGGefk55MEIE37WriR7GoltcLCzHVw+Q72rt5Pu4Fp3P74EAC+enWpeT6AQHkQ2eM0gS3OY2fkxNFs+XwTAFZNxSrbaNWnDQ6HBXelMH11GNKe1r1TkHUFMWLSLcgeO25V7DdAqv2QdrTqnYKsyBxYu5/kzFScioxTE2zA43Fw06QxFG86wMppcxg2aQy16teieH0hyZmp3PSUYEuqJOlVACo5t/84F4+eI755fUY/fzsqEqumf8nQnNuQFSeDxo8WD1k/h4oUwxZvfl4wnbeHTOFg/m5aZXVgyPiRALgVmSE5t5lsIdpU5VJkE9QMs5mKhazsW6K+NQIMKrx+Vk+bTUJyQwoXfYcc5+JXi3MAWJM33wSZATpo1AjqYO6vSdbmzSfo9WNBI+j1s0YHuSFT7o45btfMdQCUlpwl5PWzZtoXDMy5w1TIrYd2IikjFTnKLFSqJySWlpylxwNDq+03rjlY5qdk/T6SMtvG7GvSNdlkfoP16/lGB7FoALRghPoKkRA+J4Od9jVZ3Dx9LHIN3+TNqwaKFV4/a/XzWtCu+lyvJt0euJGQN8Dumeu4WHw6Zp+KREj7t5m2/sf66acg/9HwX03Tjurb7cD2f3GNa3Ugqzpeo9jDlTS8FAskj/5chLF++N4Gyv0BXFaV58f8GX95kOKD57hc6qdHn5YmAbZXhqnnFYzkk7fX4S8PsX/XCVI7NsXlkbH4Qnzx+irue3wQo8Z1xV8eonDnCRZMnoPLIxO+Us7+zUfo0Kslvxs/WFzL76MBSTAap91Cu97JOO0WaoWEycqqquZWqRBMQr1SzpevLGHs08MB+PKVJdw+YQSKAT5r9xIoC2C1ih9g50FpBLxB5r28iHYD0lj87Bc4PTJjnhpe7XmpkgRqRczY6CciprslqiqAS3Hi1I+zaipWTcXhsHDzRAFGLsVBqz5tkBWZ/OkLTKU77KmbUZHMJD6L1YJDDaNKFhNwALPsjHldSITLfKx4YR7DJo3Boe+XajANCX9HhHHZtAjzGBLN6sxx1TxHtOyavYE6iQlcKjnLheIz1G1eX2cpfo5sPMCh/N0Mzrk9yjd0dVGvsvfg8u0cyt9NSlYHWg/tZDIx417W5M0n4I1E89VNqo8zipEZCjkWrKq/pVfdb9yrBZHUaZgpo4HkVMEhkjLbcqrgkDl+cPl2Dufvok7zBhxYWsBA3XS5ZtoXJGd1JP2ufvqLiQCWI2t3R9rnZlc3TKzLm4v/ohdXvGLulxWXCULGNf4zMViVHOfi54snAwLMvp7wSUyrXQ2JgPrvcbb/O/TTT0Gu55EggKTBeeH/UPV06jf/vo1yXwXzvi7k6MnLZHZvRkW4km3bTxKnOPR5YTL7tKRXh4a43Q7irwj2sW1VIZs2H6VJk9psyj/Ag7/vS7xH5ncP98Ntlygv9fLJW+to3LQOW1YV0iOjBXEuO517JOFy2ajlFwCh6m3wPvvLWnzlIVwemfbtG/Hx66vompnC7OcX4PI4cNkkOvZsgcsmUSso5tZxWrjnqaG4nBZ2bCimfa+WlGw9jBISQFNxxU/hpmLa9RZE8O5HBjL7zZXcmX0T+789zPyXvuKOp4fjDkec8vNf/5qAN8ih7cdI7pKE0yMz6slh4lqjlGC4zMfClxdx6zMjcVbqppMyH4te+op2A9OwaZXYNZXsLx835857fh6LX/ySURNH41ArUSWJRq1uoG5DwcgcWiVqlLKf1H48Fb4K7G47U/fOMMdPFBSTktmG7bM3CUe84qTdkPak9G5FScFhlk2ehUNxUuEN8vUL87hpklBMjihQigaLFdMXmgA3ZPwo829iSFz9WhxeX4jNaUcNq1itFkJePyumzaVVVnudPckxQFX1HIZYajDRVT1fVrZgYe+PeIH9i7Yixzlp2jWZfN0n1+WuTJEJHsOerq5k45Pqm9trKeNfLs6tcb3KYAUl6/eRnNXBnG9cceiKj+aZaZwqOETL/u11s2DEBPj+4MlRgLMthj1FS+Cyz9wa+4+s3U2wLIAc5zTNlRB5rjWxmGhWZUjf7DF8PeGTmIREVYPgv4+R/FfIfz2QSJKU3aiui7++s4HsW9uBUZH3fBmvzdpJXR00Tp+8hNVioWl9DxfLgmR0aIRHg0mjI1/K8CXdhxLWix9K8PiveuKxaPzurkjZ6z9/8i2P/aY3C5buF8dXqnz6Z+FzePeDzXzywhLcbgebvzuGzxek+NB5Skv99Ozdgl79UvjNI/3ZUXCMT15byQOPDqBD+4a8/+Yafv3YAJSAeDO9/7eZ5vneu+Ln49dX8YsnBuPWgURx2+nYswWXzglz3cJXl3HvY4MAmPVWPh26JeFyWXFX6CYsSSJ8xc/s6cu4oVk825fvIb1/a6yaSsAr2MeYx4Wfx+OxM/bp4RQXHGb+c3NxKjIlBUdIy0ihZOcx9q7eT/sBqdzy+I36FVZyrKCY1Ayh7AX7kEjunMQC3RdljBlS4Qtx8cRF4pvG41AjCrhll+YsfPFLWvVpzeIXFjBy4mhufU7Y0Oc9N49FL8zn5om34FZkbp54Cw7972u7CpBUeP0se2E+N00aIyK2tFhF51JkkjNTKTt7mS5je5smwGGTxsSAz8rpC0w/1uDxo2tUmIbpzgCuQeNHY9E00oZ2pGVGaxyKizV5Cwh6/Xy//wSXjp6jRWYqJwqKaZGZik22Mfx5PYFSqzSf1+q8CNsbGAMwIrrN2FpQY14Ifshbfk1+FZtso3lmGmWnL3F0/X6ycsaayn5t3nxWTv47clSmudVqqcaejGMD3gCSJKDL6rCaPqmz+09QevQsSZltzbGTBYdo0lWYYQ8t30Fx/i6Sszqa566JVa3LmwdVnO0aEoHK/3rV+KPk+tMC5fQlP97zXjh9GewCSOIqVXJHpTFz8zEueUM0r+MCSWLV3u9pXt/Dxt2nyb2tA29/sAVvoALFaWf8HaIA4PCODenXKgHFZefxcSKMM1waCR12BsKEg2HsEvRKb4zbArXKxFtXxWUff35/M3/4dS+CZX4KohiQTVV57F5hcnv3Q4nu6U1w2y1oEjz0UCZuuwV3QADF+3/dgN8XwuV2UMtp5YFHB+CUrbiDYv9bn4haSu/MWCmu74qPua+vwF8exKnI/Ha88LWoBpBYLMS5bNz75BBWzRMh7xZNI3zFx+czlnP3+BtxhgX7uOsREcn96YuLmfXKEsZlD6N1p0Q+z1tKg6QEvBfLsWiayVZUSaIyWEHhxoN0GJBqgsbRbUdIzUhhy9xvsWoqsuJklG5Ck90OEprG43A7cKhhcx23x8Etz4zk8LajjJ44CqfHYYKE2+PQgyAcoInoIqsODNGMIRpIXB6HCTi2Gkxpj3yVfdUv1rIZi1j87BfIihzDgGyaehVGolG0fCcH8vfQOqu9aWKLNrUtfvYLVkybS73kG2iZmYoc5ySxa0uW6wxo2bOzIv4jXSeHvH5WTpvLkJzbqgFhtLN9Td4CAlcBnKuJARqlJy/w9eSZyIpgSKv0gIhOd/WNAYiQ10/+tNkMyhlLm6HpJGW04WRBcY1rH1i+neL83bjjFRq0TUSOc3FQH7O7HNROrEf5uVJCup+qrs5sWmZ1NH0/l/QtwH26OQsiQRLHNhZC1X4kmkRIvc5IfoxcBxLwNlIcKKEwfF9mAsmaXafxBsNYVY3cISkospW/bhal26+Uh8gd3gZFVfFeKmfqV4XkjkxFuijAwuIPYQmGhW25VADEm1/tNwGnIhRm+qyd9GnfkA07TzHx7s4oer+FeKtE9s+7oVglajts9O7YmPOXfPxmbCc8bjtuvaXr43d1Nv05b332HfZwJfZwWJjBfCG27jjJps0lPPxgH5wemXA4jCNsxa2XDQ/r/oeiHcfNbUVFJd9uOEz3Pi35pc5ojLdaVZK473diTHHZ8ZcHcXlkNAl+8cRgZJcdR2U4Zo7itvOzp4bictvRkLh7/I0c2HGcQXd0x6nIMcefLxH1oM6XXMBRKfwhrTs144tXlpCWkcLclxdz+4QRpjJ/a/vz5h9Q1cdUzRLFcjDX/mr6YtNnc8dkYRp66abp7F29n7YD0+CZqozEYs4doQcnAKADwNIZi0x2EeOzIdYUVeH1s/SFBQyfdCtORWb4pFuRFQcWLdYbokqR/0XDS1WlD+D0yNyYcxvHCopp1jUZWQ8WuDHnNo5sLGL5tLncmHMb+dMXmEzRqTjNAIWrswyJ4DUAp6b7A2jaNZmV0+bQIjONVdNmMzjndpyKk8E5t3OioDiqlpZgO7Li1H08TvN+zx84RdHSbaRkdUBCM9lTack58zwtB7RHVlwcWC6CTZQb6nDp6FmdybjIyhnLzpnfmGvWTWrAxeIzACYDijaBHdBD3eOTG0LVfiRAsPI6kPwY+a8HEk3T8rrV97yS3aIunLoCLuFk83qDfHOyjL5N4pjStTEAy/d8z6HzPuJlK/hDoKpsPXKJvi3qsvXAedCBxFvqZ+rSA+Te1Bou6WOX/Uz9ch+5o9u8Su0xAAAgAElEQVRScPQSfVPrc/ZiObm3dUCxgKtMmKRyRqaa1xYe0y7yWTe5zXh/M15/BYrLzsM/FxGHocsB3vzoW568vweqReKtD7aQlFiHHp2bsHfXKTq2a8hf3tvEI7/LwGkCiVgvve0N5rZg+0kAzpy4xAevLMPldnDf7/rpx0eU3f2/i5jNooGGUOza9zzUP3KcDnoz38rHXx7CplZi001S0YoUNGyqiippuN12xmUP4+D2Y4zLHobsjgaryJy5byw3lSaICLXibSUkd0lCVmRC3iDzX17MmAk362tHlKHxKVpxGr6KmliDioUKb4BFL37JyImj+XrGIgLeAE7FyU1PjYhxRzg9sh5Y4OCmJwUgLXl1MV89N9u81mBUmY6gN4jNYdUBR8amVVZ5Nnrkk6ZRGQzz9bS5pglN0jRKT1wgOTOV41uLCYfCJrOxyjbTn2Cwm7dvfolgWQDvOeEbTB3akUNr99JSN5VVjdqKjobLMqLlEM7qITm3cbzgMEN0sMoaPxpVklg2eRYrp81hcM7t+nNVTR8PiHyrVdPmUNfMQRHPY5XOWAwJ+YLk6wynzdBONM9ow4mCYrrc09902gPUa92Y9Lv6RoVOt6FkYxH5UWHeVf/uNYmqSfgr/utV44+S608LIKzC+XLyDl7Aq4Fis6AAfRt4BN89L8BgaONaZNT3sPF0GVNXHyG3V1NCwTDfHC0lwWWj32vrURxWBqQkkDuwBYqmgVf3SaCRO6wVChrdmtRi6pIickelMeXmNuIa9KgbyR55E3p9UaHJYrLHCrNZ8IqfvJk7mHRXJ9w+sXYdu4Wn7+2KYrewbudpendszOkL5Xy7/SRP3t+D7XtO07NTE/buPoVTN2WE9TLw+3afMrf9M5rTvVNjCnac5N231vHQQ5kmwzHefP2+EHt2n6Zdh8a43A5+8ZAAmg/f3WCylHt+LwAkWmEbQBIqC/C311byiycG4wiHzX2Nmtbl9JHzNEysqzMSibsfGaivE2EI6BFqX7y53Axv3plfyK61RXTs34bUXsnM0VnMnJcXM/bp4RzZXkJaRgpHth0VyhmJToPSSO3Z0lToNjXKtKVfdzS4mPciqbg8DtNsFvD6+erFhaQNbEvQG4jJHYphM4ZppyzA4hcXcPNEYTpa/KLIGSredJDC/L2kZrXjludui8yp4qQPeQMse2E+bbLacdOkMXpuTYBlL8wjOTOV4vWFDJs0hq2zNgBwseQcaqVqhlFbNE3UkioLcHh9IS0zxYvLkPGjCHkDfK0zmuiQWguaGUAwNOc2VkdF2H37UT4hXwi7W+Y3iyKJsRZNM0FGVpzmeaP9NXIUc+l6Tz/zbyFCr+XITUdp/ZrCpL+ePNMEGqOWlnHcmrz5JGW0QVZcZhi1rLj0UGgBNBeLz1QzbVVcZyQ/Sv7rgUSSpOxGdgt520/jrdSYeuIKuUm1WZLeMHKQDiSUhyCscuJygL43eNh6/LL5BloeDPPNscs0r+Vgya0RBzylwmSV3bOpOZS3voTcwckCaC6L/Xlrj+INhtl6vJRuzeuiyDbylhZxobyCBI+d7JvFD35b0Vn6pjVgW9FZZL9gAM/cGmEuvvIQL/19GwO6NOHOrBQUu4Wureoz/ZPvePL+HjhCAkhsYaGcO7VpYG4NhvOXj76je8fGuB02vN4Ab7+9gd8/KFjIu2+vp2u3RN57ay0P/r4vjgq9m2OZnw/eWstvHukfAYgoIDFYisdl5/4/ZOFy2U3lrWoaPQa0okP3JAp3nuDTFxbjVJyMe1T4WiaMewe/N4RTkXnhC9GrJeQNMGv619w9/kaO7BLmuSO7jtMlK1VnMce5M/smZI9MSuckvnhlCXc8PdxkJLf9YWjMNVpQ+fK1ZQS8wkc0+olhNYbjWjSN0U8MM+dOH/06bfq04mLJeRau3sfoiaMihQq16vNLth2mVZ/WlGw7TGq/NEZOHI3DI3PhqDDjXDh6LtasVOXVOWIik7nxKZET8/WMrxg+6VZKCg4zfNKtOBSZhKR6nC/+noSkelwoOS+u3WoRTEMTTCI5M9VU3hZNM81mhhKP6R2jiH0OxUnQG2C5DiohX4jS4xeok5hQjcVEMxeD0WybuZ4Lxd/TKqs9D654NmYfEOObKVq+kwvFZ6jdOIHOd2UiK07WRiWA9jdDgYW5rGRjoclmopNZ08f2QULjwPIdZhh1q6GdATPYILYfiQaBiutA8mPkvx5IAOV0hYrXG0KxSOQ2VFAqVLgcVWXXIb5U3vIQUw9dpG9dJ998X05uaj22XgnQt4GbrRf8gIZNE0Dhrahk69lyujWOQ7Fbye7X3Fwuu4cOKk47BITS9XqDTF1xiL7J8cLnclNrwqr4YYZVDXwCNLo1r8vUeXvJHdMOgmLuq3N2m8yltt1Czrh03B4HT90hHP15c3Yz4Z4uFOw7Q97bG2PMYrv3nTG3jpBY7+FfRJJ0//TJVh79bQYul40t3x2je9em7Nl7mkaNarFs8V4ee1Swj+WL9tCocS2WL9rDw4/HMgmAT97+Br8viNPj5MGn9DyZSsO0JfHzBwWzeeSO9/n0tZV06ZuCpGn4y4McKzrLmeMX6dCrpalk3R6H8L94HLjjnJRd8uGOc4o3Ug06ZqYw9rHBqJLEs7f/hXa9kyneVoJFU6kpm8OmquxauZfda4po2LK+6QMxQKMmUAARJTb/pa9Q4j0kNI3n2znf4vLIptN6hJ6Hs3jGEgLlQSqDYQ5uOMCoiaMZ8eRw8/73rdjNucNnqZdUL5YNVGFFw3SfzLIZi0wT2U163k20SGgk925tgkLAG4oBiIcXPV1tTmz+jDjviukLdf+SzAgjwfPml2iZmcrxgmIcbgd1EhNwuB0xa1X1xRQt38HB/D24REkSiDKXHd1YxMH8PQzJuc2MSpMVF6lD02me0SbG+R9tLjMA2zCXrc5bYCZUBsv8HF2/H2dtt+n4j5Zop3/R0m1Vwn8lQhXXyvi5LlXlOpCAt5FFQgmrZMfJJmhQGgUkbuE3USpVcpvVZmtZkNyWdVFUjVBI5ZvzPlLcdu5qURfFZsHrq2DqzjP0vcHD1M0nyO3WmLy1R/BWVApQyWwO6IATqkRxWFFsFnIHtmDr6TLh3LdKNIyTqeW04bZboUIoXcVqIXdUGorVArqZylseZOrcPeTe1p4pelSXZrOYc7JvFz+iyZ9t4+VPtzLhni5miHKXVvXNrTEWLRZNRVJVLKpKetoNvPneJho3iuPU6St079oUiw529RLcbN16nG7dErFVih94OOqlLugN8P5ba3ng0QHYdAB5+L7P8JUHcSkyXXq3xF8e4syJS4AAg6A3wKevr6JWXTcNmtSh9HyZOffuhweaa+9af5AGjevgVGRCZX5m6lFkhhJu3akZM6cvY1z2MH0s2lykJz1qGud0h3/ZxXLm6M59U5FHNZYymIusOHF5HNz6zEjW/2MT50rO06ZPK4LegBm2bMwPegN8+dJXtB2YZprFls5YZFYc6DC4Pa16t8LpkcWcmoz4UbrZMJGNmHSLfhexbMBgK9XXUE2Aj2nLq39WkWJyZ/av2GX6WoY+JUKZm3VNNk1gDy56psYLvFqmuTteoe/vhwllb+bbdNBNYC5zzPi/hEbx2r3m9YhQ5zR2zt4IEAMy0Wzm8No9NM9M4+y+4+ZYdGY/wKCcsZwQEWOx4b8aBELXVeOPkf/6p6VpWl43m+WVbICyoAkaNUpFpchWUlXhV9E08X8gyWljSqt4APKOlJLbrgFbL/rITW+IAngDYaZuPUVut8amgvf6Kpi68Ri5Gc2YMjRFzN1yAm8wDJUWCieIt/28/GImz9+LIlvJHi5MXHnLDjD5i10osg3FYSV3TDsURwRwon/Gxh95R9FZ+rRvyI6isyZoxDlt5tYABWML4PcGefODLTz2QC88bgePPdCLz+bspHHDOC5c8JmK3e1y0K1rIm6XA4tusrJEmbbcbju/faQfTpfdXP/owbOcOlFK46Z1aNuhCR++uZpumcnceEu6Wdrl/j9ksWvrMQrWH+IXTwxmlu6sd3pk7tJ9KC/PEk26VEni8z+u4p6nhuL0OEz24fY4RMTY9mP8fdoiZEVm9/qDuhnLyejlol1yg6QEzhw5T1y8mxG/HYDscVSLXlIliZ0r97FnTSHtB6QyeckTqFg4su0ICU3qiigpj8ytegjy3Ofnm5FTtzwzki1zv6Nw7X5kxUk4FGafHjk2YVl2bA6HprFkxmI9HFs48qOVvawYjnzZ9D+Yc6+So/L1jK9MpgWCpRwrKObBpeNYPn0hQ8eP0v0hwucybNIYLuqRU8a2JhNYTRJ9rQCpQ9NpkdGG41GhvscLimmZmYpNtjLi+TtRkXjv5hdpkZnK8YLDJHZtyYppc2mRmcrKaXMYknNb1FiayUxqypP59eJJQNUcmtHVzJVfT55J0dJtsT3bNYngdUbyo+S/HkgAAQb+KhVko6KU0MuIeEMqU8+W09xuYenlywyqJTO0npuMOIdgCCGdAaTER+a6xCPOK7pAbudGKJJkHqfYLOT2TkSxWUxA8vormLrmCLkDWoD+Zu8NhJm6spjcoSmR4wJh4bAfmcoU3REv7kV/c1ajIpP0z11T6vGC7qg3lPkT4zqZ21c/K8Drr8ClOHj0HsFsFJedJ37ZE5fLDpqGpEFa6/ps2HKMx37T21znw3cjnQR/+euZ+HwiE//dD0T9pV8/0EdclkUyHcjWqBIo+3edpHOPJM6duoykiZDRe/Wor0/e/oYO3ZNwehz4y0N8opu+IiHIkpn/cuejkaTKT15cglNxMvYxYUr75MUlzJy+jLvGDyPgDbI3KrPfoql0zkojrUdLM7lSlSQzm9+pyNyqhxZXfde2oDJx/qPi/rCw8LWlSJpGOBhm/ktfceszIxk7WSi4/esKKdpwkDZ9WlF6WkRMGaHPFlTTBCZ7nATKg3ylZ/tHg4UFzXTkX80EVpMEvUGWvDCf4ZNupXjTAYry95KgF+0M6kEhgAhr1h35CUn1OV8sqgYvevaLSNiu/l1YlfelafoaHOUTiTwbcV1Dxo9CRWLJs5+b/pXErslm/suSZz9HVpxUBis4sr6QVlki3Dc2IszFobV7aZGZytnCE7TITONEQbEZgmxEh0EsgAybcvXeJfr9xPpIVAgEr/tIfoxcBxIQjDxUSR7g1TQUSSLbEfVF0j8rEuTWd/OXC8IxWBII8+HpMnyVGn5Vw4sAh+y29SNzK8UPKbt9g6gxoUizuzepNqbYLOT2ay7ARZ+r2K3C3OWwkresCG+wki+2naRvSgJbj1wib3Eh3kAYxWkj+5Z2MecFyFsgfCjbii+QMy4dRbZFWIMOMhZV5eOFezhy6gp1aznxlYdQ3HYe+UUPQADAK+9s5I2o0OJde8+Y57BERT35fCG2FhynSZPa/On1fNxuB/f9rm+1x96sRQL1Gyg4FSdtOzbm/TfX0LhpXT7QmYkBJPfqkWGqxcLf/7SG+x4fxIr5O9j2zSG69k2hXffmfPbaSu59cghfvLkKf3mQPd8dZfu6g/zsqaE6M8FkJrIi41JkUbOshrdqCc1kM0FvkNlRNcsA0ge1pU2vZNMMVVVx71q5lz1rCrmhZX3GTLgZ2RM5h1Nx0qZPK5yKk3pJNr4/fJZ6SQnm/kB5kC9fXGhWjza215KqeS0WTeONUdNNxvXoV+OxoOFUZEZMusUsVAngvyK+y8cKirHoZq/oCtKbPlpD3cQEfJfKTZYCxHz+OupztKyc/mW1bP5opz3A0Kj8l6E50VV8Y531hhimrxaZqRxZv9+MCjOiv5ZNFgmZRct3mo71aJOX4VcxmMmA7FtZMuGzaj6S60Dy4+QnDyTXaGXZEpiNaKD1il6u+ZriBaZWqOTaIoohz1ch/BiSRHZDwX5nlga4oL+J+yo1jocqsQJTD18i2WUDuwVvWGVraYBu9TwCFOwWvBUqit0ScbbXINmZSdXH+rcwwWzwu9+yqug8LruFou/LSanvpltygpmjUpMs33GKVbtOk5XeiCn3dAGooYMHnNaj00rLAsz4+Dv6dW3KQzqQAHjcdh7/VU8+mrOTkuOlJCVG2ii8++FmfL4QbrcDt1uYuc6e8/KXv6znoYcyzTfmaNt5uw6NeU/3m7jcDh54dABLv9x11WcD8LOHBwCwe2sJJ4+KN3mXR+bnTwzG6ZHZurqIbd8cpHGLBGHiilKaBjNRJSnmM4g3+qA3wOd5y7gzqnfMoW0ltM1IoXh7SQw7uTtnJKokseC1r002NPqJYTGtZes3S+COybegShKv3PKGmW/y7MoJqJLEoleX0qpXCs6o8Ngtc74lvmk8387ZQt7ul36QuSuk57WkDmxnKu5gWZBDG4pIyWxjzh8WlTx5cO1+UjLbUHpaFCtN6lpzb6WKUJhLxy/gruvhpkljTAAw8lc2fbSauokJbJu9ieFT7oyZG/QGTV+KIQZrif4erJr+JS10p7phAjOSJ6v6WnbM3kSdxATOFp40WYqRt/LO4OdZqdccO7XjCAAlm4pMcPmh2fqaBhWh/33T1r9Td/2n5ScPJFy7ZeUgvfrmDxIFyLVJKFFfXq+mMfVykNzasmniSnJYOVShkiRb2ekPU8si4dWBpVIDb1hlatEF+ia4mLr3LLkdGkClxNSdZ8jt3EiEGldUorjs1UHFepUvsCX2B6XpijmsgeK0kTu6LYrzn/85VX19I6/jmhJ1StVi4aH7egIwe+l+Si8HqKxUeefDLfj8Ib5cso+S46Vk9Ezi449Fd773PthkgktN5pa9u0/RpXsz9u0+yVsfi5ItsuI0FfO1pPuA1rTv3hyXxxHjEThz/KL5+b5nbrqqmWf2myt1h7nMiMm/B0QC4bjsYTG2/5QuInR47NPD2bFqH7vXFNFhQBvTzBUoDzL35cXcNiGSM5I+WDCWjfO28tzgV5DjnJwsPMX5kgsx7GP/ukITXG5+UoBXrfq1OLDhAK37tK7xug1z18iJsUmBN0+8hUObDrBIz1GR42RSMtuYLYRBRHoZ5p6kri1Y/MIC2mS105+7zNczvjKjuwxWYpgfPfEKI58fazrjDYlrUNtsBVDVvCYr1X0pBkuJJGEGOF5QTGJXYWIcFMVCVk3/Uo9+iyRBes9exn+pHJurui/zku7HuVRyDrmWG99FL+GKMCunzSEhuWGNQLImbz5UbWylSvj9/7/4SP5tuus/Lf8vAMm1WlbeIQlFstVAe0OiOyTWRtRzzgYRkgtgE1+krWGNvrKVraFKU8kPjZPJqONEsVrIiIepJZdJdtpo7LKhWC0oso3ctvX54thl+jbwsPWinwFNa5PbpTGK3YJXVYXjvXdiBCAMALFGKb6Yz/q5295ARnICb687Qn2HFdlmIXtkWuQ4c73I3KGdG5OR1oDP1x9lwFOLUFx2Frykh55aIsDictoJhCqxWix0a98Qu91qVkOOllYtE2jcMA6P24HPH+KP726kSZPaAGhRh/8yqnBkTf0ES45c4ETJRZomxZsK/+eGGSsKAP7257XmW7jBSBbP/JagP4zssjFwVCc+1U1bDRPjOXX0AjckRvxUk+54F79XRIdNnf0gAAFv0IzkMs5nFJ2MFqdH5o6nh1dxLEvm9RVvKyE1I4WN80SDPFEPTDzbvesOULhR+EOseh6NsRXXEDD9JYteXYq/PMiVc1do3ac1TkVm8YwlZmCBkeTo9MiMnDg6BiBuemqEWbolRQ/5bdMvzSwLY0jQGzCbppUUHCElsw02h1ABNz41koXPzWGpnuxoMJsGrRpSq1HdGGAPRjnjZT0fpezsZT0cuWZfSWSuYCmGGWv5tLm0zEytwbQlzmNEcBlSEdBrv1VUVttXN6m+KOWfVB+bbKNO0wSOFxwiHFZRK2O/gUavmJIaam2hQeWPYyQ/tENiVfmXdNf/Rfl/AUiixbS16HTwPQBJkt4Ffht9oNEhUZKkKZch12uRBHjoJqQ8XwVeVSMEfBOsJDfBZSrz7EZxECfi5ofvO0ffOk4Um4Ulmc3E4vrb0sYLPlZ9X86gRopQ8BbAIqHYrOT2aoriskXOt/m4MKG57MKUBWbdL8AECCMxEask8k1Gt41hMXl6NvzWwxfpllIPxWnjSd2hnr/3e9bvOUOf9g3NkiuvzdpB7gCx7dCqHusKTtCogcLmnad44pc9o4Amotg/+ssd5uf7fj+b7l2bcv6Cj98/mCnYRw3gY4x98G6kmKRqJCSqqplnsnf3KdI6NsUZlSHv84X4+I18fvHEYFOBB/1hzp4spUGTOjgVJ/c+OQSnImOTrXTo1RKbw4YqSaiSRfhMNh+mXe9kc/7BHcdo1zuZg9uPmdc4940VBLxBDm4/RopeJt8AF2Nem14pMT6LcChM4cZDeOq4mfvyYtoPEH+fgDfI5fNXSM1ohaw4adjKSZ1GtblyrowvpizAqTi5cq6MhKbxXD5Xxq6Ve6pFcM17fh4LdWe7cQ3Dxgvz1NIZi5n/3NyY8iqyIptZ8QuemxsTHgwC5ISPxEmzri1Nx3tkv3CyH950gKV6gclmXZPNz4YcKzhMcmYqxwoO89CiCYBwxC/TzVgG6yiYuZ7zxd/TOqu9CS5ylI/EKMniPXfZrAUWLXJU+ZWlz85CVlzUbpzAheIzWB02knq15HjBYfJ15nL55AVaZKZhk21m1NYreltrm2yLccAHvcHo/JIYZ7ukSjh9PxxI/FyzQ+IPlR+su/4vyk8GSCRJur3KUKmmaSu5SstKnXF8odPDeK4u3kaScHLjsIKsJx8GhUlrkMtGbgMPikUCtx6BdeIK3lI/itVCtwQXU4sukNsmwQQQDBOToVAtFmEi23qK3F5NmWIkJ0YBhTesimitoSmR+dFAYjAlfWxrSSl9U+uz9egls/Q9wPKdp1m16zTNb1BYWnCSnHHpphJX3HYyOjREcdl5bdYOvP4KZq86SC6wsuA4/Xs3p1t6E3YUfs/tw9Nwu+3m3LDVyn0PzRamKo+DD98WYNK+fSP+9PYGHnook0ceGwBEWM577280QUNDwu8LsWPbcb7dcJgHHh2ArzyER5HxlYfw+UJ88OYa0ns258M38rnv8UF89pd1+MuDzP90Ew2a1CF/4U7unyAYhOyy06BJHWSXnTv08veqJOErD/H3Gcv52VMRduHyyLTv3dJ8q1YliZTOzZhVxR8S8Ab5PG8pnjputq3YS8OW9dAkzJyRW/TkxAWvfc2sqQuRFZmzx4SfJhSoiFlnnt6PxYjWmj1lAfP11s0L9L4sPW/rzoKXvmL0xFEc3CR6p58vuSBChj3OGp3tS2csJuANcGjTQfav3meWWlkUVXZFlSQccQI0opWz4SMxQoGNbHgQZi/DlmlzWM2orYNr95GcmUrB7E1oCOV+9uBpzhd/T73kG8yck2MFh00zlsE6jORDI3RYZLtHgC06Q94sf0/EfzJQP3bps7NM9tH7gcF6EuMBDupNwwLeACv1ml1H1u+PST5MH5thRnQF9eOM/JHmmWlYZTtAjLPdooIc/FFAck35X9Rd/2fkJwMkmqbNucqua7Wy7Kb//+lrrJvXzWF9JTtBFHpDL9muaJgAkp1cV98nftBeq4Wphy+R2yYBxWknt10DAUQ6AOQVnsdbUYnDrjMPuxXsFnIzm4nIq+9OCvbhtpM9UDBaxeMgd2gKikeuBhoxn/X+Ed1a1RNJiGM7mGMQMS1d8VXQp31Dviu+yCtz9+D1V5DRJZHHfiac7dM+2MKMT7eS2KiWmIeEahH/enVvxkP3CSe7UdpEtUiU+0N8t+0E3bommuNOj8xDD2Wye+8Z3nhrnR6hJUxaG78p5tuNR+iR0YL0bkn89a21dO+TzK8eG4jskams1Cj3Bomr7UJWnNz/hyz27zrJfY8PwqnILPxsCyePXsAu27h8wUeHXi34x5/W4C8PMuxnPc1Q30jhSAtOxSlK2ntkVMmCKkm079va9IcIliIhK07uzL7JZCRz3ljJwe3HaJuRQuG34jdddtGHvzzEHL27pHGuHasieSSGyG4HI/9wo6m4b31mpAkAqiSxee53gn2cvaw/bzi87Sit+7TmSMERbA4brfu0pvR0qRm1NebZMZF708+z9oPVnC0+iyfeI3wh+nfSYBrG8cOqViW+SoLg9wdF5N3+Fbtp2bs1S1+YR5us9uZ3oiJUSfH6QuKb1zfNWYaZSK1UTTNXa30ORFjHN3/52rzX6CRHww9i5JEYuSVXKw5phAFHO9ZFFnubmPpc22eur3Z/RvkUg7kZlYejS91TxUfyYxnJP5P/Ld31f0l+MkByNfknrSxX/qBFLJIJIAZYEKqESo013hDe014R1ltfvGEpLhu5HQR4ZHcVIbx5O88wec9ZFLtVRH/pPpApQ/REw29PiF+Uw2ayj0Gt6+FVNRTZZvo58lYcYvKSIjEWHYUlx4KL4pHJGZeOx2nnpS/34vWHUVw2sno0o0eHRnyef4gNe87Qv0sTrgQrmf5ZAU/e34Ow7vtxxsk8/queLFx5QCwrW1mzpYQNW46R0TOJXz+QAUT5UCQJl1umW9dEzl/08fqfBGjcr4f1vvXmat55ax2/faSfCTKartQ0SWLv7lN06pGETbbyQLZgC5/8eU3k7yhJaJJEpz7J3P3wQBER9bHoJy9J0KFXC1yKjM8X4m+vruBnTw01lebnf8zHr/sDxv5B9FGZ/eZKPnlxCbIiEygPMmv6Mjr2b4O/PKQrH3G+sF4Wxl8eJLlLErNfWYKnjpvyUh9x8R6cHpnbJ4yIgFCVhLb6zRL4/vA5PHU85v1G35MBXHG6E71eUj36/CzDzBMxTFeHNh3kwIYDNGjZgFETRyNHgYIhKhKVYaHENT24Q4sqmxIty2YsMsGzapa7KlnYt2IPRfl7sOss+kLJOWwOK8mZqVwoOUdR/p6YkN7AFb9pzmqY2oQ6TROQ45w44pxmCXsjQktW5GopkchkpUkAACAASURBVNHsw5BwMMzh9YW0yupgAl10Zns0qNw45S79GQipyXEu63XADHBRsZj1uKrKmrz5DMoZy6a/LAXhI3kAXW9YVP6tQHI1+bforv8j8pMHkv+pmEUb/Xq5kWAlilViuTfEqgt+6tosLC0NMKi+G45fFiG8ThtTuoloq7y93+OtqGTjmTJWHb9CbkYzwS76NReZ5noNIq+qiYrBQ1NQFAe5N7Vm49FLTF12kNyRqSYLWb7/LKv2fM+g9jeQHdVV0TBfVepA8uRdnUw/R9tfzOLwqSu0bFyLbZ+L6KcNhWc5cuoKqkVi28Fz9OzUhO0HzhJyiPNUWi2oVotZzysQ1jh5WnRL3Fd0llf/vB6328GvfiMAJWy18pePRDTWTYP+yNt//obEpLqELRb8vhB795zmgUdFNrgBJD0GtKaDHlnlKw/x0Rv5dM1M4Z0ZK3F5ZNp2S8LvDeFSZMp9IT59fRX3PjmEsNUqSnG0uYH6TeqaxRpVycLsN1fGMA4QhSpnTv+acdnDTOXrKw/x+XRhujq0/Thteydz9vgFdq0tMnNCZr+yhA46qzCUz+0TRnBoewnJnZNwKjKjjAKNemCvKklYZbtwoMt22vZtQ0rvVhzcfIj5elkUwDRZGddz5dwV4pvGY5Nt3PqsUKZLZiw2QeO8XlgR4JbnbkNFMpXmG6OmEywLIsfJ2GQbdRMTCJUHWRTlA6nKOAJRyYdQtVQ/mOVMojR+Ytdkk110G9cHWXGSNqQjLTLacGRjEQfy93Bjzm1mza1oWTn9S5pntMGhONm/fCcH8/eINwDgyqlLyHpPlOMFxSx59nMciouL+j1fjOo7Es0+DFBJyerwgxtuaXoHlJoKbkaLUR1429/W4rvoBTDpv6SBI3CtQvPXpar81wMJRtFGXUFPPVIq/B36m7v5+7Rb8VosTN11mtzuTaCWbuaSJKZuOcmg5nVE6XjZRvbQVpHVdbPT1lNlIoHwVBlLsvXSJ0uLyEhrgCLbTCZUct5nbl9eVGj2Hnn8LlGtdPrsXXj9FWwvOkd62g0oLjsVethlhaYR0qNw+mW0oGunpnjcdryBMG++t4lHf5tByC72lwUr+dN7m6KirSQaNa5DybFSPIrMn99ez+8e7mceH62IKvVkx8pKDW8gzAdvreWXf8jiV3pXxbCuQAo2HYlpgNWxZwtOn7hEwfpD/PyJwbz0+W/1tSOlTQp3HOeDl5fhVJxMmf0QALlj3+aJEX/Uxx405xi5MI44YaYyWAMIYLjj6eE4FJmWOtNo2LIeaRkpHNp+jHZ9W5tMAzB7z4PwgQS8QVQshKXYxDRVZzFFGw7SbmAaI54ajipJzBj1Gq37tObwtqOk9Utl9MRRyB6nqdB63N6ThXrYrml+Gh9hEmvfXy3+DsSCgipJBLyRnJBuY3ux+IUFpGa1I7l3K2HO0o9/a2Se+Ubeqn9bPe9DrgYiKhKpQ9Jp0buNWW4+Pqm+6US3OWzc/PwdMYxopZnrIZtrRItWg+lMskholRpWh830d7w95Hkzmz0+qR4Xis8Qn1TPvNfoXvOr8xYwOOd2jm4sqrEcisE2jEq/ZacvcaH4DINyxppRWbLijCkpb4wZfeMbpDXl0tGzXmC/cV5LpYSz/HqJlB8j14EEuio2C1v9YQY08JDb8QYUuwWHP0zfRgpn/WEeTq0n/BwOK7l9kwTTqCt8Kkptp9lBMftGEfuft/qwKAlfUkq35AQUp41ureuZVXvzVhwS1XrdDqboAGEwjcRGcRw6U0ZiozhKK1RembmDAV2acLFSlCu5UqHy6mcF9EpvzPRPvuPxX/XUw3Fr4XHbCejM5le/6WPe4DsfbeHhB/vg8MgEdBOZrDh58Pd92bPnNAC9+6VQKUl07J7E3j2nGD6mEw6Pg5BNBxKLhT/c+zG+8iA+X4hOPQXTMHwbsuKM+FOiWMGuLUfp2LMF6ZkpfPbqCjr3a0XW7V0FczHNZhazrPvTo//E32csJ71fa27TzVS+8hB7Nx2mbe/kmDmGGDkd0eBSFRhunzCCws3F7FlTyJgJN+tmKslUgNGA4S8PMf/lRdzyzMgYZWqE6BrFHTX9nCoWwqFKDmw4QNuBbc2uiYtfXcLc5+fh1HtvjJw4miPbjjDvuXlmFroh8Un1OHv4LEgS85+fK0p76FV9ZcVJSqbwBzgUZ0wZeVWKpEAGvEGK1xeRnJnKUL0kCdQcem1U+jWYWOrQjmz86yrTiW7c98rpX5rBBjfpDvG3b37RbJT1W70HiWG6GpJzm9l8auM7y7G7HNjdsaHT4tlJ2GQbLXSHd035Pgb7MKr6OhQnAW+AVXrSoXFdZ/ef4NLRs7jqekwfSHSDLOM5BLyBak2u7l+cywTLrUWappmJQNcZyY+X60ACBd6wOrxb41qiZInuK1k+dy/fnPYyqHkdpozQnaqeqFLZOtPIHhXlx9CVuFeSmLq4iL6p9UXG+dgOeGq5TJ/G5VAlL84Wpd39ukPWMFP1792crulNUNx2Ki0WnvhlT+Z9Xciabd+R2b0Z/TKa89gDvfhqeRE9ujRle9E5evRqYSb+BRyOmPUAs0S7apEI6WNG+ZEP3hNvpBVWK/fW0JAqZDh7LRbKfSF2fltCx54t+OPCh2KOVS0Wc21j7OKFcuo3qcPFC+UU7jxB+94iLPeeSUKBGswl+nzRfpXP/7iKgDfIsQPfU69pXUrPewlbrNXmGFLjGBZu1su1L3xtKa17pSArTnau3MveNftpNzANJsXOdShOnVFEGI6KBV95iIUvLqTtwLb0GtdbmNcQDn3DQmSAC4iCl4te/JKbJ95ihuXOGPYyi14UjOLG8RHfRduhHWmZ0YbiTQdYrLfnNRSg0RdelSwsn74wYr6JAlMVibKzl6mbmEDZ2cvVGMPVEjMH6SXYB48fzfp3VgBQftFr1tUqXL6Lg/l7aJXV3nSSH918EP+lclx1PaycvpCg18+O2ZvMYosp/UWS48CnRpsMwwAzqw4eNtn2/7V35uFVVOcf/57sgRsIYXFBtrAjooRgyyIgJqhVcWGJW221NdSq1bqAYsSfFpeE2tZaq6BWrSsSUFEqS0B2RZIAyg4Jq4osIZCFJCR5f3/MmcncuXO3zN3zfp7nPvfemTNne8+c96zvMbWRpea1Hv08hzq3oT97pPa00ouHEMh8RrHt9tY1f0F3aYtLRT2SVz1B0RlRjUBCFSsSb2BFop7ZnhwPdGilKYsDFXVN3ymtFJdSUeR9uQuV9cpcydQJOoOJslfRqm0inrjlEsxbvQ8jBp6Lb/eXY35eU+vzxblb8OhvhiLOFodq2Vr7xwfFqKo+i0RbPB58oGleAgC+2XYE+384hYZoodmsqo+JwSuvrsU9916G07UNeO3VdfjDfaO0Hke9buPbW6+t1c4CMW74+3rNXu076wH7VVD6341RynnbF/2yh2KuXe2p6FZMqagKoH3nZGxZtVvb9Kcut63Tei6OwwfqrvB4WwKKl2/H9yt3olO39jh64AQmPHaN1iNRh5+UeYyrHeJtjD8AbVNfoxDYsnwbAGi9i4UvLgYA7dTFG5+aYNfDAaD1KlTzJI1ouj8g8yL0HNYHcUkJqJfp2l+sbPrbX7xPi4edwtFV9uNk72LprIVIHdbXbkhq6ayF2m7w2sraptVThiGwwZOHaxPexmGp2spa7Zz3ON3KKe15CJzTX5lEP7L9sDb8pPYgyg4cx6Kn5jpUwk22r/pj39oduuW48x0UBNB0xru6kkr9VpWH2ZCUGj8A2pDUqrxP0HV4P8TZEpHQzobqskoIAEtnfIB4WyI6D+np0PsYPfVGl700FdEIxJ1hReINrEgAZdVW63j8asF2ZTI9PgbdOtmw90Q1unWyASnyMB7ZC6kUAn/5dDtybr4Yzy/epa2Y+tPtyp6ke+5UTInUxcVqJxNW6ncYx8egrqER0bGxqGytvJjl9YR/vbkBf/zjSFS2Uty+/oZiYiQ6XjHBntgqDtUJiuLZvONnDL60G77bfgSDhylLamNax2P2m99ou6HVDX0VNfV4+6WV+M1DGaiJVRSNUQE0iijt3kcvr9B2gk98IFNz/3/z79XSYOx96Cuuquqz+HjWYgwa01eZp2gdj61rd6P/8F7YvfkQ6qLti53+2e/X7kFNRQ0SkhK0PRrlR0+j74je2LvpoDYEtWX5dmz7SulR6BWEEWeTrgMzLkKvYX20/RtnqhTrt5/LHkS9iZK78pFrtTD0CqYRwu5QKLWSUjf9Xf3ETVq8+2cOQuqwvnI+x3HuQr8rfIlcMlv69W5tovtgcSlSR/bDgeJSh/QelMtpDxaV2CmZmspabQe5uqtcNT+yed7XeGDnJLx27fPI/kLZxPdq5jPYs+J7AALlP5xAcpcOOHOyEsukcuj2yz7a0FacLVEzmKgckdu0zNZMQWyZt17rKfxuUY5D+vXDT86WLAOKUlDZvXQzykqOIL5NK6yYOQ+X50zGD0Ul6DZyAA4b8kJlte6kRSOiAUioZEXiDaxIANtPp2tRGR2FHcersP9YNbp3ao17ru6H4YPOQ+He43ji852wJcagITpameg+cAqP/mYoYhNjcbyuAX/7YBMeuusXON1G6bmoS2xj2iXi/j8MR0yrOJy2tdICPFlPePX1b/CLYT1QXt+IVq3iEN2mFbLvH40YW7ymLMrrGvHmK2swdEQqzkbHICYmBnPe+BpnqmpRW9+ITd8ewG//fAUmPpih+f1m7hK8+48VuP2RcaiOV/yJadsKtz0yDts3H9JWTKlGCy/OGKB918QoiqSiuh5z/7oUWVOv1q7pMeuxfPq3JVprPjYpARMeuwbrFxSibs1uJCQlIDWtBxa88AVueuxarVI1U0JnKmuxa/1e9B3RGx26dcDPpcfQplNb7Fq3B9dPH980R6K1LIWdf+qGPbXXYBdvfQ9ADiv978VFAIDYJEWh6/djuKrIlPBcT8jG2hJxlTR0uGTW56itrEHxvK+R1KmtYrH20aYd60ZLuQC0Q6U69DxH2w2uN72uDj+pvQv1XmbOBG3IKd6WiDi5EkodfjqoO+sjuYsy0V1bUYPlsz5DbWUNouNjNKWw/Ysi7Fu7A+26d8LwP16FOFsi7lr0pJbGlXmfgCCQOnqg6XnqKuqcRbvunbB/7Q70HHsR8vrfh7PVdYhtFYdHdrwCwPnwk1EWekXQe9wl6Dq8H34o2otLbh+DeFsCOg/pha9mfozLcyab+lNTWYOVMz/GmBzHFWhRjYIViZewIgEqz01JRKuU1oiW8wpRMVGY8vthAIBn39iA597ZqJgLaQT+8W4RHvz9L3GvPGL23+98i/vuGSGVhVL41WGl2+67XPtdqTMbEt22NX73wOXYUnQQr/1rNe58cCx+91iTzSfVVkNMm1a446EMbN24H/+RyoEAvP+PFRg8qjduffRKRLeOR3Vc02RmdJtWuHnqVdix6SDeyF2imPmQS1hzxv8TH8xagkFj+qIuOlobGgKA6x6+GjWyQo9pk4gJj12DGFt80zCUk5a9qgSqqs/ikxcW4cbHr8OEp5QKZeua3dgpbUnFJiXi+unjEdva3M+/jX8RNZU1+HHXT+g9Qhki6jeqP1KH9cH+4n0YdtsIxNgS8NmLi1FbWYvo+BhtQ169aNrrUl1Vi0XPfYZrnnDsVegrI+MhTxmPXo+lsxbKZb7CcbWWG6VizA9A2Ryq7I+RNqaeXYDkLu1RsnYnUkf2s4uf2mvoPXagNomsDoO169YJVz6tnKnx/IAHkNylPX7YvF87nlaNm6ow4myJdsNL6nkcBKHNSRySJw0e3XlYeTYpETWVtVguh53GyX0bG95agbZdOiA6Pgbj5PzDyrxPNGOKu5duRsmK79Fz7EXasJMZcVJBbPlwjbwiUFZyBI31jYiKidLSQFCX8Db1Yn4o2ovOQ3rZrbaqrazRFEXmM7eiEQL/veYZlK7civikRPQYPRBjcibj+3nrtGt3LJqhxSfelogxOZNN50t4aMt7WJFAGf+vtCXg5kmXoKK2Aa0S4/Dcp9tQXV2HRatKMCS9CzbuPYEhw7pjyv2jUPj9j3j2jQ1IbB2Hxvh45Uys+HiUJdk0/1TqdUYRVcY/olTs302ejYHDUrF16084naAUaH1FdM2j0vjfhH9jwPBe2L7lB1w4qg8mTfsVSjYdQF10DKKiY1CpUySb15egpqIGJ4+cQtGy7bjpsWtRGat030u/O6x9pw7rg09z/6fte6iOabLQq58Ezv/rl1pPw9UQUkxSK1w3/XrE2BJQE6X0YmKTEtF7RF/EJsVrQz+NQqDG4WmguqoWe9ftRq+RffHwVzNMXCg9gBl9H9RWFv1RHvP6hZxDiLfFY3/RPvQc2Q/7ivajTtgXb/3u6nVvfKX5g8eAehGFM1V1WPLsAlyZM8GlEtKjtuLjTeYddugmqvuOuwSZOROw/rWlSO7SHhXHTjv0GtSlrkulAoiOj5WrmmKahtRq61F+6AQS27VGRs5ExNoSNaU3ymRSWj+8FGdL1K51HtILy3VzCHcuehKr8j7B2JxJiLMlault27m9pijMVj/pLe66UraXybjF2RK1/CpdvVXJ24ZGLJvxgXZP7SkcXL8TpSu+Q0K71tj9ZTFSxw4CQaC28gx+LCrBmJzJdnGtrTiDA2u3o9vIAVp4+1ZuxYG129F15AC7+I2Yqix+ePeapwGgrxBikbpyK6qRh7a8hRUJYDt6vAonGgXue/Bybd/EK39bgTdfXYfzL2iHosJDGDKyF26QS0r/88JivC6tzTaKRrz/0le47ZFxKG+lzKWYDf2oq43017qmp2omyE/HObaM9O7UzW51UTGoi25AzdlG5L+wCNdPH4/q6CZFUl1Zh93r96JDtw64bvr1iLYloCZaLvlNSkRlWRXikxIRndQK106/AVFJipKpjo6zMzOu7pbesnwbdq3Yhr5jL8RYucJH35rPlJWnfqOYOn/Sa3STFVlVuTgjzpaIniOVJZ71Itp0sjjeFm9nnkOt7FUFMC5nAjqn99J2UBuVwfZlTRW73h8AqEcUYmWLPtaWiHpZ+ZqZ7NDLZ8fS77QDlEYbhnaaNtwd11ra5w3qjr0rvscVOZNwprIWy2fO15asEpTNjsbKXlnCqsRHXaEkhEDGM7cp8TDJT7VVr2zOs5+oBpTJ6stzJmumQxohtMrX3k+hfet7Puqz7bp1QlnJEbTr1smlIlmTt0DLxytkvFf/9VM01J1Fw9kGfCWVh76n8NMW5UyR2oozMk2KEls182P0kEqlEU1KvvLYKbTp0gGVx5pWrR3beRhxbRJxfOdhrMmbj7rKGsTZEnCZVCTSbxt01n+VHonTpDAmhL0ikYfDpANI0xtec3ZojAmV7c9JArVLwvE2SU2rkVLa4JZHr8LKfMU69NnoaPzntXWoqarF3u9/wsTHrgG1jgcElLMobPEoj1fmQdRKUN13kNDafs+AVkm2sSmG9mzxmPePZcrKnKQEO+N6ALB700H0GtkXezYdVKyxPrcQfcdeiKufuAnCFo/q6KZlyeXHKtCuS3tExcdqZiXk4kh0GnAB2nbpgPikBIyeZj8MURMVi6qqs1jy7KcYlzMB1VFxdnFohMBL42ehtqIGR7YfRnVZJXqPHWhqgkJ9pqqqDsueXYDMnAmoMwwVGVGtta6Y9Rk++795dhV3dWWdNkzTqf8FaHuBkgbVzwNFpegxsr+yoW70hbKlnuCgSPQVu+pPnJwbqRfRdhWtOpmur+yNw116Th44hi9nKDu2VYWSLM2aJ3friDOVtVgxMx89x16ktfpLV23VJp7VVUYpPc9FbcUZxCclInX0QLseQiMEzr0kVbbSbVgy40O74R49NZU1+EpOPJtV8JdNNaz60v3WV/rR8bHoNnKAstdDuhk5tcnMCUGgy/B+TpfU6nsxq2Z+jNE5Wdq1oX+4GqtmzkWPsYPQdXh/xNoStJ4CAGx47UucOVGB+KRE/OLeazWlNzonCwfX78CqmXMxOidLC+fCSSOxeuZcjNKF0aHfBTi4djvOHdkDe5duxr4VW9Bj7MUgCNRVnkHVsVOAYvlXs/4b1QAkVHCPxBvCXpHIQ2EKAaQZbrk6NEb/fF7PtO65Vzx+PY6iaWPa5Y8pLext3/2ApPNTgIR4lNUQvsj9H66dfgPGPa0sbdS/gOXCfiK4vLoBi59biCtzJmDB35dorWrVAuqIaU3LI7986iMse+5T9B47EBVVZ5WWmWzln5feWxvbjpLHiup39mpvAICLJo/UWrGqMlDHmnuMvkibEK02VC7VIg5RttYYmzMJB4pKsPAppTLvNS4NXYb3R7wtETu+2Ij9a3cioa1UmIhCjXDe0zhYtA/dR/bHwaJ9DsNMRlblfYLayjM4sH4nSlZ8j7E5k7RnYm2tMDZnEmJtifitbpxbrezP1jZg39od6Dl2EDa8tUKbwL1sqv35FmrF3rZbJ9yx6Cm7e/W6+Rr9RO4hufrnUFGJ5kZ/v9e4wegyvD8Oyn0N+oq797jB6Dq8v7Yy6PKcyXYVf40c5x+TMxmxsiW++b2V2L92B7qNHKBVqmvyFmDxjA8Rb0uUfvbDwfU7tWfNFEWc9E8/9GPEqEjUFvt3H67CyZIjWgWvVthm/jQCDj0DM+JsCRidk4Ufi/Zi+Yz3EWtLRKwtEaNyshBnS9SU0+q8+airPIM4qcTadOmAMycqsG/l94hLSsTti/4PALA2bz66DO+PWFsiVuctQF3lGfxYtFfzTws3KRFdRw5AXFIiGmpVC83KaZhrZs7FZTk3Y83Mj+w3JHKPxGvCXpG4wNWhMXacjYrG0TjFCm7T8k6l0jhnaB9t2WOjHGNutCWgLFoOYzlp1QEAJSUpL6AtAacqa7Bq5nyMzsnCaZHg4J5sSRiVk4VD63di2cz5GJWThcV5X8gXZB9G5WQBtkQM1VWO1XBE2FpjVE4WhC0R1ZAbJCvrsHrmPIzKydKuqazNm49p025AQd5nGDlVGS9fMeM9rJAtu7HP3K653bNqG7qOHICqY6dw6f3XKZO6sghFOZjpA84d0lurhOrgukdSXVmLVTPnocfYQRidk4VoW4L2zLCpTQp3ucnwhDoM0wigrroOpw8dR5suHRzCTB2XhguGD1CGzwyLB/T/z1TWaq3n83Rp+CrvE9RV1uDg+h3Yt+I7jM7J0oZp1uTNxwXD+yPGlqC5i7Ml4HJd/jWFpRBjS8TonCy7lvgPRSVoI3tKZq15fXhdZCverALXt+zdVfKQ92sra7B65lwkd++kXVcr+1gnCkl9ZpQTRdMUH0WGK2a8h1UmZUulrvIMVssKPqlzB+xfsQXxbVvj4Nrt6DLyQi2M4boy8d+MJ7B/xRZ0H3sxxjzzay3NAHDroqc1d+vy8jX5A8BlOTdrv/VENQIJFU6TwpggiBwrgHBDHcYyDG3NI6JJ8vcyIso0PKOekAgAAwFsdeL9OVAMujUA+NlCND31R+8uGopl0p8A/OhFWB0AHNf9dxX2+SZhBDrNrtwa0+Iuvh2gHCHWCGCbD+INOMqjAkpH0Fm6zOJolpbmxMeKPDwNpxWUdoqr8NS0eBs3d+7199sCSIKie2vktb0mz/SR7ioA7PYgDkb6ElGS+kcIsRhK+jzlOBFd5d5Z5BI2PRIXh8M4w/TQGBX1hETpd6EPTjjzOUKIqVAmASv1StKD5zxOT3PDCBTGtAQzvp6G7cxdqJaz5hCItFjNby/C0R+Ti5auFJpDpPRIsgFMQtORlOrhMJ5MtkfUCw5EVno4LaEJp4XREzY9ElfoexeSPMM3wzAM4yfY6L7CHPdOwopISg+nJTThtDAaETG0xTAMwwSPiBjaYhiG8QQfbGBmTGhxisRZgQnHguQmLelQNmkWu1ndFhK4y3+5oOJjIioPRvy8wVVaZDpKASQTUX6QougVbtKTBiAFAMKhnFndwMyY0xLnSNQCkw8gy4ProYyzOE+G8sLnAZgWlJh5j9P8lxVZJmSFFQaYpkUuYS8looJwUSISZ+nJADQF4nLTbxgwVNdICfe0BJyWqEicFZhwLEimcSaiOURUKoRIhckemhDFVf6nA9gY4PhYwVlaMgGkCiEmqpVwmOCsnBUAeF0IMRvAx0GJmX9IDnYEwo2WqEj0OCsw4ViQzOI8BeHTI9GjpUUOnRS6cBvqGOVSKFv24SgXwFE2dwMoAfB40GLkGzbKhhcQPo2vkKElKhJnBSYcC5LTOMthlOcRPsNBztKSCqVHMhRAuLTinaWlJBiR8QHO0pNBRMVyCPVEEOLVXCYDyBRCpMrPVChLgCfK92Z2cKMXfrS45b/GiUMA5fByJ3yo4CItpVBaiGVQJttDvvXrLC1ElCfvzQMwT24+DWk8LGPuTPyEDC7So86NlAJICZf0ML6nxSkShmEYxre0xKEthmEYxoewImEYhmEswYqEYRiGsQQrEoZhWizhtJ9HXWUW7HiYwYqEadHIlzPbvUsmWAgh0oQQJUKIDLmZc6oLtx5XtEKIbCIqEEIkS7+nyu9k+XuiDNvlfwtpclruzNIhD+kLScXX4mxtMYyBDIT3hsewwMophkRULIQoVZcXS+Wfa1zWLivfifD8HCJ1c+VkAAVSqSwDsAz2drdOuPnv9VYBub3A9Dk36SjTnfwaMrAiYVossjU5BcrLWRoOBiHDGBuAJwH8xapH0vxPhpRfOhSFMAeKIcahul6Cds+JbMulf+qR2+qemKE6ZZcKINXNfzvkpsYsAHOlX9Ok3xlQ9napcUmT4WVB2QSpWiTWp0PdUKzeK9Y9FzLw0BbTYpGtwlIiymcl4ncqoSiRSl95KOVXJv9mQNkguVHutjfes0NW7GWGy2YmhYwmbtz9hy4e+QBKpGLJlTbw8gFMkb2r9vJ/mfzf0/C8qjQyAahGPssQgrYAuUfCtFjkjm1jZcL4AW+Hs1whlUChHFaaC6WFn2y4P8Xsng67KC3d6gAAIABJREFUCtlgUmijbvioFIoycPXfFckmbozxMW3EyHSoCiQXwCQZv5DqjQCsSJiWTTqAZUKItHAwidNSkUM8qXKFVTKUoaUpcrI6FUrlOgRKS769vFaivyeEKND3OuX8hur/RCgmhaZAGTp6HkC2EKIUypBTqZv/ZgyV8W0v515KZXzLAOTKe2qa0qTSSFcVlBBCTUeajNMy6a/6P6RgEylMi0U3bl3IiqTlIVdt+dx2m2qbzJe9MJ3ffomzVViRMAzTYhFCZPja2KQ62U5Ek3zsbyqgLQMOKViRMAzDMJbgVVsMwzCMJViRMAzDMJZgRcIwDMNYghUJwzAMYwlWJAzDMIwlWJEwDMMwlmBFwjAMw1iCFQnDMAxjCVYkDMMwjCVYkTAMwzCWYEXCMAzDWIIVCcMwDGMJViQMwzCMJViRMAzDMJZgReInhBAThRAZQoipTu5ny0+u7lquei9Q8WQ8wwN5OsjO3TNMcHElHyFEmhCChBAl8jNbXud31ARWJCYIIVKtFBR5NCjkgTnl6n/d/QwABfKkM/W4TUA5vrMEIXgmczjjb3lK7GTn4TNMMwmATFOISBBRTyhnpasNPn5HTWBFYk4GgEILz2cBUM+HLpX+6UnVXSuV/wFgEhH19PWJbYzf5Qk4ys6TZ5jm41eZGt7BVN2phPyOmhAT7AiEGrJlMgVAmRCilIjK3T1jQjKAMt3/9vqbhjOX0wDMVX8LIQAgzR/nPbdEAiFPiVF2njzDNIMAylQbPdBd4nfUBFYkBoioWBbOfP11eV6yaavSoBg8Rr4Qy4ioWPqTJ69n+uMs6ZZIoORplF2zIst4RCDfUQCZ+veQ31FzWJEYEEIYWyoAANm19bQwlgNIkb+TAZxw4i5DVzAnynDypftUJ88wXhAIeTqRnadlgPGSAL+j2twJv6POYUXiSDqAZUKINLWnAGitnYlmD5h0cedKfwClsBVIP5LVbrgQIlunRDKgjNOq47A9Acz2TXJaPIGQp5nsCs2eYXxCoN5RtUGgwu+oE1iROKJOvNmtypCtHY/GRGXXO10qiHJdYV8OYIi8niuEmAalVTRJPpMthCgDUKJ/QRhL+F2ezmTn5BnGOn6Xqc5pmeEZfkdNEEQU7DgwDMMwYQwv/2UYhmEswYqEYRiGsQQrEoZhGMYSrEgYhmEYS4TUqi25PjwdHuwa7dChA3Xv3j0g8YokioqKjhNRx0CE5Y08AZZpcwikPAF+RwNBoGXqC0JKkRBRuRCiELpNQM7o3r07CgutmNppmQghDgQqLG/kCbBMm0Mg5QnwOxoIAi1TX8BDWwzDMIwlwkqRyM1AhUKIwmPHjgU7OowPYJlGFizPlklYKRIimkNE6USU3rFjWA0hMk5gmUYWLM+WSSgqkskAMqWdGyb8YXlGHixTxo6QmmwHNHPPzTX5zIQYLM/Ig2XKGAnFHgnDMAwTRrAiYRiGYSzBioRhGIaxBCsShmEYxhKsSBiGYRhLsCJhGIZhLMGKhGEYhrEEKxKGYRjGEqxIGIZhGEuwImEYhmEswYqEYRiGsQQrEoZhGMYSrEgYhmEYS7AiYRiGYSwRcmbkg0n9zydwbPMPqK2PRtuLuqJd16RgR4lhGCbkafE9kpqd+7HlykfxQ6teiDm3A8676mJ0v3Yg2nZri1faP4knnwR+/DHYsWQYhgldWqwiaWgA3s47CurfHxcv/Ss6nylBBWzYFTMAJbF9UY8YzC3LxMyZQO/ewAvPNaKhIdixZhiGCT1apCLZswcYMQK4c1onvIiH8b92t+HL6WtQ+9NJ9D27DT3rdiLq9Ck8s+IyXH89UF1NSH3iZuT3egwnTzQGO/oMwzAhRcuaIyHCtjty8eSCS7Ch+iqcfz7Q/58zcfVNgBD2TmOSEjHmcmDM5cD6l4tx6Z8WIGZ/Axb2PoJh299Ex3Ojg5MGhmGYEMOSIhFCTACQCaAdgDIAAgABWEZEC6xHz3dQQyOKRvwJ6RtewWx0QKvxpXjlv0lo29b9s8PvH4Kf2y+B7fbrMf7kO/j8QsLl+9+GLUm4fzjMCCeZMu5heTKBoFmKRAgxGEAPAMVENN/kfg9ZgEuIaLPFOFqmsa4exRf/Fuk730ct4rDujjl49+0kh16IK8659QqcsC0BbrgS15X9F+8NScXN259CTIT06cJNpoxrWJ5MIGnuHEkpES0gon1mN4lonyy8p5ofNd/QWN+Irwf8Duk730cFbPj6yS9xwzs3eqVEVNqPH4FTr32EBkTh9j3/h/m35Ps+wsEjbGTKeATLkwkYzVIkRKQVPiFEGxfuTAtxoKBGwsrBf8aIkv+iEq2x46VlGPPMWEt+np99LUrv/RsA4IL8v2PFcvJFVINOuMiU8QyWJxNIfDEw87gQYi4RbZbdaQqFrjIR8OJd2/DA1n+jFnHYk/cpLv3TL33id++X/4TP98Uj6393oO3tAtu2ASkpPvE6VAhJmXpEYyOOFR/Cnt2EQ9HdcfIkkNBYjV6lS9H2kh7odmU/tOkYH+xYBprwlScTFvhCkRQCSBVClBLRJiGEtSa/j5g5E5jxzkCsjv4MT02rwZBHM3znuRD41cI/YMgYYO1a4OGHgbfe8p33IUBIytQZJ78/jD2zPkXUimXo8+NKdKTT+Ay/w914AwDQFwexEzcCAM4iBpta/QJHhvwK3R6ZjAHjewUx5gEjrOTJhB++UCSpAMoB5AkhegBYBmCFD/xtNv99uxEzZkQhKgq446NfYchE34cRHQ28+SYw8qJT+MXb07D+0nsw/J6LfR9QcAg5mRppbAS2zJiP6Ndfw8Cjy3EpmoYYj4pOSD43EZNGAsnJQLuyWBSuuxYdy3ahS91eDK5eB6xZB6x5AhuSrsDPT72Kax7sjejIXdEd8vJkwhwisvQBMMHw/yarfnryGTJkCJmxdv4R2oJBlIkl9PLLpk58yvoxjxEBtCVuCFWcPOv/AC0CoJDCTKZ66uqI3nmHqF8/ohfxZyKAahBHqztNoGW3vEklXx2gxkbnz5/5+RRtfvoT+qbvHVSFRDqKDtQaFdSnD9HcueTy2VAk3OXJOOKJTEPtY7lHQkTzhRDdiWi/HH/tadXP5rLru1rETL4Jg/AdXu08Ez3vzYSybN5/DF0wHT+d+wEG1RXhfze8iF+tnObX8AJBKMlUpaHyDIp+8xLeXd0d/zp+MwBg7nl/Rv/03hj03M24bGA7j/xJ6NQGF8+4AZhxA2qOvISvX9mDcz6wYfdu4LdZ1Uj880Po987j6J3RzZ/JCSihKE93nP25DD+v3oUT3/2AmkPHgOPH0FBxBlsG3IITnQchJgboVrEVvSo2IaF3F3Qc3hvnXHIeRHSLNNYRfIKtyZr7MbZ2fj7SSHNtdxEBdCzhAqo//JMTfe97dry0hAigaiTQ3sV7AhZuc0AIt3ZMW7D19fTdQ2/RTzEXEAG0Hf2oX58GevttpXfiC+rqiGbPJspNfIoIoCok0tIrXqC66sjoYQbr42mP5MTBSlqyhOi554juuuYIHY/qSKSsl3H4TMZH2t9HkWt3rwqJtLX1pfTVwPto3R/+S/tKGsKuh0kU2jJ19gmp7XRCiGQA2QBKoayDL/bkuTNngPd+8TIeqvwPaqIS0brgM0R3PtevcdXT70/j8PXLv8awve/i9C3ZoOPLIaIib9e7tzRXnir7XlsCenQqLqr8DgCwLfYSHH0kD1v/EuXT+YzYWCA7Gzg5/G5svGEnhpbMRebyx/B9h0+QMPcd9L62r+8CC3OsyhQAKg+dxO5Xl+Ps54vRddcy7D97Pq7E14r/6Ih/oQKVaI39sX1wsm03nG3bEXVtOwJJNlw24CL0TgHOngW6bemHVdtuRbvyfTivai860jFcWPUtsPVbHNzaBd1e+zU6dwbGjQN+e/5SXHzXELRNbe/bDGEUfKmVALQFsAdAdwCXNOP5qQCS5e9cV27V1k5DA9Ezly2lekQRAXTytY881vy+5PjOY3RMdCACaOM9bwYlDkYOFB6luXPtr8HL1o4VmXojT9LJ9KeiH2jr+ZlaS/Og6Epf3Pwunalq8Ec2ObA5dzH9GN2Z1F5mwbV/p/q6wITtjpVfVtOGDU3/AylPauY7WlNDtOHdXbR89NP0XdIw7V1VP0fQiUYOq6f77yd6+22i7V8doZoz3nUlGhuJju4qo01/LaCVVz5Hb/XPpfbtlSDa4QQ1QFADBG2zXUqrxz5Fu975mhrP1nsVhj84dozoww+JTp5suuatTEPhE/QI2EUGmGf22+yjFtJnHquin3AOEUA/3z3djdj8y7LfvkcE0H9s91NlZVCjQhUrvqWqqNb0AP5O773b9FIGspB6I0+SMj11iujcttV0AF3oJNrSJyPy6NihM37KJeecPniS1vX+DamV3UP9FtGuXQGPhsaBJTuo8Jxf0XzcSIMHE9XLOjDQlU5z3tE33yT6Nd7R8rIWsVSYNIa+HPM8ffNqMVVX+kdJNzYSbdlCNOfhnVSYPJZqEEd6BVYm2tE3PbLoi3+V2lXk/qTyaBVtnLmYVqU/RHsSBlIqSgggmjevyU2LVCQA2vgsMvaFdJnJ/Wwoa+ILu3btSkRKQZl83mo6fOVdSvckiNSfbaTb+nxLANH0IOq0s4eP0NF4pUX9Ybs/eN3a8ZVM3cmTnMj0vvuIHhn9Le355rifcshzCmd8Ru+2yiagkRISiP7+98AWsxMniF64YxvVIYYIoHK0oZemHqbaWuV+IOVJzXxH9+0jGt3vCK256B76ZvpnVH7otP8yzAXlhyto3eOf0/IB99K+6FQigBogqD2OUXQ00WWXEc2/NZ+2vPQVVZ3wTePl58N1tOGpRbRy+OO0qc0oOoN40iuzP0a/RldcQbR4cdMzLUqRAPg9gEugW0oo/3vdXdY9PxVAqvw925Vb/USe+lKFAuvXK7kaF0e0c2fgw29sJFp54R+JAPomZgSV7rTPHFeF1Ncy9UaepJNpffBHHOwoKyO64w5FrgOwlYrbjqGDS3f4Ncyaqnr6+9+J2rUjAhppMcbRV32y6cdNR+zcBVKeZOEdDTUaG4l2fL6HPrvlQxo1iig6WsnnQ1AaYGcRTbsSLqK1Pe+ggqtn0fqHPqZNn+6nvXuV8lBV0UCVJ+vo9OFT9OPmn2nH/G1U9MJS+uq3b9GCK/5F111H1L07UQzqqAqJpCqOBgja1iqdlg+bTt/OWklVJx0rr5amSHoAuFu2PuYCeBXATQB+b8HPZFlQJwJIc+U2lAvpnXcS/RLraUPKVdR4KrCtr3/8gygB1fRS9IP07ULHlWtuKh6fytQbeVKIy5SI6NNPif4Xfz0RQGcQT2tHT6fqn30r35qKOlpx2xu0P7oHDcJmAojGjiXatNF8BVkg5UkR9I4aKS8nWvB+NS0d9DDtThjoMI9DAN2Hf2p/f485Dvf1q8eiUE8AUevWRPM6P0ArLp1G66d/TidLTriNS4tSJJoHwGD53RbAFQB6BCLioVxIjx1tpMKYS4kA2j7uTwELd+FCIiEUqX7wgbkbD4dCWKZOOL73JH3V406t0jga1Ym+ueMVqjttbSjk+L7TtOzGV7QhFwLo/ZT7aOFC15skWZ7+ofJoFRX/+2tadfO/adXgB2j9uTfQ3X1WUo8eRG3aED0U8xLVI4oq0JqOiw60P64XFSePobU9bqM1Y3JowXtV9P33zetdtxhF4umYqy/HZo2fUC+knz29ic4imhogqHzJN34Pb9uLX9KCqAnUGhX09NPO3TkrpCxT79j4z/W0udUvSa9QPpqygg4f9tyPmhqitf/YSMv6/JFOIUnzqzS+L2144H1qqHNfC7E8I49wVCTN3UcyVAhBROTUXo88NOckWqhNn+uevAQfvvEIbj2Ui4qbf4+2R4qAuDi/hFWycBsueDgLA3Aas4ddjlufvLc53rBMvSD9/mFouGc9VjwwH+e8+Tx61W7Fn2YPwLE5wLBhwAPt/otufeJhG9gdtp7nAEKg6mgVyrceQmH1hVi24wKsXg1MO70A0/FvAMD37Uah7u57MXjmBPSItbxRhuXJBIxmKRIiWi6EaCuEeBSKuQWSt9RjPIugrO5osYfmCAEMWfgU9g7OR6+TW7H77lno884TPg/nxw2HkHjTVWiD01h33kRkrbynWYd2sUy9JzpGYOwrE9H4zwlYOWc3Rhacg0WLgPXrgY/wBLosOmz63CfIwxd4FABQ3PtmrO94Fl2m/xoXXTPIZ3FjeTKBRCg9qfAjPT2dCgsLgx0Nt3z4++W45c0M1CAe1auLkHLZhT7z+8j2MlQOHoledTuwpc1I9C5dilbtE10+I4QoIqJ0n0XCh4SLTF1x+jSwevlZJL44E7a9m9Hm9GG0qTsOCOBsVALKky7ArosmoeHuP2D4cKB7d2vhsTwjj1CWqTN8aiJFCNEdQBkRnfalv+HM5NlXYNEXd2H4zwvwt2k/4y/rLmxWj8HIkd2n8dOQazG4bgf2xl+IrpsWulUizYFl6h1t2gDX3hgL3Pi0UzeXBDA+RliejD+wbCpTCPGaEGKuEOL3UJYGTrYercghOhoYtPKfGJNUjGe/HouZM637eegQkD/sRQyu+Ro/xnZFyreL0S7VM+u3nsAyjSxYnoy/8YUZ+T8AgBDiCgCZAMJzrMyPdOnXGs9+0APjxwMzZgC/iC3GuGmD0ZyuyaZNwDXXAMfKctC+fRmuXPIQUgZd4NP4skwjC5Yn42980SO5RAgxloiWE9EsAF5bA20JXHstMGsWcBfeRMbj6dg18QllsacXLHlxK66/rAw//QSMGB2LK3e/jJQhPXweV5ZpZMHyZPyNL06BGQqgp9p9BpDmAz8jkoceAkZdn4JGRKHvguexY9idoJpat8+dKie8f9lrGPnIL/B21UT8+uazWLIESEnxW1RZppEFy5PxK76YbC+AYlb6dR/4FdEIAdzxyY14b/IC3JR/C/pveAeHOn6LqNf+jc63jnYY6qquBhY/9TXOe2kabju7BgBw/qUX4J3/NEDEx/ozqizTyILlyfgVX8yR7PNFRFoKQgC/njcei59bg9ScW9Gncgdw++XY/cd0fPFgAZK7tUXFkSp0f/9Z9Nj1JW5q2AwAKI9pj1PPvoJ+U7P8HkeWaWTB8mT8TUidkNiSuGp6Gn7M2oRPJs7CqM0vIeb0CTz8TBsAQBQSUI6XkYRKnIpOwQ/j70H//zyK5OS2QY41wzCMI6xIgsj5PRNx46YZOLb/YWx9dy8eLBMoLwfatInGxqN/Q59R56LznePQNiE+2FFlGIZxCiuSEKBj99YY/+TFGG939e4gxYZhGMY7fLFqi2EYhmnBsCJhGIZhLMGKhGEYhrEEKxKGYRjGEqxIGIZhGEuwImEYhmEswYqEYRiGsQQrEoZhGMYSrEgYhmEYS7AiYRiGYSzBioRhGIaxBCsShmEYxhKsSBiGYRhLsCJhGIZhLBFSikQIkSyEyBBCTA12XBjfwDKNLFiejBkhpUiIqBxAYbDjwfgOlmlkwfJkzAgpRcIwDMOEH2GlSIQQ2UKIQiFE4bFjx4IdHcYHsEwjC5ZnyyQoR+0KISYaLpUTUYG754hoDoA5AJCenk7+iBvTPFimkQXLk/GGoCgSIsp3cXsygEwhRD4RlQYqTow1WKaRBcuT8YagKBJX6Fs0TGTAMo0sWJ6MEUEUnr1PIcQxAAd0lzoAOB6k6BgJ5bh0I6KOwYqMKwwyDeU8DDb6+ISLPIHQysdQjkvIytQZYatIjAghCokoPdjxADguviCU4h1KcQFCLz6eEkrx5rj4lrBatcUwDMOEHqxIGIZhGEtEkiIJpck/jot1QineoRQXIPTi4ymhFG+Oiw+JmDkShmEYJjhEUo+E0cHG9SIPlmlkEUnyjChFEmzByPCnCiEmCiHSghEHlUgxrhdMmYaSPIHIkCm/o01EgjxVIkqRhIBgsgHMkbuCs4IYj4ghyDJlefoYfkcjk4hSJCHAUPmiAEBqUGPC+AKWZ+TBMvUDrEj8R3KwI8D4FJZn5MEy9REhZ2vLE5prmTQAbBRCpEpDdqFgzC5sjOuFqExDTZ5AmMg0ROUJhJ5Mw0Ke7oi45b9CiGwAkwBMCbRghBDJUMZgSwGUElFxIMOPVIIlU5anf+B3NPKIOEXCMAzDBBaeI2EYhmEswYqEYRiGsQQrEoZhGMYSrEgYhmEYS7AiYRiGYSzBioRhGIaxRFhuSAxV5CasVChr1IcCeF5njoEJQ1imkQXL0z9wj8RHyN2y+QDUQjmXC2h4wzKNLFie/oMViY/Q7dAdAqCAd8yGPyzTyILl6T9YkfgI3dkGqURUHuyzDhjrsEwjC5an/+A5Et+RIYRIBbBMCJEBoCzYEWIswzKNLFiefoJtbTEMwzCW4KEthmEYxhKsSBiGYRhLsCJhGIZhLMGKhGEYhrEEKxKGYRjGEqxIGIZhGEuwImEYhmEswYqEYRiGsQQrEoYJU4QQyXKHNsMEFVYkTEghhEgTQpQIITKEEBOFEPOEEMnN9CvV1/HzNSbpnerps9Jy7SSdP9lOwkh154ZhrMCKhAkppEXWUiIqAFAA4G4AKd76IyvPiT6Ons/Rp1eaOO/ZHGOCRFRMRHOM1/X54MwNw1iFjTYyXiEEfGKcjQjCxe0UeQBRFhFNAlAu/0+Rn2kAZgNIB5AMYA4UZTMRylkThVAOLxoqhEizbC5cCFdpngK1clZa+7MdXBC5SquRFAClMr2Z8louAHUIq0B+Z0A5nClFCVpkAEgDkA8n+SDdqm5Uo4XlUPIwS8Y9jYjyvIgvw7AiYUKSMiLKF0Kpf9UDiYQQKQAmEtEU9TqUSjADSqU7TZoHT4ZSyaaGy5kTUhEkQ57YJ4QoADCUiKYJIeYBeF46TYUynKWmdRIAEFGBECITipJ1mg/STa5U0BBCzCOiSUKITOnHpECmm4kMeGiL8QoiCF98PAuL8uVPdainFEBPABBC5Mr/DopCf+qdT+ZJiISLzxyduzmmbjwKQhnaMii+E7rfpfJeoefR9igf1PknPimQaTasSJiQQg7BpOon29E01JMGYLYQYhmAn6C0zlOh9EZeBfC4fCZVVqLt5f2QRZde47xIBpQzxQGll5GtW6GVC2Cy/J8uhEiVv1PlPdN80LmZJoTIlnmaqw6LSWWTHg6LFJjQgs8jYRiGYSzBPRKGYRjGEqxIGIZhGEuwImEYhmEswYqEYRiGsQQrEoZhGMYSrEgYhmEYS7AiYRiGYSzBioRhGIaxBCsShmEYxhKsSBiGYRhLsCJhGIZhLMGKhGEYhrEEKxKGYRjGEqxIGIZhGEuwImEYhmEswYqEYRiGsQQrEoZhGMYSrEgYhmEYS7AiYRiGYSzBioRhGIaxBCsShmEYxhKsSBiGYRhLsCJhGIZhLMGKhGEYhrEEKxKGYRjGEqxIGIZhGEuwImEYhmEswYqEYRiGsQQrEoZhGMYSrEgYhmEYS7AiYRiGYSzBioRhGIaxBCsShmEYxhKsSBiGYRhLsCJhGIZhLMGKhGEYhrFETLAj0FyEEBTsODAMwzQXIhLBjoOvCFtFAkSWIBjrCCGIywQTDkRaQzisFUkoI4SYCqAUQLm8lEZEeUGIRxqAeQDyAWwEMBTAMiIqMLmXAqCMiPKdPJsCYBoR9Qx0Ohj/IoSYCKWsmpZTIUSG/JlJRNN019OIqNjEn1QimuPNs4HGXZoZz+E5Ej8ghJgNoJiI8omoAEAZAL9VvvKFMEW+qAUA5sr4TIOiHMzuzQEwVH3x5f1iw/1ppgExHiOESA52HPTIBgNkWS1X/xvuZ8r7aep9WU5eN7grle5KhRBpnj4baNylmfEOViQ+RgiRCiBdFlAAWoVc5KfwkgFkevlYmYynGbMB5LoIq8DFs4xnZISYMslCU8+5FECG/iYRFet6EqlqL0LXSNKTq3fn5bOBxGWaGe9gReJ70qAUTDt03fxs2VLLlv8nCiHmye+pxv/SzVQhRIbuGf3/dADprnolemQFVk5EDnGU8SwF4ExRZBCR02dbGkKIVFWe8v9sf/npj7B0JMO+Um/vJG5TAUxx5olUEqVCiBKDf26f9XP6zPAozYxn8BxJAJEvUzERFQshUoQQ2UQ0RwiRS0STdO60/0KIXDTNaeRK5VEq/0+V36XqvIYLMoQQKVCUxBVu3BpbyxlCiCwAJ7xKcOSj5lOK4dsffvojLK8gojzZyCkkonLjfbWRAqVX+7oQolhtdLh7Fj5In+wpm/Ys1IYc4x9YkfieYgCPGy/KltZQKBPXgNJrmQJgjnzG6IdKKoBk+XwJgCFQXlR4OUFYrB9uc4asDIzxKZDKL0O6SeVeidICF0JMkY2BDADL1Hsmk9D6Sm4IgFQhRLn0Z447P12F5Qq1F2ug1FAWymGvsOwaDLr5hGIo5TYbgFnZywbwPBGVCyGKAUwUQhR48mxz02fwoxTK++QJLtPMeAcrEh9DRKVCiEIhRIb6surGwzdCUQzq8NFGD7zcCOXFLxZClEIp9KkAioUQyfrWnY9WwWQDeN7shuz9qOG3eEUiUSujNMj5I1mhZUGnkPWVnByGLHDSMnflp7PrTvGwJT4XyhApoMhWK7cyjhm6tCTDg3Iry4qqPD191uv06ZHhmQ7xmjS6TNPMNA9WJH6AiKbIeQytwpVKpVheB+SSQ9n6SlOVgPG/dDNVDkupQwS50g9A6eGUqpWTMS6yNZkufxcaFQ+UF71cxjUVyvyJfvlvGoAseT8FSi9qEhiVjaJpeWs6gI/VvLTQc3Pw001YgCKXkuYM4chyly79Ltc1RpZD6T3NATBZnYfTlY+JkPNzclWfWlZLAaTI3kWyJ896mj40lXGH9Mq89qiX7iLNTDMQROG5L0bw5jPGQKiUCbUl7qxS96BH4m14yQCyI3UvhDF9kZDeUCmrvoIVCRMxhEqZ0PUCC/w9l6RbrZcCx7mPsMeYPthPyodtekOlrPoKViTa7ftRAAAJXElEQVRMxMBlggkXIq2shvUciYgwezWMdbhMMEzgCWtFEkkanbFOpLXymMgl0ho8EbezXSi7xkvkyqZkw71cuSmwuX6nCiHm6f5nyM9EY1hOnncI3xDfifI7w8m9bN2YsbP7JS7CNzXNIa97vW7fU6zmu/RD3UsTUsh8zzBLn5QPSRmVCMNubf0zQtl4qu37cPasvD5ReGjJwB+4SrO8r74XuYbrDja8nKXFkDfZ8uNgusfgzjTcQOIubyKViFMkZG9o0LgqZq63/ukLuZw4vVt3e5Juss8TWz0O4VOAjCqqCsRspZBMg09WEDnBbb67qxhlvANu48tVA0G4N/yXQkSCFGvJk6CzYSZlOFTnVm0ElLp5dopcLpsaDMXqLs3COyONpmnR5438XSDLdqpuebDRnWm4gcSD8hCxRJwicYNXlaUwGEQUTXst7JCVuDsTJd6E7w+jitlBXOHiMt3GfHZBcRBa4q4MLLozdqjPb3d7SiYRUU/1GbNnZdpL5P28IO198ImBRy/SorcI4NQOnLNwA0yLNQTZIhSJkEYOYdj1KnTGD9XhHbVbKpqWcBoNIqpDEBnqPePQjXBiZNEYvpO4+suoop0Ze2McXd1Thx90/83yyiwtzvLdzj+Y5LOJGzXt3lo69qdBQE+NHWZAt1lUKJtNjUo9zWxIxPDsUADt5ZCQatAz0EYefWLgESZpkc/Z5Q0RzdHtx0kDUGjmzixcP+aBM1qsIciIVySyIlLtTOlf5lzddbUlmCK/8wFkyd+aQURZkan2kfT35jrz11n4JmTISmMymmdUMRceDv0IneFHo18m8U+D0sLLh3xBzfLKSRhm+e7MPy2fzdzoaI6xQqcGAQM0/JBpGFJ0SINslRdAqVz1LVnjsyfU1rZUvCFp5FFuFpziamgQjmkBnMRTymmZrqdh6s4Qrk8MQYqmORq7j7d+RTJhvWrLQ4bAvAI3GkMEmn8+gv5FNzOy6MmQUiCNKroy/GgXf2qyVJwB+/xxl1em6Xbhn6duvJYRuTYIaGcTC/DcwCI8N/ynH/93aEmrlahUnCdg3yDQKzq9efZSAEOJKN8sbW7SbIqTytFfBh4d0iIUK9bO3oEMatrZbpaHDuGSYrKFDUEGgJagSIpgbmTQaAwRcDGWLzw3iGjmry+NHPrCqGIJnBh+hCH+auUiX8ZpOvfu5ntM892Ff+p9zTaYMzfNxMEgoPzvYBOLPDew6M7YoaqU7BoahrDV82vU8HtCKnmTZwvQNEyoN/rpsZFHnV9mtqoCaeDRLC0OeSPLod48SgaUho4xD52F61EeCCc2ywQbgvSIiBvaEvaGBpNlgUiTBTADQKa8noem4STVeJu62mOi/J2MJoOIparfsruruk+FUvhM/XUWviG+6QAmGYcBdC9Ilmg66MqZUUV1PmE53CgtGcehMl0ZunSlGeMv/VJ7KMW6e2Z5pQ/DWbod/JOPaPnswo0VjAYB1dbwMje9N6fohmXMjB3qKdM9oy7MSIEcepHPqYYNSwwNFv2zpVBWA9kZQHSRNofr0o8yKMNKzTLw6CbN6uoqp0YanaXFLG9kOLlCWQJ90lkeOgvX0zxwli9EVCqHHR0+XuRNxMMmUloIslUX1of7SKWdRk5WyHlbJnRK3KlNLDc9krBDiMi2zeUJZnkQ6HyJtPqLFUkLQfYGMpxVwuGAsDc5bnafywQTFkRaWY24oS3GHHVewzgEFS4I3dkuDMOEFmHdIwl2HBiGYZpLJPVIwnrVViQJItRQJyj1Y8XuhpaCTaQNFzCRS6Q1hCN6aEuwAUePDTgKe1tH6lLIUumXuvvY0qY2Y565cRuSRhqNCPcGDNX72bprdgYa5e+pupV3qjzNjDY6NWAYKDxIs1ujjS7SZ+q3sSwY88uZu0DjLm8ilYhWJMQGHD0y4CgcDeploGmZZKn0u73VVV8meebKbVCMNBpx1SgQTZvgXBkwVFcAleru2xlo1MkwH4o1gVSYGG0ULgwYBgoP0+yJ0Uaz9Jn6bXzWSX6ZhRFQ3OVNJBPRisQNbMBRQgaDelDsGaWoE9xSgXqteE3iZJpnLgiGkUYjzTbaKFHlozckaGegEUq5UhcSlEBZXWdm8NEjA4Z+xidGG52kz9Rvk/LpkF9O3AUaNtrYUhBswBEwGHA08Vet8FJlz2Cos81VTvJKvZcthzD0ww9qnqlGCtUNjg55Rc000mgSx6AYMJR5Vip7H3p3RgONJ2BvWkOTj9oLkf45GDB0lrZgpVkXb3dGG1V3eqOUnho9dJpfBr/ZaGOAaFGKRLABR48hogK5USsbwPPypXSY/zHLK0CrSEp1lWm2Ps9Ud7phH7u80gXhC2ODQTHaqDYEoPQcX1d7h+RooDEfTWluD3sbTUajjUYDhuFstBEwSZ8HuMovPWy0MUCE9aqtZsAGHL1AP5ciFUGeaDJboscsr4ZCeeEBpZs/BfbG754H8LhUIHfDXAbO/PYKCp7RxmwAz8v8KwYwUUj7a6Qz0CgV9lydUtPLy0zRaQYMnaXNTZpNcVI5+stoo1n6PDJ6SMrZLM7yS+/O6zwwCwtstNEtLU2RsAFHL/2nJptCrobDzPJqoy5svYFBlQx1LF32XszyypcExWijzk81TAcDjerQqazw1FMDzYw2qqZuNAOGao/QmDYKfaONZunzyOihs/xyAhttDAARrUiEvVHDUllgpgohIK9nCiHmyJb2VCFEinwOaFpxohoo1BtwLFD9Fk0TyHoDjmlm/roIv1wX33T5u5AcreJmQFkNoobpzIBjKpQXaAqUFTHu8kkzqGeoxPQVuqliFfYGHLW80qUdUOxj5RnzTDTNN+XLVqaWV/D9S2g03vcxlDyyZLRRCKEa/DQaMByiy4NSKMN/auWULYQog85Aozp0CGn5V4f+VEHVgOE0GXdVtmZpM70ue0fJsGC00VWaoShg1QClqdFGQ8Vf5s5v47PSnUN+OQnDozyQ5c8hX2TZcNWj8iRvIp6w3tlOvPmsWQgPDDgae12y8k9DAA0YqmG6aXHq3XtVJnSKm402tiDM8iDQ+RJp9RcrkhaICBMDjiatV3fuuUwwYUGkldUWtWqLUaAwMOBoMrTGMEyIEtY9kmDHgWEYprlEUo8kbBUJwzAMExrw0BbDMAxjCVYkDMMwjCVYkTAMwzCWYEXCMAzDWIIVCcMwDGMJViQMwzCMJf4fyV0GuZo9mr0AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}