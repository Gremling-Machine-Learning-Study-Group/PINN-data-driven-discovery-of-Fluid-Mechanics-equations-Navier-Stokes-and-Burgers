{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Burgers_nu3_2000_2layers_mais.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvsbii5zbr9p",
        "outputId": "b327e8f2-e80c-4e17-99b4-5e8498e6ecce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-lmodern fonts-noto-mono libcupsfilters1\n",
            "  libcupsimage2 libgs9 libgs9-common libijs-0.35 libjbig2dec0 libkpathsea6\n",
            "  libpotrace0 libptexenc1 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13\n",
            "  lmodern poppler-data t1utils tex-common texlive-base texlive-binaries\n",
            "  texlive-latex-base\n",
            "Suggested packages:\n",
            "  fonts-noto poppler-utils ghostscript fonts-japanese-mincho\n",
            "  | fonts-ipafont-mincho fonts-japanese-gothic | fonts-ipafont-gothic\n",
            "  fonts-arphic-ukai fonts-arphic-uming fonts-nanum debhelper gv\n",
            "  | postscript-viewer perl-tk xpdf-reader | pdf-viewer texlive-latex-base-doc\n",
            "  texlive-latex-recommended-doc texlive-pstricks\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-lmodern fonts-noto-mono libcupsfilters1\n",
            "  libcupsimage2 libgs9 libgs9-common libijs-0.35 libjbig2dec0 libkpathsea6\n",
            "  libpotrace0 libptexenc1 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13\n",
            "  lmodern poppler-data t1utils tex-common texlive-base texlive-binaries\n",
            "  texlive-latex-base texlive-latex-recommended\n",
            "0 upgraded, 24 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 68.4 MB of archives.\n",
            "After this operation, 223 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 tex-common all 6.09 [33.0 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lmodern all 2.004.5-3 [4,551 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.15 [5,092 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.15 [2,265 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkpathsea6 amd64 2017.20170613.44572-8ubuntu0.1 [54.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpotrace0 amd64 1.14-2 [17.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libptexenc1 amd64 2017.20170613.44572-8ubuntu0.1 [34.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsynctex1 amd64 2017.20170613.44572-8ubuntu0.1 [41.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexlua52 amd64 2017.20170613.44572-8ubuntu0.1 [91.2 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexluajit2 amd64 2017.20170613.44572-8ubuntu0.1 [230 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libzzip-0-13 amd64 0.13.62-3.1ubuntu0.18.04.1 [26.0 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 lmodern all 2.004.5-3 [9,631 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 t1utils amd64 1.41-2 [56.0 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 texlive-binaries amd64 2017.20170613.44572-8ubuntu0.1 [8,179 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-base all 2017.20180305-1 [18.7 MB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-base all 2017.20180305-1 [951 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-recommended all 2017.20180305-1 [14.9 MB]\n",
            "Fetched 68.4 MB in 3s (26.2 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 24.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 155335 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../01-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../02-tex-common_6.09_all.deb ...\n",
            "Unpacking tex-common (6.09) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../03-fonts-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../04-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../05-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../06-libcupsimage2_2.2.7-1ubuntu2.8_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../07-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../08-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../09-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.15_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../10-libgs9_9.26~dfsg+0-0ubuntu0.18.04.15_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../11-libkpathsea6_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libpotrace0.\n",
            "Preparing to unpack .../12-libpotrace0_1.14-2_amd64.deb ...\n",
            "Unpacking libpotrace0 (1.14-2) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../13-libptexenc1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libsynctex1:amd64.\n",
            "Preparing to unpack .../14-libsynctex1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexlua52:amd64.\n",
            "Preparing to unpack .../15-libtexlua52_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../16-libtexluajit2_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../17-libzzip-0-13_0.13.62-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../18-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../19-t1utils_1.41-2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-2) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../20-texlive-binaries_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../21-texlive-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../22-texlive-latex-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../23-texlive-latex-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2017.20180305-1) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n",
            "Setting up libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up t1utils (1.41-2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up libpotrace0 (1.14-2) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n",
            "Setting up libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-lmodern (2.004.5-3) ...\n",
            "Setting up texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up texlive-base (2017.20180305-1) ...\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/config/pdftexconfig.tex\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up texlive-latex-base (2017.20180305-1) ...\n",
            "Setting up lmodern (2.004.5-3) ...\n",
            "Setting up texlive-latex-recommended (2017.20180305-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-lato fonts-texgyre javascript-common libjs-jquery libruby2.5\n",
            "  preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration tex-gyre texlive-fonts-recommended texlive-pictures\n",
            "  texlive-plain-generic tipa\n",
            "Suggested packages:\n",
            "  apache2 | lighttpd | httpd ri ruby-dev bundler texlive-fonts-recommended-doc\n",
            "  python-pygments icc-profiles libfile-which-perl\n",
            "  libspreadsheet-parseexcel-perl texlive-latex-extra-doc dot2tex prerex\n",
            "  ruby-tcltk | libtcltk-ruby texlive-pictures-doc vprerex\n",
            "The following NEW packages will be installed:\n",
            "  fonts-lato fonts-texgyre javascript-common libjs-jquery libruby2.5\n",
            "  preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration tex-gyre texlive-fonts-recommended texlive-latex-extra\n",
            "  texlive-pictures texlive-plain-generic tipa\n",
            "0 upgraded, 21 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 66.6 MB of archives.\n",
            "After this operation, 216 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lato all 2.0-2 [2,698 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-texgyre all 20160520-1 [8,761 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 rubygems-integration all 1.11 [4,994 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ruby2.5 amd64 2.5.1-1ubuntu1.11 [48.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby amd64 1:2.5.1 [5,712 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 rake all 12.3.1-1ubuntu0.1 [44.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-did-you-mean all 1.2.0-2 [9,700 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-minitest all 5.10.3-1 [38.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-power-assert all 0.3.0-1 [7,952 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-test-unit all 3.2.5-1 [61.1 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libruby2.5 amd64 2.5.1-1ubuntu1.11 [3,072 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 preview-latex-style all 11.91-1ubuntu1 [185 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tex-gyre all 20160520-1 [4,998 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-recommended all 2017.20180305-1 [5,262 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-pictures all 2017.20180305-1 [4,026 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-latex-extra all 2017.20180305-2 [10.6 MB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-plain-generic all 2017.20180305-2 [23.6 MB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tipa all 2:1.3-20 [2,978 kB]\n",
            "Fetched 66.6 MB in 3s (23.2 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 21.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-lato.\n",
            "(Reading database ... 162669 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-lato_2.0-2_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../01-fonts-texgyre_20160520-1_all.deb ...\n",
            "Unpacking fonts-texgyre (20160520-1) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../02-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../03-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../04-rubygems-integration_1.11_all.deb ...\n",
            "Unpacking rubygems-integration (1.11) ...\n",
            "Selecting previously unselected package ruby2.5.\n",
            "Preparing to unpack .../05-ruby2.5_2.5.1-1ubuntu1.11_amd64.deb ...\n",
            "Unpacking ruby2.5 (2.5.1-1ubuntu1.11) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../06-ruby_1%3a2.5.1_amd64.deb ...\n",
            "Unpacking ruby (1:2.5.1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../07-rake_12.3.1-1ubuntu0.1_all.deb ...\n",
            "Unpacking rake (12.3.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-did-you-mean.\n",
            "Preparing to unpack .../08-ruby-did-you-mean_1.2.0-2_all.deb ...\n",
            "Unpacking ruby-did-you-mean (1.2.0-2) ...\n",
            "Selecting previously unselected package ruby-minitest.\n",
            "Preparing to unpack .../09-ruby-minitest_5.10.3-1_all.deb ...\n",
            "Unpacking ruby-minitest (5.10.3-1) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../10-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-power-assert.\n",
            "Preparing to unpack .../11-ruby-power-assert_0.3.0-1_all.deb ...\n",
            "Unpacking ruby-power-assert (0.3.0-1) ...\n",
            "Selecting previously unselected package ruby-test-unit.\n",
            "Preparing to unpack .../12-ruby-test-unit_3.2.5-1_all.deb ...\n",
            "Unpacking ruby-test-unit (3.2.5-1) ...\n",
            "Selecting previously unselected package libruby2.5:amd64.\n",
            "Preparing to unpack .../13-libruby2.5_2.5.1-1ubuntu1.11_amd64.deb ...\n",
            "Unpacking libruby2.5:amd64 (2.5.1-1ubuntu1.11) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../14-preview-latex-style_11.91-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (11.91-1ubuntu1) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../15-tex-gyre_20160520-1_all.deb ...\n",
            "Unpacking tex-gyre (20160520-1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../16-texlive-fonts-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../17-texlive-pictures_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-pictures (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../18-texlive-latex-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-latex-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../19-texlive-plain-generic_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-plain-generic (2017.20180305-2) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../20-tipa_2%3a1.3-20_all.deb ...\n",
            "Unpacking tipa (2:1.3-20) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up texlive-pictures (2017.20180305-1) ...\n",
            "Setting up tex-gyre (20160520-1) ...\n",
            "Setting up tipa (2:1.3-20) ...\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-DEBIAN'... done.\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST'... done.\n",
            "update-fmtutil has updated the following file(s):\n",
            "\t/var/lib/texmf/fmtutil.cnf-DEBIAN\n",
            "\t/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST\n",
            "If you want to activate the changes in the above file(s),\n",
            "you should run fmtutil-sys or fmtutil.\n",
            "Setting up preview-latex-style (11.91-1ubuntu1) ...\n",
            "Setting up fonts-texgyre (20160520-1) ...\n",
            "Setting up fonts-lato (2.0-2) ...\n",
            "Setting up ruby-did-you-mean (1.2.0-2) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up rubygems-integration (1.11) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-plain-generic (2017.20180305-2) ...\n",
            "Setting up ruby-minitest (5.10.3-1) ...\n",
            "Setting up ruby-power-assert (0.3.0-1) ...\n",
            "Setting up texlive-latex-extra (2017.20180305-2) ...\n",
            "Setting up ruby-test-unit (3.2.5-1) ...\n",
            "Setting up libruby2.5:amd64 (2.5.1-1ubuntu1.11) ...\n",
            "Setting up ruby2.5 (2.5.1-1ubuntu1.11) ...\n",
            "Setting up ruby (1:2.5.1) ...\n",
            "Setting up rake (12.3.1-1ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running mktexlsr. This may take some time... done.\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  ghostscript gsfonts\n",
            "Suggested packages:\n",
            "  ghostscript-x\n",
            "The following NEW packages will be installed:\n",
            "  dvipng ghostscript gsfonts\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 3,250 kB of archives.\n",
            "After this operation, 4,947 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.15 [51.4 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 dvipng amd64 1.15-1 [78.2 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.4 [3,120 kB]\n",
            "Fetched 3,250 kB in 1s (3,781 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package ghostscript.\n",
            "(Reading database ... 181020 files and directories currently installed.)\n",
            "Preparing to unpack .../ghostscript_9.26~dfsg+0-0ubuntu0.18.04.15_amd64.deb ...\n",
            "Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n",
            "Selecting previously unselected package dvipng.\n",
            "Preparing to unpack .../dvipng_1.15-1_amd64.deb ...\n",
            "Unpacking dvipng (1.15-1) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.4_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.15) ...\n",
            "Setting up dvipng (1.15-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cm-super-minimal pfb2t1c2pfb\n",
            "The following NEW packages will be installed:\n",
            "  cm-super cm-super-minimal pfb2t1c2pfb\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 24.5 MB of archives.\n",
            "After this operation, 59.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cm-super-minimal all 0.3.4-11 [5,810 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 pfb2t1c2pfb amd64 0.3-11 [9,342 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cm-super all 0.3.4-11 [18.7 MB]\n",
            "Fetched 24.5 MB in 1s (16.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package cm-super-minimal.\n",
            "(Reading database ... 181213 files and directories currently installed.)\n",
            "Preparing to unpack .../cm-super-minimal_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super-minimal (0.3.4-11) ...\n",
            "Selecting previously unselected package pfb2t1c2pfb.\n",
            "Preparing to unpack .../pfb2t1c2pfb_0.3-11_amd64.deb ...\n",
            "Unpacking pfb2t1c2pfb (0.3-11) ...\n",
            "Selecting previously unselected package cm-super.\n",
            "Preparing to unpack .../cm-super_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super (0.3.4-11) ...\n",
            "Setting up pfb2t1c2pfb (0.3-11) ...\n",
            "Setting up cm-super-minimal (0.3.4-11) ...\n",
            "Setting up cm-super (0.3.4-11) ...\n",
            "Creating fonts. This may take some time... done.\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running mktexlsr. This may take some time... done.\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ],
      "source": [
        "#devido aos plots no final do script devemos intalar latex na máquina\n",
        "! sudo apt-get install texlive-latex-recommended \n",
        "! sudo apt install texlive-latex-extra\n",
        "! sudo apt install dvipng\n",
        "! sudo apt install cm-super\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.15.2\n",
        "import tensorflow as tf   #machine learning framework\n",
        "#tf.disable_v2_behavior()\n",
        "print('TensorFlow version: ', tf.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBCUeYMwbyT4",
        "outputId": "3c821f60-ae16-4838-901c-8f42d4f56787"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15.2`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "TensorFlow version:  <module 'tensorflow._api.v1.version' from '/tensorflow-1.15.2/python3.7/tensorflow_core/_api/v1/version/__init__.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "@author: Maziar Raissi\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, '../../Utilities/')\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "from plotting import newfig, savefig\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.gridspec as gridspec\n",
        "import time\n",
        "\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)"
      ],
      "metadata": {
        "id": "ReZIGxTKnaNa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PhysicsInformedNN:\n",
        "    # Initialize the class\n",
        "    def __init__(self, X, u, layers, lb, ub):\n",
        "        \n",
        "        self.lb = lb\n",
        "        self.ub = ub\n",
        "        \n",
        "        self.x = X[:,0:1]\n",
        "        self.t = X[:,1:2]\n",
        "        self.u = u\n",
        "        \n",
        "        self.layers = layers\n",
        "        \n",
        "        # Initialize NNs\n",
        "        self.weights, self.biases = self.initialize_NN(layers)\n",
        "        \n",
        "        # tf placeholders and graph\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "        \n",
        "        # Initialize parameters\n",
        "        self.lambda_1 = tf.Variable([0.0], dtype=tf.float32)\n",
        "        self.lambda_2 = tf.Variable([-6.0], dtype=tf.float32)\n",
        "        \n",
        "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n",
        "        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n",
        "        self.u_tf = tf.placeholder(tf.float32, shape=[None, self.u.shape[1]])\n",
        "                \n",
        "        self.u_pred = self.net_u(self.x_tf, self.t_tf)\n",
        "        self.f_pred = self.net_f(self.x_tf, self.t_tf)\n",
        "        \n",
        "        self.loss = tf.reduce_mean(tf.square(self.u_tf - self.u_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.f_pred))\n",
        "        \n",
        "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
        "                                                                method = 'L-BFGS-B', \n",
        "                                                                options = {'maxiter': 50000,\n",
        "                                                                           'maxfun': 50000,\n",
        "                                                                           'maxcor': 50,\n",
        "                                                                           'maxls': 50,\n",
        "                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n",
        "    \n",
        "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    def initialize_NN(self, layers):        \n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers) \n",
        "        for l in range(0,num_layers-1):\n",
        "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
        "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)        \n",
        "        return weights, biases\n",
        "        \n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]        \n",
        "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
        "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
        "    \n",
        "    def neural_net(self, X, weights, biases):\n",
        "        num_layers = len(weights) + 1\n",
        "        \n",
        "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
        "        for l in range(0,num_layers-2):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        Y = tf.add(tf.matmul(H, W), b)\n",
        "        return Y\n",
        "            \n",
        "    def net_u(self, x, t):  \n",
        "        u = self.neural_net(tf.concat([x,t],1), self.weights, self.biases)\n",
        "        return u\n",
        "    \n",
        "    def net_f(self, x, t):\n",
        "        lambda_1 = self.lambda_1        \n",
        "        lambda_2 = tf.exp(self.lambda_2)\n",
        "        u = self.net_u(x,t)\n",
        "        u_t = tf.gradients(u, t)[0]\n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        u_xx = tf.gradients(u_x, x)[0]\n",
        "        f = u_t + lambda_1*u*u_x - lambda_2*u_xx\n",
        "        \n",
        "        return f\n",
        "    \n",
        "    def callback(self, loss, lambda_1, lambda_2):\n",
        "        print('Loss: %e, l1: %.5f, l2: %.5f' % (loss, lambda_1, np.exp(lambda_2)))\n",
        "        \n",
        "        \n",
        "    def train(self, nIter):\n",
        "        tf_dict = {self.x_tf: self.x, self.t_tf: self.t, self.u_tf: self.u}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(nIter):\n",
        "            self.sess.run(self.train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.loss, tf_dict)\n",
        "                lambda_1_value = self.sess.run(self.lambda_1)\n",
        "                lambda_2_value = np.exp(self.sess.run(self.lambda_2))\n",
        "                print('It: %d, Loss: %.3e, Lambda_1: %.3f, Lambda_2: %.6f, Time: %.2f' % \n",
        "                      (it, loss_value, lambda_1_value, lambda_2_value, elapsed))\n",
        "                start_time = time.time()\n",
        "        \n",
        "        self.optimizer.minimize(self.sess,\n",
        "                                feed_dict = tf_dict,\n",
        "                                fetches = [self.loss, self.lambda_1, self.lambda_2],\n",
        "                                loss_callback = self.callback)\n",
        "        \n",
        "        \n",
        "    def predict(self, X_star):\n",
        "        \n",
        "        tf_dict = {self.x_tf: X_star[:,0:1], self.t_tf: X_star[:,1:2]}\n",
        "        \n",
        "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
        "        f_star = self.sess.run(self.f_pred, tf_dict)\n",
        "        \n",
        "        return u_star, f_star"
      ],
      "metadata": {
        "id": "bfhlzV7fnbJb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\": \n",
        "     \n",
        "    nu = 0.1/np.pi   #nu: valor de lambda_2\n",
        "\n",
        "    N_u = 2000  #N: número de elementos de treino\n",
        "    layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 1] #2 layers a mais\n",
        "    \n",
        "    data = scipy.io.loadmat('../content/un100.mat')\n",
        "    \n",
        "    t = data['t'].flatten()[:,None]\n",
        "    x = data['x'].flatten()[:,None]\n",
        "    Exact = np.real(data['usol']).T   #.T: transposição da matriz de dados usol\n",
        "    \n",
        "    X, T = np.meshgrid(x,t)\n",
        "    \n",
        "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
        "    u_star = Exact.flatten()[:,None]              \n",
        "\n",
        "    # Domain bounds\n",
        "    lb = X_star.min(0)\n",
        "    ub = X_star.max(0)    \n",
        "    \n",
        "    ######################################################################\n",
        "    ######################## Noiseless Data ###############################\n",
        "    ######################################################################\n",
        "    noise = 0.0            \n",
        "             \n",
        "    idx = np.random.choice(X_star.shape[0], N_u, replace=False)\n",
        "    X_u_train = X_star[idx,:]\n",
        "    u_train = u_star[idx,:]\n",
        "    \n",
        "    model = PhysicsInformedNN(X_u_train, u_train, layers, lb, ub)\n",
        "    model.train(2000)\n",
        "    \n",
        "    u_pred, f_pred = model.predict(X_star)\n",
        "            \n",
        "    error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
        "    \n",
        "    U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
        "        \n",
        "    lambda_1_value = model.sess.run(model.lambda_1)\n",
        "    lambda_2_value = model.sess.run(model.lambda_2)\n",
        "    lambda_2_value = np.exp(lambda_2_value)\n",
        "    \n",
        "    error_lambda_1 = np.abs(lambda_1_value - 1.0)*100\n",
        "    error_lambda_2 = np.abs(lambda_2_value - nu)/nu * 100\n",
        "    \n",
        "    print('Error u: %e' % (error_u))    \n",
        "    print('Error l1: %.5f%%' % (error_lambda_1))                             \n",
        "    print('Error l2: %.5f%%' % (error_lambda_2))  \n",
        "    \n",
        "                               "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWIWsRhBnzr2",
        "outputId": "077989bc-506b-4438-b969-5074c8506f7d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "It: 0, Loss: 3.007e-01, Lambda_1: 0.001, Lambda_2: 0.002477, Time: 1.69\n",
            "It: 10, Loss: 1.743e-01, Lambda_1: 0.002, Lambda_2: 0.002476, Time: 0.35\n",
            "It: 20, Loss: 1.597e-01, Lambda_1: -0.007, Lambda_2: 0.002500, Time: 0.34\n",
            "It: 30, Loss: 1.347e-01, Lambda_1: -0.018, Lambda_2: 0.002529, Time: 0.33\n",
            "It: 40, Loss: 1.064e-01, Lambda_1: -0.025, Lambda_2: 0.002548, Time: 0.33\n",
            "It: 50, Loss: 7.968e-02, Lambda_1: -0.023, Lambda_2: 0.002526, Time: 0.31\n",
            "It: 60, Loss: 6.637e-02, Lambda_1: -0.011, Lambda_2: 0.002485, Time: 0.32\n",
            "It: 70, Loss: 6.140e-02, Lambda_1: 0.006, Lambda_2: 0.002440, Time: 0.34\n",
            "It: 80, Loss: 5.710e-02, Lambda_1: 0.025, Lambda_2: 0.002394, Time: 0.31\n",
            "It: 90, Loss: 5.182e-02, Lambda_1: 0.042, Lambda_2: 0.002353, Time: 0.32\n",
            "It: 100, Loss: 4.628e-02, Lambda_1: 0.056, Lambda_2: 0.002321, Time: 0.31\n",
            "It: 110, Loss: 4.030e-02, Lambda_1: 0.065, Lambda_2: 0.002300, Time: 0.32\n",
            "It: 120, Loss: 3.386e-02, Lambda_1: 0.070, Lambda_2: 0.002286, Time: 0.32\n",
            "It: 130, Loss: 2.703e-02, Lambda_1: 0.071, Lambda_2: 0.002279, Time: 0.31\n",
            "It: 140, Loss: 2.211e-02, Lambda_1: 0.072, Lambda_2: 0.002275, Time: 0.34\n",
            "It: 150, Loss: 1.957e-02, Lambda_1: 0.080, Lambda_2: 0.002274, Time: 0.33\n",
            "It: 160, Loss: 1.852e-02, Lambda_1: 0.082, Lambda_2: 0.002278, Time: 0.32\n",
            "It: 170, Loss: 1.804e-02, Lambda_1: 0.080, Lambda_2: 0.002287, Time: 0.32\n",
            "It: 180, Loss: 1.781e-02, Lambda_1: 0.078, Lambda_2: 0.002296, Time: 0.31\n",
            "It: 190, Loss: 1.768e-02, Lambda_1: 0.076, Lambda_2: 0.002304, Time: 0.31\n",
            "It: 200, Loss: 1.749e-02, Lambda_1: 0.076, Lambda_2: 0.002313, Time: 0.32\n",
            "It: 210, Loss: 1.736e-02, Lambda_1: 0.077, Lambda_2: 0.002321, Time: 0.31\n",
            "It: 220, Loss: 1.723e-02, Lambda_1: 0.078, Lambda_2: 0.002329, Time: 0.31\n",
            "It: 230, Loss: 1.709e-02, Lambda_1: 0.080, Lambda_2: 0.002338, Time: 0.33\n",
            "It: 240, Loss: 1.696e-02, Lambda_1: 0.081, Lambda_2: 0.002348, Time: 0.31\n",
            "It: 250, Loss: 1.683e-02, Lambda_1: 0.082, Lambda_2: 0.002359, Time: 0.32\n",
            "It: 260, Loss: 1.669e-02, Lambda_1: 0.084, Lambda_2: 0.002371, Time: 0.32\n",
            "It: 270, Loss: 1.656e-02, Lambda_1: 0.085, Lambda_2: 0.002384, Time: 0.31\n",
            "It: 280, Loss: 1.642e-02, Lambda_1: 0.088, Lambda_2: 0.002397, Time: 0.32\n",
            "It: 290, Loss: 1.628e-02, Lambda_1: 0.090, Lambda_2: 0.002411, Time: 0.31\n",
            "It: 300, Loss: 1.614e-02, Lambda_1: 0.093, Lambda_2: 0.002426, Time: 0.31\n",
            "It: 310, Loss: 1.598e-02, Lambda_1: 0.096, Lambda_2: 0.002441, Time: 0.32\n",
            "It: 320, Loss: 1.585e-02, Lambda_1: 0.099, Lambda_2: 0.002457, Time: 0.35\n",
            "It: 330, Loss: 1.569e-02, Lambda_1: 0.103, Lambda_2: 0.002474, Time: 0.33\n",
            "It: 340, Loss: 1.551e-02, Lambda_1: 0.108, Lambda_2: 0.002492, Time: 0.32\n",
            "It: 350, Loss: 1.536e-02, Lambda_1: 0.112, Lambda_2: 0.002510, Time: 0.32\n",
            "It: 360, Loss: 1.526e-02, Lambda_1: 0.118, Lambda_2: 0.002528, Time: 0.30\n",
            "It: 370, Loss: 1.506e-02, Lambda_1: 0.123, Lambda_2: 0.002548, Time: 0.31\n",
            "It: 380, Loss: 1.482e-02, Lambda_1: 0.129, Lambda_2: 0.002568, Time: 0.31\n",
            "It: 390, Loss: 1.468e-02, Lambda_1: 0.135, Lambda_2: 0.002589, Time: 0.32\n",
            "It: 400, Loss: 1.465e-02, Lambda_1: 0.141, Lambda_2: 0.002611, Time: 0.31\n",
            "It: 410, Loss: 1.437e-02, Lambda_1: 0.148, Lambda_2: 0.002634, Time: 0.32\n",
            "It: 420, Loss: 1.409e-02, Lambda_1: 0.154, Lambda_2: 0.002658, Time: 0.33\n",
            "It: 430, Loss: 1.391e-02, Lambda_1: 0.161, Lambda_2: 0.002682, Time: 0.31\n",
            "It: 440, Loss: 1.371e-02, Lambda_1: 0.168, Lambda_2: 0.002708, Time: 0.31\n",
            "It: 450, Loss: 1.384e-02, Lambda_1: 0.175, Lambda_2: 0.002735, Time: 0.32\n",
            "It: 460, Loss: 1.357e-02, Lambda_1: 0.181, Lambda_2: 0.002763, Time: 0.33\n",
            "It: 470, Loss: 1.326e-02, Lambda_1: 0.188, Lambda_2: 0.002792, Time: 0.31\n",
            "It: 480, Loss: 1.308e-02, Lambda_1: 0.194, Lambda_2: 0.002822, Time: 0.33\n",
            "It: 490, Loss: 1.293e-02, Lambda_1: 0.200, Lambda_2: 0.002854, Time: 0.31\n",
            "It: 500, Loss: 1.279e-02, Lambda_1: 0.207, Lambda_2: 0.002886, Time: 0.31\n",
            "It: 510, Loss: 1.265e-02, Lambda_1: 0.213, Lambda_2: 0.002920, Time: 0.32\n",
            "It: 520, Loss: 1.252e-02, Lambda_1: 0.219, Lambda_2: 0.002955, Time: 0.31\n",
            "It: 530, Loss: 1.239e-02, Lambda_1: 0.225, Lambda_2: 0.002991, Time: 0.30\n",
            "It: 540, Loss: 1.228e-02, Lambda_1: 0.230, Lambda_2: 0.003029, Time: 0.32\n",
            "It: 550, Loss: 1.230e-02, Lambda_1: 0.236, Lambda_2: 0.003067, Time: 0.31\n",
            "It: 560, Loss: 1.227e-02, Lambda_1: 0.241, Lambda_2: 0.003106, Time: 0.30\n",
            "It: 570, Loss: 1.199e-02, Lambda_1: 0.246, Lambda_2: 0.003146, Time: 0.31\n",
            "It: 580, Loss: 1.192e-02, Lambda_1: 0.251, Lambda_2: 0.003186, Time: 0.33\n",
            "It: 590, Loss: 1.180e-02, Lambda_1: 0.257, Lambda_2: 0.003227, Time: 0.32\n",
            "It: 600, Loss: 1.170e-02, Lambda_1: 0.262, Lambda_2: 0.003269, Time: 0.31\n",
            "It: 610, Loss: 1.163e-02, Lambda_1: 0.267, Lambda_2: 0.003312, Time: 0.31\n",
            "It: 620, Loss: 1.220e-02, Lambda_1: 0.272, Lambda_2: 0.003355, Time: 0.30\n",
            "It: 630, Loss: 1.155e-02, Lambda_1: 0.277, Lambda_2: 0.003398, Time: 0.31\n",
            "It: 640, Loss: 1.144e-02, Lambda_1: 0.282, Lambda_2: 0.003443, Time: 0.32\n",
            "It: 650, Loss: 1.131e-02, Lambda_1: 0.286, Lambda_2: 0.003488, Time: 0.32\n",
            "It: 660, Loss: 1.124e-02, Lambda_1: 0.291, Lambda_2: 0.003533, Time: 0.31\n",
            "It: 670, Loss: 1.116e-02, Lambda_1: 0.296, Lambda_2: 0.003579, Time: 0.33\n",
            "It: 680, Loss: 1.111e-02, Lambda_1: 0.301, Lambda_2: 0.003626, Time: 0.30\n",
            "It: 690, Loss: 1.139e-02, Lambda_1: 0.305, Lambda_2: 0.003673, Time: 0.31\n",
            "It: 700, Loss: 1.104e-02, Lambda_1: 0.310, Lambda_2: 0.003720, Time: 0.33\n",
            "It: 710, Loss: 1.093e-02, Lambda_1: 0.314, Lambda_2: 0.003769, Time: 0.32\n",
            "It: 720, Loss: 1.080e-02, Lambda_1: 0.319, Lambda_2: 0.003818, Time: 0.31\n",
            "It: 730, Loss: 1.073e-02, Lambda_1: 0.323, Lambda_2: 0.003867, Time: 0.32\n",
            "It: 740, Loss: 1.066e-02, Lambda_1: 0.328, Lambda_2: 0.003918, Time: 0.31\n",
            "It: 750, Loss: 1.139e-02, Lambda_1: 0.332, Lambda_2: 0.003970, Time: 0.31\n",
            "It: 760, Loss: 1.060e-02, Lambda_1: 0.336, Lambda_2: 0.004020, Time: 0.31\n",
            "It: 770, Loss: 1.053e-02, Lambda_1: 0.340, Lambda_2: 0.004072, Time: 0.32\n",
            "It: 780, Loss: 1.044e-02, Lambda_1: 0.344, Lambda_2: 0.004124, Time: 0.31\n",
            "It: 790, Loss: 1.033e-02, Lambda_1: 0.348, Lambda_2: 0.004177, Time: 0.31\n",
            "It: 800, Loss: 1.025e-02, Lambda_1: 0.353, Lambda_2: 0.004232, Time: 0.32\n",
            "It: 810, Loss: 1.018e-02, Lambda_1: 0.357, Lambda_2: 0.004287, Time: 0.31\n",
            "It: 820, Loss: 1.011e-02, Lambda_1: 0.362, Lambda_2: 0.004344, Time: 0.31\n",
            "It: 830, Loss: 1.012e-02, Lambda_1: 0.366, Lambda_2: 0.004402, Time: 0.33\n",
            "It: 840, Loss: 1.021e-02, Lambda_1: 0.370, Lambda_2: 0.004458, Time: 0.31\n",
            "It: 850, Loss: 1.041e-02, Lambda_1: 0.373, Lambda_2: 0.004514, Time: 0.31\n",
            "It: 860, Loss: 9.868e-03, Lambda_1: 0.376, Lambda_2: 0.004571, Time: 0.31\n",
            "It: 870, Loss: 9.866e-03, Lambda_1: 0.379, Lambda_2: 0.004629, Time: 0.32\n",
            "It: 880, Loss: 9.742e-03, Lambda_1: 0.384, Lambda_2: 0.004687, Time: 0.32\n",
            "It: 890, Loss: 9.674e-03, Lambda_1: 0.388, Lambda_2: 0.004747, Time: 0.34\n",
            "It: 900, Loss: 9.609e-03, Lambda_1: 0.392, Lambda_2: 0.004809, Time: 0.33\n",
            "It: 910, Loss: 9.545e-03, Lambda_1: 0.396, Lambda_2: 0.004872, Time: 0.32\n",
            "It: 920, Loss: 9.483e-03, Lambda_1: 0.400, Lambda_2: 0.004936, Time: 0.32\n",
            "It: 930, Loss: 1.232e-02, Lambda_1: 0.403, Lambda_2: 0.005001, Time: 0.31\n",
            "It: 940, Loss: 9.429e-03, Lambda_1: 0.406, Lambda_2: 0.005061, Time: 0.31\n",
            "It: 950, Loss: 9.342e-03, Lambda_1: 0.408, Lambda_2: 0.005124, Time: 0.32\n",
            "It: 960, Loss: 9.285e-03, Lambda_1: 0.411, Lambda_2: 0.005187, Time: 0.31\n",
            "It: 970, Loss: 9.211e-03, Lambda_1: 0.414, Lambda_2: 0.005250, Time: 0.32\n",
            "It: 980, Loss: 9.145e-03, Lambda_1: 0.418, Lambda_2: 0.005317, Time: 0.32\n",
            "It: 990, Loss: 9.087e-03, Lambda_1: 0.422, Lambda_2: 0.005386, Time: 0.32\n",
            "It: 1000, Loss: 9.021e-03, Lambda_1: 0.426, Lambda_2: 0.005457, Time: 0.32\n",
            "It: 1010, Loss: 8.959e-03, Lambda_1: 0.429, Lambda_2: 0.005529, Time: 0.32\n",
            "It: 1020, Loss: 8.896e-03, Lambda_1: 0.433, Lambda_2: 0.005602, Time: 0.32\n",
            "It: 1030, Loss: 8.833e-03, Lambda_1: 0.437, Lambda_2: 0.005677, Time: 0.32\n",
            "It: 1040, Loss: 8.770e-03, Lambda_1: 0.440, Lambda_2: 0.005752, Time: 0.30\n",
            "It: 1050, Loss: 8.712e-03, Lambda_1: 0.444, Lambda_2: 0.005829, Time: 0.33\n",
            "It: 1060, Loss: 1.280e-02, Lambda_1: 0.447, Lambda_2: 0.005907, Time: 0.31\n",
            "It: 1070, Loss: 9.473e-03, Lambda_1: 0.448, Lambda_2: 0.005972, Time: 0.31\n",
            "It: 1080, Loss: 9.028e-03, Lambda_1: 0.448, Lambda_2: 0.006048, Time: 0.32\n",
            "It: 1090, Loss: 8.613e-03, Lambda_1: 0.450, Lambda_2: 0.006121, Time: 0.31\n",
            "It: 1100, Loss: 8.472e-03, Lambda_1: 0.454, Lambda_2: 0.006195, Time: 0.32\n",
            "It: 1110, Loss: 8.396e-03, Lambda_1: 0.457, Lambda_2: 0.006274, Time: 0.32\n",
            "It: 1120, Loss: 8.328e-03, Lambda_1: 0.461, Lambda_2: 0.006356, Time: 0.31\n",
            "It: 1130, Loss: 8.256e-03, Lambda_1: 0.465, Lambda_2: 0.006439, Time: 0.33\n",
            "It: 1140, Loss: 8.192e-03, Lambda_1: 0.468, Lambda_2: 0.006523, Time: 0.32\n",
            "It: 1150, Loss: 8.127e-03, Lambda_1: 0.472, Lambda_2: 0.006609, Time: 0.32\n",
            "It: 1160, Loss: 8.061e-03, Lambda_1: 0.476, Lambda_2: 0.006697, Time: 0.31\n",
            "It: 1170, Loss: 7.994e-03, Lambda_1: 0.479, Lambda_2: 0.006786, Time: 0.31\n",
            "It: 1180, Loss: 7.927e-03, Lambda_1: 0.483, Lambda_2: 0.006876, Time: 0.33\n",
            "It: 1190, Loss: 7.859e-03, Lambda_1: 0.486, Lambda_2: 0.006969, Time: 0.31\n",
            "It: 1200, Loss: 7.791e-03, Lambda_1: 0.490, Lambda_2: 0.007062, Time: 0.31\n",
            "It: 1210, Loss: 8.005e-03, Lambda_1: 0.494, Lambda_2: 0.007158, Time: 0.34\n",
            "It: 1220, Loss: 9.069e-03, Lambda_1: 0.496, Lambda_2: 0.007245, Time: 0.32\n",
            "It: 1230, Loss: 8.344e-03, Lambda_1: 0.496, Lambda_2: 0.007335, Time: 0.31\n",
            "It: 1240, Loss: 7.769e-03, Lambda_1: 0.497, Lambda_2: 0.007428, Time: 0.34\n",
            "It: 1250, Loss: 7.588e-03, Lambda_1: 0.500, Lambda_2: 0.007521, Time: 0.31\n",
            "It: 1260, Loss: 7.463e-03, Lambda_1: 0.504, Lambda_2: 0.007619, Time: 0.32\n",
            "It: 1270, Loss: 7.359e-03, Lambda_1: 0.508, Lambda_2: 0.007720, Time: 0.32\n",
            "It: 1280, Loss: 7.291e-03, Lambda_1: 0.512, Lambda_2: 0.007822, Time: 0.32\n",
            "It: 1290, Loss: 7.214e-03, Lambda_1: 0.516, Lambda_2: 0.007927, Time: 0.31\n",
            "It: 1300, Loss: 7.140e-03, Lambda_1: 0.520, Lambda_2: 0.008035, Time: 0.33\n",
            "It: 1310, Loss: 7.065e-03, Lambda_1: 0.524, Lambda_2: 0.008144, Time: 0.32\n",
            "It: 1320, Loss: 6.990e-03, Lambda_1: 0.528, Lambda_2: 0.008254, Time: 0.31\n",
            "It: 1330, Loss: 6.915e-03, Lambda_1: 0.532, Lambda_2: 0.008367, Time: 0.34\n",
            "It: 1340, Loss: 6.840e-03, Lambda_1: 0.536, Lambda_2: 0.008482, Time: 0.31\n",
            "It: 1350, Loss: 1.068e-02, Lambda_1: 0.539, Lambda_2: 0.008598, Time: 0.31\n",
            "It: 1360, Loss: 8.362e-03, Lambda_1: 0.541, Lambda_2: 0.008692, Time: 0.33\n",
            "It: 1370, Loss: 6.872e-03, Lambda_1: 0.540, Lambda_2: 0.008805, Time: 0.32\n",
            "It: 1380, Loss: 6.630e-03, Lambda_1: 0.541, Lambda_2: 0.008913, Time: 0.34\n",
            "It: 1390, Loss: 6.577e-03, Lambda_1: 0.545, Lambda_2: 0.009019, Time: 0.32\n",
            "It: 1400, Loss: 6.482e-03, Lambda_1: 0.549, Lambda_2: 0.009132, Time: 0.30\n",
            "It: 1410, Loss: 6.392e-03, Lambda_1: 0.553, Lambda_2: 0.009245, Time: 0.30\n",
            "It: 1420, Loss: 6.316e-03, Lambda_1: 0.557, Lambda_2: 0.009361, Time: 0.30\n",
            "It: 1430, Loss: 6.242e-03, Lambda_1: 0.561, Lambda_2: 0.009481, Time: 0.33\n",
            "It: 1440, Loss: 6.165e-03, Lambda_1: 0.565, Lambda_2: 0.009603, Time: 0.31\n",
            "It: 1450, Loss: 6.089e-03, Lambda_1: 0.570, Lambda_2: 0.009726, Time: 0.31\n",
            "It: 1460, Loss: 6.014e-03, Lambda_1: 0.574, Lambda_2: 0.009852, Time: 0.32\n",
            "It: 1470, Loss: 6.005e-03, Lambda_1: 0.578, Lambda_2: 0.009979, Time: 0.31\n",
            "It: 1480, Loss: 6.389e-03, Lambda_1: 0.582, Lambda_2: 0.010101, Time: 0.32\n",
            "It: 1490, Loss: 6.499e-03, Lambda_1: 0.583, Lambda_2: 0.010218, Time: 0.33\n",
            "It: 1500, Loss: 5.966e-03, Lambda_1: 0.584, Lambda_2: 0.010345, Time: 0.31\n",
            "It: 1510, Loss: 5.714e-03, Lambda_1: 0.587, Lambda_2: 0.010469, Time: 0.32\n",
            "It: 1520, Loss: 5.658e-03, Lambda_1: 0.591, Lambda_2: 0.010595, Time: 0.35\n",
            "It: 1530, Loss: 5.557e-03, Lambda_1: 0.595, Lambda_2: 0.010725, Time: 0.31\n",
            "It: 1540, Loss: 5.477e-03, Lambda_1: 0.599, Lambda_2: 0.010857, Time: 0.31\n",
            "It: 1550, Loss: 5.400e-03, Lambda_1: 0.603, Lambda_2: 0.010993, Time: 0.32\n",
            "It: 1560, Loss: 5.325e-03, Lambda_1: 0.607, Lambda_2: 0.011131, Time: 0.32\n",
            "It: 1570, Loss: 5.252e-03, Lambda_1: 0.612, Lambda_2: 0.011271, Time: 0.31\n",
            "It: 1580, Loss: 5.180e-03, Lambda_1: 0.616, Lambda_2: 0.011412, Time: 0.32\n",
            "It: 1590, Loss: 5.175e-03, Lambda_1: 0.620, Lambda_2: 0.011556, Time: 0.31\n",
            "It: 1600, Loss: 5.478e-03, Lambda_1: 0.623, Lambda_2: 0.011694, Time: 0.31\n",
            "It: 1610, Loss: 5.865e-03, Lambda_1: 0.624, Lambda_2: 0.011826, Time: 0.31\n",
            "It: 1620, Loss: 5.043e-03, Lambda_1: 0.624, Lambda_2: 0.011971, Time: 0.31\n",
            "It: 1630, Loss: 4.915e-03, Lambda_1: 0.627, Lambda_2: 0.012108, Time: 0.31\n",
            "It: 1640, Loss: 4.857e-03, Lambda_1: 0.631, Lambda_2: 0.012248, Time: 0.30\n",
            "It: 1650, Loss: 4.754e-03, Lambda_1: 0.635, Lambda_2: 0.012391, Time: 0.32\n",
            "It: 1660, Loss: 4.677e-03, Lambda_1: 0.639, Lambda_2: 0.012538, Time: 0.32\n",
            "It: 1670, Loss: 4.609e-03, Lambda_1: 0.643, Lambda_2: 0.012688, Time: 0.30\n",
            "It: 1680, Loss: 4.541e-03, Lambda_1: 0.648, Lambda_2: 0.012840, Time: 0.32\n",
            "It: 1690, Loss: 4.474e-03, Lambda_1: 0.652, Lambda_2: 0.012994, Time: 0.32\n",
            "It: 1700, Loss: 4.407e-03, Lambda_1: 0.656, Lambda_2: 0.013149, Time: 0.31\n",
            "It: 1710, Loss: 4.342e-03, Lambda_1: 0.660, Lambda_2: 0.013306, Time: 0.32\n",
            "It: 1720, Loss: 4.297e-03, Lambda_1: 0.664, Lambda_2: 0.013464, Time: 0.31\n",
            "It: 1730, Loss: 9.244e-03, Lambda_1: 0.667, Lambda_2: 0.013620, Time: 0.30\n",
            "It: 1740, Loss: 4.393e-03, Lambda_1: 0.668, Lambda_2: 0.013758, Time: 0.33\n",
            "It: 1750, Loss: 4.195e-03, Lambda_1: 0.667, Lambda_2: 0.013917, Time: 0.31\n",
            "It: 1760, Loss: 4.094e-03, Lambda_1: 0.668, Lambda_2: 0.014065, Time: 0.31\n",
            "It: 1770, Loss: 4.046e-03, Lambda_1: 0.672, Lambda_2: 0.014213, Time: 0.33\n",
            "It: 1780, Loss: 3.989e-03, Lambda_1: 0.675, Lambda_2: 0.014365, Time: 0.31\n",
            "It: 1790, Loss: 3.903e-03, Lambda_1: 0.680, Lambda_2: 0.014521, Time: 0.32\n",
            "It: 1800, Loss: 3.845e-03, Lambda_1: 0.684, Lambda_2: 0.014681, Time: 0.33\n",
            "It: 1810, Loss: 3.784e-03, Lambda_1: 0.688, Lambda_2: 0.014843, Time: 0.33\n",
            "It: 1820, Loss: 3.724e-03, Lambda_1: 0.692, Lambda_2: 0.015007, Time: 0.31\n",
            "It: 1830, Loss: 3.665e-03, Lambda_1: 0.696, Lambda_2: 0.015172, Time: 0.30\n",
            "It: 1840, Loss: 3.607e-03, Lambda_1: 0.699, Lambda_2: 0.015338, Time: 0.34\n",
            "It: 1850, Loss: 3.550e-03, Lambda_1: 0.703, Lambda_2: 0.015505, Time: 0.31\n",
            "It: 1860, Loss: 3.493e-03, Lambda_1: 0.707, Lambda_2: 0.015673, Time: 0.32\n",
            "It: 1870, Loss: 3.437e-03, Lambda_1: 0.710, Lambda_2: 0.015842, Time: 0.34\n",
            "It: 1880, Loss: 3.614e-03, Lambda_1: 0.714, Lambda_2: 0.016011, Time: 0.31\n",
            "It: 1890, Loss: 6.219e-03, Lambda_1: 0.717, Lambda_2: 0.016167, Time: 0.31\n",
            "It: 1900, Loss: 3.380e-03, Lambda_1: 0.718, Lambda_2: 0.016319, Time: 0.32\n",
            "It: 1910, Loss: 3.271e-03, Lambda_1: 0.718, Lambda_2: 0.016475, Time: 0.32\n",
            "It: 1920, Loss: 3.252e-03, Lambda_1: 0.720, Lambda_2: 0.016621, Time: 0.32\n",
            "It: 1930, Loss: 3.216e-03, Lambda_1: 0.722, Lambda_2: 0.016765, Time: 0.32\n",
            "It: 1940, Loss: 3.120e-03, Lambda_1: 0.725, Lambda_2: 0.016916, Time: 0.32\n",
            "It: 1950, Loss: 3.068e-03, Lambda_1: 0.728, Lambda_2: 0.017067, Time: 0.33\n",
            "It: 1960, Loss: 3.018e-03, Lambda_1: 0.731, Lambda_2: 0.017221, Time: 0.33\n",
            "It: 1970, Loss: 2.977e-03, Lambda_1: 0.734, Lambda_2: 0.017377, Time: 0.32\n",
            "It: 1980, Loss: 3.236e-03, Lambda_1: 0.737, Lambda_2: 0.017533, Time: 0.33\n",
            "It: 1990, Loss: 2.999e-03, Lambda_1: 0.740, Lambda_2: 0.017678, Time: 0.33\n",
            "Loss: 2.975805e-03, l1: 0.74012, l2: 0.01782\n",
            "Loss: 3.803239e+00, l1: 0.74030, l2: 0.01804\n",
            "Loss: 2.117320e-02, l1: 0.74012, l2: 0.01782\n",
            "Loss: 2.869466e-03, l1: 0.74012, l2: 0.01782\n",
            "Loss: 2.868367e-03, l1: 0.74012, l2: 0.01782\n",
            "Loss: 2.864093e-03, l1: 0.74013, l2: 0.01782\n",
            "Loss: 2.863057e-03, l1: 0.74014, l2: 0.01782\n",
            "Loss: 2.860812e-03, l1: 0.74018, l2: 0.01783\n",
            "Loss: 2.855926e-03, l1: 0.74029, l2: 0.01784\n",
            "Loss: 2.848211e-03, l1: 0.74051, l2: 0.01787\n",
            "Loss: 2.837276e-03, l1: 0.74089, l2: 0.01792\n",
            "Loss: 2.823506e-03, l1: 0.74148, l2: 0.01798\n",
            "Loss: 2.813775e-03, l1: 0.74199, l2: 0.01803\n",
            "Loss: 2.808215e-03, l1: 0.74237, l2: 0.01805\n",
            "Loss: 2.798441e-03, l1: 0.74329, l2: 0.01809\n",
            "Loss: 2.781399e-03, l1: 0.74618, l2: 0.01821\n",
            "Loss: 2.761059e-03, l1: 0.74937, l2: 0.01833\n",
            "Loss: 2.741602e-03, l1: 0.75170, l2: 0.01840\n",
            "Loss: 2.704741e-03, l1: 0.75738, l2: 0.01858\n",
            "Loss: 2.666030e-03, l1: 0.76398, l2: 0.01880\n",
            "Loss: 2.584058e-03, l1: 0.77937, l2: 0.01931\n",
            "Loss: 2.499864e-03, l1: 0.79990, l2: 0.02001\n",
            "Loss: 2.434309e-03, l1: 0.80881, l2: 0.02034\n",
            "Loss: 2.382060e-03, l1: 0.81620, l2: 0.02066\n",
            "Loss: 2.331755e-03, l1: 0.82152, l2: 0.02090\n",
            "Loss: 2.220563e-03, l1: 0.83763, l2: 0.02167\n",
            "Loss: 2.129906e-03, l1: 0.85474, l2: 0.02255\n",
            "Loss: 2.052186e-03, l1: 0.86020, l2: 0.02287\n",
            "Loss: 1.996953e-03, l1: 0.87466, l2: 0.02361\n",
            "Loss: 1.973544e-03, l1: 0.87629, l2: 0.02368\n",
            "Loss: 1.936125e-03, l1: 0.88402, l2: 0.02405\n",
            "Loss: 1.895734e-03, l1: 0.89001, l2: 0.02436\n",
            "Loss: 1.840625e-03, l1: 0.90200, l2: 0.02498\n",
            "Loss: 1.796682e-03, l1: 0.90849, l2: 0.02535\n",
            "Loss: 1.769872e-03, l1: 0.91217, l2: 0.02557\n",
            "Loss: 1.744877e-03, l1: 0.91498, l2: 0.02574\n",
            "Loss: 1.677260e-03, l1: 0.92277, l2: 0.02622\n",
            "Loss: 1.619484e-03, l1: 0.92927, l2: 0.02664\n",
            "Loss: 1.586395e-03, l1: 0.93126, l2: 0.02683\n",
            "Loss: 1.572355e-03, l1: 0.93284, l2: 0.02696\n",
            "Loss: 1.550828e-03, l1: 0.93385, l2: 0.02710\n",
            "Loss: 1.520949e-03, l1: 0.93771, l2: 0.02747\n",
            "Loss: 1.473237e-03, l1: 0.93991, l2: 0.02786\n",
            "Loss: 1.400496e-03, l1: 0.94480, l2: 0.02870\n",
            "Loss: 1.347155e-03, l1: 0.93991, l2: 0.02885\n",
            "Loss: 1.289397e-03, l1: 0.93904, l2: 0.02921\n",
            "Loss: 1.223581e-03, l1: 0.93617, l2: 0.02948\n",
            "Loss: 1.177269e-03, l1: 0.93650, l2: 0.02982\n",
            "Loss: 1.133010e-03, l1: 0.94401, l2: 0.03062\n",
            "Loss: 1.120495e-03, l1: 0.94702, l2: 0.03095\n",
            "Loss: 1.113501e-03, l1: 0.95237, l2: 0.03136\n",
            "Loss: 1.107512e-03, l1: 0.95372, l2: 0.03147\n",
            "Loss: 1.097267e-03, l1: 0.95767, l2: 0.03190\n",
            "Loss: 1.078553e-03, l1: 0.95552, l2: 0.03196\n",
            "Loss: 1.055317e-03, l1: 0.95140, l2: 0.03207\n",
            "Loss: 1.045684e-03, l1: 0.94524, l2: 0.03174\n",
            "Loss: 1.037341e-03, l1: 0.94289, l2: 0.03161\n",
            "Loss: 1.028233e-03, l1: 0.94172, l2: 0.03155\n",
            "Loss: 1.012381e-03, l1: 0.94175, l2: 0.03169\n",
            "Loss: 9.970567e-04, l1: 0.94277, l2: 0.03206\n",
            "Loss: 9.883312e-04, l1: 0.94603, l2: 0.03263\n",
            "Loss: 9.833963e-04, l1: 0.94719, l2: 0.03272\n",
            "Loss: 9.786738e-04, l1: 0.94845, l2: 0.03288\n",
            "Loss: 9.679933e-04, l1: 0.94728, l2: 0.03287\n",
            "Loss: 9.545385e-04, l1: 0.94350, l2: 0.03287\n",
            "Loss: 9.469819e-04, l1: 0.93792, l2: 0.03251\n",
            "Loss: 9.433661e-04, l1: 0.93542, l2: 0.03237\n",
            "Loss: 9.395621e-04, l1: 0.93338, l2: 0.03228\n",
            "Loss: 9.336880e-04, l1: 0.93118, l2: 0.03223\n",
            "Loss: 9.209615e-04, l1: 0.92795, l2: 0.03226\n",
            "Loss: 9.069468e-04, l1: 0.92552, l2: 0.03240\n",
            "Loss: 9.243409e-04, l1: 0.92883, l2: 0.03283\n",
            "Loss: 9.030340e-04, l1: 0.92651, l2: 0.03253\n",
            "Loss: 8.961579e-04, l1: 0.92731, l2: 0.03273\n",
            "Loss: 8.935283e-04, l1: 0.92838, l2: 0.03283\n",
            "Loss: 8.902997e-04, l1: 0.92981, l2: 0.03295\n",
            "Loss: 8.828948e-04, l1: 0.93078, l2: 0.03308\n",
            "Loss: 8.672097e-04, l1: 0.92982, l2: 0.03319\n",
            "Loss: 8.505692e-04, l1: 0.92618, l2: 0.03334\n",
            "Loss: 8.394236e-04, l1: 0.92101, l2: 0.03302\n",
            "Loss: 8.350875e-04, l1: 0.91873, l2: 0.03304\n",
            "Loss: 8.338679e-04, l1: 0.91740, l2: 0.03287\n",
            "Loss: 8.328082e-04, l1: 0.91728, l2: 0.03286\n",
            "Loss: 8.274064e-04, l1: 0.91717, l2: 0.03283\n",
            "Loss: 8.195469e-04, l1: 0.91700, l2: 0.03290\n",
            "Loss: 8.071226e-04, l1: 0.91475, l2: 0.03293\n",
            "Loss: 7.985915e-04, l1: 0.91191, l2: 0.03324\n",
            "Loss: 7.883632e-04, l1: 0.91132, l2: 0.03324\n",
            "Loss: 7.854372e-04, l1: 0.90958, l2: 0.03317\n",
            "Loss: 7.845098e-04, l1: 0.90918, l2: 0.03318\n",
            "Loss: 7.837092e-04, l1: 0.90854, l2: 0.03313\n",
            "Loss: 7.817984e-04, l1: 0.90789, l2: 0.03307\n",
            "Loss: 7.784559e-04, l1: 0.90661, l2: 0.03299\n",
            "Loss: 7.726817e-04, l1: 0.90564, l2: 0.03294\n",
            "Loss: 7.690332e-04, l1: 0.90378, l2: 0.03299\n",
            "Loss: 7.575980e-04, l1: 0.90296, l2: 0.03297\n",
            "Loss: 7.524327e-04, l1: 0.90242, l2: 0.03299\n",
            "Loss: 7.492020e-04, l1: 0.90184, l2: 0.03299\n",
            "Loss: 7.423615e-04, l1: 0.90094, l2: 0.03297\n",
            "Loss: 7.249755e-04, l1: 0.90019, l2: 0.03274\n",
            "Loss: 7.135490e-04, l1: 0.90022, l2: 0.03288\n",
            "Loss: 7.055704e-04, l1: 0.90126, l2: 0.03283\n",
            "Loss: 6.977542e-04, l1: 0.90334, l2: 0.03284\n",
            "Loss: 6.937245e-04, l1: 0.90131, l2: 0.03266\n",
            "Loss: 6.877847e-04, l1: 0.90178, l2: 0.03273\n",
            "Loss: 6.830536e-04, l1: 0.90174, l2: 0.03267\n",
            "Loss: 6.785552e-04, l1: 0.90031, l2: 0.03266\n",
            "Loss: 6.668595e-04, l1: 0.89857, l2: 0.03263\n",
            "Loss: 6.545283e-04, l1: 0.89805, l2: 0.03262\n",
            "Loss: 6.521925e-04, l1: 0.90216, l2: 0.03281\n",
            "Loss: 6.441226e-04, l1: 0.90019, l2: 0.03272\n",
            "Loss: 6.352082e-04, l1: 0.90356, l2: 0.03274\n",
            "Loss: 6.322215e-04, l1: 0.90600, l2: 0.03280\n",
            "Loss: 6.303779e-04, l1: 0.90686, l2: 0.03284\n",
            "Loss: 6.279431e-04, l1: 0.90727, l2: 0.03286\n",
            "Loss: 6.248459e-04, l1: 0.90791, l2: 0.03293\n",
            "Loss: 6.163624e-04, l1: 0.91013, l2: 0.03299\n",
            "Loss: 6.039762e-04, l1: 0.91189, l2: 0.03303\n",
            "Loss: 5.918454e-04, l1: 0.91250, l2: 0.03280\n",
            "Loss: 6.034052e-04, l1: 0.91746, l2: 0.03311\n",
            "Loss: 5.860348e-04, l1: 0.91431, l2: 0.03292\n",
            "Loss: 5.814942e-04, l1: 0.91407, l2: 0.03286\n",
            "Loss: 5.794949e-04, l1: 0.91479, l2: 0.03284\n",
            "Loss: 5.785542e-04, l1: 0.91583, l2: 0.03289\n",
            "Loss: 5.765042e-04, l1: 0.91798, l2: 0.03297\n",
            "Loss: 5.735817e-04, l1: 0.92096, l2: 0.03302\n",
            "Loss: 5.701926e-04, l1: 0.92359, l2: 0.03306\n",
            "Loss: 5.641327e-04, l1: 0.92828, l2: 0.03302\n",
            "Loss: 5.562049e-04, l1: 0.93097, l2: 0.03296\n",
            "Loss: 5.468515e-04, l1: 0.93183, l2: 0.03284\n",
            "Loss: 5.277027e-04, l1: 0.93231, l2: 0.03260\n",
            "Loss: 5.048854e-04, l1: 0.93549, l2: 0.03223\n",
            "Loss: 5.097314e-04, l1: 0.93706, l2: 0.03236\n",
            "Loss: 4.987749e-04, l1: 0.93617, l2: 0.03229\n",
            "Loss: 4.937740e-04, l1: 0.93492, l2: 0.03222\n",
            "Loss: 4.919856e-04, l1: 0.93491, l2: 0.03224\n",
            "Loss: 4.912855e-04, l1: 0.93481, l2: 0.03232\n",
            "Loss: 4.909354e-04, l1: 0.93519, l2: 0.03230\n",
            "Loss: 4.903206e-04, l1: 0.93580, l2: 0.03233\n",
            "Loss: 4.892208e-04, l1: 0.93709, l2: 0.03240\n",
            "Loss: 4.872848e-04, l1: 0.93826, l2: 0.03253\n",
            "Loss: 4.828511e-04, l1: 0.93935, l2: 0.03267\n",
            "Loss: 4.808636e-04, l1: 0.94141, l2: 0.03321\n",
            "Loss: 4.696475e-04, l1: 0.93896, l2: 0.03299\n",
            "Loss: 4.609399e-04, l1: 0.93643, l2: 0.03276\n",
            "Loss: 4.483756e-04, l1: 0.93284, l2: 0.03252\n",
            "Loss: 4.361596e-04, l1: 0.93147, l2: 0.03213\n",
            "Loss: 4.240850e-04, l1: 0.93284, l2: 0.03205\n",
            "Loss: 4.167247e-04, l1: 0.93816, l2: 0.03223\n",
            "Loss: 4.131313e-04, l1: 0.93810, l2: 0.03220\n",
            "Loss: 4.115970e-04, l1: 0.93941, l2: 0.03221\n",
            "Loss: 4.093311e-04, l1: 0.94163, l2: 0.03230\n",
            "Loss: 4.059239e-04, l1: 0.94482, l2: 0.03236\n",
            "Loss: 4.018149e-04, l1: 0.94806, l2: 0.03250\n",
            "Loss: 3.968483e-04, l1: 0.95190, l2: 0.03256\n",
            "Loss: 3.883757e-04, l1: 0.95705, l2: 0.03270\n",
            "Loss: 3.751046e-04, l1: 0.96378, l2: 0.03289\n",
            "Loss: 3.605282e-04, l1: 0.96343, l2: 0.03278\n",
            "Loss: 3.455990e-04, l1: 0.96280, l2: 0.03269\n",
            "Loss: 3.358143e-04, l1: 0.96118, l2: 0.03245\n",
            "Loss: 3.245347e-04, l1: 0.96331, l2: 0.03218\n",
            "Loss: 3.138293e-04, l1: 0.96035, l2: 0.03199\n",
            "Loss: 3.044944e-04, l1: 0.96077, l2: 0.03184\n",
            "Loss: 3.006474e-04, l1: 0.95933, l2: 0.03194\n",
            "Loss: 2.986691e-04, l1: 0.95949, l2: 0.03197\n",
            "Loss: 2.969958e-04, l1: 0.95929, l2: 0.03196\n",
            "Loss: 2.955812e-04, l1: 0.95953, l2: 0.03203\n",
            "Loss: 2.941310e-04, l1: 0.95852, l2: 0.03199\n",
            "Loss: 2.927462e-04, l1: 0.95976, l2: 0.03204\n",
            "Loss: 2.913059e-04, l1: 0.95988, l2: 0.03198\n",
            "Loss: 2.884741e-04, l1: 0.95993, l2: 0.03188\n",
            "Loss: 2.845254e-04, l1: 0.95968, l2: 0.03174\n",
            "Loss: 2.758100e-04, l1: 0.96100, l2: 0.03163\n",
            "Loss: 2.650884e-04, l1: 0.95909, l2: 0.03146\n",
            "Loss: 2.556563e-04, l1: 0.96175, l2: 0.03154\n",
            "Loss: 2.483093e-04, l1: 0.95502, l2: 0.03156\n",
            "Loss: 2.403778e-04, l1: 0.95806, l2: 0.03178\n",
            "Loss: 2.343169e-04, l1: 0.96024, l2: 0.03203\n",
            "Loss: 2.274996e-04, l1: 0.96199, l2: 0.03221\n",
            "Loss: 2.404469e-04, l1: 0.96190, l2: 0.03275\n",
            "Loss: 2.226661e-04, l1: 0.96196, l2: 0.03239\n",
            "Loss: 2.138738e-04, l1: 0.96275, l2: 0.03239\n",
            "Loss: 2.106344e-04, l1: 0.96227, l2: 0.03233\n",
            "Loss: 2.085847e-04, l1: 0.96307, l2: 0.03228\n",
            "Loss: 2.069487e-04, l1: 0.96377, l2: 0.03228\n",
            "Loss: 2.048075e-04, l1: 0.96467, l2: 0.03228\n",
            "Loss: 2.025459e-04, l1: 0.96660, l2: 0.03235\n",
            "Loss: 2.006286e-04, l1: 0.96753, l2: 0.03240\n",
            "Loss: 1.971552e-04, l1: 0.96965, l2: 0.03251\n",
            "Loss: 1.940491e-04, l1: 0.97144, l2: 0.03259\n",
            "Loss: 1.913478e-04, l1: 0.97105, l2: 0.03267\n",
            "Loss: 1.887336e-04, l1: 0.97120, l2: 0.03256\n",
            "Loss: 1.869663e-04, l1: 0.96993, l2: 0.03246\n",
            "Loss: 1.849964e-04, l1: 0.96887, l2: 0.03237\n",
            "Loss: 1.813476e-04, l1: 0.96818, l2: 0.03229\n",
            "Loss: 1.768406e-04, l1: 0.96708, l2: 0.03223\n",
            "Loss: 1.723183e-04, l1: 0.96518, l2: 0.03215\n",
            "Loss: 1.833498e-04, l1: 0.97074, l2: 0.03263\n",
            "Loss: 1.697091e-04, l1: 0.96689, l2: 0.03229\n",
            "Loss: 1.645548e-04, l1: 0.96507, l2: 0.03221\n",
            "Loss: 1.598049e-04, l1: 0.96303, l2: 0.03216\n",
            "Loss: 1.596761e-04, l1: 0.96260, l2: 0.03210\n",
            "Loss: 1.578023e-04, l1: 0.96281, l2: 0.03213\n",
            "Loss: 1.555657e-04, l1: 0.96249, l2: 0.03210\n",
            "Loss: 1.539509e-04, l1: 0.96225, l2: 0.03208\n",
            "Loss: 1.523369e-04, l1: 0.96312, l2: 0.03203\n",
            "Loss: 1.509295e-04, l1: 0.96400, l2: 0.03196\n",
            "Loss: 1.495889e-04, l1: 0.96528, l2: 0.03193\n",
            "Loss: 1.483191e-04, l1: 0.96631, l2: 0.03188\n",
            "Loss: 1.469962e-04, l1: 0.96755, l2: 0.03188\n",
            "Loss: 1.450295e-04, l1: 0.97066, l2: 0.03186\n",
            "Loss: 1.430110e-04, l1: 0.97254, l2: 0.03192\n",
            "Loss: 1.414556e-04, l1: 0.97351, l2: 0.03196\n",
            "Loss: 1.389835e-04, l1: 0.97506, l2: 0.03204\n",
            "Loss: 1.361086e-04, l1: 0.97595, l2: 0.03209\n",
            "Loss: 1.310098e-04, l1: 0.97722, l2: 0.03213\n",
            "Loss: 1.267907e-04, l1: 0.97859, l2: 0.03220\n",
            "Loss: 1.290778e-04, l1: 0.97910, l2: 0.03225\n",
            "Loss: 1.243835e-04, l1: 0.97880, l2: 0.03222\n",
            "Loss: 1.465400e-04, l1: 0.97894, l2: 0.03237\n",
            "Loss: 1.233003e-04, l1: 0.97883, l2: 0.03225\n",
            "Loss: 1.214893e-04, l1: 0.97812, l2: 0.03220\n",
            "Loss: 1.202504e-04, l1: 0.97778, l2: 0.03217\n",
            "Loss: 1.195151e-04, l1: 0.97733, l2: 0.03214\n",
            "Loss: 1.188410e-04, l1: 0.97745, l2: 0.03215\n",
            "Loss: 1.183257e-04, l1: 0.97806, l2: 0.03216\n",
            "Loss: 1.181538e-04, l1: 0.97816, l2: 0.03217\n",
            "Loss: 1.178585e-04, l1: 0.97817, l2: 0.03216\n",
            "Loss: 1.177040e-04, l1: 0.97844, l2: 0.03225\n",
            "Loss: 1.172299e-04, l1: 0.97769, l2: 0.03219\n",
            "Loss: 1.169193e-04, l1: 0.97703, l2: 0.03215\n",
            "Loss: 1.166828e-04, l1: 0.97667, l2: 0.03213\n",
            "Loss: 1.165096e-04, l1: 0.97679, l2: 0.03214\n",
            "Loss: 1.162584e-04, l1: 0.97740, l2: 0.03216\n",
            "Loss: 1.160847e-04, l1: 0.97818, l2: 0.03220\n",
            "Loss: 1.158168e-04, l1: 0.97844, l2: 0.03222\n",
            "Loss: 1.155166e-04, l1: 0.97869, l2: 0.03224\n",
            "Loss: 1.152154e-04, l1: 0.97879, l2: 0.03226\n",
            "Loss: 1.146629e-04, l1: 0.97890, l2: 0.03228\n",
            "Loss: 1.137790e-04, l1: 0.97925, l2: 0.03231\n",
            "Loss: 1.125032e-04, l1: 0.97857, l2: 0.03232\n",
            "Loss: 1.107353e-04, l1: 0.97910, l2: 0.03233\n",
            "Loss: 1.080479e-04, l1: 0.98089, l2: 0.03228\n",
            "Loss: 1.073562e-04, l1: 0.98069, l2: 0.03231\n",
            "Loss: 1.058192e-04, l1: 0.98174, l2: 0.03225\n",
            "Loss: 1.047457e-04, l1: 0.98240, l2: 0.03221\n",
            "Loss: 1.065153e-04, l1: 0.98393, l2: 0.03218\n",
            "Loss: 1.043118e-04, l1: 0.98287, l2: 0.03220\n",
            "Loss: 1.025732e-04, l1: 0.98368, l2: 0.03215\n",
            "Loss: 1.015605e-04, l1: 0.98287, l2: 0.03209\n",
            "Loss: 1.005160e-04, l1: 0.98228, l2: 0.03213\n",
            "Loss: 9.980837e-05, l1: 0.98192, l2: 0.03216\n",
            "Loss: 9.955175e-05, l1: 0.98180, l2: 0.03217\n",
            "Loss: 9.924378e-05, l1: 0.98179, l2: 0.03216\n",
            "Loss: 9.997933e-05, l1: 0.98086, l2: 0.03207\n",
            "Loss: 9.913083e-05, l1: 0.98154, l2: 0.03214\n",
            "Loss: 9.884255e-05, l1: 0.98144, l2: 0.03213\n",
            "Loss: 9.836910e-05, l1: 0.98131, l2: 0.03210\n",
            "Loss: 9.780869e-05, l1: 0.98111, l2: 0.03208\n",
            "Loss: 9.674075e-05, l1: 0.98081, l2: 0.03203\n",
            "Loss: 9.523593e-05, l1: 0.98047, l2: 0.03197\n",
            "Loss: 9.304385e-05, l1: 0.98059, l2: 0.03192\n",
            "Loss: 9.024977e-05, l1: 0.98050, l2: 0.03187\n",
            "Loss: 8.760509e-05, l1: 0.98126, l2: 0.03185\n",
            "Loss: 8.594679e-05, l1: 0.98106, l2: 0.03183\n",
            "Loss: 8.471978e-05, l1: 0.98189, l2: 0.03182\n",
            "Loss: 8.296043e-05, l1: 0.98353, l2: 0.03184\n",
            "Loss: 8.208877e-05, l1: 0.98404, l2: 0.03181\n",
            "Loss: 8.158614e-05, l1: 0.98430, l2: 0.03184\n",
            "Loss: 8.127819e-05, l1: 0.98424, l2: 0.03185\n",
            "Loss: 8.106793e-05, l1: 0.98434, l2: 0.03188\n",
            "Loss: 8.095084e-05, l1: 0.98451, l2: 0.03190\n",
            "Loss: 8.079230e-05, l1: 0.98495, l2: 0.03192\n",
            "Loss: 8.057620e-05, l1: 0.98561, l2: 0.03194\n",
            "Loss: 8.038513e-05, l1: 0.98636, l2: 0.03194\n",
            "Loss: 8.023256e-05, l1: 0.98685, l2: 0.03194\n",
            "Loss: 8.011343e-05, l1: 0.98773, l2: 0.03195\n",
            "Loss: 7.988060e-05, l1: 0.98793, l2: 0.03195\n",
            "Loss: 7.966824e-05, l1: 0.98777, l2: 0.03196\n",
            "Loss: 7.914899e-05, l1: 0.98800, l2: 0.03200\n",
            "Loss: 7.876648e-05, l1: 0.98849, l2: 0.03204\n",
            "Loss: 7.783625e-05, l1: 0.98984, l2: 0.03210\n",
            "Loss: 7.714956e-05, l1: 0.99052, l2: 0.03215\n",
            "Loss: 7.641360e-05, l1: 0.99111, l2: 0.03217\n",
            "Loss: 7.567432e-05, l1: 0.99044, l2: 0.03207\n",
            "Loss: 7.495203e-05, l1: 0.99057, l2: 0.03206\n",
            "Loss: 7.528050e-05, l1: 0.98805, l2: 0.03196\n",
            "Loss: 7.443082e-05, l1: 0.98947, l2: 0.03202\n",
            "Loss: 7.390621e-05, l1: 0.98957, l2: 0.03202\n",
            "Loss: 7.366298e-05, l1: 0.98926, l2: 0.03202\n",
            "Loss: 7.337175e-05, l1: 0.98923, l2: 0.03201\n",
            "Loss: 7.315123e-05, l1: 0.98920, l2: 0.03201\n",
            "Loss: 7.301255e-05, l1: 0.98944, l2: 0.03201\n",
            "Loss: 7.277610e-05, l1: 0.98976, l2: 0.03200\n",
            "Loss: 7.257650e-05, l1: 0.99033, l2: 0.03199\n",
            "Loss: 7.238520e-05, l1: 0.99102, l2: 0.03198\n",
            "Loss: 7.222092e-05, l1: 0.99155, l2: 0.03197\n",
            "Loss: 7.203344e-05, l1: 0.99191, l2: 0.03197\n",
            "Loss: 7.189767e-05, l1: 0.99163, l2: 0.03196\n",
            "Loss: 7.178901e-05, l1: 0.99138, l2: 0.03196\n",
            "Loss: 7.167560e-05, l1: 0.99126, l2: 0.03196\n",
            "Loss: 7.147932e-05, l1: 0.99132, l2: 0.03196\n",
            "Loss: 7.143266e-05, l1: 0.99092, l2: 0.03195\n",
            "Loss: 7.130806e-05, l1: 0.99200, l2: 0.03199\n",
            "Loss: 7.068940e-05, l1: 0.99165, l2: 0.03194\n",
            "Loss: 7.044493e-05, l1: 0.99163, l2: 0.03193\n",
            "Loss: 7.019146e-05, l1: 0.99176, l2: 0.03191\n",
            "Loss: 6.988575e-05, l1: 0.99183, l2: 0.03189\n",
            "Loss: 6.930344e-05, l1: 0.99169, l2: 0.03188\n",
            "Loss: 6.843667e-05, l1: 0.99163, l2: 0.03184\n",
            "Loss: 6.749735e-05, l1: 0.99159, l2: 0.03188\n",
            "Loss: 6.668152e-05, l1: 0.99188, l2: 0.03190\n",
            "Loss: 6.645716e-05, l1: 0.99134, l2: 0.03193\n",
            "Loss: 6.577262e-05, l1: 0.99194, l2: 0.03194\n",
            "Loss: 6.536931e-05, l1: 0.99224, l2: 0.03197\n",
            "Loss: 6.492879e-05, l1: 0.99252, l2: 0.03198\n",
            "Loss: 6.441628e-05, l1: 0.99286, l2: 0.03201\n",
            "Loss: 6.415975e-05, l1: 0.99306, l2: 0.03202\n",
            "Loss: 6.373929e-05, l1: 0.99363, l2: 0.03204\n",
            "Loss: 6.365336e-05, l1: 0.99393, l2: 0.03205\n",
            "Loss: 6.343348e-05, l1: 0.99446, l2: 0.03206\n",
            "Loss: 6.334430e-05, l1: 0.99524, l2: 0.03208\n",
            "Loss: 6.383351e-05, l1: 0.99738, l2: 0.03223\n",
            "Loss: 6.307274e-05, l1: 0.99604, l2: 0.03214\n",
            "Loss: 6.297311e-05, l1: 0.99431, l2: 0.03209\n",
            "Loss: 6.254186e-05, l1: 0.99458, l2: 0.03211\n",
            "Loss: 6.242278e-05, l1: 0.99467, l2: 0.03213\n",
            "Loss: 6.218393e-05, l1: 0.99426, l2: 0.03214\n",
            "Loss: 6.185383e-05, l1: 0.99395, l2: 0.03215\n",
            "Loss: 6.139954e-05, l1: 0.99328, l2: 0.03215\n",
            "Loss: 6.148773e-05, l1: 0.99247, l2: 0.03219\n",
            "Loss: 6.115731e-05, l1: 0.99291, l2: 0.03217\n",
            "Loss: 6.077091e-05, l1: 0.99206, l2: 0.03213\n",
            "Loss: 6.056077e-05, l1: 0.99203, l2: 0.03211\n",
            "Loss: 6.046186e-05, l1: 0.99221, l2: 0.03211\n",
            "Loss: 6.032006e-05, l1: 0.99224, l2: 0.03211\n",
            "Loss: 5.996433e-05, l1: 0.99220, l2: 0.03211\n",
            "Loss: 5.961250e-05, l1: 0.99204, l2: 0.03214\n",
            "Loss: 5.912094e-05, l1: 0.99158, l2: 0.03215\n",
            "Loss: 5.879235e-05, l1: 0.99113, l2: 0.03216\n",
            "Loss: 5.922622e-05, l1: 0.99039, l2: 0.03214\n",
            "Loss: 5.868998e-05, l1: 0.99091, l2: 0.03216\n",
            "Loss: 5.878548e-05, l1: 0.99126, l2: 0.03219\n",
            "Loss: 5.853562e-05, l1: 0.99106, l2: 0.03217\n",
            "Loss: 5.838247e-05, l1: 0.99084, l2: 0.03216\n",
            "Loss: 5.819543e-05, l1: 0.99058, l2: 0.03215\n",
            "Loss: 5.807668e-05, l1: 0.99032, l2: 0.03213\n",
            "Loss: 5.798454e-05, l1: 0.99049, l2: 0.03212\n",
            "Loss: 5.781647e-05, l1: 0.99082, l2: 0.03213\n",
            "Loss: 5.755836e-05, l1: 0.99090, l2: 0.03210\n",
            "Loss: 5.696543e-05, l1: 0.99084, l2: 0.03205\n",
            "Loss: 6.099387e-05, l1: 0.99015, l2: 0.03213\n",
            "Loss: 5.686858e-05, l1: 0.99075, l2: 0.03206\n",
            "Loss: 5.634958e-05, l1: 0.99029, l2: 0.03201\n",
            "Loss: 5.587445e-05, l1: 0.98994, l2: 0.03197\n",
            "Loss: 5.680460e-05, l1: 0.98922, l2: 0.03198\n",
            "Loss: 5.568453e-05, l1: 0.98973, l2: 0.03197\n",
            "Loss: 5.538070e-05, l1: 0.98944, l2: 0.03196\n",
            "Loss: 5.499076e-05, l1: 0.98902, l2: 0.03195\n",
            "Loss: 5.477036e-05, l1: 0.98864, l2: 0.03193\n",
            "Loss: 5.465251e-05, l1: 0.98862, l2: 0.03192\n",
            "Loss: 5.452052e-05, l1: 0.98865, l2: 0.03191\n",
            "Loss: 5.440428e-05, l1: 0.98877, l2: 0.03192\n",
            "Loss: 5.434034e-05, l1: 0.98895, l2: 0.03191\n",
            "Loss: 5.423607e-05, l1: 0.98883, l2: 0.03193\n",
            "Loss: 5.419514e-05, l1: 0.98877, l2: 0.03194\n",
            "Loss: 5.414071e-05, l1: 0.98862, l2: 0.03194\n",
            "Loss: 5.405210e-05, l1: 0.98827, l2: 0.03194\n",
            "Loss: 5.396085e-05, l1: 0.98796, l2: 0.03193\n",
            "Loss: 5.450427e-05, l1: 0.98772, l2: 0.03192\n",
            "Loss: 5.387916e-05, l1: 0.98789, l2: 0.03193\n",
            "Loss: 5.368401e-05, l1: 0.98753, l2: 0.03192\n",
            "Loss: 5.347453e-05, l1: 0.98754, l2: 0.03193\n",
            "Loss: 5.310950e-05, l1: 0.98792, l2: 0.03193\n",
            "Loss: 5.285811e-05, l1: 0.98894, l2: 0.03195\n",
            "Loss: 5.236271e-05, l1: 0.98952, l2: 0.03197\n",
            "Loss: 5.202970e-05, l1: 0.99036, l2: 0.03199\n",
            "Loss: 5.178684e-05, l1: 0.99131, l2: 0.03200\n",
            "Loss: 5.139127e-05, l1: 0.99190, l2: 0.03199\n",
            "Loss: 5.280766e-05, l1: 0.99558, l2: 0.03206\n",
            "Loss: 5.114218e-05, l1: 0.99295, l2: 0.03201\n",
            "Loss: 5.068947e-05, l1: 0.99322, l2: 0.03198\n",
            "Loss: 5.045766e-05, l1: 0.99313, l2: 0.03198\n",
            "Loss: 5.022209e-05, l1: 0.99321, l2: 0.03199\n",
            "Loss: 4.989617e-05, l1: 0.99361, l2: 0.03202\n",
            "Loss: 4.934318e-05, l1: 0.99440, l2: 0.03208\n",
            "Loss: 4.942561e-05, l1: 0.99469, l2: 0.03212\n",
            "Loss: 4.904242e-05, l1: 0.99454, l2: 0.03210\n",
            "Loss: 4.851754e-05, l1: 0.99480, l2: 0.03213\n",
            "Loss: 4.805614e-05, l1: 0.99459, l2: 0.03213\n",
            "Loss: 4.790358e-05, l1: 0.99459, l2: 0.03213\n",
            "Loss: 4.775158e-05, l1: 0.99441, l2: 0.03212\n",
            "Loss: 4.769362e-05, l1: 0.99440, l2: 0.03211\n",
            "Loss: 4.759041e-05, l1: 0.99440, l2: 0.03211\n",
            "Loss: 4.740774e-05, l1: 0.99444, l2: 0.03211\n",
            "Loss: 4.762605e-05, l1: 0.99349, l2: 0.03208\n",
            "Loss: 4.724691e-05, l1: 0.99406, l2: 0.03209\n",
            "Loss: 4.702287e-05, l1: 0.99389, l2: 0.03209\n",
            "Loss: 4.675280e-05, l1: 0.99303, l2: 0.03208\n",
            "Loss: 4.667274e-05, l1: 0.99266, l2: 0.03206\n",
            "Loss: 4.660946e-05, l1: 0.99231, l2: 0.03205\n",
            "Loss: 4.657359e-05, l1: 0.99212, l2: 0.03205\n",
            "Loss: 4.655332e-05, l1: 0.99208, l2: 0.03205\n",
            "Loss: 4.653946e-05, l1: 0.99181, l2: 0.03204\n",
            "Loss: 4.651863e-05, l1: 0.99187, l2: 0.03203\n",
            "Loss: 4.647391e-05, l1: 0.99200, l2: 0.03204\n",
            "Loss: 4.643446e-05, l1: 0.99202, l2: 0.03205\n",
            "Loss: 4.626219e-05, l1: 0.99208, l2: 0.03206\n",
            "Loss: 4.650155e-05, l1: 0.99225, l2: 0.03206\n",
            "Loss: 4.618999e-05, l1: 0.99213, l2: 0.03206\n",
            "Loss: 4.602578e-05, l1: 0.99209, l2: 0.03205\n",
            "Loss: 4.583000e-05, l1: 0.99187, l2: 0.03204\n",
            "Loss: 4.604376e-05, l1: 0.99140, l2: 0.03200\n",
            "Loss: 4.574990e-05, l1: 0.99171, l2: 0.03203\n",
            "Loss: 4.554167e-05, l1: 0.99174, l2: 0.03201\n",
            "Loss: 4.520410e-05, l1: 0.99177, l2: 0.03198\n",
            "Loss: 4.475495e-05, l1: 0.99173, l2: 0.03196\n",
            "Loss: 4.423748e-05, l1: 0.99140, l2: 0.03193\n",
            "Loss: 4.487704e-05, l1: 0.99136, l2: 0.03186\n",
            "Loss: 4.387689e-05, l1: 0.99139, l2: 0.03191\n",
            "Loss: 4.329433e-05, l1: 0.99091, l2: 0.03189\n",
            "Loss: 4.260987e-05, l1: 0.98980, l2: 0.03187\n",
            "Loss: 4.204604e-05, l1: 0.98897, l2: 0.03184\n",
            "Loss: 4.142195e-05, l1: 0.98909, l2: 0.03183\n",
            "Loss: 4.102798e-05, l1: 0.98928, l2: 0.03181\n",
            "Loss: 4.080806e-05, l1: 0.98966, l2: 0.03181\n",
            "Loss: 4.056084e-05, l1: 0.99001, l2: 0.03180\n",
            "Loss: 4.026316e-05, l1: 0.99040, l2: 0.03182\n",
            "Loss: 3.992702e-05, l1: 0.99085, l2: 0.03185\n",
            "Loss: 3.968873e-05, l1: 0.99112, l2: 0.03187\n",
            "Loss: 3.962392e-05, l1: 0.99117, l2: 0.03193\n",
            "Loss: 3.910100e-05, l1: 0.99137, l2: 0.03191\n",
            "Loss: 3.886800e-05, l1: 0.99160, l2: 0.03191\n",
            "Loss: 3.852083e-05, l1: 0.99194, l2: 0.03191\n",
            "Loss: 4.368158e-05, l1: 0.99694, l2: 0.03217\n",
            "Loss: 3.848684e-05, l1: 0.99232, l2: 0.03193\n",
            "Loss: 3.823077e-05, l1: 0.99254, l2: 0.03194\n",
            "Loss: 3.805604e-05, l1: 0.99259, l2: 0.03195\n",
            "Loss: 3.793536e-05, l1: 0.99275, l2: 0.03197\n",
            "Loss: 3.784768e-05, l1: 0.99257, l2: 0.03195\n",
            "Loss: 3.771099e-05, l1: 0.99264, l2: 0.03195\n",
            "Loss: 3.759304e-05, l1: 0.99305, l2: 0.03194\n",
            "Loss: 3.750714e-05, l1: 0.99326, l2: 0.03193\n",
            "Loss: 3.739663e-05, l1: 0.99363, l2: 0.03192\n",
            "Loss: 3.729104e-05, l1: 0.99380, l2: 0.03191\n",
            "Loss: 3.754724e-05, l1: 0.99406, l2: 0.03189\n",
            "Loss: 3.721549e-05, l1: 0.99389, l2: 0.03190\n",
            "Loss: 3.707432e-05, l1: 0.99397, l2: 0.03190\n",
            "Loss: 3.698264e-05, l1: 0.99401, l2: 0.03190\n",
            "Loss: 3.686519e-05, l1: 0.99395, l2: 0.03192\n",
            "Loss: 3.673895e-05, l1: 0.99402, l2: 0.03193\n",
            "Loss: 3.654377e-05, l1: 0.99440, l2: 0.03194\n",
            "Loss: 3.639251e-05, l1: 0.99481, l2: 0.03195\n",
            "Loss: 3.627162e-05, l1: 0.99520, l2: 0.03195\n",
            "Loss: 3.616709e-05, l1: 0.99545, l2: 0.03195\n",
            "Loss: 3.597309e-05, l1: 0.99568, l2: 0.03194\n",
            "Loss: 3.566991e-05, l1: 0.99594, l2: 0.03193\n",
            "Loss: 4.189628e-05, l1: 0.99516, l2: 0.03176\n",
            "Loss: 3.559110e-05, l1: 0.99586, l2: 0.03192\n",
            "Loss: 3.499650e-05, l1: 0.99606, l2: 0.03191\n",
            "Loss: 3.454841e-05, l1: 0.99601, l2: 0.03189\n",
            "Loss: 3.405204e-05, l1: 0.99578, l2: 0.03189\n",
            "Loss: 3.372153e-05, l1: 0.99580, l2: 0.03189\n",
            "Loss: 3.339122e-05, l1: 0.99600, l2: 0.03190\n",
            "Loss: 3.321349e-05, l1: 0.99622, l2: 0.03187\n",
            "Loss: 3.292655e-05, l1: 0.99658, l2: 0.03190\n",
            "Loss: 3.277377e-05, l1: 0.99664, l2: 0.03191\n",
            "Loss: 3.262388e-05, l1: 0.99671, l2: 0.03192\n",
            "Loss: 3.252651e-05, l1: 0.99650, l2: 0.03192\n",
            "Loss: 3.245034e-05, l1: 0.99646, l2: 0.03192\n",
            "Loss: 3.239462e-05, l1: 0.99649, l2: 0.03192\n",
            "Loss: 3.233314e-05, l1: 0.99651, l2: 0.03192\n",
            "Loss: 3.223323e-05, l1: 0.99661, l2: 0.03192\n",
            "Loss: 3.290573e-05, l1: 0.99620, l2: 0.03185\n",
            "Loss: 3.220836e-05, l1: 0.99654, l2: 0.03191\n",
            "Loss: 3.212271e-05, l1: 0.99651, l2: 0.03191\n",
            "Loss: 3.219488e-05, l1: 0.99633, l2: 0.03190\n",
            "Loss: 3.206099e-05, l1: 0.99643, l2: 0.03191\n",
            "Loss: 3.200715e-05, l1: 0.99638, l2: 0.03192\n",
            "Loss: 3.192193e-05, l1: 0.99593, l2: 0.03190\n",
            "Loss: 3.188079e-05, l1: 0.99568, l2: 0.03188\n",
            "Loss: 3.182015e-05, l1: 0.99512, l2: 0.03186\n",
            "Loss: 3.177688e-05, l1: 0.99519, l2: 0.03186\n",
            "Loss: 3.171202e-05, l1: 0.99524, l2: 0.03186\n",
            "Loss: 3.159551e-05, l1: 0.99543, l2: 0.03187\n",
            "Loss: 3.141367e-05, l1: 0.99576, l2: 0.03188\n",
            "Loss: 3.114397e-05, l1: 0.99635, l2: 0.03189\n",
            "Loss: 3.169401e-05, l1: 0.99587, l2: 0.03186\n",
            "Loss: 3.104517e-05, l1: 0.99621, l2: 0.03188\n",
            "Loss: 3.085731e-05, l1: 0.99672, l2: 0.03187\n",
            "Loss: 3.085247e-05, l1: 0.99663, l2: 0.03188\n",
            "Loss: 3.076760e-05, l1: 0.99667, l2: 0.03187\n",
            "Loss: 3.069755e-05, l1: 0.99642, l2: 0.03186\n",
            "Loss: 3.057829e-05, l1: 0.99609, l2: 0.03185\n",
            "Loss: 3.039536e-05, l1: 0.99572, l2: 0.03185\n",
            "Loss: 3.018664e-05, l1: 0.99563, l2: 0.03186\n",
            "Loss: 2.999767e-05, l1: 0.99583, l2: 0.03188\n",
            "Loss: 2.987603e-05, l1: 0.99630, l2: 0.03191\n",
            "Loss: 2.979727e-05, l1: 0.99660, l2: 0.03192\n",
            "Loss: 2.972148e-05, l1: 0.99684, l2: 0.03193\n",
            "Loss: 2.961575e-05, l1: 0.99694, l2: 0.03193\n",
            "Loss: 2.956590e-05, l1: 0.99665, l2: 0.03193\n",
            "Loss: 2.946533e-05, l1: 0.99665, l2: 0.03192\n",
            "Loss: 2.940683e-05, l1: 0.99655, l2: 0.03191\n",
            "Loss: 2.929781e-05, l1: 0.99637, l2: 0.03190\n",
            "Loss: 2.918094e-05, l1: 0.99621, l2: 0.03188\n",
            "Loss: 2.956981e-05, l1: 0.99641, l2: 0.03188\n",
            "Loss: 2.913041e-05, l1: 0.99626, l2: 0.03188\n",
            "Loss: 2.905177e-05, l1: 0.99632, l2: 0.03188\n",
            "Loss: 2.897152e-05, l1: 0.99629, l2: 0.03188\n",
            "Loss: 2.889608e-05, l1: 0.99601, l2: 0.03187\n",
            "Loss: 2.879426e-05, l1: 0.99553, l2: 0.03187\n",
            "Loss: 2.865431e-05, l1: 0.99509, l2: 0.03188\n",
            "Loss: 2.885242e-05, l1: 0.99233, l2: 0.03187\n",
            "Loss: 2.857166e-05, l1: 0.99412, l2: 0.03188\n",
            "Loss: 2.848525e-05, l1: 0.99391, l2: 0.03188\n",
            "Loss: 2.840691e-05, l1: 0.99373, l2: 0.03189\n",
            "Loss: 2.831570e-05, l1: 0.99349, l2: 0.03189\n",
            "Loss: 2.817794e-05, l1: 0.99309, l2: 0.03188\n",
            "Loss: 2.802859e-05, l1: 0.99261, l2: 0.03186\n",
            "Loss: 2.793528e-05, l1: 0.99217, l2: 0.03184\n",
            "Loss: 2.781123e-05, l1: 0.99198, l2: 0.03182\n",
            "Loss: 2.775179e-05, l1: 0.99206, l2: 0.03182\n",
            "Loss: 2.764977e-05, l1: 0.99213, l2: 0.03182\n",
            "Loss: 2.758766e-05, l1: 0.99217, l2: 0.03183\n",
            "Loss: 2.754023e-05, l1: 0.99214, l2: 0.03183\n",
            "Loss: 2.750209e-05, l1: 0.99217, l2: 0.03183\n",
            "Loss: 2.745496e-05, l1: 0.99217, l2: 0.03183\n",
            "Loss: 2.739027e-05, l1: 0.99231, l2: 0.03183\n",
            "Loss: 2.727039e-05, l1: 0.99265, l2: 0.03184\n",
            "Loss: 2.733912e-05, l1: 0.99407, l2: 0.03188\n",
            "Loss: 2.720314e-05, l1: 0.99324, l2: 0.03185\n",
            "Loss: 2.709319e-05, l1: 0.99336, l2: 0.03185\n",
            "Loss: 2.702343e-05, l1: 0.99353, l2: 0.03186\n",
            "Loss: 2.697041e-05, l1: 0.99354, l2: 0.03186\n",
            "Loss: 2.690673e-05, l1: 0.99339, l2: 0.03185\n",
            "Loss: 2.682385e-05, l1: 0.99338, l2: 0.03185\n",
            "Loss: 2.674353e-05, l1: 0.99328, l2: 0.03184\n",
            "Loss: 2.669534e-05, l1: 0.99334, l2: 0.03184\n",
            "Loss: 2.665268e-05, l1: 0.99345, l2: 0.03184\n",
            "Loss: 2.659089e-05, l1: 0.99362, l2: 0.03184\n",
            "Loss: 2.647124e-05, l1: 0.99382, l2: 0.03185\n",
            "Loss: 2.630019e-05, l1: 0.99412, l2: 0.03185\n",
            "Loss: 2.616380e-05, l1: 0.99426, l2: 0.03186\n",
            "Loss: 2.605270e-05, l1: 0.99427, l2: 0.03186\n",
            "Loss: 2.595896e-05, l1: 0.99426, l2: 0.03186\n",
            "Loss: 2.583961e-05, l1: 0.99427, l2: 0.03187\n",
            "Loss: 2.792846e-05, l1: 0.99422, l2: 0.03196\n",
            "Loss: 2.576977e-05, l1: 0.99426, l2: 0.03189\n",
            "Loss: 2.562271e-05, l1: 0.99422, l2: 0.03189\n",
            "Loss: 2.549660e-05, l1: 0.99413, l2: 0.03189\n",
            "Loss: 2.537239e-05, l1: 0.99405, l2: 0.03189\n",
            "Loss: 2.522039e-05, l1: 0.99399, l2: 0.03190\n",
            "Loss: 2.508180e-05, l1: 0.99391, l2: 0.03189\n",
            "Loss: 2.490732e-05, l1: 0.99390, l2: 0.03189\n",
            "Loss: 2.470957e-05, l1: 0.99403, l2: 0.03188\n",
            "Loss: 2.443769e-05, l1: 0.99425, l2: 0.03188\n",
            "Loss: 2.427678e-05, l1: 0.99425, l2: 0.03189\n",
            "Loss: 2.412429e-05, l1: 0.99413, l2: 0.03189\n",
            "Loss: 2.401322e-05, l1: 0.99414, l2: 0.03190\n",
            "Loss: 2.386158e-05, l1: 0.99398, l2: 0.03192\n",
            "Loss: 2.378560e-05, l1: 0.99452, l2: 0.03194\n",
            "Loss: 2.354718e-05, l1: 0.99384, l2: 0.03194\n",
            "Loss: 2.339135e-05, l1: 0.99415, l2: 0.03194\n",
            "Loss: 2.325114e-05, l1: 0.99434, l2: 0.03196\n",
            "Loss: 2.316684e-05, l1: 0.99446, l2: 0.03198\n",
            "Loss: 2.303219e-05, l1: 0.99452, l2: 0.03201\n",
            "Loss: 2.296943e-05, l1: 0.99476, l2: 0.03202\n",
            "Loss: 2.294194e-05, l1: 0.99477, l2: 0.03202\n",
            "Loss: 2.291753e-05, l1: 0.99467, l2: 0.03203\n",
            "Loss: 2.287491e-05, l1: 0.99442, l2: 0.03203\n",
            "Loss: 2.284512e-05, l1: 0.99431, l2: 0.03203\n",
            "Loss: 2.280165e-05, l1: 0.99425, l2: 0.03203\n",
            "Loss: 2.276610e-05, l1: 0.99431, l2: 0.03203\n",
            "Loss: 2.273011e-05, l1: 0.99433, l2: 0.03203\n",
            "Loss: 2.268903e-05, l1: 0.99442, l2: 0.03203\n",
            "Loss: 2.263882e-05, l1: 0.99456, l2: 0.03202\n",
            "Loss: 2.258260e-05, l1: 0.99447, l2: 0.03202\n",
            "Loss: 2.253780e-05, l1: 0.99450, l2: 0.03203\n",
            "Loss: 2.250484e-05, l1: 0.99449, l2: 0.03203\n",
            "Loss: 2.249116e-05, l1: 0.99442, l2: 0.03204\n",
            "Loss: 2.246294e-05, l1: 0.99447, l2: 0.03204\n",
            "Loss: 2.242889e-05, l1: 0.99458, l2: 0.03204\n",
            "Loss: 2.240053e-05, l1: 0.99469, l2: 0.03205\n",
            "Loss: 2.235317e-05, l1: 0.99488, l2: 0.03205\n",
            "Loss: 2.224577e-05, l1: 0.99529, l2: 0.03206\n",
            "Loss: 2.214185e-05, l1: 0.99559, l2: 0.03206\n",
            "Loss: 2.205397e-05, l1: 0.99576, l2: 0.03207\n",
            "Loss: 2.200080e-05, l1: 0.99575, l2: 0.03207\n",
            "Loss: 2.191878e-05, l1: 0.99565, l2: 0.03207\n",
            "Loss: 2.181092e-05, l1: 0.99543, l2: 0.03206\n",
            "Loss: 2.180556e-05, l1: 0.99505, l2: 0.03206\n",
            "Loss: 2.175735e-05, l1: 0.99524, l2: 0.03206\n",
            "Loss: 2.169677e-05, l1: 0.99507, l2: 0.03204\n",
            "Loss: 2.166644e-05, l1: 0.99495, l2: 0.03203\n",
            "Loss: 2.162998e-05, l1: 0.99486, l2: 0.03202\n",
            "Loss: 2.155693e-05, l1: 0.99476, l2: 0.03201\n",
            "Loss: 2.143823e-05, l1: 0.99471, l2: 0.03198\n",
            "Loss: 2.126902e-05, l1: 0.99471, l2: 0.03195\n",
            "Loss: 2.111717e-05, l1: 0.99470, l2: 0.03193\n",
            "Loss: 2.144103e-05, l1: 0.99388, l2: 0.03188\n",
            "Loss: 2.108214e-05, l1: 0.99450, l2: 0.03192\n",
            "Loss: 2.104042e-05, l1: 0.99450, l2: 0.03193\n",
            "Loss: 2.101046e-05, l1: 0.99449, l2: 0.03194\n",
            "Loss: 2.097837e-05, l1: 0.99439, l2: 0.03194\n",
            "Loss: 2.093540e-05, l1: 0.99422, l2: 0.03194\n",
            "Loss: 2.087356e-05, l1: 0.99413, l2: 0.03194\n",
            "Loss: 2.085749e-05, l1: 0.99348, l2: 0.03192\n",
            "Loss: 2.077168e-05, l1: 0.99381, l2: 0.03191\n",
            "Loss: 2.072798e-05, l1: 0.99399, l2: 0.03191\n",
            "Loss: 2.067177e-05, l1: 0.99408, l2: 0.03189\n",
            "Loss: 2.562233e-05, l1: 0.99301, l2: 0.03180\n",
            "Loss: 2.066355e-05, l1: 0.99403, l2: 0.03189\n",
            "Loss: 2.063119e-05, l1: 0.99398, l2: 0.03189\n",
            "Loss: 2.057421e-05, l1: 0.99390, l2: 0.03188\n",
            "Loss: 2.048330e-05, l1: 0.99385, l2: 0.03188\n",
            "Loss: 2.036726e-05, l1: 0.99384, l2: 0.03187\n",
            "Loss: 2.020939e-05, l1: 0.99401, l2: 0.03186\n",
            "Loss: 2.010899e-05, l1: 0.99399, l2: 0.03182\n",
            "Loss: 2.005444e-05, l1: 0.99412, l2: 0.03182\n",
            "Loss: 2.000431e-05, l1: 0.99433, l2: 0.03183\n",
            "Loss: 1.996125e-05, l1: 0.99436, l2: 0.03182\n",
            "Loss: 1.992956e-05, l1: 0.99433, l2: 0.03181\n",
            "Loss: 1.991969e-05, l1: 0.99423, l2: 0.03181\n",
            "Loss: 1.989234e-05, l1: 0.99428, l2: 0.03181\n",
            "Loss: 1.986440e-05, l1: 0.99433, l2: 0.03181\n",
            "Loss: 1.980970e-05, l1: 0.99443, l2: 0.03182\n",
            "Loss: 1.972702e-05, l1: 0.99457, l2: 0.03182\n",
            "Loss: 1.977257e-05, l1: 0.99482, l2: 0.03179\n",
            "Loss: 1.968314e-05, l1: 0.99467, l2: 0.03181\n",
            "Loss: 1.958294e-05, l1: 0.99494, l2: 0.03181\n",
            "Loss: 1.950978e-05, l1: 0.99504, l2: 0.03180\n",
            "Loss: 1.942929e-05, l1: 0.99508, l2: 0.03179\n",
            "Loss: 1.934236e-05, l1: 0.99519, l2: 0.03178\n",
            "Loss: 1.929497e-05, l1: 0.99551, l2: 0.03177\n",
            "Loss: 1.918154e-05, l1: 0.99549, l2: 0.03177\n",
            "Loss: 1.907316e-05, l1: 0.99546, l2: 0.03176\n",
            "Loss: 1.899909e-05, l1: 0.99542, l2: 0.03175\n",
            "Loss: 1.892629e-05, l1: 0.99525, l2: 0.03174\n",
            "Loss: 1.892665e-05, l1: 0.99543, l2: 0.03170\n",
            "Loss: 1.887636e-05, l1: 0.99534, l2: 0.03172\n",
            "Loss: 1.881505e-05, l1: 0.99522, l2: 0.03172\n",
            "Loss: 1.875182e-05, l1: 0.99517, l2: 0.03172\n",
            "Loss: 1.870118e-05, l1: 0.99524, l2: 0.03172\n",
            "Loss: 1.856184e-05, l1: 0.99547, l2: 0.03170\n",
            "Loss: 1.868416e-05, l1: 0.99642, l2: 0.03171\n",
            "Loss: 1.848628e-05, l1: 0.99583, l2: 0.03171\n",
            "Loss: 1.836236e-05, l1: 0.99599, l2: 0.03170\n",
            "Loss: 1.818054e-05, l1: 0.99622, l2: 0.03167\n",
            "Loss: 1.807545e-05, l1: 0.99630, l2: 0.03166\n",
            "Loss: 1.796475e-05, l1: 0.99659, l2: 0.03165\n",
            "Loss: 1.776957e-05, l1: 0.99664, l2: 0.03159\n",
            "Loss: 1.760705e-05, l1: 0.99662, l2: 0.03162\n",
            "Loss: 1.749323e-05, l1: 0.99654, l2: 0.03163\n",
            "Loss: 1.739323e-05, l1: 0.99662, l2: 0.03163\n",
            "Loss: 1.714768e-05, l1: 0.99656, l2: 0.03162\n",
            "Loss: 1.695523e-05, l1: 0.99671, l2: 0.03160\n",
            "Loss: 1.736510e-05, l1: 0.99602, l2: 0.03153\n",
            "Loss: 1.691460e-05, l1: 0.99655, l2: 0.03159\n",
            "Loss: 1.682526e-05, l1: 0.99659, l2: 0.03157\n",
            "Loss: 1.675793e-05, l1: 0.99665, l2: 0.03157\n",
            "Loss: 1.669773e-05, l1: 0.99661, l2: 0.03156\n",
            "Loss: 1.662739e-05, l1: 0.99678, l2: 0.03156\n",
            "Loss: 1.652540e-05, l1: 0.99666, l2: 0.03156\n",
            "Loss: 1.648408e-05, l1: 0.99663, l2: 0.03156\n",
            "Loss: 1.644654e-05, l1: 0.99669, l2: 0.03156\n",
            "Loss: 1.641786e-05, l1: 0.99674, l2: 0.03156\n",
            "Loss: 1.638081e-05, l1: 0.99682, l2: 0.03155\n",
            "Loss: 1.634662e-05, l1: 0.99690, l2: 0.03155\n",
            "Loss: 1.632276e-05, l1: 0.99678, l2: 0.03155\n",
            "Loss: 1.628015e-05, l1: 0.99689, l2: 0.03156\n",
            "Loss: 1.625557e-05, l1: 0.99691, l2: 0.03156\n",
            "Loss: 1.621481e-05, l1: 0.99695, l2: 0.03156\n",
            "Loss: 1.615439e-05, l1: 0.99703, l2: 0.03157\n",
            "Loss: 1.988488e-05, l1: 0.99664, l2: 0.03169\n",
            "Loss: 1.614754e-05, l1: 0.99702, l2: 0.03157\n",
            "Loss: 1.608283e-05, l1: 0.99712, l2: 0.03158\n",
            "Loss: 1.602596e-05, l1: 0.99722, l2: 0.03159\n",
            "Loss: 1.598115e-05, l1: 0.99727, l2: 0.03160\n",
            "Loss: 1.594081e-05, l1: 0.99731, l2: 0.03161\n",
            "Loss: 1.587531e-05, l1: 0.99739, l2: 0.03163\n",
            "Loss: 1.578518e-05, l1: 0.99736, l2: 0.03166\n",
            "Loss: 1.566918e-05, l1: 0.99740, l2: 0.03168\n",
            "Loss: 1.558109e-05, l1: 0.99734, l2: 0.03169\n",
            "Loss: 1.548258e-05, l1: 0.99727, l2: 0.03170\n",
            "Loss: 1.540503e-05, l1: 0.99725, l2: 0.03170\n",
            "Loss: 1.533131e-05, l1: 0.99728, l2: 0.03170\n",
            "Loss: 1.526924e-05, l1: 0.99736, l2: 0.03172\n",
            "Loss: 1.522803e-05, l1: 0.99740, l2: 0.03172\n",
            "Loss: 1.514919e-05, l1: 0.99746, l2: 0.03172\n",
            "Loss: 1.508345e-05, l1: 0.99767, l2: 0.03173\n",
            "Loss: 1.533656e-05, l1: 0.99720, l2: 0.03173\n",
            "Loss: 1.504707e-05, l1: 0.99754, l2: 0.03173\n",
            "Loss: 1.496192e-05, l1: 0.99763, l2: 0.03174\n",
            "Loss: 1.488917e-05, l1: 0.99766, l2: 0.03176\n",
            "Loss: 1.484152e-05, l1: 0.99762, l2: 0.03176\n",
            "Loss: 1.479797e-05, l1: 0.99755, l2: 0.03176\n",
            "Loss: 1.473142e-05, l1: 0.99748, l2: 0.03177\n",
            "Loss: 1.468501e-05, l1: 0.99751, l2: 0.03177\n",
            "Loss: 1.460792e-05, l1: 0.99761, l2: 0.03179\n",
            "Loss: 1.512066e-05, l1: 0.99838, l2: 0.03180\n",
            "Loss: 1.458231e-05, l1: 0.99775, l2: 0.03179\n",
            "Loss: 1.452409e-05, l1: 0.99785, l2: 0.03180\n",
            "Loss: 1.445283e-05, l1: 0.99793, l2: 0.03181\n",
            "Loss: 1.437475e-05, l1: 0.99803, l2: 0.03181\n",
            "Loss: 1.431163e-05, l1: 0.99802, l2: 0.03181\n",
            "Loss: 1.426894e-05, l1: 0.99817, l2: 0.03180\n",
            "Loss: 1.415092e-05, l1: 0.99805, l2: 0.03180\n",
            "Loss: 1.409706e-05, l1: 0.99804, l2: 0.03181\n",
            "Loss: 1.400775e-05, l1: 0.99803, l2: 0.03182\n",
            "Loss: 1.392457e-05, l1: 0.99807, l2: 0.03183\n",
            "Loss: 1.386718e-05, l1: 0.99822, l2: 0.03184\n",
            "Loss: 1.381899e-05, l1: 0.99818, l2: 0.03185\n",
            "Loss: 1.376099e-05, l1: 0.99818, l2: 0.03185\n",
            "Loss: 1.371500e-05, l1: 0.99825, l2: 0.03186\n",
            "Loss: 1.367641e-05, l1: 0.99823, l2: 0.03186\n",
            "Loss: 1.383190e-05, l1: 0.99855, l2: 0.03191\n",
            "Loss: 1.365487e-05, l1: 0.99831, l2: 0.03187\n",
            "Loss: 1.361288e-05, l1: 0.99818, l2: 0.03188\n",
            "Loss: 1.358680e-05, l1: 0.99812, l2: 0.03188\n",
            "Loss: 1.356047e-05, l1: 0.99806, l2: 0.03189\n",
            "Loss: 1.346268e-05, l1: 0.99799, l2: 0.03190\n",
            "Loss: 1.338448e-05, l1: 0.99798, l2: 0.03192\n",
            "Loss: 1.332674e-05, l1: 0.99811, l2: 0.03193\n",
            "Loss: 1.328190e-05, l1: 0.99825, l2: 0.03193\n",
            "Loss: 1.323919e-05, l1: 0.99835, l2: 0.03193\n",
            "Loss: 1.319671e-05, l1: 0.99842, l2: 0.03193\n",
            "Loss: 1.315019e-05, l1: 0.99838, l2: 0.03193\n",
            "Loss: 1.311577e-05, l1: 0.99846, l2: 0.03193\n",
            "Loss: 1.307258e-05, l1: 0.99846, l2: 0.03191\n",
            "Loss: 1.304842e-05, l1: 0.99833, l2: 0.03193\n",
            "Loss: 1.298141e-05, l1: 0.99846, l2: 0.03192\n",
            "Loss: 1.295358e-05, l1: 0.99850, l2: 0.03191\n",
            "Loss: 1.292788e-05, l1: 0.99853, l2: 0.03191\n",
            "Loss: 1.291516e-05, l1: 0.99846, l2: 0.03191\n",
            "Loss: 1.290627e-05, l1: 0.99838, l2: 0.03191\n",
            "Loss: 1.290069e-05, l1: 0.99831, l2: 0.03191\n",
            "Loss: 1.288707e-05, l1: 0.99824, l2: 0.03192\n",
            "Loss: 1.286117e-05, l1: 0.99806, l2: 0.03192\n",
            "Loss: 1.284177e-05, l1: 0.99797, l2: 0.03193\n",
            "Loss: 1.282942e-05, l1: 0.99779, l2: 0.03193\n",
            "Loss: 1.283342e-05, l1: 0.99781, l2: 0.03193\n",
            "Loss: 1.282071e-05, l1: 0.99780, l2: 0.03193\n",
            "Loss: 1.280694e-05, l1: 0.99784, l2: 0.03193\n",
            "Loss: 1.278949e-05, l1: 0.99785, l2: 0.03192\n",
            "Loss: 1.277384e-05, l1: 0.99781, l2: 0.03191\n",
            "Loss: 1.274576e-05, l1: 0.99770, l2: 0.03190\n",
            "Loss: 1.280440e-05, l1: 0.99715, l2: 0.03188\n",
            "Loss: 1.273489e-05, l1: 0.99755, l2: 0.03190\n",
            "Loss: 1.270219e-05, l1: 0.99740, l2: 0.03189\n",
            "Loss: 1.267697e-05, l1: 0.99729, l2: 0.03189\n",
            "Loss: 1.265457e-05, l1: 0.99721, l2: 0.03190\n",
            "Loss: 1.264859e-05, l1: 0.99705, l2: 0.03190\n",
            "Loss: 1.261188e-05, l1: 0.99704, l2: 0.03190\n",
            "Loss: 1.256815e-05, l1: 0.99694, l2: 0.03191\n",
            "Loss: 1.252527e-05, l1: 0.99674, l2: 0.03192\n",
            "Loss: 1.250159e-05, l1: 0.99656, l2: 0.03192\n",
            "Loss: 1.247046e-05, l1: 0.99647, l2: 0.03192\n",
            "Loss: 1.244053e-05, l1: 0.99642, l2: 0.03192\n",
            "Loss: 1.241872e-05, l1: 0.99638, l2: 0.03192\n",
            "Loss: 1.239881e-05, l1: 0.99632, l2: 0.03192\n",
            "Loss: 1.237846e-05, l1: 0.99625, l2: 0.03191\n",
            "Loss: 1.235515e-05, l1: 0.99613, l2: 0.03191\n",
            "Loss: 1.234070e-05, l1: 0.99609, l2: 0.03190\n",
            "Loss: 1.232586e-05, l1: 0.99610, l2: 0.03190\n",
            "Loss: 1.230542e-05, l1: 0.99617, l2: 0.03190\n",
            "Loss: 1.228635e-05, l1: 0.99623, l2: 0.03190\n",
            "Loss: 1.228254e-05, l1: 0.99609, l2: 0.03189\n",
            "Loss: 1.222738e-05, l1: 0.99627, l2: 0.03188\n",
            "Loss: 1.219249e-05, l1: 0.99627, l2: 0.03188\n",
            "Loss: 1.214132e-05, l1: 0.99614, l2: 0.03187\n",
            "Loss: 1.211527e-05, l1: 0.99602, l2: 0.03187\n",
            "Loss: 1.206437e-05, l1: 0.99606, l2: 0.03187\n",
            "Loss: 1.203614e-05, l1: 0.99606, l2: 0.03188\n",
            "Loss: 1.200994e-05, l1: 0.99609, l2: 0.03190\n",
            "Loss: 1.198872e-05, l1: 0.99611, l2: 0.03191\n",
            "Loss: 1.203166e-05, l1: 0.99624, l2: 0.03192\n",
            "Loss: 1.197675e-05, l1: 0.99615, l2: 0.03191\n",
            "Loss: 1.193503e-05, l1: 0.99630, l2: 0.03193\n",
            "Loss: 1.193851e-05, l1: 0.99642, l2: 0.03194\n",
            "Loss: 1.191938e-05, l1: 0.99636, l2: 0.03193\n",
            "Loss: 1.189851e-05, l1: 0.99644, l2: 0.03193\n",
            "Loss: 1.186541e-05, l1: 0.99658, l2: 0.03193\n",
            "Loss: 1.182907e-05, l1: 0.99673, l2: 0.03193\n",
            "Loss: 1.176979e-05, l1: 0.99683, l2: 0.03193\n",
            "Loss: 1.172157e-05, l1: 0.99688, l2: 0.03193\n",
            "Loss: 1.165898e-05, l1: 0.99689, l2: 0.03192\n",
            "Loss: 1.163238e-05, l1: 0.99673, l2: 0.03191\n",
            "Loss: 1.159414e-05, l1: 0.99683, l2: 0.03190\n",
            "Loss: 1.157674e-05, l1: 0.99690, l2: 0.03190\n",
            "Loss: 1.156001e-05, l1: 0.99698, l2: 0.03190\n",
            "Loss: 1.208974e-05, l1: 0.99726, l2: 0.03192\n",
            "Loss: 1.155134e-05, l1: 0.99701, l2: 0.03190\n",
            "Loss: 1.153359e-05, l1: 0.99706, l2: 0.03190\n",
            "Loss: 1.151085e-05, l1: 0.99710, l2: 0.03190\n",
            "Loss: 1.149464e-05, l1: 0.99708, l2: 0.03190\n",
            "Loss: 1.147308e-05, l1: 0.99705, l2: 0.03191\n",
            "Loss: 1.144762e-05, l1: 0.99702, l2: 0.03191\n",
            "Loss: 1.142305e-05, l1: 0.99701, l2: 0.03190\n",
            "Loss: 1.140939e-05, l1: 0.99702, l2: 0.03190\n",
            "Loss: 1.141163e-05, l1: 0.99696, l2: 0.03189\n",
            "Loss: 1.139620e-05, l1: 0.99699, l2: 0.03189\n",
            "Loss: 1.138580e-05, l1: 0.99698, l2: 0.03189\n",
            "Loss: 1.136843e-05, l1: 0.99695, l2: 0.03189\n",
            "Loss: 1.135676e-05, l1: 0.99694, l2: 0.03189\n",
            "Loss: 1.131941e-05, l1: 0.99689, l2: 0.03189\n",
            "Loss: 1.127888e-05, l1: 0.99686, l2: 0.03188\n",
            "Loss: 1.127413e-05, l1: 0.99689, l2: 0.03186\n",
            "Loss: 1.125596e-05, l1: 0.99688, l2: 0.03187\n",
            "Loss: 1.121379e-05, l1: 0.99683, l2: 0.03186\n",
            "Loss: 1.118666e-05, l1: 0.99681, l2: 0.03187\n",
            "Loss: 1.116784e-05, l1: 0.99682, l2: 0.03186\n",
            "Loss: 1.113467e-05, l1: 0.99675, l2: 0.03185\n",
            "Loss: 1.108918e-05, l1: 0.99666, l2: 0.03184\n",
            "Loss: 1.105362e-05, l1: 0.99652, l2: 0.03183\n",
            "Loss: 1.102260e-05, l1: 0.99637, l2: 0.03181\n",
            "Loss: 1.100412e-05, l1: 0.99611, l2: 0.03180\n",
            "Loss: 1.096377e-05, l1: 0.99612, l2: 0.03180\n",
            "Loss: 1.090840e-05, l1: 0.99613, l2: 0.03180\n",
            "Loss: 1.085140e-05, l1: 0.99611, l2: 0.03180\n",
            "Loss: 1.083666e-05, l1: 0.99644, l2: 0.03179\n",
            "Loss: 1.076807e-05, l1: 0.99628, l2: 0.03180\n",
            "Loss: 1.074704e-05, l1: 0.99622, l2: 0.03179\n",
            "Loss: 1.072836e-05, l1: 0.99621, l2: 0.03179\n",
            "Loss: 1.070362e-05, l1: 0.99623, l2: 0.03178\n",
            "Loss: 1.068287e-05, l1: 0.99628, l2: 0.03177\n",
            "Loss: 1.066426e-05, l1: 0.99640, l2: 0.03176\n",
            "Loss: 1.068517e-05, l1: 0.99637, l2: 0.03176\n",
            "Loss: 1.065464e-05, l1: 0.99638, l2: 0.03176\n",
            "Loss: 1.064168e-05, l1: 0.99683, l2: 0.03174\n",
            "Loss: 1.058664e-05, l1: 0.99664, l2: 0.03174\n",
            "Loss: 1.054976e-05, l1: 0.99657, l2: 0.03175\n",
            "Loss: 1.051069e-05, l1: 0.99655, l2: 0.03176\n",
            "Loss: 1.047551e-05, l1: 0.99661, l2: 0.03176\n",
            "Loss: 1.039905e-05, l1: 0.99677, l2: 0.03176\n",
            "Loss: 1.057618e-05, l1: 0.99699, l2: 0.03173\n",
            "Loss: 1.036938e-05, l1: 0.99683, l2: 0.03175\n",
            "Loss: 1.029534e-05, l1: 0.99690, l2: 0.03174\n",
            "Loss: 1.026815e-05, l1: 0.99690, l2: 0.03175\n",
            "Loss: 1.023260e-05, l1: 0.99678, l2: 0.03174\n",
            "Loss: 1.020696e-05, l1: 0.99668, l2: 0.03174\n",
            "Loss: 1.015294e-05, l1: 0.99660, l2: 0.03173\n",
            "Loss: 1.010616e-05, l1: 0.99649, l2: 0.03172\n",
            "Loss: 1.007630e-05, l1: 0.99642, l2: 0.03172\n",
            "Loss: 1.010490e-05, l1: 0.99660, l2: 0.03172\n",
            "Loss: 1.006631e-05, l1: 0.99648, l2: 0.03172\n",
            "Loss: 1.004661e-05, l1: 0.99640, l2: 0.03173\n",
            "Loss: 1.001917e-05, l1: 0.99630, l2: 0.03174\n",
            "Loss: 9.989588e-06, l1: 0.99620, l2: 0.03175\n",
            "Loss: 9.964977e-06, l1: 0.99613, l2: 0.03176\n",
            "Loss: 9.937539e-06, l1: 0.99617, l2: 0.03176\n",
            "Loss: 9.905683e-06, l1: 0.99633, l2: 0.03175\n",
            "Loss: 9.868931e-06, l1: 0.99653, l2: 0.03175\n",
            "Loss: 9.847143e-06, l1: 0.99661, l2: 0.03176\n",
            "Loss: 9.813877e-06, l1: 0.99663, l2: 0.03177\n",
            "Loss: 9.746666e-06, l1: 0.99654, l2: 0.03178\n",
            "Loss: 9.673221e-06, l1: 0.99639, l2: 0.03179\n",
            "Loss: 1.000813e-05, l1: 0.99619, l2: 0.03186\n",
            "Loss: 9.634075e-06, l1: 0.99634, l2: 0.03181\n",
            "Loss: 9.587411e-06, l1: 0.99628, l2: 0.03180\n",
            "Loss: 9.550237e-06, l1: 0.99621, l2: 0.03179\n",
            "Loss: 9.519743e-06, l1: 0.99615, l2: 0.03179\n",
            "Loss: 9.530656e-06, l1: 0.99616, l2: 0.03176\n",
            "Loss: 9.496245e-06, l1: 0.99615, l2: 0.03178\n",
            "Loss: 9.463891e-06, l1: 0.99607, l2: 0.03178\n",
            "Loss: 9.454806e-06, l1: 0.99594, l2: 0.03179\n",
            "Loss: 9.437455e-06, l1: 0.99594, l2: 0.03180\n",
            "Loss: 9.430428e-06, l1: 0.99597, l2: 0.03180\n",
            "Loss: 9.419839e-06, l1: 0.99597, l2: 0.03179\n",
            "Loss: 9.398681e-06, l1: 0.99592, l2: 0.03179\n",
            "Loss: 9.368887e-06, l1: 0.99589, l2: 0.03179\n",
            "Loss: 9.337276e-06, l1: 0.99575, l2: 0.03179\n",
            "Loss: 9.334131e-06, l1: 0.99568, l2: 0.03177\n",
            "Loss: 9.301244e-06, l1: 0.99572, l2: 0.03178\n",
            "Loss: 9.241905e-06, l1: 0.99614, l2: 0.03180\n",
            "Loss: 9.187072e-06, l1: 0.99635, l2: 0.03181\n",
            "Loss: 9.167870e-06, l1: 0.99640, l2: 0.03182\n",
            "Loss: 9.145430e-06, l1: 0.99644, l2: 0.03182\n",
            "Loss: 9.108018e-06, l1: 0.99657, l2: 0.03184\n",
            "Loss: 9.049988e-06, l1: 0.99682, l2: 0.03185\n",
            "Loss: 9.056166e-06, l1: 0.99740, l2: 0.03188\n",
            "Loss: 9.011687e-06, l1: 0.99710, l2: 0.03187\n",
            "Loss: 8.991422e-06, l1: 0.99777, l2: 0.03189\n",
            "Loss: 8.953069e-06, l1: 0.99756, l2: 0.03189\n",
            "Loss: 8.866296e-06, l1: 0.99738, l2: 0.03187\n",
            "Loss: 8.851152e-06, l1: 0.99739, l2: 0.03186\n",
            "Loss: 8.832673e-06, l1: 0.99750, l2: 0.03185\n",
            "Loss: 8.817461e-06, l1: 0.99754, l2: 0.03185\n",
            "Loss: 8.794400e-06, l1: 0.99760, l2: 0.03184\n",
            "Loss: 8.777129e-06, l1: 0.99776, l2: 0.03184\n",
            "Loss: 8.739356e-06, l1: 0.99783, l2: 0.03184\n",
            "Loss: 8.704251e-06, l1: 0.99795, l2: 0.03185\n",
            "Loss: 8.669940e-06, l1: 0.99815, l2: 0.03186\n",
            "Loss: 8.633391e-06, l1: 0.99841, l2: 0.03186\n",
            "Loss: 8.612143e-06, l1: 0.99862, l2: 0.03187\n",
            "Loss: 8.587542e-06, l1: 0.99863, l2: 0.03186\n",
            "Loss: 8.568448e-06, l1: 0.99858, l2: 0.03185\n",
            "Loss: 8.546458e-06, l1: 0.99856, l2: 0.03184\n",
            "Loss: 8.532154e-06, l1: 0.99855, l2: 0.03184\n",
            "Loss: 8.520011e-06, l1: 0.99858, l2: 0.03184\n",
            "Loss: 8.509923e-06, l1: 0.99860, l2: 0.03185\n",
            "Loss: 8.496579e-06, l1: 0.99862, l2: 0.03185\n",
            "Loss: 8.494299e-06, l1: 0.99862, l2: 0.03187\n",
            "Loss: 8.483521e-06, l1: 0.99862, l2: 0.03186\n",
            "Loss: 8.459145e-06, l1: 0.99866, l2: 0.03187\n",
            "Loss: 8.438456e-06, l1: 0.99869, l2: 0.03187\n",
            "Loss: 8.418949e-06, l1: 0.99871, l2: 0.03186\n",
            "Loss: 8.407342e-06, l1: 0.99868, l2: 0.03186\n",
            "Loss: 8.397959e-06, l1: 0.99873, l2: 0.03186\n",
            "Loss: 8.392664e-06, l1: 0.99877, l2: 0.03186\n",
            "Loss: 8.385946e-06, l1: 0.99881, l2: 0.03186\n",
            "Loss: 8.377322e-06, l1: 0.99883, l2: 0.03185\n",
            "Loss: 8.362697e-06, l1: 0.99882, l2: 0.03185\n",
            "Loss: 8.342989e-06, l1: 0.99881, l2: 0.03185\n",
            "Loss: 8.324440e-06, l1: 0.99876, l2: 0.03185\n",
            "Loss: 8.308751e-06, l1: 0.99883, l2: 0.03185\n",
            "Loss: 8.281322e-06, l1: 0.99872, l2: 0.03186\n",
            "Loss: 8.262132e-06, l1: 0.99861, l2: 0.03186\n",
            "Loss: 8.243799e-06, l1: 0.99850, l2: 0.03186\n",
            "Loss: 8.229390e-06, l1: 0.99848, l2: 0.03186\n",
            "Loss: 8.277251e-06, l1: 0.99850, l2: 0.03187\n",
            "Loss: 8.225163e-06, l1: 0.99849, l2: 0.03186\n",
            "Loss: 8.212386e-06, l1: 0.99832, l2: 0.03185\n",
            "Loss: 8.207228e-06, l1: 0.99830, l2: 0.03185\n",
            "Loss: 8.199991e-06, l1: 0.99827, l2: 0.03185\n",
            "Loss: 8.196590e-06, l1: 0.99827, l2: 0.03186\n",
            "Loss: 8.190715e-06, l1: 0.99832, l2: 0.03186\n",
            "Loss: 8.184358e-06, l1: 0.99836, l2: 0.03187\n",
            "Loss: 8.178387e-06, l1: 0.99839, l2: 0.03186\n",
            "Loss: 8.163564e-06, l1: 0.99845, l2: 0.03185\n",
            "Loss: 8.156757e-06, l1: 0.99845, l2: 0.03185\n",
            "Loss: 8.173881e-06, l1: 0.99837, l2: 0.03184\n",
            "Loss: 8.149636e-06, l1: 0.99842, l2: 0.03185\n",
            "Loss: 8.136345e-06, l1: 0.99840, l2: 0.03186\n",
            "Loss: 8.127400e-06, l1: 0.99836, l2: 0.03186\n",
            "Loss: 8.119614e-06, l1: 0.99835, l2: 0.03187\n",
            "Loss: 8.109807e-06, l1: 0.99834, l2: 0.03188\n",
            "Loss: 8.097853e-06, l1: 0.99831, l2: 0.03189\n",
            "Loss: 8.134653e-06, l1: 0.99836, l2: 0.03188\n",
            "Loss: 8.092511e-06, l1: 0.99832, l2: 0.03189\n",
            "Loss: 8.076222e-06, l1: 0.99821, l2: 0.03189\n",
            "Loss: 8.064349e-06, l1: 0.99815, l2: 0.03189\n",
            "Loss: 8.051705e-06, l1: 0.99804, l2: 0.03189\n",
            "Loss: 8.039733e-06, l1: 0.99810, l2: 0.03189\n",
            "Loss: 8.025392e-06, l1: 0.99821, l2: 0.03190\n",
            "Loss: 8.013885e-06, l1: 0.99829, l2: 0.03190\n",
            "Loss: 8.006678e-06, l1: 0.99833, l2: 0.03192\n",
            "Loss: 7.993330e-06, l1: 0.99840, l2: 0.03192\n",
            "Loss: 7.987479e-06, l1: 0.99841, l2: 0.03192\n",
            "Loss: 7.980989e-06, l1: 0.99844, l2: 0.03192\n",
            "Loss: 7.972874e-06, l1: 0.99848, l2: 0.03192\n",
            "Loss: 7.963198e-06, l1: 0.99860, l2: 0.03192\n",
            "Loss: 7.951754e-06, l1: 0.99881, l2: 0.03192\n",
            "Loss: 7.939300e-06, l1: 0.99885, l2: 0.03192\n",
            "Loss: 7.918446e-06, l1: 0.99889, l2: 0.03192\n",
            "Loss: 7.904164e-06, l1: 0.99890, l2: 0.03192\n",
            "Loss: 7.889007e-06, l1: 0.99882, l2: 0.03191\n",
            "Loss: 7.871529e-06, l1: 0.99872, l2: 0.03192\n",
            "Loss: 7.851398e-06, l1: 0.99858, l2: 0.03191\n",
            "Loss: 7.841777e-06, l1: 0.99855, l2: 0.03190\n",
            "Loss: 7.829426e-06, l1: 0.99856, l2: 0.03190\n",
            "Loss: 7.823615e-06, l1: 0.99857, l2: 0.03190\n",
            "Loss: 7.816548e-06, l1: 0.99859, l2: 0.03190\n",
            "Loss: 7.807374e-06, l1: 0.99862, l2: 0.03190\n",
            "Loss: 7.792898e-06, l1: 0.99870, l2: 0.03190\n",
            "Loss: 7.783502e-06, l1: 0.99875, l2: 0.03190\n",
            "Loss: 7.764256e-06, l1: 0.99876, l2: 0.03190\n",
            "Loss: 7.742739e-06, l1: 0.99876, l2: 0.03190\n",
            "Loss: 7.730755e-06, l1: 0.99876, l2: 0.03190\n",
            "Loss: 7.707359e-06, l1: 0.99872, l2: 0.03189\n",
            "Loss: 7.689546e-06, l1: 0.99882, l2: 0.03188\n",
            "Loss: 7.704779e-06, l1: 0.99893, l2: 0.03187\n",
            "Loss: 7.676016e-06, l1: 0.99887, l2: 0.03188\n",
            "Loss: 7.663059e-06, l1: 0.99884, l2: 0.03188\n",
            "Loss: 7.642415e-06, l1: 0.99886, l2: 0.03187\n",
            "Loss: 7.628282e-06, l1: 0.99887, l2: 0.03187\n",
            "Loss: 7.606280e-06, l1: 0.99895, l2: 0.03187\n",
            "Loss: 7.594569e-06, l1: 0.99899, l2: 0.03187\n",
            "Loss: 7.584527e-06, l1: 0.99901, l2: 0.03187\n",
            "Loss: 7.574035e-06, l1: 0.99900, l2: 0.03186\n",
            "Loss: 7.563436e-06, l1: 0.99896, l2: 0.03186\n",
            "Loss: 7.544870e-06, l1: 0.99884, l2: 0.03186\n",
            "Loss: 7.535292e-06, l1: 0.99878, l2: 0.03186\n",
            "Loss: 7.526029e-06, l1: 0.99872, l2: 0.03186\n",
            "Loss: 7.519391e-06, l1: 0.99872, l2: 0.03186\n",
            "Loss: 7.508262e-06, l1: 0.99868, l2: 0.03186\n",
            "Loss: 7.500916e-06, l1: 0.99868, l2: 0.03185\n",
            "Loss: 7.493178e-06, l1: 0.99865, l2: 0.03185\n",
            "Loss: 7.486136e-06, l1: 0.99863, l2: 0.03185\n",
            "Loss: 7.468218e-06, l1: 0.99861, l2: 0.03185\n",
            "Loss: 7.508773e-06, l1: 0.99831, l2: 0.03186\n",
            "Loss: 7.461465e-06, l1: 0.99853, l2: 0.03185\n",
            "Loss: 7.440329e-06, l1: 0.99853, l2: 0.03185\n",
            "Loss: 7.418859e-06, l1: 0.99858, l2: 0.03185\n",
            "Loss: 7.396749e-06, l1: 0.99860, l2: 0.03186\n",
            "Loss: 7.364482e-06, l1: 0.99860, l2: 0.03186\n",
            "Loss: 7.328811e-06, l1: 0.99852, l2: 0.03186\n",
            "Loss: 7.309946e-06, l1: 0.99864, l2: 0.03185\n",
            "Loss: 7.240797e-06, l1: 0.99851, l2: 0.03185\n",
            "Loss: 7.221025e-06, l1: 0.99843, l2: 0.03185\n",
            "Loss: 7.205569e-06, l1: 0.99849, l2: 0.03185\n",
            "Loss: 7.197255e-06, l1: 0.99853, l2: 0.03185\n",
            "Loss: 7.179190e-06, l1: 0.99860, l2: 0.03185\n",
            "Loss: 7.161991e-06, l1: 0.99865, l2: 0.03185\n",
            "Loss: 7.143967e-06, l1: 0.99864, l2: 0.03185\n",
            "Loss: 7.128041e-06, l1: 0.99864, l2: 0.03185\n",
            "Loss: 7.112281e-06, l1: 0.99852, l2: 0.03185\n",
            "Loss: 7.105618e-06, l1: 0.99846, l2: 0.03185\n",
            "Loss: 7.098675e-06, l1: 0.99839, l2: 0.03185\n",
            "Loss: 7.090090e-06, l1: 0.99830, l2: 0.03185\n",
            "Loss: 7.079765e-06, l1: 0.99819, l2: 0.03185\n",
            "Loss: 7.098572e-06, l1: 0.99801, l2: 0.03186\n",
            "Loss: 7.073009e-06, l1: 0.99813, l2: 0.03185\n",
            "Loss: 7.062004e-06, l1: 0.99809, l2: 0.03186\n",
            "Loss: 7.055471e-06, l1: 0.99810, l2: 0.03186\n",
            "Loss: 7.051921e-06, l1: 0.99811, l2: 0.03186\n",
            "Loss: 7.048236e-06, l1: 0.99811, l2: 0.03186\n",
            "Loss: 7.036433e-06, l1: 0.99808, l2: 0.03186\n",
            "Loss: 7.033754e-06, l1: 0.99806, l2: 0.03186\n",
            "Loss: 7.031399e-06, l1: 0.99805, l2: 0.03186\n",
            "Loss: 7.029698e-06, l1: 0.99806, l2: 0.03186\n",
            "Loss: 7.027690e-06, l1: 0.99807, l2: 0.03186\n",
            "Loss: 7.025973e-06, l1: 0.99809, l2: 0.03186\n",
            "Loss: 7.023743e-06, l1: 0.99808, l2: 0.03186\n",
            "Loss: 7.019536e-06, l1: 0.99804, l2: 0.03185\n",
            "Loss: 7.014673e-06, l1: 0.99798, l2: 0.03185\n",
            "Loss: 7.029363e-06, l1: 0.99777, l2: 0.03186\n",
            "Loss: 7.009937e-06, l1: 0.99791, l2: 0.03185\n",
            "Loss: 7.001688e-06, l1: 0.99787, l2: 0.03185\n",
            "Loss: 6.994167e-06, l1: 0.99784, l2: 0.03185\n",
            "Loss: 6.990911e-06, l1: 0.99785, l2: 0.03186\n",
            "Loss: 6.986558e-06, l1: 0.99787, l2: 0.03186\n",
            "Loss: 6.976182e-06, l1: 0.99789, l2: 0.03187\n",
            "Loss: 6.961982e-06, l1: 0.99798, l2: 0.03187\n",
            "Loss: 6.944493e-06, l1: 0.99795, l2: 0.03187\n",
            "Loss: 6.926118e-06, l1: 0.99795, l2: 0.03186\n",
            "Loss: 6.912696e-06, l1: 0.99799, l2: 0.03186\n",
            "Loss: 6.891912e-06, l1: 0.99800, l2: 0.03185\n",
            "Loss: 6.880010e-06, l1: 0.99819, l2: 0.03183\n",
            "Loss: 6.844129e-06, l1: 0.99812, l2: 0.03184\n",
            "Loss: 6.826013e-06, l1: 0.99803, l2: 0.03185\n",
            "Loss: 6.818525e-06, l1: 0.99801, l2: 0.03186\n",
            "Loss: 6.805661e-06, l1: 0.99798, l2: 0.03185\n",
            "Loss: 6.798386e-06, l1: 0.99796, l2: 0.03185\n",
            "Loss: 6.785116e-06, l1: 0.99792, l2: 0.03184\n",
            "Loss: 6.758217e-06, l1: 0.99792, l2: 0.03183\n",
            "Loss: 6.735016e-06, l1: 0.99783, l2: 0.03182\n",
            "Loss: 6.714784e-06, l1: 0.99786, l2: 0.03182\n",
            "Loss: 6.705745e-06, l1: 0.99790, l2: 0.03182\n",
            "Loss: 6.698469e-06, l1: 0.99793, l2: 0.03182\n",
            "Loss: 6.685257e-06, l1: 0.99799, l2: 0.03182\n",
            "Loss: 6.673513e-06, l1: 0.99801, l2: 0.03182\n",
            "Loss: 6.659824e-06, l1: 0.99801, l2: 0.03181\n",
            "Loss: 6.706090e-06, l1: 0.99771, l2: 0.03181\n",
            "Loss: 6.656743e-06, l1: 0.99795, l2: 0.03181\n",
            "Loss: 6.649130e-06, l1: 0.99792, l2: 0.03181\n",
            "Loss: 6.644281e-06, l1: 0.99788, l2: 0.03181\n",
            "Loss: 6.641496e-06, l1: 0.99786, l2: 0.03181\n",
            "Loss: 6.637034e-06, l1: 0.99784, l2: 0.03182\n",
            "Loss: 6.629839e-06, l1: 0.99786, l2: 0.03183\n",
            "Loss: 6.669522e-06, l1: 0.99805, l2: 0.03185\n",
            "Loss: 6.626185e-06, l1: 0.99790, l2: 0.03183\n",
            "Loss: 6.619684e-06, l1: 0.99793, l2: 0.03183\n",
            "Loss: 6.611609e-06, l1: 0.99798, l2: 0.03184\n",
            "Loss: 6.606107e-06, l1: 0.99800, l2: 0.03184\n",
            "Loss: 6.598636e-06, l1: 0.99800, l2: 0.03184\n",
            "Loss: 6.588913e-06, l1: 0.99798, l2: 0.03184\n",
            "Loss: 6.576895e-06, l1: 0.99796, l2: 0.03185\n",
            "Loss: 6.568999e-06, l1: 0.99796, l2: 0.03186\n",
            "Loss: 6.556971e-06, l1: 0.99801, l2: 0.03186\n",
            "Loss: 6.573803e-06, l1: 0.99807, l2: 0.03186\n",
            "Loss: 6.553753e-06, l1: 0.99803, l2: 0.03186\n",
            "Loss: 6.546650e-06, l1: 0.99811, l2: 0.03186\n",
            "Loss: 6.541470e-06, l1: 0.99819, l2: 0.03186\n",
            "Loss: 6.536676e-06, l1: 0.99825, l2: 0.03186\n",
            "Loss: 6.529344e-06, l1: 0.99830, l2: 0.03186\n",
            "Loss: 6.554232e-06, l1: 0.99836, l2: 0.03187\n",
            "Loss: 6.526235e-06, l1: 0.99832, l2: 0.03186\n",
            "Loss: 6.516359e-06, l1: 0.99834, l2: 0.03187\n",
            "Loss: 6.509101e-06, l1: 0.99836, l2: 0.03187\n",
            "Loss: 6.501794e-06, l1: 0.99834, l2: 0.03187\n",
            "Loss: 6.493511e-06, l1: 0.99832, l2: 0.03187\n",
            "Loss: 6.482400e-06, l1: 0.99832, l2: 0.03187\n",
            "Loss: 6.476635e-06, l1: 0.99833, l2: 0.03187\n",
            "Loss: 6.471459e-06, l1: 0.99834, l2: 0.03187\n",
            "Loss: 6.462089e-06, l1: 0.99834, l2: 0.03187\n",
            "Loss: 6.449416e-06, l1: 0.99821, l2: 0.03187\n",
            "Loss: 6.429481e-06, l1: 0.99823, l2: 0.03187\n",
            "Loss: 6.409906e-06, l1: 0.99820, l2: 0.03188\n",
            "Loss: 6.394742e-06, l1: 0.99815, l2: 0.03188\n",
            "Loss: 6.380990e-06, l1: 0.99811, l2: 0.03188\n",
            "Loss: 6.369151e-06, l1: 0.99804, l2: 0.03188\n",
            "Loss: 6.359441e-06, l1: 0.99804, l2: 0.03188\n",
            "Loss: 6.344477e-06, l1: 0.99800, l2: 0.03188\n",
            "Loss: 6.322382e-06, l1: 0.99798, l2: 0.03188\n",
            "Loss: 6.300143e-06, l1: 0.99801, l2: 0.03188\n",
            "Loss: 6.281178e-06, l1: 0.99806, l2: 0.03188\n",
            "Loss: 6.268580e-06, l1: 0.99811, l2: 0.03189\n",
            "Loss: 6.229103e-06, l1: 0.99816, l2: 0.03189\n",
            "Loss: 6.200502e-06, l1: 0.99812, l2: 0.03189\n",
            "Loss: 6.166438e-06, l1: 0.99802, l2: 0.03189\n",
            "Loss: 6.143236e-06, l1: 0.99800, l2: 0.03188\n",
            "Loss: 6.129142e-06, l1: 0.99796, l2: 0.03189\n",
            "Loss: 6.119538e-06, l1: 0.99793, l2: 0.03189\n",
            "Loss: 6.115520e-06, l1: 0.99790, l2: 0.03189\n",
            "Loss: 6.108758e-06, l1: 0.99786, l2: 0.03189\n",
            "Loss: 6.100061e-06, l1: 0.99779, l2: 0.03189\n",
            "Loss: 6.091288e-06, l1: 0.99774, l2: 0.03190\n",
            "Loss: 6.084606e-06, l1: 0.99769, l2: 0.03189\n",
            "Loss: 6.097253e-06, l1: 0.99779, l2: 0.03189\n",
            "Loss: 6.082106e-06, l1: 0.99772, l2: 0.03189\n",
            "Loss: 6.074293e-06, l1: 0.99773, l2: 0.03189\n",
            "Loss: 6.068336e-06, l1: 0.99775, l2: 0.03188\n",
            "Loss: 6.060008e-06, l1: 0.99775, l2: 0.03188\n",
            "Loss: 6.050984e-06, l1: 0.99771, l2: 0.03187\n",
            "Loss: 6.039678e-06, l1: 0.99762, l2: 0.03186\n",
            "Loss: 6.090390e-06, l1: 0.99759, l2: 0.03187\n",
            "Loss: 6.037404e-06, l1: 0.99761, l2: 0.03186\n",
            "Loss: 6.031526e-06, l1: 0.99757, l2: 0.03186\n",
            "Loss: 6.025749e-06, l1: 0.99758, l2: 0.03187\n",
            "Loss: 6.018449e-06, l1: 0.99760, l2: 0.03186\n",
            "Loss: 6.008500e-06, l1: 0.99769, l2: 0.03187\n",
            "Loss: 6.002538e-06, l1: 0.99776, l2: 0.03187\n",
            "Loss: 5.993415e-06, l1: 0.99787, l2: 0.03187\n",
            "Loss: 5.985487e-06, l1: 0.99793, l2: 0.03187\n",
            "Loss: 5.978753e-06, l1: 0.99795, l2: 0.03187\n",
            "Loss: 5.975618e-06, l1: 0.99795, l2: 0.03187\n",
            "Loss: 5.966332e-06, l1: 0.99787, l2: 0.03187\n",
            "Loss: 5.959917e-06, l1: 0.99782, l2: 0.03187\n",
            "Loss: 5.946648e-06, l1: 0.99772, l2: 0.03187\n",
            "Loss: 5.929776e-06, l1: 0.99771, l2: 0.03187\n",
            "Loss: 5.918182e-06, l1: 0.99776, l2: 0.03187\n",
            "Loss: 5.921523e-06, l1: 0.99779, l2: 0.03187\n",
            "Loss: 5.915940e-06, l1: 0.99777, l2: 0.03187\n",
            "Loss: 5.909343e-06, l1: 0.99786, l2: 0.03187\n",
            "Loss: 5.904410e-06, l1: 0.99785, l2: 0.03187\n",
            "Loss: 5.898646e-06, l1: 0.99785, l2: 0.03187\n",
            "Loss: 5.895000e-06, l1: 0.99784, l2: 0.03187\n",
            "Loss: 5.886930e-06, l1: 0.99780, l2: 0.03187\n",
            "Loss: 5.881277e-06, l1: 0.99779, l2: 0.03187\n",
            "Loss: 5.881254e-06, l1: 0.99774, l2: 0.03188\n",
            "Loss: 5.876178e-06, l1: 0.99777, l2: 0.03187\n",
            "Loss: 5.871257e-06, l1: 0.99781, l2: 0.03188\n",
            "Loss: 5.866847e-06, l1: 0.99780, l2: 0.03188\n",
            "Loss: 5.862762e-06, l1: 0.99779, l2: 0.03188\n",
            "Loss: 5.855278e-06, l1: 0.99777, l2: 0.03188\n",
            "Loss: 5.844355e-06, l1: 0.99774, l2: 0.03188\n",
            "Loss: 5.831227e-06, l1: 0.99770, l2: 0.03188\n",
            "Loss: 5.845500e-06, l1: 0.99770, l2: 0.03188\n",
            "Loss: 5.828183e-06, l1: 0.99770, l2: 0.03188\n",
            "Loss: 5.821831e-06, l1: 0.99768, l2: 0.03188\n",
            "Loss: 5.817612e-06, l1: 0.99770, l2: 0.03188\n",
            "Loss: 5.810884e-06, l1: 0.99774, l2: 0.03188\n",
            "Loss: 5.803247e-06, l1: 0.99780, l2: 0.03188\n",
            "Loss: 5.796354e-06, l1: 0.99784, l2: 0.03188\n",
            "Loss: 5.791805e-06, l1: 0.99784, l2: 0.03188\n",
            "Loss: 5.788226e-06, l1: 0.99782, l2: 0.03188\n",
            "Loss: 5.783880e-06, l1: 0.99776, l2: 0.03188\n",
            "Loss: 5.781223e-06, l1: 0.99773, l2: 0.03187\n",
            "Loss: 5.777700e-06, l1: 0.99766, l2: 0.03187\n",
            "Loss: 5.775626e-06, l1: 0.99768, l2: 0.03187\n",
            "Loss: 5.773735e-06, l1: 0.99771, l2: 0.03187\n",
            "Loss: 5.772114e-06, l1: 0.99772, l2: 0.03187\n",
            "Loss: 5.766702e-06, l1: 0.99775, l2: 0.03186\n",
            "Loss: 5.761020e-06, l1: 0.99779, l2: 0.03186\n",
            "Loss: 5.755947e-06, l1: 0.99779, l2: 0.03186\n",
            "Loss: 5.751121e-06, l1: 0.99778, l2: 0.03186\n",
            "Loss: 5.748988e-06, l1: 0.99779, l2: 0.03186\n",
            "Loss: 5.745644e-06, l1: 0.99780, l2: 0.03186\n",
            "Loss: 5.741216e-06, l1: 0.99780, l2: 0.03186\n",
            "Loss: 5.737980e-06, l1: 0.99781, l2: 0.03186\n",
            "Loss: 5.733280e-06, l1: 0.99779, l2: 0.03186\n",
            "Loss: 5.730707e-06, l1: 0.99777, l2: 0.03186\n",
            "Loss: 5.728540e-06, l1: 0.99774, l2: 0.03186\n",
            "Loss: 5.722352e-06, l1: 0.99775, l2: 0.03186\n",
            "Loss: 5.716191e-06, l1: 0.99777, l2: 0.03186\n",
            "Loss: 5.703200e-06, l1: 0.99783, l2: 0.03186\n",
            "Loss: 5.695070e-06, l1: 0.99786, l2: 0.03186\n",
            "Loss: 5.686780e-06, l1: 0.99787, l2: 0.03185\n",
            "Loss: 5.680900e-06, l1: 0.99792, l2: 0.03185\n",
            "Loss: 5.675189e-06, l1: 0.99792, l2: 0.03185\n",
            "Loss: 5.663552e-06, l1: 0.99789, l2: 0.03185\n",
            "Loss: 5.675442e-06, l1: 0.99792, l2: 0.03185\n",
            "Loss: 5.660599e-06, l1: 0.99790, l2: 0.03185\n",
            "Loss: 5.654499e-06, l1: 0.99789, l2: 0.03185\n",
            "Loss: 5.647118e-06, l1: 0.99787, l2: 0.03185\n",
            "Loss: 5.642412e-06, l1: 0.99788, l2: 0.03185\n",
            "Loss: 5.633243e-06, l1: 0.99791, l2: 0.03185\n",
            "Loss: 5.624313e-06, l1: 0.99796, l2: 0.03185\n",
            "Loss: 5.614602e-06, l1: 0.99803, l2: 0.03186\n",
            "Loss: 5.759291e-06, l1: 0.99853, l2: 0.03184\n",
            "Loss: 5.611273e-06, l1: 0.99809, l2: 0.03185\n",
            "Loss: 5.602474e-06, l1: 0.99816, l2: 0.03186\n",
            "Loss: 5.594127e-06, l1: 0.99823, l2: 0.03186\n",
            "Loss: 5.588802e-06, l1: 0.99828, l2: 0.03186\n",
            "Loss: 5.583432e-06, l1: 0.99834, l2: 0.03186\n",
            "Loss: 5.575183e-06, l1: 0.99843, l2: 0.03186\n",
            "Loss: 5.565127e-06, l1: 0.99853, l2: 0.03186\n",
            "Loss: 5.557108e-06, l1: 0.99870, l2: 0.03186\n",
            "Loss: 5.545715e-06, l1: 0.99864, l2: 0.03186\n",
            "Loss: 5.533623e-06, l1: 0.99858, l2: 0.03186\n",
            "Loss: 5.519295e-06, l1: 0.99862, l2: 0.03186\n",
            "Loss: 5.494685e-06, l1: 0.99870, l2: 0.03185\n",
            "Loss: 5.474024e-06, l1: 0.99882, l2: 0.03185\n",
            "Loss: 5.461395e-06, l1: 0.99887, l2: 0.03184\n",
            "Loss: 5.453337e-06, l1: 0.99885, l2: 0.03184\n",
            "Loss: 5.444346e-06, l1: 0.99880, l2: 0.03184\n",
            "Loss: 5.437460e-06, l1: 0.99877, l2: 0.03183\n",
            "Loss: 5.426521e-06, l1: 0.99875, l2: 0.03183\n",
            "Loss: 5.419509e-06, l1: 0.99875, l2: 0.03183\n",
            "Loss: 5.401878e-06, l1: 0.99878, l2: 0.03181\n",
            "Loss: 5.392923e-06, l1: 0.99885, l2: 0.03181\n",
            "Loss: 5.388576e-06, l1: 0.99886, l2: 0.03181\n",
            "Loss: 5.384331e-06, l1: 0.99891, l2: 0.03181\n",
            "Loss: 5.379052e-06, l1: 0.99888, l2: 0.03181\n",
            "Loss: 5.366994e-06, l1: 0.99882, l2: 0.03180\n",
            "Loss: 5.363110e-06, l1: 0.99878, l2: 0.03180\n",
            "Loss: 5.358492e-06, l1: 0.99878, l2: 0.03180\n",
            "Loss: 5.354475e-06, l1: 0.99880, l2: 0.03180\n",
            "Loss: 5.350130e-06, l1: 0.99880, l2: 0.03180\n",
            "Loss: 5.343560e-06, l1: 0.99890, l2: 0.03180\n",
            "Loss: 5.333277e-06, l1: 0.99886, l2: 0.03179\n",
            "Loss: 5.323402e-06, l1: 0.99885, l2: 0.03179\n",
            "Loss: 5.308681e-06, l1: 0.99882, l2: 0.03179\n",
            "Loss: 5.304008e-06, l1: 0.99878, l2: 0.03180\n",
            "Loss: 5.295115e-06, l1: 0.99875, l2: 0.03180\n",
            "Loss: 5.288960e-06, l1: 0.99873, l2: 0.03180\n",
            "Loss: 5.283384e-06, l1: 0.99870, l2: 0.03181\n",
            "Loss: 5.278366e-06, l1: 0.99869, l2: 0.03181\n",
            "Loss: 5.269329e-06, l1: 0.99871, l2: 0.03182\n",
            "Loss: 5.262710e-06, l1: 0.99872, l2: 0.03182\n",
            "Loss: 5.255567e-06, l1: 0.99877, l2: 0.03182\n",
            "Loss: 5.250469e-06, l1: 0.99880, l2: 0.03181\n",
            "Loss: 5.243744e-06, l1: 0.99881, l2: 0.03181\n",
            "Loss: 5.238247e-06, l1: 0.99881, l2: 0.03181\n",
            "Loss: 5.229935e-06, l1: 0.99879, l2: 0.03180\n",
            "Loss: 5.259277e-06, l1: 0.99857, l2: 0.03181\n",
            "Loss: 5.228562e-06, l1: 0.99875, l2: 0.03180\n",
            "Loss: 5.223234e-06, l1: 0.99874, l2: 0.03181\n",
            "Loss: 5.220069e-06, l1: 0.99872, l2: 0.03181\n",
            "Loss: 5.215005e-06, l1: 0.99871, l2: 0.03181\n",
            "Loss: 5.208582e-06, l1: 0.99870, l2: 0.03181\n",
            "Loss: 5.216665e-06, l1: 0.99866, l2: 0.03182\n",
            "Loss: 5.206108e-06, l1: 0.99869, l2: 0.03182\n",
            "Loss: 5.200220e-06, l1: 0.99869, l2: 0.03181\n",
            "Loss: 5.201016e-06, l1: 0.99858, l2: 0.03181\n",
            "Loss: 5.197441e-06, l1: 0.99864, l2: 0.03181\n",
            "Loss: 5.192646e-06, l1: 0.99864, l2: 0.03181\n",
            "Loss: 5.185530e-06, l1: 0.99861, l2: 0.03180\n",
            "Loss: 5.176156e-06, l1: 0.99855, l2: 0.03180\n",
            "Loss: 5.165155e-06, l1: 0.99848, l2: 0.03180\n",
            "Loss: 5.151078e-06, l1: 0.99841, l2: 0.03181\n",
            "Loss: 5.139665e-06, l1: 0.99827, l2: 0.03181\n",
            "Loss: 5.127307e-06, l1: 0.99830, l2: 0.03182\n",
            "Loss: 5.118274e-06, l1: 0.99831, l2: 0.03182\n",
            "Loss: 5.108492e-06, l1: 0.99832, l2: 0.03182\n",
            "Loss: 5.099537e-06, l1: 0.99831, l2: 0.03183\n",
            "Loss: 5.085082e-06, l1: 0.99825, l2: 0.03183\n",
            "Loss: 5.271322e-06, l1: 0.99848, l2: 0.03184\n",
            "Loss: 5.081522e-06, l1: 0.99828, l2: 0.03183\n",
            "Loss: 5.070560e-06, l1: 0.99822, l2: 0.03183\n",
            "Loss: 5.060965e-06, l1: 0.99817, l2: 0.03183\n",
            "Loss: 5.054840e-06, l1: 0.99814, l2: 0.03183\n",
            "Loss: 5.045237e-06, l1: 0.99811, l2: 0.03183\n",
            "Loss: 5.028978e-06, l1: 0.99807, l2: 0.03183\n",
            "Loss: 5.266334e-06, l1: 0.99792, l2: 0.03180\n",
            "Loss: 5.022545e-06, l1: 0.99805, l2: 0.03183\n",
            "Loss: 4.999736e-06, l1: 0.99802, l2: 0.03183\n",
            "Loss: 5.000388e-06, l1: 0.99788, l2: 0.03182\n",
            "Loss: 4.988631e-06, l1: 0.99795, l2: 0.03182\n",
            "Loss: 4.973485e-06, l1: 0.99797, l2: 0.03182\n",
            "Loss: 5.010342e-06, l1: 0.99800, l2: 0.03182\n",
            "Loss: 4.969180e-06, l1: 0.99798, l2: 0.03182\n",
            "Loss: 4.961185e-06, l1: 0.99799, l2: 0.03182\n",
            "Loss: 4.952641e-06, l1: 0.99801, l2: 0.03182\n",
            "Loss: 4.943849e-06, l1: 0.99808, l2: 0.03181\n",
            "Loss: 4.940106e-06, l1: 0.99809, l2: 0.03181\n",
            "Loss: 4.936623e-06, l1: 0.99810, l2: 0.03181\n",
            "Loss: 4.929900e-06, l1: 0.99811, l2: 0.03181\n",
            "Loss: 4.924608e-06, l1: 0.99814, l2: 0.03181\n",
            "Loss: 4.916523e-06, l1: 0.99814, l2: 0.03181\n",
            "Loss: 4.903335e-06, l1: 0.99813, l2: 0.03181\n",
            "Loss: 4.887679e-06, l1: 0.99819, l2: 0.03181\n",
            "Loss: 4.892093e-06, l1: 0.99817, l2: 0.03182\n",
            "Loss: 4.880572e-06, l1: 0.99818, l2: 0.03182\n",
            "Loss: 4.872021e-06, l1: 0.99822, l2: 0.03182\n",
            "Loss: 4.855748e-06, l1: 0.99829, l2: 0.03182\n",
            "Loss: 4.838320e-06, l1: 0.99836, l2: 0.03182\n",
            "Loss: 4.813505e-06, l1: 0.99855, l2: 0.03183\n",
            "Loss: 4.789572e-06, l1: 0.99860, l2: 0.03183\n",
            "Loss: 4.768545e-06, l1: 0.99865, l2: 0.03183\n",
            "Loss: 4.752764e-06, l1: 0.99872, l2: 0.03183\n",
            "Loss: 4.733370e-06, l1: 0.99879, l2: 0.03183\n",
            "Loss: 4.708303e-06, l1: 0.99889, l2: 0.03183\n",
            "Loss: 4.689564e-06, l1: 0.99902, l2: 0.03184\n",
            "Loss: 4.682822e-06, l1: 0.99904, l2: 0.03184\n",
            "Loss: 4.675994e-06, l1: 0.99907, l2: 0.03184\n",
            "Loss: 4.668787e-06, l1: 0.99911, l2: 0.03184\n",
            "Loss: 4.659037e-06, l1: 0.99911, l2: 0.03184\n",
            "Loss: 4.651181e-06, l1: 0.99911, l2: 0.03184\n",
            "Loss: 4.643336e-06, l1: 0.99913, l2: 0.03185\n",
            "Loss: 4.635112e-06, l1: 0.99914, l2: 0.03185\n",
            "Loss: 4.622139e-06, l1: 0.99928, l2: 0.03185\n",
            "Loss: 4.609500e-06, l1: 0.99917, l2: 0.03186\n",
            "Loss: 4.591235e-06, l1: 0.99923, l2: 0.03186\n",
            "Loss: 4.573329e-06, l1: 0.99931, l2: 0.03186\n",
            "Loss: 4.561998e-06, l1: 0.99935, l2: 0.03186\n",
            "Loss: 4.551366e-06, l1: 0.99953, l2: 0.03186\n",
            "Loss: 4.538627e-06, l1: 0.99947, l2: 0.03186\n",
            "Loss: 4.531979e-06, l1: 0.99948, l2: 0.03186\n",
            "Loss: 4.542092e-06, l1: 0.99927, l2: 0.03185\n",
            "Loss: 4.527472e-06, l1: 0.99940, l2: 0.03185\n",
            "Loss: 4.520599e-06, l1: 0.99946, l2: 0.03185\n",
            "Loss: 4.515895e-06, l1: 0.99949, l2: 0.03186\n",
            "Loss: 4.508966e-06, l1: 0.99952, l2: 0.03186\n",
            "Loss: 4.502735e-06, l1: 0.99951, l2: 0.03186\n",
            "Loss: 4.498245e-06, l1: 0.99951, l2: 0.03186\n",
            "Loss: 4.488750e-06, l1: 0.99947, l2: 0.03186\n",
            "Loss: 4.483173e-06, l1: 0.99944, l2: 0.03186\n",
            "Loss: 4.469503e-06, l1: 0.99947, l2: 0.03186\n",
            "Loss: 4.458258e-06, l1: 0.99946, l2: 0.03186\n",
            "Loss: 4.451616e-06, l1: 0.99946, l2: 0.03186\n",
            "Loss: 4.450781e-06, l1: 0.99942, l2: 0.03187\n",
            "Loss: 4.440450e-06, l1: 0.99943, l2: 0.03186\n",
            "Loss: 4.432731e-06, l1: 0.99945, l2: 0.03186\n",
            "Loss: 4.418677e-06, l1: 0.99949, l2: 0.03185\n",
            "Loss: 4.415527e-06, l1: 0.99947, l2: 0.03185\n",
            "Loss: 4.408428e-06, l1: 0.99949, l2: 0.03185\n",
            "Loss: 4.406624e-06, l1: 0.99949, l2: 0.03185\n",
            "Loss: 4.403697e-06, l1: 0.99948, l2: 0.03185\n",
            "Loss: 4.398527e-06, l1: 0.99945, l2: 0.03185\n",
            "Loss: 4.390013e-06, l1: 0.99939, l2: 0.03185\n",
            "Loss: 4.402063e-06, l1: 0.99940, l2: 0.03184\n",
            "Loss: 4.386265e-06, l1: 0.99939, l2: 0.03184\n",
            "Loss: 4.373719e-06, l1: 0.99927, l2: 0.03184\n",
            "Loss: 4.364766e-06, l1: 0.99923, l2: 0.03184\n",
            "Loss: 4.352063e-06, l1: 0.99919, l2: 0.03184\n",
            "Loss: 4.345336e-06, l1: 0.99917, l2: 0.03185\n",
            "Loss: 4.335022e-06, l1: 0.99918, l2: 0.03185\n",
            "Loss: 4.326677e-06, l1: 0.99919, l2: 0.03184\n",
            "Loss: 4.322450e-06, l1: 0.99918, l2: 0.03184\n",
            "Loss: 4.314144e-06, l1: 0.99917, l2: 0.03184\n",
            "Loss: 4.302721e-06, l1: 0.99916, l2: 0.03184\n",
            "Loss: 4.284789e-06, l1: 0.99912, l2: 0.03184\n",
            "Loss: 4.284024e-06, l1: 0.99906, l2: 0.03183\n",
            "Loss: 4.272172e-06, l1: 0.99909, l2: 0.03183\n",
            "Loss: 4.260486e-06, l1: 0.99909, l2: 0.03183\n",
            "Loss: 4.254522e-06, l1: 0.99906, l2: 0.03183\n",
            "Loss: 4.253026e-06, l1: 0.99905, l2: 0.03183\n",
            "Loss: 4.247192e-06, l1: 0.99905, l2: 0.03183\n",
            "Loss: 4.240043e-06, l1: 0.99905, l2: 0.03184\n",
            "Loss: 4.231578e-06, l1: 0.99906, l2: 0.03184\n",
            "Loss: 4.231117e-06, l1: 0.99907, l2: 0.03184\n",
            "Loss: 4.227384e-06, l1: 0.99907, l2: 0.03184\n",
            "Loss: 4.221738e-06, l1: 0.99909, l2: 0.03184\n",
            "Loss: 4.214239e-06, l1: 0.99914, l2: 0.03184\n",
            "Loss: 4.203378e-06, l1: 0.99923, l2: 0.03184\n",
            "Loss: 4.190689e-06, l1: 0.99926, l2: 0.03184\n",
            "Loss: 4.210494e-06, l1: 0.99951, l2: 0.03184\n",
            "Loss: 4.185680e-06, l1: 0.99934, l2: 0.03184\n",
            "Loss: 4.177738e-06, l1: 0.99931, l2: 0.03184\n",
            "Loss: 4.169596e-06, l1: 0.99927, l2: 0.03185\n",
            "Loss: 4.162204e-06, l1: 0.99923, l2: 0.03185\n",
            "Loss: 4.152862e-06, l1: 0.99917, l2: 0.03185\n",
            "Loss: 4.145994e-06, l1: 0.99914, l2: 0.03185\n",
            "Loss: 4.138245e-06, l1: 0.99914, l2: 0.03185\n",
            "Loss: 4.131052e-06, l1: 0.99915, l2: 0.03185\n",
            "Loss: 4.125601e-06, l1: 0.99913, l2: 0.03184\n",
            "Loss: 4.120945e-06, l1: 0.99912, l2: 0.03184\n",
            "Loss: 4.118289e-06, l1: 0.99906, l2: 0.03185\n",
            "Loss: 4.115735e-06, l1: 0.99904, l2: 0.03185\n",
            "Loss: 4.112882e-06, l1: 0.99900, l2: 0.03185\n",
            "Loss: 4.108108e-06, l1: 0.99892, l2: 0.03185\n",
            "Loss: 4.105911e-06, l1: 0.99886, l2: 0.03185\n",
            "Loss: 4.102482e-06, l1: 0.99887, l2: 0.03185\n",
            "Loss: 4.098706e-06, l1: 0.99887, l2: 0.03185\n",
            "Loss: 4.095569e-06, l1: 0.99885, l2: 0.03185\n",
            "Loss: 4.090814e-06, l1: 0.99880, l2: 0.03185\n",
            "Loss: 4.082665e-06, l1: 0.99874, l2: 0.03185\n",
            "Loss: 4.082530e-06, l1: 0.99863, l2: 0.03185\n",
            "Loss: 4.078587e-06, l1: 0.99869, l2: 0.03185\n",
            "Loss: 4.072138e-06, l1: 0.99859, l2: 0.03185\n",
            "Loss: 4.068751e-06, l1: 0.99862, l2: 0.03185\n",
            "Loss: 4.061786e-06, l1: 0.99870, l2: 0.03185\n",
            "Loss: 4.054125e-06, l1: 0.99872, l2: 0.03185\n",
            "Loss: 4.045302e-06, l1: 0.99883, l2: 0.03186\n",
            "Loss: 4.029275e-06, l1: 0.99873, l2: 0.03187\n",
            "Loss: 4.022920e-06, l1: 0.99869, l2: 0.03187\n",
            "Loss: 4.013767e-06, l1: 0.99869, l2: 0.03188\n",
            "Loss: 4.008017e-06, l1: 0.99869, l2: 0.03188\n",
            "Loss: 4.003409e-06, l1: 0.99873, l2: 0.03188\n",
            "Loss: 3.998507e-06, l1: 0.99879, l2: 0.03188\n",
            "Loss: 3.993563e-06, l1: 0.99883, l2: 0.03188\n",
            "Loss: 3.986088e-06, l1: 0.99886, l2: 0.03189\n",
            "Loss: 3.978189e-06, l1: 0.99888, l2: 0.03189\n",
            "Loss: 3.971505e-06, l1: 0.99882, l2: 0.03189\n",
            "Loss: 3.965079e-06, l1: 0.99872, l2: 0.03189\n",
            "Loss: 3.961807e-06, l1: 0.99868, l2: 0.03189\n",
            "Loss: 3.956403e-06, l1: 0.99865, l2: 0.03189\n",
            "Loss: 3.949978e-06, l1: 0.99863, l2: 0.03189\n",
            "Loss: 3.942495e-06, l1: 0.99865, l2: 0.03189\n",
            "Loss: 3.929878e-06, l1: 0.99867, l2: 0.03188\n",
            "Loss: 3.915688e-06, l1: 0.99873, l2: 0.03188\n",
            "Loss: 3.906398e-06, l1: 0.99876, l2: 0.03188\n",
            "Loss: 3.897028e-06, l1: 0.99877, l2: 0.03188\n",
            "Loss: 3.885694e-06, l1: 0.99875, l2: 0.03188\n",
            "Loss: 3.876879e-06, l1: 0.99873, l2: 0.03188\n",
            "Loss: 3.879193e-06, l1: 0.99872, l2: 0.03188\n",
            "Loss: 3.873767e-06, l1: 0.99872, l2: 0.03188\n",
            "Loss: 3.867410e-06, l1: 0.99869, l2: 0.03188\n",
            "Loss: 3.865328e-06, l1: 0.99868, l2: 0.03187\n",
            "Loss: 3.863106e-06, l1: 0.99868, l2: 0.03187\n",
            "Loss: 3.861230e-06, l1: 0.99871, l2: 0.03187\n",
            "Loss: 3.858758e-06, l1: 0.99870, l2: 0.03187\n",
            "Loss: 3.857020e-06, l1: 0.99870, l2: 0.03187\n",
            "Loss: 3.853849e-06, l1: 0.99870, l2: 0.03187\n",
            "Loss: 3.849468e-06, l1: 0.99870, l2: 0.03187\n",
            "Loss: 3.840511e-06, l1: 0.99872, l2: 0.03187\n",
            "Loss: 3.845802e-06, l1: 0.99874, l2: 0.03187\n",
            "Loss: 3.836559e-06, l1: 0.99873, l2: 0.03187\n",
            "Loss: 3.831827e-06, l1: 0.99874, l2: 0.03187\n",
            "Loss: 3.827766e-06, l1: 0.99873, l2: 0.03187\n",
            "Loss: 3.823629e-06, l1: 0.99872, l2: 0.03187\n",
            "Loss: 3.816847e-06, l1: 0.99867, l2: 0.03186\n",
            "Loss: 3.999967e-06, l1: 0.99848, l2: 0.03185\n",
            "Loss: 3.814097e-06, l1: 0.99865, l2: 0.03186\n",
            "Loss: 3.806558e-06, l1: 0.99862, l2: 0.03186\n",
            "Loss: 3.793833e-06, l1: 0.99857, l2: 0.03186\n",
            "Loss: 3.785509e-06, l1: 0.99854, l2: 0.03186\n",
            "Loss: 3.776814e-06, l1: 0.99849, l2: 0.03186\n",
            "Loss: 3.767617e-06, l1: 0.99855, l2: 0.03186\n",
            "Loss: 3.761847e-06, l1: 0.99857, l2: 0.03186\n",
            "Loss: 3.752324e-06, l1: 0.99860, l2: 0.03185\n",
            "Loss: 3.743042e-06, l1: 0.99863, l2: 0.03185\n",
            "Loss: 3.729863e-06, l1: 0.99866, l2: 0.03185\n",
            "Loss: 3.710418e-06, l1: 0.99871, l2: 0.03185\n",
            "Loss: 3.717885e-06, l1: 0.99889, l2: 0.03185\n",
            "Loss: 3.700604e-06, l1: 0.99879, l2: 0.03185\n",
            "Loss: 3.687964e-06, l1: 0.99877, l2: 0.03186\n",
            "Loss: 3.680255e-06, l1: 0.99876, l2: 0.03186\n",
            "Loss: 3.674285e-06, l1: 0.99871, l2: 0.03186\n",
            "Loss: 3.668632e-06, l1: 0.99871, l2: 0.03187\n",
            "Loss: 3.659574e-06, l1: 0.99867, l2: 0.03187\n",
            "Loss: 3.644021e-06, l1: 0.99863, l2: 0.03187\n",
            "Loss: 3.632737e-06, l1: 0.99862, l2: 0.03187\n",
            "Loss: 3.612062e-06, l1: 0.99859, l2: 0.03187\n",
            "Loss: 3.595587e-06, l1: 0.99859, l2: 0.03187\n",
            "Loss: 3.588501e-06, l1: 0.99861, l2: 0.03187\n",
            "Loss: 3.585455e-06, l1: 0.99861, l2: 0.03187\n",
            "Loss: 3.582550e-06, l1: 0.99862, l2: 0.03187\n",
            "Loss: 3.579205e-06, l1: 0.99861, l2: 0.03187\n",
            "Loss: 3.583219e-06, l1: 0.99869, l2: 0.03187\n",
            "Loss: 3.576708e-06, l1: 0.99864, l2: 0.03187\n",
            "Loss: 3.570132e-06, l1: 0.99862, l2: 0.03187\n",
            "Loss: 3.560034e-06, l1: 0.99856, l2: 0.03187\n",
            "Loss: 3.548777e-06, l1: 0.99851, l2: 0.03187\n",
            "Loss: 3.540263e-06, l1: 0.99850, l2: 0.03187\n",
            "Loss: 3.530627e-06, l1: 0.99852, l2: 0.03187\n",
            "Loss: 3.558350e-06, l1: 0.99844, l2: 0.03187\n",
            "Loss: 3.527175e-06, l1: 0.99850, l2: 0.03187\n",
            "Loss: 3.519565e-06, l1: 0.99852, l2: 0.03187\n",
            "Loss: 3.513452e-06, l1: 0.99854, l2: 0.03187\n",
            "Loss: 3.508650e-06, l1: 0.99854, l2: 0.03187\n",
            "Loss: 3.499670e-06, l1: 0.99853, l2: 0.03186\n",
            "Loss: 3.484379e-06, l1: 0.99851, l2: 0.03185\n",
            "Loss: 3.982882e-06, l1: 0.99815, l2: 0.03182\n",
            "Loss: 3.482277e-06, l1: 0.99849, l2: 0.03185\n",
            "Loss: 3.460839e-06, l1: 0.99843, l2: 0.03184\n",
            "Loss: 3.446961e-06, l1: 0.99843, l2: 0.03183\n",
            "Loss: 3.439900e-06, l1: 0.99844, l2: 0.03183\n",
            "Loss: 3.434697e-06, l1: 0.99848, l2: 0.03183\n",
            "Loss: 3.427478e-06, l1: 0.99850, l2: 0.03184\n",
            "Loss: 3.422036e-06, l1: 0.99862, l2: 0.03184\n",
            "Loss: 3.416194e-06, l1: 0.99860, l2: 0.03184\n",
            "Loss: 3.413139e-06, l1: 0.99862, l2: 0.03184\n",
            "Loss: 3.411523e-06, l1: 0.99863, l2: 0.03183\n",
            "Loss: 3.407113e-06, l1: 0.99866, l2: 0.03183\n",
            "Loss: 3.404478e-06, l1: 0.99873, l2: 0.03184\n",
            "Loss: 3.397996e-06, l1: 0.99872, l2: 0.03184\n",
            "Loss: 3.395774e-06, l1: 0.99871, l2: 0.03184\n",
            "Loss: 3.393158e-06, l1: 0.99868, l2: 0.03184\n",
            "Loss: 3.389763e-06, l1: 0.99867, l2: 0.03184\n",
            "Loss: 3.382867e-06, l1: 0.99868, l2: 0.03184\n",
            "Loss: 3.378422e-06, l1: 0.99871, l2: 0.03184\n",
            "Loss: 3.376147e-06, l1: 0.99875, l2: 0.03184\n",
            "Loss: 3.374797e-06, l1: 0.99880, l2: 0.03184\n",
            "Loss: 3.372169e-06, l1: 0.99881, l2: 0.03184\n",
            "Loss: 3.370793e-06, l1: 0.99881, l2: 0.03184\n",
            "Loss: 3.367805e-06, l1: 0.99881, l2: 0.03184\n",
            "Loss: 3.364775e-06, l1: 0.99882, l2: 0.03184\n",
            "Loss: 3.359087e-06, l1: 0.99885, l2: 0.03183\n",
            "Loss: 3.358188e-06, l1: 0.99894, l2: 0.03183\n",
            "Loss: 3.351828e-06, l1: 0.99892, l2: 0.03183\n",
            "Loss: 3.348981e-06, l1: 0.99894, l2: 0.03183\n",
            "Loss: 3.344719e-06, l1: 0.99900, l2: 0.03183\n",
            "Loss: 3.341283e-06, l1: 0.99905, l2: 0.03183\n",
            "Loss: 3.336445e-06, l1: 0.99909, l2: 0.03184\n",
            "Loss: 3.334647e-06, l1: 0.99921, l2: 0.03184\n",
            "Loss: 3.328361e-06, l1: 0.99914, l2: 0.03184\n",
            "Loss: 3.324015e-06, l1: 0.99908, l2: 0.03184\n",
            "Loss: 3.318578e-06, l1: 0.99902, l2: 0.03183\n",
            "Loss: 3.313399e-06, l1: 0.99899, l2: 0.03183\n",
            "Loss: 3.305521e-06, l1: 0.99897, l2: 0.03183\n",
            "Loss: 3.381447e-06, l1: 0.99905, l2: 0.03183\n",
            "Loss: 3.303704e-06, l1: 0.99898, l2: 0.03183\n",
            "Loss: 3.298384e-06, l1: 0.99898, l2: 0.03183\n",
            "Loss: 3.295501e-06, l1: 0.99899, l2: 0.03183\n",
            "Loss: 3.292717e-06, l1: 0.99897, l2: 0.03183\n",
            "Loss: 3.289285e-06, l1: 0.99898, l2: 0.03183\n",
            "Loss: 3.281689e-06, l1: 0.99900, l2: 0.03183\n",
            "Loss: 3.272530e-06, l1: 0.99903, l2: 0.03183\n",
            "Loss: 3.264077e-06, l1: 0.99906, l2: 0.03183\n",
            "Loss: 3.255552e-06, l1: 0.99911, l2: 0.03183\n",
            "Loss: 3.251815e-06, l1: 0.99915, l2: 0.03183\n",
            "Loss: 3.246563e-06, l1: 0.99913, l2: 0.03183\n",
            "Loss: 3.244475e-06, l1: 0.99911, l2: 0.03183\n",
            "Loss: 3.241491e-06, l1: 0.99909, l2: 0.03183\n",
            "Loss: 3.236159e-06, l1: 0.99907, l2: 0.03183\n",
            "Loss: 3.231022e-06, l1: 0.99904, l2: 0.03182\n",
            "Loss: 3.222023e-06, l1: 0.99906, l2: 0.03183\n",
            "Loss: 3.216102e-06, l1: 0.99908, l2: 0.03183\n",
            "Loss: 3.208774e-06, l1: 0.99906, l2: 0.03182\n",
            "Loss: 3.205588e-06, l1: 0.99908, l2: 0.03183\n",
            "Loss: 3.202231e-06, l1: 0.99905, l2: 0.03183\n",
            "Loss: 3.196074e-06, l1: 0.99901, l2: 0.03182\n",
            "Loss: 3.200400e-06, l1: 0.99886, l2: 0.03182\n",
            "Loss: 3.187710e-06, l1: 0.99894, l2: 0.03182\n",
            "Loss: 3.183462e-06, l1: 0.99898, l2: 0.03182\n",
            "Loss: 3.177301e-06, l1: 0.99898, l2: 0.03182\n",
            "Loss: 3.173749e-06, l1: 0.99900, l2: 0.03182\n",
            "Loss: 3.168654e-06, l1: 0.99904, l2: 0.03182\n",
            "Loss: 3.162973e-06, l1: 0.99907, l2: 0.03182\n",
            "Loss: 3.158886e-06, l1: 0.99909, l2: 0.03182\n",
            "Loss: 3.152856e-06, l1: 0.99914, l2: 0.03182\n",
            "Loss: 3.149813e-06, l1: 0.99914, l2: 0.03182\n",
            "Loss: 3.144371e-06, l1: 0.99917, l2: 0.03182\n",
            "Loss: 3.139128e-06, l1: 0.99918, l2: 0.03182\n",
            "Loss: 3.131192e-06, l1: 0.99922, l2: 0.03182\n",
            "Loss: 3.126910e-06, l1: 0.99918, l2: 0.03182\n",
            "Loss: 3.123889e-06, l1: 0.99921, l2: 0.03182\n",
            "Loss: 3.117991e-06, l1: 0.99920, l2: 0.03182\n",
            "Loss: 3.113164e-06, l1: 0.99918, l2: 0.03182\n",
            "Loss: 3.108232e-06, l1: 0.99916, l2: 0.03182\n",
            "Loss: 3.101399e-06, l1: 0.99916, l2: 0.03182\n",
            "Loss: 3.098622e-06, l1: 0.99918, l2: 0.03182\n",
            "Loss: 3.096369e-06, l1: 0.99916, l2: 0.03182\n",
            "Loss: 3.089185e-06, l1: 0.99919, l2: 0.03182\n",
            "Loss: 3.086633e-06, l1: 0.99919, l2: 0.03182\n",
            "Loss: 3.079720e-06, l1: 0.99919, l2: 0.03182\n",
            "Loss: 3.072049e-06, l1: 0.99916, l2: 0.03182\n",
            "Loss: 3.066853e-06, l1: 0.99915, l2: 0.03182\n",
            "Loss: 3.063272e-06, l1: 0.99914, l2: 0.03182\n",
            "Loss: 3.061896e-06, l1: 0.99913, l2: 0.03182\n",
            "Loss: 3.058358e-06, l1: 0.99915, l2: 0.03182\n",
            "Loss: 3.071488e-06, l1: 0.99906, l2: 0.03181\n",
            "Loss: 3.056590e-06, l1: 0.99913, l2: 0.03182\n",
            "Loss: 3.052186e-06, l1: 0.99917, l2: 0.03182\n",
            "Loss: 3.048737e-06, l1: 0.99921, l2: 0.03182\n",
            "Loss: 3.053972e-06, l1: 0.99924, l2: 0.03182\n",
            "Loss: 3.047281e-06, l1: 0.99922, l2: 0.03182\n",
            "Loss: 3.044546e-06, l1: 0.99923, l2: 0.03182\n",
            "Loss: 3.042356e-06, l1: 0.99922, l2: 0.03182\n",
            "Loss: 3.040668e-06, l1: 0.99917, l2: 0.03182\n",
            "Loss: 3.037459e-06, l1: 0.99918, l2: 0.03182\n",
            "Loss: 3.035351e-06, l1: 0.99918, l2: 0.03182\n",
            "Loss: 3.033188e-06, l1: 0.99919, l2: 0.03182\n",
            "Loss: 3.030855e-06, l1: 0.99919, l2: 0.03182\n",
            "Loss: 3.027468e-06, l1: 0.99918, l2: 0.03182\n",
            "Loss: 3.048248e-06, l1: 0.99920, l2: 0.03182\n",
            "Loss: 3.025838e-06, l1: 0.99918, l2: 0.03182\n",
            "Loss: 3.023117e-06, l1: 0.99918, l2: 0.03182\n",
            "Loss: 3.017608e-06, l1: 0.99917, l2: 0.03182\n",
            "Loss: 3.013253e-06, l1: 0.99916, l2: 0.03182\n",
            "Loss: 3.008954e-06, l1: 0.99916, l2: 0.03182\n",
            "Loss: 3.007160e-06, l1: 0.99915, l2: 0.03182\n",
            "Loss: 3.003622e-06, l1: 0.99915, l2: 0.03182\n",
            "Loss: 3.000420e-06, l1: 0.99914, l2: 0.03182\n",
            "Loss: 2.996376e-06, l1: 0.99912, l2: 0.03182\n",
            "Loss: 2.993342e-06, l1: 0.99904, l2: 0.03182\n",
            "Loss: 2.988084e-06, l1: 0.99905, l2: 0.03182\n",
            "Loss: 2.986088e-06, l1: 0.99904, l2: 0.03182\n",
            "Loss: 2.983511e-06, l1: 0.99901, l2: 0.03182\n",
            "Loss: 2.980854e-06, l1: 0.99898, l2: 0.03182\n",
            "Loss: 2.984764e-06, l1: 0.99891, l2: 0.03182\n",
            "Loss: 2.979262e-06, l1: 0.99896, l2: 0.03182\n",
            "Loss: 2.975841e-06, l1: 0.99894, l2: 0.03182\n",
            "Loss: 2.973524e-06, l1: 0.99894, l2: 0.03182\n",
            "Loss: 2.971032e-06, l1: 0.99895, l2: 0.03182\n",
            "Loss: 2.968494e-06, l1: 0.99897, l2: 0.03182\n",
            "Loss: 2.969746e-06, l1: 0.99900, l2: 0.03182\n",
            "Loss: 2.967098e-06, l1: 0.99898, l2: 0.03182\n",
            "Loss: 2.964656e-06, l1: 0.99899, l2: 0.03182\n",
            "Loss: 2.962960e-06, l1: 0.99900, l2: 0.03182\n",
            "Loss: 2.961067e-06, l1: 0.99900, l2: 0.03182\n",
            "Loss: 2.958657e-06, l1: 0.99900, l2: 0.03182\n",
            "Loss: 2.956207e-06, l1: 0.99900, l2: 0.03182\n",
            "Loss: 2.958648e-06, l1: 0.99903, l2: 0.03182\n",
            "Loss: 2.955062e-06, l1: 0.99901, l2: 0.03182\n",
            "Loss: 2.954077e-06, l1: 0.99900, l2: 0.03182\n",
            "Loss: 2.952396e-06, l1: 0.99899, l2: 0.03182\n",
            "Loss: 2.950429e-06, l1: 0.99898, l2: 0.03182\n",
            "Loss: 2.946890e-06, l1: 0.99895, l2: 0.03182\n",
            "Loss: 2.943232e-06, l1: 0.99892, l2: 0.03182\n",
            "Loss: 2.942307e-06, l1: 0.99886, l2: 0.03182\n",
            "Loss: 2.938772e-06, l1: 0.99884, l2: 0.03182\n",
            "Loss: 2.936800e-06, l1: 0.99886, l2: 0.03182\n",
            "Loss: 2.932855e-06, l1: 0.99886, l2: 0.03182\n",
            "Loss: 3.049348e-06, l1: 0.99883, l2: 0.03183\n",
            "Loss: 2.931587e-06, l1: 0.99886, l2: 0.03182\n",
            "Loss: 2.928557e-06, l1: 0.99883, l2: 0.03182\n",
            "Loss: 2.924103e-06, l1: 0.99878, l2: 0.03182\n",
            "Loss: 2.920009e-06, l1: 0.99871, l2: 0.03182\n",
            "Loss: 2.914348e-06, l1: 0.99864, l2: 0.03183\n",
            "Loss: 2.908501e-06, l1: 0.99857, l2: 0.03183\n",
            "Loss: 2.906568e-06, l1: 0.99859, l2: 0.03183\n",
            "Loss: 2.904757e-06, l1: 0.99860, l2: 0.03183\n",
            "Loss: 2.902447e-06, l1: 0.99862, l2: 0.03183\n",
            "Loss: 2.914880e-06, l1: 0.99865, l2: 0.03183\n",
            "Loss: 2.901152e-06, l1: 0.99863, l2: 0.03183\n",
            "Loss: 2.896681e-06, l1: 0.99862, l2: 0.03183\n",
            "Loss: 2.891433e-06, l1: 0.99860, l2: 0.03183\n",
            "Loss: 2.887758e-06, l1: 0.99857, l2: 0.03183\n",
            "Loss: 2.885243e-06, l1: 0.99856, l2: 0.03183\n",
            "Loss: 2.883836e-06, l1: 0.99849, l2: 0.03183\n",
            "Loss: 2.878854e-06, l1: 0.99853, l2: 0.03183\n",
            "Loss: 2.875372e-06, l1: 0.99854, l2: 0.03183\n",
            "Loss: 2.872432e-06, l1: 0.99855, l2: 0.03183\n",
            "Loss: 2.869414e-06, l1: 0.99853, l2: 0.03183\n",
            "Loss: 2.865767e-06, l1: 0.99853, l2: 0.03183\n",
            "Loss: 2.863401e-06, l1: 0.99851, l2: 0.03183\n",
            "Loss: 2.860251e-06, l1: 0.99850, l2: 0.03183\n",
            "Loss: 2.857957e-06, l1: 0.99850, l2: 0.03183\n",
            "Loss: 2.853154e-06, l1: 0.99848, l2: 0.03183\n",
            "Loss: 2.850597e-06, l1: 0.99850, l2: 0.03183\n",
            "Loss: 2.843912e-06, l1: 0.99853, l2: 0.03183\n",
            "Loss: 2.841715e-06, l1: 0.99851, l2: 0.03183\n",
            "Loss: 2.839603e-06, l1: 0.99854, l2: 0.03183\n",
            "Loss: 2.838442e-06, l1: 0.99855, l2: 0.03183\n",
            "Loss: 2.836437e-06, l1: 0.99856, l2: 0.03183\n",
            "Loss: 2.834749e-06, l1: 0.99858, l2: 0.03183\n",
            "Loss: 2.833484e-06, l1: 0.99858, l2: 0.03183\n",
            "Loss: 2.832055e-06, l1: 0.99855, l2: 0.03183\n",
            "Loss: 2.852375e-06, l1: 0.99863, l2: 0.03182\n",
            "Loss: 2.830766e-06, l1: 0.99857, l2: 0.03183\n",
            "Loss: 2.828742e-06, l1: 0.99855, l2: 0.03183\n",
            "Loss: 2.824499e-06, l1: 0.99852, l2: 0.03183\n",
            "Loss: 2.822854e-06, l1: 0.99851, l2: 0.03183\n",
            "Loss: 2.820171e-06, l1: 0.99850, l2: 0.03183\n",
            "Loss: 2.818539e-06, l1: 0.99853, l2: 0.03183\n",
            "Loss: 2.816626e-06, l1: 0.99853, l2: 0.03183\n",
            "Loss: 2.814608e-06, l1: 0.99854, l2: 0.03183\n",
            "Loss: 2.812244e-06, l1: 0.99854, l2: 0.03183\n",
            "Loss: 2.807535e-06, l1: 0.99855, l2: 0.03183\n",
            "Loss: 2.807988e-06, l1: 0.99856, l2: 0.03183\n",
            "Loss: 2.803836e-06, l1: 0.99855, l2: 0.03183\n",
            "Loss: 2.801060e-06, l1: 0.99855, l2: 0.03183\n",
            "Loss: 2.798158e-06, l1: 0.99855, l2: 0.03183\n",
            "Loss: 2.796887e-06, l1: 0.99855, l2: 0.03183\n",
            "Loss: 2.793507e-06, l1: 0.99853, l2: 0.03183\n",
            "Loss: 2.807179e-06, l1: 0.99860, l2: 0.03183\n",
            "Loss: 2.791672e-06, l1: 0.99855, l2: 0.03183\n",
            "Loss: 2.788435e-06, l1: 0.99853, l2: 0.03183\n",
            "Loss: 2.789141e-06, l1: 0.99846, l2: 0.03183\n",
            "Loss: 2.783624e-06, l1: 0.99850, l2: 0.03183\n",
            "Loss: 2.779655e-06, l1: 0.99850, l2: 0.03184\n",
            "Loss: 2.785590e-06, l1: 0.99851, l2: 0.03184\n",
            "Loss: 2.777386e-06, l1: 0.99851, l2: 0.03184\n",
            "Loss: 2.774998e-06, l1: 0.99851, l2: 0.03184\n",
            "Loss: 2.768392e-06, l1: 0.99852, l2: 0.03183\n",
            "Loss: 2.763741e-06, l1: 0.99853, l2: 0.03183\n",
            "Loss: 2.761317e-06, l1: 0.99858, l2: 0.03183\n",
            "Loss: 2.758936e-06, l1: 0.99856, l2: 0.03183\n",
            "Loss: 2.758168e-06, l1: 0.99856, l2: 0.03183\n",
            "Loss: 2.756851e-06, l1: 0.99855, l2: 0.03183\n",
            "Loss: 2.755209e-06, l1: 0.99855, l2: 0.03184\n",
            "Loss: 2.752749e-06, l1: 0.99855, l2: 0.03184\n",
            "Loss: 2.747887e-06, l1: 0.99856, l2: 0.03184\n",
            "Loss: 2.753816e-06, l1: 0.99861, l2: 0.03184\n",
            "Loss: 2.745110e-06, l1: 0.99858, l2: 0.03184\n",
            "Loss: 2.739298e-06, l1: 0.99860, l2: 0.03184\n",
            "Loss: 2.735825e-06, l1: 0.99863, l2: 0.03184\n",
            "Loss: 2.731097e-06, l1: 0.99867, l2: 0.03184\n",
            "Loss: 2.727896e-06, l1: 0.99871, l2: 0.03184\n",
            "Loss: 2.725592e-06, l1: 0.99874, l2: 0.03184\n",
            "Loss: 2.721533e-06, l1: 0.99874, l2: 0.03184\n",
            "Loss: 2.719181e-06, l1: 0.99873, l2: 0.03184\n",
            "Loss: 2.717009e-06, l1: 0.99874, l2: 0.03184\n",
            "Loss: 2.712923e-06, l1: 0.99874, l2: 0.03184\n",
            "Loss: 2.709245e-06, l1: 0.99877, l2: 0.03184\n",
            "Loss: 2.706558e-06, l1: 0.99879, l2: 0.03184\n",
            "Loss: 2.702413e-06, l1: 0.99883, l2: 0.03184\n",
            "Loss: 2.696318e-06, l1: 0.99888, l2: 0.03184\n",
            "Loss: 2.692193e-06, l1: 0.99892, l2: 0.03184\n",
            "Loss: 2.693689e-06, l1: 0.99891, l2: 0.03184\n",
            "Loss: 2.690285e-06, l1: 0.99892, l2: 0.03184\n",
            "Loss: 2.688720e-06, l1: 0.99891, l2: 0.03184\n",
            "Loss: 2.687819e-06, l1: 0.99890, l2: 0.03184\n",
            "Loss: 2.687094e-06, l1: 0.99890, l2: 0.03184\n",
            "Loss: 2.685096e-06, l1: 0.99892, l2: 0.03184\n",
            "Loss: 2.688763e-06, l1: 0.99888, l2: 0.03184\n",
            "Loss: 2.684081e-06, l1: 0.99891, l2: 0.03184\n",
            "Loss: 2.682908e-06, l1: 0.99893, l2: 0.03184\n",
            "Loss: 2.683447e-06, l1: 0.99900, l2: 0.03184\n",
            "Loss: 2.682370e-06, l1: 0.99896, l2: 0.03184\n",
            "Loss: 2.681675e-06, l1: 0.99895, l2: 0.03184\n",
            "Loss: 2.680935e-06, l1: 0.99895, l2: 0.03184\n",
            "Loss: 2.679212e-06, l1: 0.99895, l2: 0.03184\n",
            "Loss: 2.677150e-06, l1: 0.99895, l2: 0.03184\n",
            "Loss: 2.673923e-06, l1: 0.99896, l2: 0.03184\n",
            "Loss: 2.669420e-06, l1: 0.99899, l2: 0.03184\n",
            "Loss: 2.677473e-06, l1: 0.99901, l2: 0.03184\n",
            "Loss: 2.667226e-06, l1: 0.99899, l2: 0.03184\n",
            "Loss: 2.662226e-06, l1: 0.99901, l2: 0.03184\n",
            "Loss: 2.663556e-06, l1: 0.99903, l2: 0.03184\n",
            "Loss: 2.661071e-06, l1: 0.99901, l2: 0.03184\n",
            "Loss: 2.658928e-06, l1: 0.99900, l2: 0.03184\n",
            "Loss: 2.656408e-06, l1: 0.99897, l2: 0.03185\n",
            "Loss: 2.652918e-06, l1: 0.99894, l2: 0.03185\n",
            "Loss: 2.648303e-06, l1: 0.99890, l2: 0.03185\n",
            "Loss: 2.642565e-06, l1: 0.99888, l2: 0.03185\n",
            "Loss: 2.635358e-06, l1: 0.99886, l2: 0.03185\n",
            "Loss: 2.663700e-06, l1: 0.99881, l2: 0.03185\n",
            "Loss: 2.633603e-06, l1: 0.99885, l2: 0.03185\n",
            "Loss: 2.629084e-06, l1: 0.99885, l2: 0.03185\n",
            "Loss: 2.626411e-06, l1: 0.99885, l2: 0.03185\n",
            "Loss: 2.624525e-06, l1: 0.99886, l2: 0.03185\n",
            "Loss: 2.624554e-06, l1: 0.99884, l2: 0.03185\n",
            "Loss: 2.623612e-06, l1: 0.99885, l2: 0.03185\n",
            "Loss: 2.622204e-06, l1: 0.99885, l2: 0.03185\n",
            "Loss: 2.618244e-06, l1: 0.99884, l2: 0.03185\n",
            "Loss: 2.616419e-06, l1: 0.99883, l2: 0.03185\n",
            "Loss: 2.614673e-06, l1: 0.99885, l2: 0.03185\n",
            "Loss: 2.613450e-06, l1: 0.99884, l2: 0.03185\n",
            "Loss: 2.611917e-06, l1: 0.99886, l2: 0.03185\n",
            "Loss: 2.609736e-06, l1: 0.99887, l2: 0.03185\n",
            "Loss: 2.606520e-06, l1: 0.99887, l2: 0.03185\n",
            "Loss: 2.604402e-06, l1: 0.99886, l2: 0.03185\n",
            "Loss: 2.606118e-06, l1: 0.99887, l2: 0.03185\n",
            "Loss: 2.603517e-06, l1: 0.99887, l2: 0.03185\n",
            "Loss: 2.601960e-06, l1: 0.99886, l2: 0.03185\n",
            "Loss: 2.599020e-06, l1: 0.99885, l2: 0.03185\n",
            "Loss: 2.596464e-06, l1: 0.99886, l2: 0.03186\n",
            "Loss: 2.596702e-06, l1: 0.99888, l2: 0.03186\n",
            "Loss: 2.595425e-06, l1: 0.99887, l2: 0.03186\n",
            "Loss: 2.593743e-06, l1: 0.99889, l2: 0.03186\n",
            "Loss: 2.592294e-06, l1: 0.99891, l2: 0.03185\n",
            "Loss: 2.590208e-06, l1: 0.99892, l2: 0.03185\n",
            "Loss: 2.587755e-06, l1: 0.99892, l2: 0.03185\n",
            "Loss: 2.584711e-06, l1: 0.99893, l2: 0.03185\n",
            "Loss: 2.583478e-06, l1: 0.99892, l2: 0.03185\n",
            "Loss: 2.577952e-06, l1: 0.99893, l2: 0.03185\n",
            "Loss: 2.574573e-06, l1: 0.99894, l2: 0.03185\n",
            "Loss: 2.571025e-06, l1: 0.99897, l2: 0.03185\n",
            "Loss: 2.567607e-06, l1: 0.99900, l2: 0.03185\n",
            "Loss: 2.573986e-06, l1: 0.99912, l2: 0.03185\n",
            "Loss: 2.566814e-06, l1: 0.99903, l2: 0.03185\n",
            "Loss: 2.564660e-06, l1: 0.99905, l2: 0.03185\n",
            "Loss: 2.563658e-06, l1: 0.99906, l2: 0.03185\n",
            "Loss: 2.561945e-06, l1: 0.99907, l2: 0.03185\n",
            "Loss: 2.560606e-06, l1: 0.99907, l2: 0.03185\n",
            "Loss: 2.558125e-06, l1: 0.99908, l2: 0.03185\n",
            "Loss: 2.569906e-06, l1: 0.99905, l2: 0.03185\n",
            "Loss: 2.557060e-06, l1: 0.99907, l2: 0.03185\n",
            "Loss: 2.555896e-06, l1: 0.99907, l2: 0.03185\n",
            "Loss: 2.554125e-06, l1: 0.99911, l2: 0.03185\n",
            "Loss: 2.551212e-06, l1: 0.99914, l2: 0.03185\n",
            "Loss: 2.546584e-06, l1: 0.99919, l2: 0.03185\n",
            "Loss: 2.538733e-06, l1: 0.99932, l2: 0.03185\n",
            "Loss: 2.531244e-06, l1: 0.99943, l2: 0.03185\n",
            "Loss: 2.525124e-06, l1: 0.99957, l2: 0.03185\n",
            "Loss: 2.534700e-06, l1: 0.99971, l2: 0.03185\n",
            "Loss: 2.521660e-06, l1: 0.99962, l2: 0.03185\n",
            "Loss: 2.517565e-06, l1: 0.99958, l2: 0.03185\n",
            "Loss: 2.528422e-06, l1: 0.99952, l2: 0.03185\n",
            "Loss: 2.514934e-06, l1: 0.99956, l2: 0.03185\n",
            "Loss: 2.510419e-06, l1: 0.99952, l2: 0.03185\n",
            "Loss: 2.509172e-06, l1: 0.99952, l2: 0.03185\n",
            "Loss: 2.506218e-06, l1: 0.99955, l2: 0.03185\n",
            "Loss: 2.504325e-06, l1: 0.99958, l2: 0.03185\n",
            "Loss: 2.501987e-06, l1: 0.99959, l2: 0.03185\n",
            "Loss: 2.516954e-06, l1: 0.99961, l2: 0.03184\n",
            "Loss: 2.500960e-06, l1: 0.99959, l2: 0.03185\n",
            "Loss: 2.499289e-06, l1: 0.99959, l2: 0.03185\n",
            "Loss: 2.495365e-06, l1: 0.99960, l2: 0.03185\n",
            "Loss: 2.493108e-06, l1: 0.99961, l2: 0.03184\n",
            "Loss: 2.489521e-06, l1: 0.99963, l2: 0.03184\n",
            "Loss: 2.490212e-06, l1: 0.99971, l2: 0.03184\n",
            "Loss: 2.487068e-06, l1: 0.99967, l2: 0.03184\n",
            "Loss: 2.484527e-06, l1: 0.99967, l2: 0.03184\n",
            "Loss: 2.481909e-06, l1: 0.99967, l2: 0.03184\n",
            "Loss: 2.479509e-06, l1: 0.99967, l2: 0.03184\n",
            "Loss: 2.475958e-06, l1: 0.99969, l2: 0.03184\n",
            "Loss: 2.472518e-06, l1: 0.99970, l2: 0.03184\n",
            "Loss: 2.467640e-06, l1: 0.99974, l2: 0.03184\n",
            "Loss: 2.462624e-06, l1: 0.99978, l2: 0.03184\n",
            "Loss: 2.455539e-06, l1: 0.99982, l2: 0.03184\n",
            "Loss: 2.449881e-06, l1: 0.99986, l2: 0.03184\n",
            "Loss: 2.448224e-06, l1: 0.99985, l2: 0.03184\n",
            "Loss: 2.445038e-06, l1: 0.99984, l2: 0.03184\n",
            "Loss: 2.443832e-06, l1: 0.99982, l2: 0.03184\n",
            "Loss: 2.442405e-06, l1: 0.99981, l2: 0.03184\n",
            "Loss: 2.439604e-06, l1: 0.99980, l2: 0.03184\n",
            "Loss: 2.437701e-06, l1: 0.99980, l2: 0.03184\n",
            "Loss: 2.434930e-06, l1: 0.99981, l2: 0.03184\n",
            "Loss: 2.433549e-06, l1: 0.99983, l2: 0.03184\n",
            "Loss: 2.430400e-06, l1: 0.99986, l2: 0.03184\n",
            "Loss: 2.427873e-06, l1: 0.99986, l2: 0.03184\n",
            "Loss: 2.425034e-06, l1: 0.99986, l2: 0.03184\n",
            "Loss: 2.426541e-06, l1: 0.99979, l2: 0.03184\n",
            "Loss: 2.424029e-06, l1: 0.99983, l2: 0.03184\n",
            "Loss: 2.421736e-06, l1: 0.99983, l2: 0.03184\n",
            "Loss: 2.420199e-06, l1: 0.99983, l2: 0.03184\n",
            "Loss: 2.418614e-06, l1: 0.99982, l2: 0.03184\n",
            "Loss: 2.418869e-06, l1: 0.99987, l2: 0.03184\n",
            "Loss: 2.417672e-06, l1: 0.99984, l2: 0.03184\n",
            "Loss: 2.416097e-06, l1: 0.99984, l2: 0.03184\n",
            "Loss: 2.412666e-06, l1: 0.99984, l2: 0.03184\n",
            "Loss: 2.407719e-06, l1: 0.99984, l2: 0.03184\n",
            "Loss: 2.403389e-06, l1: 0.99983, l2: 0.03184\n",
            "Loss: 2.421547e-06, l1: 0.99985, l2: 0.03184\n",
            "Loss: 2.402580e-06, l1: 0.99983, l2: 0.03184\n",
            "Loss: 2.399792e-06, l1: 0.99981, l2: 0.03184\n",
            "Loss: 2.396562e-06, l1: 0.99977, l2: 0.03184\n",
            "Loss: 2.394691e-06, l1: 0.99975, l2: 0.03184\n",
            "Loss: 2.392548e-06, l1: 0.99974, l2: 0.03184\n",
            "Loss: 2.392094e-06, l1: 0.99974, l2: 0.03184\n",
            "Loss: 2.388944e-06, l1: 0.99974, l2: 0.03184\n",
            "Loss: 2.387295e-06, l1: 0.99974, l2: 0.03184\n",
            "Loss: 2.385237e-06, l1: 0.99974, l2: 0.03184\n",
            "Loss: 2.383594e-06, l1: 0.99973, l2: 0.03184\n",
            "Loss: 2.418912e-06, l1: 0.99962, l2: 0.03184\n",
            "Loss: 2.383308e-06, l1: 0.99972, l2: 0.03184\n",
            "Loss: 2.381690e-06, l1: 0.99968, l2: 0.03184\n",
            "Loss: 2.380435e-06, l1: 0.99965, l2: 0.03184\n",
            "Loss: 2.379063e-06, l1: 0.99961, l2: 0.03184\n",
            "Loss: 2.377337e-06, l1: 0.99958, l2: 0.03184\n",
            "Loss: 2.377399e-06, l1: 0.99947, l2: 0.03184\n",
            "Loss: 2.375966e-06, l1: 0.99953, l2: 0.03184\n",
            "Loss: 2.373902e-06, l1: 0.99950, l2: 0.03184\n",
            "Loss: 2.371477e-06, l1: 0.99952, l2: 0.03184\n",
            "Loss: 2.366313e-06, l1: 0.99954, l2: 0.03184\n",
            "Loss: 2.360713e-06, l1: 0.99951, l2: 0.03184\n",
            "Loss: 2.355638e-06, l1: 0.99944, l2: 0.03184\n",
            "Loss: 2.353060e-06, l1: 0.99942, l2: 0.03184\n",
            "Loss: 2.349129e-06, l1: 0.99934, l2: 0.03184\n",
            "Loss: 2.347045e-06, l1: 0.99935, l2: 0.03184\n",
            "Loss: 2.345120e-06, l1: 0.99933, l2: 0.03184\n",
            "Loss: 2.343324e-06, l1: 0.99932, l2: 0.03184\n",
            "Loss: 2.340636e-06, l1: 0.99932, l2: 0.03184\n",
            "Loss: 2.337953e-06, l1: 0.99932, l2: 0.03184\n",
            "Loss: 2.344615e-06, l1: 0.99922, l2: 0.03183\n",
            "Loss: 2.334627e-06, l1: 0.99928, l2: 0.03183\n",
            "Loss: 2.332864e-06, l1: 0.99927, l2: 0.03183\n",
            "Loss: 2.330761e-06, l1: 0.99924, l2: 0.03183\n",
            "Loss: 2.328267e-06, l1: 0.99922, l2: 0.03183\n",
            "Loss: 2.324400e-06, l1: 0.99914, l2: 0.03183\n",
            "Loss: 2.319516e-06, l1: 0.99914, l2: 0.03183\n",
            "Loss: 2.317307e-06, l1: 0.99916, l2: 0.03183\n",
            "Loss: 2.313127e-06, l1: 0.99916, l2: 0.03182\n",
            "Loss: 2.310330e-06, l1: 0.99914, l2: 0.03182\n",
            "Loss: 2.322563e-06, l1: 0.99910, l2: 0.03182\n",
            "Loss: 2.309549e-06, l1: 0.99913, l2: 0.03182\n",
            "Loss: 2.307298e-06, l1: 0.99911, l2: 0.03182\n",
            "Loss: 2.305758e-06, l1: 0.99909, l2: 0.03182\n",
            "Loss: 2.303969e-06, l1: 0.99907, l2: 0.03182\n",
            "Loss: 2.301669e-06, l1: 0.99904, l2: 0.03182\n",
            "Loss: 2.297579e-06, l1: 0.99899, l2: 0.03182\n",
            "Loss: 2.314349e-06, l1: 0.99885, l2: 0.03182\n",
            "Loss: 2.296936e-06, l1: 0.99897, l2: 0.03182\n",
            "Loss: 2.295107e-06, l1: 0.99896, l2: 0.03182\n",
            "Loss: 2.293969e-06, l1: 0.99896, l2: 0.03182\n",
            "Loss: 2.293096e-06, l1: 0.99896, l2: 0.03182\n",
            "Loss: 2.292015e-06, l1: 0.99895, l2: 0.03182\n",
            "Loss: 2.290800e-06, l1: 0.99897, l2: 0.03182\n",
            "Loss: 2.289015e-06, l1: 0.99896, l2: 0.03182\n",
            "Loss: 2.287473e-06, l1: 0.99897, l2: 0.03182\n",
            "Loss: 2.286063e-06, l1: 0.99896, l2: 0.03182\n",
            "Loss: 2.291574e-06, l1: 0.99891, l2: 0.03182\n",
            "Loss: 2.285255e-06, l1: 0.99895, l2: 0.03182\n",
            "Loss: 2.284172e-06, l1: 0.99895, l2: 0.03182\n",
            "Loss: 2.282473e-06, l1: 0.99896, l2: 0.03182\n",
            "Loss: 2.280952e-06, l1: 0.99898, l2: 0.03182\n",
            "Loss: 2.278307e-06, l1: 0.99904, l2: 0.03182\n",
            "Loss: 2.276729e-06, l1: 0.99909, l2: 0.03182\n",
            "Loss: 2.275193e-06, l1: 0.99912, l2: 0.03182\n",
            "Loss: 2.274518e-06, l1: 0.99913, l2: 0.03182\n",
            "Loss: 2.273854e-06, l1: 0.99914, l2: 0.03182\n",
            "Loss: 2.272936e-06, l1: 0.99915, l2: 0.03182\n",
            "Loss: 2.314112e-06, l1: 0.99911, l2: 0.03182\n",
            "Loss: 2.272719e-06, l1: 0.99914, l2: 0.03182\n",
            "Loss: 2.271762e-06, l1: 0.99915, l2: 0.03182\n",
            "Loss: 2.270171e-06, l1: 0.99914, l2: 0.03182\n",
            "Loss: 2.268371e-06, l1: 0.99914, l2: 0.03182\n",
            "Loss: 2.265470e-06, l1: 0.99913, l2: 0.03182\n",
            "Loss: 2.262625e-06, l1: 0.99908, l2: 0.03182\n",
            "Loss: 2.281750e-06, l1: 0.99920, l2: 0.03182\n",
            "Loss: 2.260025e-06, l1: 0.99911, l2: 0.03182\n",
            "Loss: 2.256832e-06, l1: 0.99911, l2: 0.03182\n",
            "Loss: 2.252948e-06, l1: 0.99910, l2: 0.03182\n",
            "Loss: 2.251314e-06, l1: 0.99909, l2: 0.03182\n",
            "Loss: 2.247263e-06, l1: 0.99905, l2: 0.03182\n",
            "Loss: 2.264488e-06, l1: 0.99910, l2: 0.03182\n",
            "Loss: 2.245914e-06, l1: 0.99906, l2: 0.03182\n",
            "Loss: 2.243501e-06, l1: 0.99904, l2: 0.03183\n",
            "Loss: 2.245790e-06, l1: 0.99900, l2: 0.03183\n",
            "Loss: 2.242281e-06, l1: 0.99903, l2: 0.03183\n",
            "Loss: 2.240054e-06, l1: 0.99901, l2: 0.03183\n",
            "Loss: 2.238771e-06, l1: 0.99901, l2: 0.03183\n",
            "Loss: 2.236470e-06, l1: 0.99901, l2: 0.03183\n",
            "Loss: 2.233365e-06, l1: 0.99903, l2: 0.03183\n",
            "Loss: 2.237066e-06, l1: 0.99901, l2: 0.03183\n",
            "Loss: 2.231961e-06, l1: 0.99903, l2: 0.03183\n",
            "Loss: 2.228786e-06, l1: 0.99904, l2: 0.03183\n",
            "Loss: 2.224457e-06, l1: 0.99903, l2: 0.03183\n",
            "Loss: 2.219810e-06, l1: 0.99901, l2: 0.03183\n",
            "Loss: 2.216138e-06, l1: 0.99896, l2: 0.03183\n",
            "Loss: 2.283013e-06, l1: 0.99875, l2: 0.03183\n",
            "Loss: 2.215625e-06, l1: 0.99894, l2: 0.03183\n",
            "Loss: 2.213253e-06, l1: 0.99890, l2: 0.03183\n",
            "Loss: 2.211807e-06, l1: 0.99889, l2: 0.03183\n",
            "Loss: 2.210882e-06, l1: 0.99889, l2: 0.03183\n",
            "Loss: 2.213379e-06, l1: 0.99890, l2: 0.03183\n",
            "Loss: 2.210599e-06, l1: 0.99889, l2: 0.03183\n",
            "Loss: 2.209915e-06, l1: 0.99890, l2: 0.03183\n",
            "Loss: 2.208646e-06, l1: 0.99891, l2: 0.03183\n",
            "Loss: 2.206872e-06, l1: 0.99892, l2: 0.03183\n",
            "Loss: 2.203860e-06, l1: 0.99895, l2: 0.03183\n",
            "Loss: 2.200283e-06, l1: 0.99896, l2: 0.03184\n",
            "Loss: 2.199680e-06, l1: 0.99900, l2: 0.03184\n",
            "Loss: 2.196187e-06, l1: 0.99897, l2: 0.03183\n",
            "Loss: 2.194302e-06, l1: 0.99895, l2: 0.03183\n",
            "Loss: 2.191698e-06, l1: 0.99893, l2: 0.03183\n",
            "Loss: 2.188711e-06, l1: 0.99893, l2: 0.03183\n",
            "Loss: 2.193706e-06, l1: 0.99894, l2: 0.03183\n",
            "Loss: 2.187586e-06, l1: 0.99893, l2: 0.03183\n",
            "Loss: 2.185042e-06, l1: 0.99895, l2: 0.03183\n",
            "Loss: 2.183117e-06, l1: 0.99897, l2: 0.03183\n",
            "Loss: 2.181014e-06, l1: 0.99898, l2: 0.03184\n",
            "Loss: 2.179960e-06, l1: 0.99902, l2: 0.03184\n",
            "Loss: 2.177106e-06, l1: 0.99899, l2: 0.03184\n",
            "Loss: 2.175595e-06, l1: 0.99897, l2: 0.03184\n",
            "Loss: 2.173014e-06, l1: 0.99894, l2: 0.03184\n",
            "Loss: 2.169140e-06, l1: 0.99892, l2: 0.03184\n",
            "Loss: 2.163757e-06, l1: 0.99890, l2: 0.03184\n",
            "Loss: 2.157489e-06, l1: 0.99890, l2: 0.03184\n",
            "Loss: 2.157774e-06, l1: 0.99894, l2: 0.03185\n",
            "Loss: 2.152527e-06, l1: 0.99892, l2: 0.03184\n",
            "Loss: 2.148228e-06, l1: 0.99895, l2: 0.03184\n",
            "Loss: 2.145151e-06, l1: 0.99899, l2: 0.03184\n",
            "Loss: 2.147382e-06, l1: 0.99904, l2: 0.03184\n",
            "Loss: 2.143800e-06, l1: 0.99901, l2: 0.03184\n",
            "Loss: 2.142312e-06, l1: 0.99902, l2: 0.03184\n",
            "Loss: 2.136913e-06, l1: 0.99905, l2: 0.03184\n",
            "Loss: 2.133922e-06, l1: 0.99908, l2: 0.03184\n",
            "Loss: 2.130445e-06, l1: 0.99912, l2: 0.03184\n",
            "Loss: 2.128321e-06, l1: 0.99915, l2: 0.03184\n",
            "Loss: 2.127106e-06, l1: 0.99916, l2: 0.03184\n",
            "Loss: 2.125669e-06, l1: 0.99917, l2: 0.03184\n",
            "Loss: 2.123772e-06, l1: 0.99919, l2: 0.03184\n",
            "Loss: 2.122851e-06, l1: 0.99926, l2: 0.03184\n",
            "Loss: 2.123577e-06, l1: 0.99924, l2: 0.03184\n",
            "Loss: 2.122225e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 2.120912e-06, l1: 0.99924, l2: 0.03184\n",
            "Loss: 2.119893e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 2.117305e-06, l1: 0.99927, l2: 0.03184\n",
            "Loss: 2.123702e-06, l1: 0.99935, l2: 0.03184\n",
            "Loss: 2.116488e-06, l1: 0.99929, l2: 0.03184\n",
            "Loss: 2.114208e-06, l1: 0.99931, l2: 0.03184\n",
            "Loss: 2.111639e-06, l1: 0.99934, l2: 0.03184\n",
            "Loss: 2.109845e-06, l1: 0.99936, l2: 0.03184\n",
            "Loss: 2.108650e-06, l1: 0.99935, l2: 0.03184\n",
            "Loss: 2.107518e-06, l1: 0.99936, l2: 0.03184\n",
            "Loss: 2.105952e-06, l1: 0.99936, l2: 0.03184\n",
            "Loss: 2.102390e-06, l1: 0.99936, l2: 0.03184\n",
            "Loss: 2.099964e-06, l1: 0.99934, l2: 0.03184\n",
            "Loss: 2.136955e-06, l1: 0.99941, l2: 0.03184\n",
            "Loss: 2.098908e-06, l1: 0.99935, l2: 0.03184\n",
            "Loss: 2.097412e-06, l1: 0.99935, l2: 0.03184\n",
            "Loss: 2.095612e-06, l1: 0.99935, l2: 0.03184\n",
            "Loss: 2.092890e-06, l1: 0.99935, l2: 0.03184\n",
            "Loss: 2.094285e-06, l1: 0.99936, l2: 0.03184\n",
            "Loss: 2.091566e-06, l1: 0.99936, l2: 0.03184\n",
            "Loss: 2.089153e-06, l1: 0.99937, l2: 0.03184\n",
            "Loss: 2.086476e-06, l1: 0.99939, l2: 0.03185\n",
            "Loss: 2.083549e-06, l1: 0.99942, l2: 0.03185\n",
            "Loss: 2.079729e-06, l1: 0.99949, l2: 0.03185\n",
            "Loss: 2.076858e-06, l1: 0.99951, l2: 0.03185\n",
            "Loss: 2.075465e-06, l1: 0.99950, l2: 0.03185\n",
            "Loss: 2.073446e-06, l1: 0.99949, l2: 0.03185\n",
            "Loss: 2.071145e-06, l1: 0.99948, l2: 0.03185\n",
            "Loss: 2.071302e-06, l1: 0.99944, l2: 0.03185\n",
            "Loss: 2.068762e-06, l1: 0.99946, l2: 0.03185\n",
            "Loss: 2.065163e-06, l1: 0.99945, l2: 0.03185\n",
            "Loss: 2.063481e-06, l1: 0.99945, l2: 0.03185\n",
            "Loss: 2.062264e-06, l1: 0.99944, l2: 0.03185\n",
            "Loss: 2.061324e-06, l1: 0.99943, l2: 0.03185\n",
            "Loss: 2.062492e-06, l1: 0.99944, l2: 0.03185\n",
            "Loss: 2.060701e-06, l1: 0.99944, l2: 0.03185\n",
            "Loss: 2.059589e-06, l1: 0.99941, l2: 0.03185\n",
            "Loss: 2.058711e-06, l1: 0.99941, l2: 0.03185\n",
            "Loss: 2.057940e-06, l1: 0.99941, l2: 0.03185\n",
            "Loss: 2.056623e-06, l1: 0.99942, l2: 0.03185\n",
            "Loss: 2.057090e-06, l1: 0.99944, l2: 0.03185\n",
            "Loss: 2.055539e-06, l1: 0.99943, l2: 0.03185\n",
            "Loss: 2.053346e-06, l1: 0.99944, l2: 0.03185\n",
            "Loss: 2.050043e-06, l1: 0.99946, l2: 0.03185\n",
            "Loss: 2.048257e-06, l1: 0.99946, l2: 0.03185\n",
            "Loss: 2.045054e-06, l1: 0.99944, l2: 0.03185\n",
            "Loss: 2.049845e-06, l1: 0.99938, l2: 0.03185\n",
            "Loss: 2.043882e-06, l1: 0.99942, l2: 0.03185\n",
            "Loss: 2.041085e-06, l1: 0.99940, l2: 0.03185\n",
            "Loss: 2.036656e-06, l1: 0.99934, l2: 0.03185\n",
            "Loss: 2.034458e-06, l1: 0.99931, l2: 0.03185\n",
            "Loss: 2.033018e-06, l1: 0.99928, l2: 0.03185\n",
            "Loss: 2.031118e-06, l1: 0.99929, l2: 0.03185\n",
            "Loss: 2.028918e-06, l1: 0.99929, l2: 0.03185\n",
            "Loss: 2.026628e-06, l1: 0.99928, l2: 0.03185\n",
            "Loss: 2.022611e-06, l1: 0.99924, l2: 0.03186\n",
            "Loss: 2.023202e-06, l1: 0.99916, l2: 0.03186\n",
            "Loss: 2.020064e-06, l1: 0.99920, l2: 0.03186\n",
            "Loss: 2.032579e-06, l1: 0.99907, l2: 0.03186\n",
            "Loss: 2.019101e-06, l1: 0.99917, l2: 0.03186\n",
            "Loss: 2.017011e-06, l1: 0.99914, l2: 0.03186\n",
            "Loss: 2.015991e-06, l1: 0.99912, l2: 0.03186\n",
            "Loss: 2.015612e-06, l1: 0.99911, l2: 0.03186\n",
            "Loss: 2.014781e-06, l1: 0.99910, l2: 0.03186\n",
            "Loss: 2.017377e-06, l1: 0.99914, l2: 0.03186\n",
            "Loss: 2.014478e-06, l1: 0.99911, l2: 0.03186\n",
            "Loss: 2.013286e-06, l1: 0.99910, l2: 0.03186\n",
            "Loss: 2.011599e-06, l1: 0.99909, l2: 0.03186\n",
            "Loss: 2.009628e-06, l1: 0.99908, l2: 0.03186\n",
            "Loss: 2.007577e-06, l1: 0.99908, l2: 0.03186\n",
            "Loss: 2.002663e-06, l1: 0.99909, l2: 0.03186\n",
            "Loss: 1.996459e-06, l1: 0.99911, l2: 0.03186\n",
            "Loss: 1.993818e-06, l1: 0.99911, l2: 0.03186\n",
            "Loss: 1.991206e-06, l1: 0.99913, l2: 0.03186\n",
            "Loss: 1.990365e-06, l1: 0.99913, l2: 0.03186\n",
            "Loss: 1.988904e-06, l1: 0.99915, l2: 0.03186\n",
            "Loss: 1.986495e-06, l1: 0.99918, l2: 0.03186\n",
            "Loss: 1.984067e-06, l1: 0.99921, l2: 0.03186\n",
            "Loss: 1.981716e-06, l1: 0.99923, l2: 0.03186\n",
            "Loss: 1.978565e-06, l1: 0.99925, l2: 0.03187\n",
            "Loss: 1.979211e-06, l1: 0.99933, l2: 0.03187\n",
            "Loss: 1.975662e-06, l1: 0.99929, l2: 0.03187\n",
            "Loss: 1.972861e-06, l1: 0.99928, l2: 0.03187\n",
            "Loss: 1.967322e-06, l1: 0.99928, l2: 0.03187\n",
            "Loss: 1.964803e-06, l1: 0.99930, l2: 0.03187\n",
            "Loss: 1.960227e-06, l1: 0.99934, l2: 0.03187\n",
            "Loss: 1.959942e-06, l1: 0.99937, l2: 0.03187\n",
            "Loss: 1.958132e-06, l1: 0.99935, l2: 0.03187\n",
            "Loss: 1.956335e-06, l1: 0.99937, l2: 0.03187\n",
            "Loss: 1.954325e-06, l1: 0.99938, l2: 0.03187\n",
            "Loss: 1.952318e-06, l1: 0.99939, l2: 0.03187\n",
            "Loss: 1.948423e-06, l1: 0.99939, l2: 0.03187\n",
            "Loss: 1.946240e-06, l1: 0.99940, l2: 0.03187\n",
            "Loss: 1.943751e-06, l1: 0.99939, l2: 0.03187\n",
            "Loss: 1.941454e-06, l1: 0.99938, l2: 0.03187\n",
            "Loss: 1.939751e-06, l1: 0.99936, l2: 0.03187\n",
            "Loss: 1.938241e-06, l1: 0.99938, l2: 0.03187\n",
            "Loss: 1.937318e-06, l1: 0.99939, l2: 0.03187\n",
            "Loss: 1.936809e-06, l1: 0.99940, l2: 0.03187\n",
            "Loss: 1.936299e-06, l1: 0.99940, l2: 0.03187\n",
            "Loss: 1.934864e-06, l1: 0.99939, l2: 0.03187\n",
            "Loss: 1.934195e-06, l1: 0.99939, l2: 0.03187\n",
            "Loss: 1.932221e-06, l1: 0.99938, l2: 0.03187\n",
            "Loss: 1.937295e-06, l1: 0.99947, l2: 0.03187\n",
            "Loss: 1.931507e-06, l1: 0.99940, l2: 0.03187\n",
            "Loss: 1.931584e-06, l1: 0.99942, l2: 0.03187\n",
            "Loss: 1.930440e-06, l1: 0.99941, l2: 0.03187\n",
            "Loss: 1.929615e-06, l1: 0.99941, l2: 0.03187\n",
            "Loss: 1.928474e-06, l1: 0.99942, l2: 0.03187\n",
            "Loss: 1.927001e-06, l1: 0.99943, l2: 0.03187\n",
            "Loss: 1.925303e-06, l1: 0.99944, l2: 0.03187\n",
            "Loss: 1.922971e-06, l1: 0.99945, l2: 0.03187\n",
            "Loss: 1.920460e-06, l1: 0.99947, l2: 0.03187\n",
            "Loss: 1.918810e-06, l1: 0.99947, l2: 0.03187\n",
            "Loss: 1.916331e-06, l1: 0.99949, l2: 0.03187\n",
            "Loss: 1.915408e-06, l1: 0.99946, l2: 0.03187\n",
            "Loss: 1.914307e-06, l1: 0.99948, l2: 0.03187\n",
            "Loss: 1.913844e-06, l1: 0.99949, l2: 0.03187\n",
            "Loss: 1.912900e-06, l1: 0.99948, l2: 0.03187\n",
            "Loss: 1.912408e-06, l1: 0.99947, l2: 0.03187\n",
            "Loss: 1.911306e-06, l1: 0.99947, l2: 0.03187\n",
            "Loss: 1.910269e-06, l1: 0.99948, l2: 0.03187\n",
            "Loss: 1.908935e-06, l1: 0.99949, l2: 0.03187\n",
            "Loss: 1.961081e-06, l1: 0.99965, l2: 0.03187\n",
            "Loss: 1.908865e-06, l1: 0.99950, l2: 0.03187\n",
            "Loss: 1.907696e-06, l1: 0.99952, l2: 0.03187\n",
            "Loss: 1.906567e-06, l1: 0.99954, l2: 0.03187\n",
            "Loss: 1.905409e-06, l1: 0.99955, l2: 0.03187\n",
            "Loss: 1.904071e-06, l1: 0.99955, l2: 0.03187\n",
            "Loss: 1.902755e-06, l1: 0.99954, l2: 0.03187\n",
            "Loss: 1.901750e-06, l1: 0.99951, l2: 0.03187\n",
            "Loss: 1.900659e-06, l1: 0.99951, l2: 0.03187\n",
            "Loss: 1.899251e-06, l1: 0.99949, l2: 0.03187\n",
            "Loss: 1.897935e-06, l1: 0.99946, l2: 0.03187\n",
            "Loss: 1.895453e-06, l1: 0.99942, l2: 0.03187\n",
            "Loss: 1.894600e-06, l1: 0.99937, l2: 0.03187\n",
            "Loss: 1.892598e-06, l1: 0.99939, l2: 0.03187\n",
            "Loss: 1.891321e-06, l1: 0.99941, l2: 0.03187\n",
            "Loss: 1.890115e-06, l1: 0.99942, l2: 0.03187\n",
            "Loss: 1.888365e-06, l1: 0.99944, l2: 0.03187\n",
            "Loss: 1.885661e-06, l1: 0.99945, l2: 0.03187\n",
            "Loss: 1.888539e-06, l1: 0.99950, l2: 0.03187\n",
            "Loss: 1.883127e-06, l1: 0.99947, l2: 0.03187\n",
            "Loss: 1.880276e-06, l1: 0.99945, l2: 0.03187\n",
            "Loss: 1.877515e-06, l1: 0.99941, l2: 0.03187\n",
            "Loss: 1.875472e-06, l1: 0.99938, l2: 0.03187\n",
            "Loss: 1.871779e-06, l1: 0.99933, l2: 0.03187\n",
            "Loss: 1.868535e-06, l1: 0.99930, l2: 0.03187\n",
            "Loss: 1.906433e-06, l1: 0.99920, l2: 0.03187\n",
            "Loss: 1.867730e-06, l1: 0.99929, l2: 0.03187\n",
            "Loss: 1.865041e-06, l1: 0.99928, l2: 0.03187\n",
            "Loss: 1.862982e-06, l1: 0.99928, l2: 0.03187\n",
            "Loss: 1.861225e-06, l1: 0.99929, l2: 0.03187\n",
            "Loss: 1.859322e-06, l1: 0.99928, l2: 0.03187\n",
            "Loss: 1.858486e-06, l1: 0.99930, l2: 0.03187\n",
            "Loss: 1.856680e-06, l1: 0.99929, l2: 0.03187\n",
            "Loss: 1.855713e-06, l1: 0.99928, l2: 0.03187\n",
            "Loss: 1.854832e-06, l1: 0.99928, l2: 0.03187\n",
            "Loss: 1.853382e-06, l1: 0.99929, l2: 0.03186\n",
            "Loss: 1.852030e-06, l1: 0.99930, l2: 0.03186\n",
            "Loss: 1.849400e-06, l1: 0.99932, l2: 0.03186\n",
            "Loss: 1.855730e-06, l1: 0.99939, l2: 0.03186\n",
            "Loss: 1.847247e-06, l1: 0.99935, l2: 0.03186\n",
            "Loss: 1.844358e-06, l1: 0.99935, l2: 0.03186\n",
            "Loss: 1.839913e-06, l1: 0.99936, l2: 0.03186\n",
            "Loss: 1.838134e-06, l1: 0.99936, l2: 0.03186\n",
            "Loss: 1.835643e-06, l1: 0.99934, l2: 0.03186\n",
            "Loss: 1.833753e-06, l1: 0.99933, l2: 0.03186\n",
            "Loss: 1.832154e-06, l1: 0.99931, l2: 0.03186\n",
            "Loss: 1.830083e-06, l1: 0.99929, l2: 0.03186\n",
            "Loss: 1.828601e-06, l1: 0.99929, l2: 0.03185\n",
            "Loss: 1.827353e-06, l1: 0.99923, l2: 0.03185\n",
            "Loss: 1.824828e-06, l1: 0.99925, l2: 0.03185\n",
            "Loss: 1.823981e-06, l1: 0.99926, l2: 0.03185\n",
            "Loss: 1.821773e-06, l1: 0.99927, l2: 0.03185\n",
            "Loss: 1.820444e-06, l1: 0.99929, l2: 0.03185\n",
            "Loss: 1.818127e-06, l1: 0.99927, l2: 0.03185\n",
            "Loss: 1.815486e-06, l1: 0.99925, l2: 0.03185\n",
            "Loss: 1.813874e-06, l1: 0.99925, l2: 0.03185\n",
            "Loss: 1.811068e-06, l1: 0.99924, l2: 0.03185\n",
            "Loss: 1.876808e-06, l1: 0.99940, l2: 0.03184\n",
            "Loss: 1.810536e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 1.808903e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 1.806946e-06, l1: 0.99927, l2: 0.03184\n",
            "Loss: 1.805064e-06, l1: 0.99929, l2: 0.03184\n",
            "Loss: 1.803713e-06, l1: 0.99932, l2: 0.03184\n",
            "Loss: 1.802703e-06, l1: 0.99934, l2: 0.03184\n",
            "Loss: 1.801098e-06, l1: 0.99933, l2: 0.03184\n",
            "Loss: 1.799104e-06, l1: 0.99932, l2: 0.03184\n",
            "Loss: 1.796186e-06, l1: 0.99931, l2: 0.03184\n",
            "Loss: 1.790644e-06, l1: 0.99931, l2: 0.03183\n",
            "Loss: 1.782841e-06, l1: 0.99936, l2: 0.03183\n",
            "Loss: 1.783618e-06, l1: 0.99945, l2: 0.03182\n",
            "Loss: 1.780310e-06, l1: 0.99940, l2: 0.03183\n",
            "Loss: 1.775792e-06, l1: 0.99945, l2: 0.03182\n",
            "Loss: 1.774755e-06, l1: 0.99945, l2: 0.03182\n",
            "Loss: 1.774099e-06, l1: 0.99945, l2: 0.03182\n",
            "Loss: 1.772678e-06, l1: 0.99946, l2: 0.03182\n",
            "Loss: 1.769442e-06, l1: 0.99947, l2: 0.03182\n",
            "Loss: 1.766912e-06, l1: 0.99950, l2: 0.03182\n",
            "Loss: 1.764699e-06, l1: 0.99952, l2: 0.03182\n",
            "Loss: 1.762542e-06, l1: 0.99954, l2: 0.03181\n",
            "Loss: 1.760378e-06, l1: 0.99957, l2: 0.03181\n",
            "Loss: 1.757870e-06, l1: 0.99959, l2: 0.03181\n",
            "Loss: 1.755360e-06, l1: 0.99962, l2: 0.03181\n",
            "Loss: 1.753877e-06, l1: 0.99961, l2: 0.03181\n",
            "Loss: 1.752384e-06, l1: 0.99960, l2: 0.03181\n",
            "Loss: 1.751385e-06, l1: 0.99959, l2: 0.03181\n",
            "Loss: 1.749594e-06, l1: 0.99959, l2: 0.03181\n",
            "Loss: 1.770330e-06, l1: 0.99966, l2: 0.03181\n",
            "Loss: 1.749223e-06, l1: 0.99959, l2: 0.03181\n",
            "Loss: 1.748099e-06, l1: 0.99958, l2: 0.03180\n",
            "Loss: 1.746774e-06, l1: 0.99957, l2: 0.03180\n",
            "Loss: 1.745417e-06, l1: 0.99955, l2: 0.03180\n",
            "Loss: 1.744193e-06, l1: 0.99954, l2: 0.03180\n",
            "Loss: 1.742821e-06, l1: 0.99952, l2: 0.03180\n",
            "Loss: 1.740960e-06, l1: 0.99950, l2: 0.03180\n",
            "Loss: 1.739236e-06, l1: 0.99947, l2: 0.03180\n",
            "Loss: 1.736770e-06, l1: 0.99947, l2: 0.03180\n",
            "Loss: 1.734690e-06, l1: 0.99946, l2: 0.03180\n",
            "Loss: 1.733233e-06, l1: 0.99945, l2: 0.03180\n",
            "Loss: 1.730920e-06, l1: 0.99942, l2: 0.03180\n",
            "Loss: 1.728434e-06, l1: 0.99940, l2: 0.03180\n",
            "Loss: 1.726029e-06, l1: 0.99937, l2: 0.03180\n",
            "Loss: 1.723864e-06, l1: 0.99935, l2: 0.03180\n",
            "Loss: 1.722537e-06, l1: 0.99935, l2: 0.03180\n",
            "Loss: 1.721317e-06, l1: 0.99935, l2: 0.03180\n",
            "Loss: 1.719681e-06, l1: 0.99935, l2: 0.03180\n",
            "Loss: 1.719314e-06, l1: 0.99932, l2: 0.03180\n",
            "Loss: 1.717655e-06, l1: 0.99933, l2: 0.03180\n",
            "Loss: 1.717000e-06, l1: 0.99934, l2: 0.03180\n",
            "Loss: 1.716069e-06, l1: 0.99934, l2: 0.03180\n",
            "Loss: 1.715900e-06, l1: 0.99936, l2: 0.03180\n",
            "Loss: 1.714504e-06, l1: 0.99935, l2: 0.03180\n",
            "Loss: 1.713634e-06, l1: 0.99935, l2: 0.03180\n",
            "Loss: 1.712138e-06, l1: 0.99937, l2: 0.03180\n",
            "Loss: 1.711095e-06, l1: 0.99941, l2: 0.03181\n",
            "Loss: 1.709279e-06, l1: 0.99943, l2: 0.03180\n",
            "Loss: 1.705860e-06, l1: 0.99946, l2: 0.03180\n",
            "Loss: 1.704816e-06, l1: 0.99949, l2: 0.03180\n",
            "Loss: 1.706339e-06, l1: 0.99950, l2: 0.03180\n",
            "Loss: 1.703692e-06, l1: 0.99950, l2: 0.03180\n",
            "Loss: 1.702965e-06, l1: 0.99948, l2: 0.03180\n",
            "Loss: 1.702222e-06, l1: 0.99946, l2: 0.03180\n",
            "Loss: 1.700811e-06, l1: 0.99946, l2: 0.03180\n",
            "Loss: 1.698128e-06, l1: 0.99946, l2: 0.03180\n",
            "Loss: 1.695462e-06, l1: 0.99950, l2: 0.03180\n",
            "Loss: 1.767186e-06, l1: 0.99957, l2: 0.03180\n",
            "Loss: 1.694920e-06, l1: 0.99950, l2: 0.03180\n",
            "Loss: 1.693328e-06, l1: 0.99953, l2: 0.03180\n",
            "Loss: 1.692270e-06, l1: 0.99955, l2: 0.03180\n",
            "Loss: 1.690804e-06, l1: 0.99955, l2: 0.03180\n",
            "Loss: 1.688376e-06, l1: 0.99956, l2: 0.03180\n",
            "Loss: 1.686903e-06, l1: 0.99950, l2: 0.03180\n",
            "Loss: 1.685152e-06, l1: 0.99950, l2: 0.03180\n",
            "Loss: 1.684094e-06, l1: 0.99950, l2: 0.03180\n",
            "Loss: 1.683380e-06, l1: 0.99949, l2: 0.03180\n",
            "Loss: 1.681696e-06, l1: 0.99948, l2: 0.03180\n",
            "Loss: 1.691313e-06, l1: 0.99957, l2: 0.03179\n",
            "Loss: 1.681512e-06, l1: 0.99950, l2: 0.03180\n",
            "Loss: 1.680310e-06, l1: 0.99950, l2: 0.03180\n",
            "Loss: 1.678544e-06, l1: 0.99952, l2: 0.03180\n",
            "Loss: 1.676131e-06, l1: 0.99953, l2: 0.03180\n",
            "Loss: 1.672770e-06, l1: 0.99954, l2: 0.03180\n",
            "Loss: 1.667664e-06, l1: 0.99950, l2: 0.03180\n",
            "Loss: 1.671010e-06, l1: 0.99947, l2: 0.03181\n",
            "Loss: 1.664699e-06, l1: 0.99949, l2: 0.03180\n",
            "Loss: 1.661388e-06, l1: 0.99945, l2: 0.03181\n",
            "Loss: 1.659055e-06, l1: 0.99940, l2: 0.03181\n",
            "Loss: 1.656669e-06, l1: 0.99940, l2: 0.03181\n",
            "Loss: 1.653705e-06, l1: 0.99941, l2: 0.03180\n",
            "Loss: 1.652585e-06, l1: 0.99943, l2: 0.03180\n",
            "Loss: 1.650405e-06, l1: 0.99944, l2: 0.03180\n",
            "Loss: 1.648276e-06, l1: 0.99945, l2: 0.03180\n",
            "Loss: 1.649962e-06, l1: 0.99946, l2: 0.03180\n",
            "Loss: 1.647289e-06, l1: 0.99945, l2: 0.03180\n",
            "Loss: 1.645708e-06, l1: 0.99944, l2: 0.03180\n",
            "Loss: 1.644005e-06, l1: 0.99944, l2: 0.03180\n",
            "Loss: 1.641548e-06, l1: 0.99945, l2: 0.03180\n",
            "Loss: 1.639621e-06, l1: 0.99947, l2: 0.03180\n",
            "Loss: 1.636032e-06, l1: 0.99946, l2: 0.03181\n",
            "Loss: 1.632335e-06, l1: 0.99946, l2: 0.03181\n",
            "Loss: 1.630972e-06, l1: 0.99945, l2: 0.03181\n",
            "Loss: 1.629784e-06, l1: 0.99944, l2: 0.03181\n",
            "Loss: 1.628862e-06, l1: 0.99943, l2: 0.03181\n",
            "Loss: 1.627618e-06, l1: 0.99942, l2: 0.03181\n",
            "Loss: 1.626685e-06, l1: 0.99942, l2: 0.03181\n",
            "Loss: 1.624525e-06, l1: 0.99941, l2: 0.03181\n",
            "Loss: 1.623097e-06, l1: 0.99942, l2: 0.03181\n",
            "Loss: 1.622051e-06, l1: 0.99942, l2: 0.03181\n",
            "Loss: 1.620769e-06, l1: 0.99944, l2: 0.03181\n",
            "Loss: 1.619428e-06, l1: 0.99944, l2: 0.03181\n",
            "Loss: 1.622812e-06, l1: 0.99942, l2: 0.03182\n",
            "Loss: 1.618954e-06, l1: 0.99943, l2: 0.03181\n",
            "Loss: 1.618124e-06, l1: 0.99943, l2: 0.03181\n",
            "Loss: 1.614859e-06, l1: 0.99945, l2: 0.03181\n",
            "Loss: 1.612961e-06, l1: 0.99946, l2: 0.03182\n",
            "Loss: 1.610763e-06, l1: 0.99948, l2: 0.03182\n",
            "Loss: 1.611279e-06, l1: 0.99952, l2: 0.03182\n",
            "Loss: 1.609428e-06, l1: 0.99950, l2: 0.03182\n",
            "Loss: 1.607561e-06, l1: 0.99951, l2: 0.03182\n",
            "Loss: 1.604945e-06, l1: 0.99952, l2: 0.03182\n",
            "Loss: 1.603299e-06, l1: 0.99952, l2: 0.03182\n",
            "Loss: 1.600017e-06, l1: 0.99951, l2: 0.03182\n",
            "Loss: 1.596471e-06, l1: 0.99949, l2: 0.03183\n",
            "Loss: 1.595059e-06, l1: 0.99951, l2: 0.03183\n",
            "Loss: 1.589821e-06, l1: 0.99947, l2: 0.03183\n",
            "Loss: 1.587920e-06, l1: 0.99949, l2: 0.03183\n",
            "Loss: 1.585200e-06, l1: 0.99951, l2: 0.03183\n",
            "Loss: 1.581363e-06, l1: 0.99953, l2: 0.03183\n",
            "Loss: 1.577997e-06, l1: 0.99954, l2: 0.03183\n",
            "Loss: 1.575017e-06, l1: 0.99955, l2: 0.03183\n",
            "Loss: 1.573614e-06, l1: 0.99953, l2: 0.03184\n",
            "Loss: 1.573044e-06, l1: 0.99952, l2: 0.03184\n",
            "Loss: 1.572244e-06, l1: 0.99951, l2: 0.03184\n",
            "Loss: 1.571040e-06, l1: 0.99953, l2: 0.03184\n",
            "Loss: 1.574990e-06, l1: 0.99952, l2: 0.03184\n",
            "Loss: 1.569693e-06, l1: 0.99952, l2: 0.03184\n",
            "Loss: 1.568366e-06, l1: 0.99954, l2: 0.03184\n",
            "Loss: 1.566734e-06, l1: 0.99959, l2: 0.03184\n",
            "Loss: 1.566194e-06, l1: 0.99961, l2: 0.03184\n",
            "Loss: 1.564381e-06, l1: 0.99965, l2: 0.03183\n",
            "Loss: 1.563484e-06, l1: 0.99966, l2: 0.03183\n",
            "Loss: 1.562864e-06, l1: 0.99966, l2: 0.03183\n",
            "Loss: 1.561657e-06, l1: 0.99964, l2: 0.03183\n",
            "Loss: 1.560580e-06, l1: 0.99963, l2: 0.03184\n",
            "Loss: 1.558378e-06, l1: 0.99963, l2: 0.03184\n",
            "Loss: 1.555932e-06, l1: 0.99964, l2: 0.03184\n",
            "Loss: 1.553467e-06, l1: 0.99966, l2: 0.03184\n",
            "Loss: 1.550579e-06, l1: 0.99968, l2: 0.03184\n",
            "Loss: 1.548883e-06, l1: 0.99969, l2: 0.03184\n",
            "Loss: 1.547889e-06, l1: 0.99969, l2: 0.03184\n",
            "Loss: 1.546987e-06, l1: 0.99968, l2: 0.03184\n",
            "Loss: 1.545898e-06, l1: 0.99968, l2: 0.03184\n",
            "Loss: 1.544336e-06, l1: 0.99969, l2: 0.03184\n",
            "Loss: 1.542805e-06, l1: 0.99970, l2: 0.03184\n",
            "Loss: 1.541020e-06, l1: 0.99972, l2: 0.03184\n",
            "Loss: 1.538663e-06, l1: 0.99973, l2: 0.03184\n",
            "Loss: 1.543387e-06, l1: 0.99983, l2: 0.03184\n",
            "Loss: 1.536739e-06, l1: 0.99976, l2: 0.03184\n",
            "Loss: 1.534942e-06, l1: 0.99977, l2: 0.03184\n",
            "Loss: 1.533388e-06, l1: 0.99977, l2: 0.03184\n",
            "Loss: 1.532086e-06, l1: 0.99978, l2: 0.03184\n",
            "Loss: 1.530861e-06, l1: 0.99978, l2: 0.03184\n",
            "Loss: 1.527856e-06, l1: 0.99979, l2: 0.03184\n",
            "Loss: 1.525619e-06, l1: 0.99981, l2: 0.03184\n",
            "Loss: 1.523862e-06, l1: 0.99982, l2: 0.03184\n",
            "Loss: 1.522678e-06, l1: 0.99981, l2: 0.03184\n",
            "Loss: 1.521749e-06, l1: 0.99980, l2: 0.03184\n",
            "Loss: 1.520576e-06, l1: 0.99980, l2: 0.03184\n",
            "Loss: 1.518437e-06, l1: 0.99980, l2: 0.03184\n",
            "Loss: 1.517325e-06, l1: 0.99978, l2: 0.03184\n",
            "Loss: 1.515950e-06, l1: 0.99979, l2: 0.03184\n",
            "Loss: 1.514643e-06, l1: 0.99979, l2: 0.03184\n",
            "Loss: 1.513444e-06, l1: 0.99979, l2: 0.03184\n",
            "Loss: 1.511573e-06, l1: 0.99979, l2: 0.03184\n",
            "Loss: 1.524162e-06, l1: 0.99983, l2: 0.03184\n",
            "Loss: 1.510740e-06, l1: 0.99979, l2: 0.03184\n",
            "Loss: 1.509318e-06, l1: 0.99979, l2: 0.03184\n",
            "Loss: 1.507846e-06, l1: 0.99980, l2: 0.03184\n",
            "Loss: 1.507203e-06, l1: 0.99981, l2: 0.03184\n",
            "Loss: 1.506819e-06, l1: 0.99987, l2: 0.03184\n",
            "Loss: 1.505556e-06, l1: 0.99985, l2: 0.03184\n",
            "Loss: 1.504864e-06, l1: 0.99985, l2: 0.03184\n",
            "Loss: 1.504111e-06, l1: 0.99986, l2: 0.03184\n",
            "Loss: 1.503581e-06, l1: 0.99986, l2: 0.03184\n",
            "Loss: 1.503464e-06, l1: 0.99987, l2: 0.03184\n",
            "Loss: 1.503104e-06, l1: 0.99986, l2: 0.03184\n",
            "Loss: 1.502824e-06, l1: 0.99985, l2: 0.03184\n",
            "Loss: 1.502460e-06, l1: 0.99984, l2: 0.03184\n",
            "Loss: 1.501696e-06, l1: 0.99982, l2: 0.03184\n",
            "Loss: 1.503500e-06, l1: 0.99975, l2: 0.03184\n",
            "Loss: 1.501133e-06, l1: 0.99980, l2: 0.03184\n",
            "Loss: 1.500477e-06, l1: 0.99979, l2: 0.03184\n",
            "Loss: 1.499713e-06, l1: 0.99979, l2: 0.03184\n",
            "Loss: 1.499190e-06, l1: 0.99978, l2: 0.03184\n",
            "Loss: 1.497664e-06, l1: 0.99977, l2: 0.03184\n",
            "Loss: 1.495596e-06, l1: 0.99975, l2: 0.03184\n",
            "Loss: 1.567729e-06, l1: 0.99966, l2: 0.03184\n",
            "Loss: 1.495152e-06, l1: 0.99974, l2: 0.03184\n",
            "Loss: 1.492699e-06, l1: 0.99971, l2: 0.03184\n",
            "Loss: 1.491072e-06, l1: 0.99970, l2: 0.03184\n",
            "Loss: 1.490197e-06, l1: 0.99969, l2: 0.03184\n",
            "Loss: 1.489314e-06, l1: 0.99968, l2: 0.03184\n",
            "Loss: 1.488142e-06, l1: 0.99967, l2: 0.03184\n",
            "Loss: 1.488192e-06, l1: 0.99966, l2: 0.03184\n",
            "Loss: 1.487503e-06, l1: 0.99967, l2: 0.03184\n",
            "Loss: 1.486295e-06, l1: 0.99965, l2: 0.03184\n",
            "Loss: 1.485224e-06, l1: 0.99964, l2: 0.03184\n",
            "Loss: 1.483994e-06, l1: 0.99962, l2: 0.03184\n",
            "Loss: 1.482276e-06, l1: 0.99960, l2: 0.03184\n",
            "Loss: 1.513748e-06, l1: 0.99950, l2: 0.03185\n",
            "Loss: 1.481880e-06, l1: 0.99959, l2: 0.03184\n",
            "Loss: 1.480268e-06, l1: 0.99957, l2: 0.03184\n",
            "Loss: 1.479304e-06, l1: 0.99956, l2: 0.03184\n",
            "Loss: 1.478658e-06, l1: 0.99956, l2: 0.03184\n",
            "Loss: 1.477904e-06, l1: 0.99954, l2: 0.03184\n",
            "Loss: 1.476742e-06, l1: 0.99953, l2: 0.03184\n",
            "Loss: 1.492283e-06, l1: 0.99945, l2: 0.03184\n",
            "Loss: 1.476333e-06, l1: 0.99952, l2: 0.03184\n",
            "Loss: 1.474654e-06, l1: 0.99949, l2: 0.03184\n",
            "Loss: 1.472908e-06, l1: 0.99948, l2: 0.03184\n",
            "Loss: 1.470988e-06, l1: 0.99948, l2: 0.03184\n",
            "Loss: 1.468820e-06, l1: 0.99947, l2: 0.03184\n",
            "Loss: 1.469237e-06, l1: 0.99949, l2: 0.03184\n",
            "Loss: 1.466971e-06, l1: 0.99948, l2: 0.03184\n",
            "Loss: 1.463494e-06, l1: 0.99946, l2: 0.03184\n",
            "Loss: 1.462211e-06, l1: 0.99945, l2: 0.03184\n",
            "Loss: 1.461443e-06, l1: 0.99944, l2: 0.03184\n",
            "Loss: 1.460631e-06, l1: 0.99943, l2: 0.03183\n",
            "Loss: 1.458565e-06, l1: 0.99940, l2: 0.03184\n",
            "Loss: 1.457175e-06, l1: 0.99938, l2: 0.03184\n",
            "Loss: 1.456172e-06, l1: 0.99937, l2: 0.03184\n",
            "Loss: 1.455196e-06, l1: 0.99935, l2: 0.03184\n",
            "Loss: 1.454050e-06, l1: 0.99936, l2: 0.03184\n",
            "Loss: 1.452883e-06, l1: 0.99936, l2: 0.03184\n",
            "Loss: 1.451901e-06, l1: 0.99935, l2: 0.03184\n",
            "Loss: 1.450287e-06, l1: 0.99934, l2: 0.03184\n",
            "Loss: 1.448671e-06, l1: 0.99933, l2: 0.03184\n",
            "Loss: 1.447680e-06, l1: 0.99931, l2: 0.03184\n",
            "Loss: 1.446769e-06, l1: 0.99929, l2: 0.03184\n",
            "Loss: 1.445824e-06, l1: 0.99927, l2: 0.03184\n",
            "Loss: 1.444617e-06, l1: 0.99924, l2: 0.03184\n",
            "Loss: 1.444320e-06, l1: 0.99921, l2: 0.03184\n",
            "Loss: 1.443282e-06, l1: 0.99922, l2: 0.03184\n",
            "Loss: 1.442842e-06, l1: 0.99922, l2: 0.03184\n",
            "Loss: 1.442387e-06, l1: 0.99922, l2: 0.03184\n",
            "Loss: 1.442173e-06, l1: 0.99923, l2: 0.03184\n",
            "Loss: 1.442197e-06, l1: 0.99919, l2: 0.03184\n",
            "Loss: 1.441603e-06, l1: 0.99921, l2: 0.03184\n",
            "Loss: 1.440352e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 1.439531e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 1.438028e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 1.436846e-06, l1: 0.99923, l2: 0.03184\n",
            "Loss: 1.436159e-06, l1: 0.99924, l2: 0.03184\n",
            "Loss: 1.434364e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 1.434327e-06, l1: 0.99926, l2: 0.03184\n",
            "Loss: 1.432779e-06, l1: 0.99926, l2: 0.03184\n",
            "Loss: 1.431995e-06, l1: 0.99926, l2: 0.03184\n",
            "Loss: 1.430800e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 1.429575e-06, l1: 0.99926, l2: 0.03184\n",
            "Loss: 1.427941e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 1.432031e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 1.426823e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 1.425392e-06, l1: 0.99926, l2: 0.03184\n",
            "Loss: 1.424009e-06, l1: 0.99928, l2: 0.03184\n",
            "Loss: 1.422226e-06, l1: 0.99930, l2: 0.03184\n",
            "Loss: 1.420150e-06, l1: 0.99933, l2: 0.03184\n",
            "Loss: 1.417306e-06, l1: 0.99934, l2: 0.03184\n",
            "Loss: 1.414356e-06, l1: 0.99933, l2: 0.03184\n",
            "Loss: 1.411256e-06, l1: 0.99929, l2: 0.03184\n",
            "Loss: 1.409630e-06, l1: 0.99926, l2: 0.03185\n",
            "Loss: 1.408378e-06, l1: 0.99925, l2: 0.03185\n",
            "Loss: 1.409862e-06, l1: 0.99921, l2: 0.03185\n",
            "Loss: 1.407774e-06, l1: 0.99924, l2: 0.03185\n",
            "Loss: 1.406945e-06, l1: 0.99924, l2: 0.03185\n",
            "Loss: 1.406430e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 1.405390e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 1.404580e-06, l1: 0.99926, l2: 0.03185\n",
            "Loss: 1.403477e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 1.402782e-06, l1: 0.99923, l2: 0.03185\n",
            "Loss: 1.401801e-06, l1: 0.99923, l2: 0.03184\n",
            "Loss: 1.401211e-06, l1: 0.99922, l2: 0.03184\n",
            "Loss: 1.400400e-06, l1: 0.99922, l2: 0.03184\n",
            "Loss: 1.399686e-06, l1: 0.99922, l2: 0.03184\n",
            "Loss: 1.398834e-06, l1: 0.99923, l2: 0.03184\n",
            "Loss: 1.398132e-06, l1: 0.99925, l2: 0.03184\n",
            "Loss: 1.397423e-06, l1: 0.99927, l2: 0.03184\n",
            "Loss: 1.396679e-06, l1: 0.99928, l2: 0.03184\n",
            "Loss: 1.395993e-06, l1: 0.99930, l2: 0.03184\n",
            "Loss: 1.395545e-06, l1: 0.99931, l2: 0.03184\n",
            "Loss: 1.394831e-06, l1: 0.99932, l2: 0.03184\n",
            "Loss: 1.394010e-06, l1: 0.99932, l2: 0.03184\n",
            "Loss: 1.393204e-06, l1: 0.99932, l2: 0.03184\n",
            "Loss: 1.392601e-06, l1: 0.99931, l2: 0.03184\n",
            "Loss: 1.391652e-06, l1: 0.99930, l2: 0.03184\n",
            "Loss: 1.389890e-06, l1: 0.99930, l2: 0.03184\n",
            "Loss: 1.388639e-06, l1: 0.99931, l2: 0.03184\n",
            "Loss: 1.387588e-06, l1: 0.99933, l2: 0.03184\n",
            "Loss: 1.415329e-06, l1: 0.99932, l2: 0.03183\n",
            "Loss: 1.387133e-06, l1: 0.99933, l2: 0.03184\n",
            "Loss: 1.386437e-06, l1: 0.99932, l2: 0.03184\n",
            "Loss: 1.385745e-06, l1: 0.99931, l2: 0.03184\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
            "  Objective function value: 0.000001\n",
            "  Number of iterations: 2249\n",
            "  Number of functions evaluations: 2445\n",
            "Error u: 8.802749e-04\n",
            "Error l1: 0.06888%\n",
            "Error l2: 0.02229%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "########################### Noisy Data ###############################\n",
        "######################################################################\n",
        "noise = 0.01        \n",
        "u_train = u_train + noise*np.std(u_train)*np.random.randn(u_train.shape[0], u_train.shape[1])\n",
        "        \n",
        "model = PhysicsInformedNN(X_u_train, u_train, layers, lb, ub)\n",
        "model.train(2000)\n",
        "    \n",
        "u_pred, f_pred = model.predict(X_star)\n",
        "        \n",
        "lambda_1_value_noisy = model.sess.run(model.lambda_1)\n",
        "lambda_2_value_noisy = model.sess.run(model.lambda_2)\n",
        "lambda_2_value_noisy = np.exp(lambda_2_value_noisy)\n",
        "            \n",
        "error_lambda_1_noisy = np.abs(lambda_1_value_noisy - 1.0)*100\n",
        "error_lambda_2_noisy = np.abs(lambda_2_value_noisy - nu)/nu * 100\n",
        "    \n",
        "print('Error lambda_1: %f%%' % (error_lambda_1_noisy))\n",
        "print('Error lambda_2: %f%%' % (error_lambda_2_noisy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WSYpFgNogBy",
        "outputId": "c9783dcc-f2ab-48e4-d2bc-a78e6087e03c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "\n",
            "It: 0, Loss: 2.851e-01, Lambda_1: -0.001, Lambda_2: 0.002478, Time: 1.64\n",
            "It: 10, Loss: 1.669e-01, Lambda_1: -0.008, Lambda_2: 0.002497, Time: 0.32\n",
            "It: 20, Loss: 1.505e-01, Lambda_1: -0.018, Lambda_2: 0.002524, Time: 0.32\n",
            "It: 30, Loss: 1.383e-01, Lambda_1: -0.028, Lambda_2: 0.002550, Time: 0.33\n",
            "It: 40, Loss: 1.141e-01, Lambda_1: -0.033, Lambda_2: 0.002561, Time: 0.32\n",
            "It: 50, Loss: 8.148e-02, Lambda_1: -0.029, Lambda_2: 0.002533, Time: 0.32\n",
            "It: 60, Loss: 5.043e-02, Lambda_1: -0.014, Lambda_2: 0.002492, Time: 0.32\n",
            "It: 70, Loss: 3.360e-02, Lambda_1: 0.004, Lambda_2: 0.002447, Time: 0.34\n",
            "It: 80, Loss: 2.978e-02, Lambda_1: 0.023, Lambda_2: 0.002400, Time: 0.31\n",
            "It: 90, Loss: 2.454e-02, Lambda_1: 0.040, Lambda_2: 0.002360, Time: 0.32\n",
            "It: 100, Loss: 2.172e-02, Lambda_1: 0.050, Lambda_2: 0.002335, Time: 0.33\n",
            "It: 110, Loss: 1.973e-02, Lambda_1: 0.054, Lambda_2: 0.002325, Time: 0.30\n",
            "It: 120, Loss: 1.884e-02, Lambda_1: 0.056, Lambda_2: 0.002323, Time: 0.31\n",
            "It: 130, Loss: 1.850e-02, Lambda_1: 0.057, Lambda_2: 0.002326, Time: 0.33\n",
            "It: 140, Loss: 1.839e-02, Lambda_1: 0.059, Lambda_2: 0.002332, Time: 0.32\n",
            "It: 150, Loss: 1.828e-02, Lambda_1: 0.060, Lambda_2: 0.002341, Time: 0.30\n",
            "It: 160, Loss: 1.817e-02, Lambda_1: 0.061, Lambda_2: 0.002351, Time: 0.31\n",
            "It: 170, Loss: 1.807e-02, Lambda_1: 0.061, Lambda_2: 0.002361, Time: 0.31\n",
            "It: 180, Loss: 1.798e-02, Lambda_1: 0.062, Lambda_2: 0.002372, Time: 0.32\n",
            "It: 190, Loss: 1.789e-02, Lambda_1: 0.063, Lambda_2: 0.002383, Time: 0.32\n",
            "It: 200, Loss: 1.780e-02, Lambda_1: 0.064, Lambda_2: 0.002395, Time: 0.32\n",
            "It: 210, Loss: 1.803e-02, Lambda_1: 0.064, Lambda_2: 0.002408, Time: 0.32\n",
            "It: 220, Loss: 1.764e-02, Lambda_1: 0.065, Lambda_2: 0.002422, Time: 0.31\n",
            "It: 230, Loss: 1.761e-02, Lambda_1: 0.066, Lambda_2: 0.002436, Time: 0.31\n",
            "It: 240, Loss: 1.749e-02, Lambda_1: 0.066, Lambda_2: 0.002451, Time: 0.31\n",
            "It: 250, Loss: 1.742e-02, Lambda_1: 0.067, Lambda_2: 0.002466, Time: 0.30\n",
            "It: 260, Loss: 1.734e-02, Lambda_1: 0.068, Lambda_2: 0.002482, Time: 0.31\n",
            "It: 270, Loss: 1.726e-02, Lambda_1: 0.069, Lambda_2: 0.002499, Time: 0.32\n",
            "It: 280, Loss: 1.720e-02, Lambda_1: 0.070, Lambda_2: 0.002517, Time: 0.31\n",
            "It: 290, Loss: 1.749e-02, Lambda_1: 0.071, Lambda_2: 0.002536, Time: 0.32\n",
            "It: 300, Loss: 1.718e-02, Lambda_1: 0.071, Lambda_2: 0.002555, Time: 0.32\n",
            "It: 310, Loss: 1.703e-02, Lambda_1: 0.072, Lambda_2: 0.002575, Time: 0.30\n",
            "It: 320, Loss: 1.693e-02, Lambda_1: 0.073, Lambda_2: 0.002595, Time: 0.31\n",
            "It: 330, Loss: 1.684e-02, Lambda_1: 0.075, Lambda_2: 0.002617, Time: 0.31\n",
            "It: 340, Loss: 1.677e-02, Lambda_1: 0.076, Lambda_2: 0.002639, Time: 0.31\n",
            "It: 350, Loss: 1.678e-02, Lambda_1: 0.077, Lambda_2: 0.002662, Time: 0.32\n",
            "It: 360, Loss: 1.683e-02, Lambda_1: 0.078, Lambda_2: 0.002686, Time: 0.31\n",
            "It: 370, Loss: 1.661e-02, Lambda_1: 0.079, Lambda_2: 0.002711, Time: 0.30\n",
            "It: 380, Loss: 1.650e-02, Lambda_1: 0.081, Lambda_2: 0.002736, Time: 0.32\n",
            "It: 390, Loss: 1.644e-02, Lambda_1: 0.082, Lambda_2: 0.002762, Time: 0.30\n",
            "It: 400, Loss: 1.636e-02, Lambda_1: 0.084, Lambda_2: 0.002789, Time: 0.30\n",
            "It: 410, Loss: 1.630e-02, Lambda_1: 0.086, Lambda_2: 0.002816, Time: 0.33\n",
            "It: 420, Loss: 1.678e-02, Lambda_1: 0.088, Lambda_2: 0.002844, Time: 0.31\n",
            "It: 430, Loss: 1.630e-02, Lambda_1: 0.090, Lambda_2: 0.002873, Time: 0.31\n",
            "It: 440, Loss: 1.608e-02, Lambda_1: 0.092, Lambda_2: 0.002901, Time: 0.32\n",
            "It: 450, Loss: 1.600e-02, Lambda_1: 0.094, Lambda_2: 0.002931, Time: 0.32\n",
            "It: 460, Loss: 1.591e-02, Lambda_1: 0.097, Lambda_2: 0.002961, Time: 0.32\n",
            "It: 470, Loss: 1.586e-02, Lambda_1: 0.099, Lambda_2: 0.002992, Time: 0.33\n",
            "It: 480, Loss: 1.624e-02, Lambda_1: 0.102, Lambda_2: 0.003023, Time: 0.32\n",
            "It: 490, Loss: 1.569e-02, Lambda_1: 0.105, Lambda_2: 0.003055, Time: 0.31\n",
            "It: 500, Loss: 1.557e-02, Lambda_1: 0.108, Lambda_2: 0.003087, Time: 0.33\n",
            "It: 510, Loss: 1.547e-02, Lambda_1: 0.111, Lambda_2: 0.003119, Time: 0.31\n",
            "It: 520, Loss: 1.554e-02, Lambda_1: 0.114, Lambda_2: 0.003153, Time: 0.31\n",
            "It: 530, Loss: 1.527e-02, Lambda_1: 0.117, Lambda_2: 0.003186, Time: 0.31\n",
            "It: 540, Loss: 1.524e-02, Lambda_1: 0.121, Lambda_2: 0.003221, Time: 0.32\n",
            "It: 550, Loss: 1.512e-02, Lambda_1: 0.124, Lambda_2: 0.003256, Time: 0.31\n",
            "It: 560, Loss: 1.518e-02, Lambda_1: 0.128, Lambda_2: 0.003292, Time: 0.32\n",
            "It: 570, Loss: 1.486e-02, Lambda_1: 0.132, Lambda_2: 0.003328, Time: 0.33\n",
            "It: 580, Loss: 1.477e-02, Lambda_1: 0.136, Lambda_2: 0.003366, Time: 0.33\n",
            "It: 590, Loss: 1.460e-02, Lambda_1: 0.141, Lambda_2: 0.003404, Time: 0.31\n",
            "It: 600, Loss: 1.471e-02, Lambda_1: 0.145, Lambda_2: 0.003443, Time: 0.32\n",
            "It: 610, Loss: 1.434e-02, Lambda_1: 0.150, Lambda_2: 0.003483, Time: 0.32\n",
            "It: 620, Loss: 1.419e-02, Lambda_1: 0.155, Lambda_2: 0.003524, Time: 0.31\n",
            "It: 630, Loss: 1.408e-02, Lambda_1: 0.160, Lambda_2: 0.003566, Time: 0.32\n",
            "It: 640, Loss: 1.418e-02, Lambda_1: 0.165, Lambda_2: 0.003609, Time: 0.30\n",
            "It: 650, Loss: 1.387e-02, Lambda_1: 0.171, Lambda_2: 0.003653, Time: 0.31\n",
            "It: 660, Loss: 1.378e-02, Lambda_1: 0.176, Lambda_2: 0.003699, Time: 0.33\n",
            "It: 670, Loss: 1.365e-02, Lambda_1: 0.182, Lambda_2: 0.003745, Time: 0.30\n",
            "It: 680, Loss: 1.332e-02, Lambda_1: 0.189, Lambda_2: 0.003793, Time: 0.31\n",
            "It: 690, Loss: 1.313e-02, Lambda_1: 0.195, Lambda_2: 0.003843, Time: 0.32\n",
            "It: 700, Loss: 1.293e-02, Lambda_1: 0.202, Lambda_2: 0.003893, Time: 0.32\n",
            "It: 710, Loss: 1.281e-02, Lambda_1: 0.209, Lambda_2: 0.003945, Time: 0.31\n",
            "It: 720, Loss: 1.395e-02, Lambda_1: 0.215, Lambda_2: 0.003998, Time: 0.31\n",
            "It: 730, Loss: 1.283e-02, Lambda_1: 0.222, Lambda_2: 0.004052, Time: 0.32\n",
            "It: 740, Loss: 1.233e-02, Lambda_1: 0.228, Lambda_2: 0.004107, Time: 0.33\n",
            "It: 750, Loss: 1.219e-02, Lambda_1: 0.235, Lambda_2: 0.004163, Time: 0.32\n",
            "It: 760, Loss: 1.204e-02, Lambda_1: 0.242, Lambda_2: 0.004221, Time: 0.32\n",
            "It: 770, Loss: 1.190e-02, Lambda_1: 0.249, Lambda_2: 0.004281, Time: 0.31\n",
            "It: 780, Loss: 1.177e-02, Lambda_1: 0.256, Lambda_2: 0.004342, Time: 0.30\n",
            "It: 790, Loss: 1.181e-02, Lambda_1: 0.263, Lambda_2: 0.004405, Time: 0.32\n",
            "It: 800, Loss: 1.196e-02, Lambda_1: 0.269, Lambda_2: 0.004470, Time: 0.30\n",
            "It: 810, Loss: 1.175e-02, Lambda_1: 0.276, Lambda_2: 0.004535, Time: 0.31\n",
            "It: 820, Loss: 1.143e-02, Lambda_1: 0.281, Lambda_2: 0.004602, Time: 0.34\n",
            "It: 830, Loss: 1.124e-02, Lambda_1: 0.287, Lambda_2: 0.004671, Time: 0.31\n",
            "It: 840, Loss: 1.112e-02, Lambda_1: 0.293, Lambda_2: 0.004740, Time: 0.30\n",
            "It: 850, Loss: 1.101e-02, Lambda_1: 0.299, Lambda_2: 0.004810, Time: 0.32\n",
            "It: 860, Loss: 1.095e-02, Lambda_1: 0.305, Lambda_2: 0.004882, Time: 0.32\n",
            "It: 870, Loss: 1.159e-02, Lambda_1: 0.310, Lambda_2: 0.004955, Time: 0.31\n",
            "It: 880, Loss: 1.103e-02, Lambda_1: 0.315, Lambda_2: 0.005027, Time: 0.31\n",
            "It: 890, Loss: 1.071e-02, Lambda_1: 0.320, Lambda_2: 0.005101, Time: 0.33\n",
            "It: 900, Loss: 1.060e-02, Lambda_1: 0.325, Lambda_2: 0.005176, Time: 0.32\n",
            "It: 910, Loss: 1.047e-02, Lambda_1: 0.330, Lambda_2: 0.005253, Time: 0.30\n",
            "It: 920, Loss: 1.038e-02, Lambda_1: 0.335, Lambda_2: 0.005331, Time: 0.33\n",
            "It: 930, Loss: 1.059e-02, Lambda_1: 0.341, Lambda_2: 0.005411, Time: 0.31\n",
            "It: 940, Loss: 1.144e-02, Lambda_1: 0.345, Lambda_2: 0.005489, Time: 0.33\n",
            "It: 950, Loss: 1.014e-02, Lambda_1: 0.349, Lambda_2: 0.005565, Time: 0.33\n",
            "It: 960, Loss: 1.020e-02, Lambda_1: 0.353, Lambda_2: 0.005644, Time: 0.31\n",
            "It: 970, Loss: 9.957e-03, Lambda_1: 0.357, Lambda_2: 0.005724, Time: 0.31\n",
            "It: 980, Loss: 9.875e-03, Lambda_1: 0.362, Lambda_2: 0.005806, Time: 0.32\n",
            "It: 990, Loss: 9.776e-03, Lambda_1: 0.367, Lambda_2: 0.005890, Time: 0.30\n",
            "It: 1000, Loss: 9.689e-03, Lambda_1: 0.372, Lambda_2: 0.005976, Time: 0.32\n",
            "It: 1010, Loss: 9.594e-03, Lambda_1: 0.378, Lambda_2: 0.006064, Time: 0.31\n",
            "It: 1020, Loss: 9.733e-03, Lambda_1: 0.383, Lambda_2: 0.006154, Time: 0.31\n",
            "It: 1030, Loss: 1.146e-02, Lambda_1: 0.387, Lambda_2: 0.006239, Time: 0.32\n",
            "It: 1040, Loss: 9.863e-03, Lambda_1: 0.390, Lambda_2: 0.006317, Time: 0.33\n",
            "It: 1050, Loss: 9.504e-03, Lambda_1: 0.393, Lambda_2: 0.006402, Time: 0.32\n",
            "It: 1060, Loss: 9.338e-03, Lambda_1: 0.396, Lambda_2: 0.006488, Time: 0.32\n",
            "It: 1070, Loss: 9.177e-03, Lambda_1: 0.401, Lambda_2: 0.006571, Time: 0.31\n",
            "It: 1080, Loss: 9.066e-03, Lambda_1: 0.406, Lambda_2: 0.006657, Time: 0.31\n",
            "It: 1090, Loss: 8.979e-03, Lambda_1: 0.411, Lambda_2: 0.006748, Time: 0.31\n",
            "It: 1100, Loss: 8.892e-03, Lambda_1: 0.415, Lambda_2: 0.006840, Time: 0.31\n",
            "It: 1110, Loss: 9.358e-03, Lambda_1: 0.420, Lambda_2: 0.006934, Time: 0.31\n",
            "It: 1120, Loss: 9.523e-03, Lambda_1: 0.424, Lambda_2: 0.007020, Time: 0.32\n",
            "It: 1130, Loss: 9.074e-03, Lambda_1: 0.426, Lambda_2: 0.007110, Time: 0.31\n",
            "It: 1140, Loss: 8.684e-03, Lambda_1: 0.428, Lambda_2: 0.007204, Time: 0.32\n",
            "It: 1150, Loss: 8.590e-03, Lambda_1: 0.432, Lambda_2: 0.007299, Time: 0.32\n",
            "It: 1160, Loss: 8.488e-03, Lambda_1: 0.436, Lambda_2: 0.007395, Time: 0.31\n",
            "It: 1170, Loss: 8.381e-03, Lambda_1: 0.441, Lambda_2: 0.007494, Time: 0.32\n",
            "It: 1180, Loss: 8.292e-03, Lambda_1: 0.446, Lambda_2: 0.007596, Time: 0.30\n",
            "It: 1190, Loss: 8.207e-03, Lambda_1: 0.451, Lambda_2: 0.007700, Time: 0.31\n",
            "It: 1200, Loss: 9.577e-03, Lambda_1: 0.455, Lambda_2: 0.007806, Time: 0.31\n",
            "It: 1210, Loss: 8.405e-03, Lambda_1: 0.458, Lambda_2: 0.007898, Time: 0.31\n",
            "It: 1220, Loss: 8.139e-03, Lambda_1: 0.459, Lambda_2: 0.008001, Time: 0.31\n",
            "It: 1230, Loss: 8.113e-03, Lambda_1: 0.461, Lambda_2: 0.008107, Time: 0.32\n",
            "It: 1240, Loss: 7.960e-03, Lambda_1: 0.465, Lambda_2: 0.008210, Time: 0.31\n",
            "It: 1250, Loss: 7.809e-03, Lambda_1: 0.469, Lambda_2: 0.008316, Time: 0.32\n",
            "It: 1260, Loss: 7.713e-03, Lambda_1: 0.474, Lambda_2: 0.008427, Time: 0.34\n",
            "It: 1270, Loss: 7.632e-03, Lambda_1: 0.479, Lambda_2: 0.008541, Time: 0.31\n",
            "It: 1280, Loss: 7.544e-03, Lambda_1: 0.483, Lambda_2: 0.008657, Time: 0.30\n",
            "It: 1290, Loss: 7.464e-03, Lambda_1: 0.488, Lambda_2: 0.008776, Time: 0.31\n",
            "It: 1300, Loss: 1.371e-02, Lambda_1: 0.493, Lambda_2: 0.008895, Time: 0.33\n",
            "It: 1310, Loss: 7.705e-03, Lambda_1: 0.494, Lambda_2: 0.008980, Time: 0.31\n",
            "It: 1320, Loss: 8.610e-03, Lambda_1: 0.492, Lambda_2: 0.009095, Time: 0.33\n",
            "It: 1330, Loss: 7.369e-03, Lambda_1: 0.491, Lambda_2: 0.009209, Time: 0.32\n",
            "It: 1340, Loss: 7.340e-03, Lambda_1: 0.494, Lambda_2: 0.009313, Time: 0.32\n",
            "It: 1350, Loss: 7.168e-03, Lambda_1: 0.498, Lambda_2: 0.009419, Time: 0.31\n",
            "It: 1360, Loss: 7.093e-03, Lambda_1: 0.502, Lambda_2: 0.009534, Time: 0.36\n",
            "It: 1370, Loss: 7.000e-03, Lambda_1: 0.507, Lambda_2: 0.009653, Time: 0.32\n",
            "It: 1380, Loss: 6.911e-03, Lambda_1: 0.512, Lambda_2: 0.009773, Time: 0.31\n",
            "It: 1390, Loss: 6.831e-03, Lambda_1: 0.516, Lambda_2: 0.009897, Time: 0.33\n",
            "It: 1400, Loss: 6.750e-03, Lambda_1: 0.521, Lambda_2: 0.010023, Time: 0.32\n",
            "It: 1410, Loss: 6.670e-03, Lambda_1: 0.526, Lambda_2: 0.010152, Time: 0.31\n",
            "It: 1420, Loss: 6.591e-03, Lambda_1: 0.530, Lambda_2: 0.010283, Time: 0.31\n",
            "It: 1430, Loss: 8.321e-03, Lambda_1: 0.535, Lambda_2: 0.010417, Time: 0.32\n",
            "It: 1440, Loss: 8.304e-03, Lambda_1: 0.538, Lambda_2: 0.010521, Time: 0.31\n",
            "It: 1450, Loss: 7.167e-03, Lambda_1: 0.539, Lambda_2: 0.010637, Time: 0.31\n",
            "It: 1460, Loss: 6.647e-03, Lambda_1: 0.540, Lambda_2: 0.010760, Time: 0.31\n",
            "It: 1470, Loss: 6.383e-03, Lambda_1: 0.544, Lambda_2: 0.010871, Time: 0.32\n",
            "It: 1480, Loss: 6.264e-03, Lambda_1: 0.547, Lambda_2: 0.010984, Time: 0.33\n",
            "It: 1490, Loss: 6.184e-03, Lambda_1: 0.551, Lambda_2: 0.011103, Time: 0.33\n",
            "It: 1500, Loss: 6.102e-03, Lambda_1: 0.554, Lambda_2: 0.011227, Time: 0.31\n",
            "It: 1510, Loss: 6.087e-03, Lambda_1: 0.558, Lambda_2: 0.011351, Time: 0.31\n",
            "It: 1520, Loss: 7.956e-03, Lambda_1: 0.561, Lambda_2: 0.011473, Time: 0.31\n",
            "It: 1530, Loss: 7.508e-03, Lambda_1: 0.562, Lambda_2: 0.011579, Time: 0.31\n",
            "It: 1540, Loss: 6.397e-03, Lambda_1: 0.561, Lambda_2: 0.011711, Time: 0.31\n",
            "It: 1550, Loss: 6.050e-03, Lambda_1: 0.562, Lambda_2: 0.011837, Time: 0.33\n",
            "It: 1560, Loss: 5.844e-03, Lambda_1: 0.565, Lambda_2: 0.011954, Time: 0.32\n",
            "It: 1570, Loss: 5.744e-03, Lambda_1: 0.569, Lambda_2: 0.012075, Time: 0.31\n",
            "It: 1580, Loss: 5.671e-03, Lambda_1: 0.572, Lambda_2: 0.012200, Time: 0.32\n",
            "It: 1590, Loss: 5.603e-03, Lambda_1: 0.576, Lambda_2: 0.012328, Time: 0.31\n",
            "It: 1600, Loss: 5.533e-03, Lambda_1: 0.580, Lambda_2: 0.012460, Time: 0.30\n",
            "It: 1610, Loss: 5.468e-03, Lambda_1: 0.584, Lambda_2: 0.012594, Time: 0.32\n",
            "It: 1620, Loss: 5.401e-03, Lambda_1: 0.588, Lambda_2: 0.012730, Time: 0.32\n",
            "It: 1630, Loss: 5.343e-03, Lambda_1: 0.591, Lambda_2: 0.012867, Time: 0.30\n",
            "It: 1640, Loss: 1.232e-02, Lambda_1: 0.595, Lambda_2: 0.013006, Time: 0.33\n",
            "It: 1650, Loss: 6.874e-03, Lambda_1: 0.596, Lambda_2: 0.013110, Time: 0.31\n",
            "It: 1660, Loss: 5.347e-03, Lambda_1: 0.594, Lambda_2: 0.013260, Time: 0.31\n",
            "It: 1670, Loss: 5.416e-03, Lambda_1: 0.593, Lambda_2: 0.013400, Time: 0.32\n",
            "It: 1680, Loss: 5.270e-03, Lambda_1: 0.595, Lambda_2: 0.013526, Time: 0.32\n",
            "It: 1690, Loss: 5.128e-03, Lambda_1: 0.598, Lambda_2: 0.013654, Time: 0.32\n",
            "It: 1700, Loss: 5.031e-03, Lambda_1: 0.602, Lambda_2: 0.013789, Time: 0.32\n",
            "It: 1710, Loss: 4.953e-03, Lambda_1: 0.606, Lambda_2: 0.013925, Time: 0.31\n",
            "It: 1720, Loss: 4.890e-03, Lambda_1: 0.610, Lambda_2: 0.014066, Time: 0.32\n",
            "It: 1730, Loss: 4.826e-03, Lambda_1: 0.614, Lambda_2: 0.014210, Time: 0.32\n",
            "It: 1740, Loss: 4.762e-03, Lambda_1: 0.618, Lambda_2: 0.014356, Time: 0.32\n",
            "It: 1750, Loss: 4.699e-03, Lambda_1: 0.621, Lambda_2: 0.014504, Time: 0.31\n",
            "It: 1760, Loss: 4.638e-03, Lambda_1: 0.625, Lambda_2: 0.014654, Time: 0.30\n",
            "It: 1770, Loss: 4.577e-03, Lambda_1: 0.629, Lambda_2: 0.014805, Time: 0.31\n",
            "It: 1780, Loss: 4.665e-03, Lambda_1: 0.633, Lambda_2: 0.014959, Time: 0.31\n",
            "It: 1790, Loss: 1.035e-02, Lambda_1: 0.634, Lambda_2: 0.015091, Time: 0.31\n",
            "It: 1800, Loss: 6.196e-03, Lambda_1: 0.631, Lambda_2: 0.015225, Time: 0.33\n",
            "It: 1810, Loss: 4.952e-03, Lambda_1: 0.628, Lambda_2: 0.015389, Time: 0.30\n",
            "It: 1820, Loss: 4.474e-03, Lambda_1: 0.629, Lambda_2: 0.015526, Time: 0.30\n",
            "It: 1830, Loss: 4.481e-03, Lambda_1: 0.631, Lambda_2: 0.015650, Time: 0.33\n",
            "It: 1840, Loss: 4.337e-03, Lambda_1: 0.634, Lambda_2: 0.015787, Time: 0.31\n",
            "It: 1850, Loss: 4.273e-03, Lambda_1: 0.638, Lambda_2: 0.015926, Time: 0.30\n",
            "It: 1860, Loss: 4.211e-03, Lambda_1: 0.642, Lambda_2: 0.016069, Time: 0.33\n",
            "It: 1870, Loss: 4.151e-03, Lambda_1: 0.646, Lambda_2: 0.016217, Time: 0.31\n",
            "It: 1880, Loss: 4.094e-03, Lambda_1: 0.650, Lambda_2: 0.016368, Time: 0.31\n",
            "It: 1890, Loss: 4.036e-03, Lambda_1: 0.654, Lambda_2: 0.016520, Time: 0.31\n",
            "It: 1900, Loss: 3.980e-03, Lambda_1: 0.657, Lambda_2: 0.016674, Time: 0.32\n",
            "It: 1910, Loss: 3.924e-03, Lambda_1: 0.661, Lambda_2: 0.016830, Time: 0.31\n",
            "It: 1920, Loss: 3.870e-03, Lambda_1: 0.665, Lambda_2: 0.016987, Time: 0.31\n",
            "It: 1930, Loss: 3.854e-03, Lambda_1: 0.668, Lambda_2: 0.017147, Time: 0.31\n",
            "It: 1940, Loss: 5.204e-03, Lambda_1: 0.671, Lambda_2: 0.017301, Time: 0.30\n",
            "It: 1950, Loss: 4.977e-03, Lambda_1: 0.674, Lambda_2: 0.017407, Time: 0.32\n",
            "It: 1960, Loss: 3.899e-03, Lambda_1: 0.674, Lambda_2: 0.017561, Time: 0.33\n",
            "It: 1970, Loss: 3.680e-03, Lambda_1: 0.677, Lambda_2: 0.017681, Time: 0.30\n",
            "It: 1980, Loss: 3.666e-03, Lambda_1: 0.679, Lambda_2: 0.017798, Time: 0.30\n",
            "It: 1990, Loss: 3.603e-03, Lambda_1: 0.681, Lambda_2: 0.017926, Time: 0.32\n",
            "Loss: 3.555762e-03, l1: 0.68373, l2: 0.01804\n",
            "Loss: 5.998031e+01, l1: 0.68418, l2: 0.01897\n",
            "Loss: 3.558296e-03, l1: 0.68373, l2: 0.01804\n",
            "Loss: 3.547203e-03, l1: 0.68373, l2: 0.01804\n",
            "Loss: 3.546825e-03, l1: 0.68373, l2: 0.01804\n",
            "Loss: 3.546580e-03, l1: 0.68374, l2: 0.01804\n",
            "Loss: 3.546528e-03, l1: 0.68374, l2: 0.01804\n",
            "Loss: 3.546037e-03, l1: 0.68382, l2: 0.01805\n",
            "Loss: 3.545389e-03, l1: 0.68393, l2: 0.01805\n",
            "Loss: 3.543323e-03, l1: 0.68434, l2: 0.01806\n",
            "Loss: 3.538786e-03, l1: 0.68531, l2: 0.01807\n",
            "Loss: 3.529950e-03, l1: 0.68733, l2: 0.01811\n",
            "Loss: 3.515483e-03, l1: 0.69063, l2: 0.01817\n",
            "Loss: 3.489109e-03, l1: 0.70007, l2: 0.01837\n",
            "Loss: 3.466181e-03, l1: 0.70201, l2: 0.01841\n",
            "Loss: 3.449943e-03, l1: 0.70500, l2: 0.01848\n",
            "Loss: 3.447572e-03, l1: 0.70522, l2: 0.01849\n",
            "Loss: 3.441718e-03, l1: 0.70589, l2: 0.01850\n",
            "Loss: 3.429394e-03, l1: 0.70784, l2: 0.01856\n",
            "Loss: 3.408482e-03, l1: 0.71179, l2: 0.01867\n",
            "Loss: 3.373534e-03, l1: 0.71865, l2: 0.01886\n",
            "Loss: 3.295563e-03, l1: 0.73330, l2: 0.01931\n",
            "Loss: 3.211406e-03, l1: 0.74898, l2: 0.01981\n",
            "Loss: 3.121635e-03, l1: 0.76214, l2: 0.02027\n",
            "Loss: 3.052240e-03, l1: 0.77176, l2: 0.02063\n",
            "Loss: 2.999346e-03, l1: 0.77792, l2: 0.02089\n",
            "Loss: 2.933661e-03, l1: 0.78654, l2: 0.02125\n",
            "Loss: 2.901084e-03, l1: 0.78401, l2: 0.02127\n",
            "Loss: 2.873517e-03, l1: 0.79349, l2: 0.02157\n",
            "Loss: 2.855039e-03, l1: 0.79092, l2: 0.02145\n",
            "Loss: 2.828317e-03, l1: 0.79294, l2: 0.02152\n",
            "Loss: 2.801670e-03, l1: 0.79955, l2: 0.02177\n",
            "Loss: 2.770845e-03, l1: 0.80829, l2: 0.02211\n",
            "Loss: 2.691634e-03, l1: 0.82416, l2: 0.02274\n",
            "Loss: 2.637008e-03, l1: 0.83019, l2: 0.02303\n",
            "Loss: 2.607395e-03, l1: 0.83447, l2: 0.02322\n",
            "Loss: 2.584419e-03, l1: 0.83083, l2: 0.02312\n",
            "Loss: 2.552385e-03, l1: 0.83242, l2: 0.02322\n",
            "Loss: 2.498223e-03, l1: 0.83218, l2: 0.02331\n",
            "Loss: 2.455785e-03, l1: 0.83465, l2: 0.02351\n",
            "Loss: 2.434409e-03, l1: 0.83748, l2: 0.02366\n",
            "Loss: 2.416376e-03, l1: 0.84328, l2: 0.02391\n",
            "Loss: 2.397541e-03, l1: 0.84983, l2: 0.02418\n",
            "Loss: 2.373425e-03, l1: 0.86196, l2: 0.02467\n",
            "Loss: 2.344558e-03, l1: 0.86839, l2: 0.02496\n",
            "Loss: 2.330047e-03, l1: 0.87332, l2: 0.02518\n",
            "Loss: 2.321257e-03, l1: 0.86960, l2: 0.02501\n",
            "Loss: 2.310232e-03, l1: 0.87000, l2: 0.02504\n",
            "Loss: 2.287276e-03, l1: 0.87012, l2: 0.02507\n",
            "Loss: 2.255835e-03, l1: 0.87003, l2: 0.02511\n",
            "Loss: 2.233511e-03, l1: 0.87177, l2: 0.02523\n",
            "Loss: 2.201527e-03, l1: 0.87807, l2: 0.02554\n",
            "Loss: 2.168610e-03, l1: 0.88928, l2: 0.02610\n",
            "Loss: 2.160393e-03, l1: 0.89548, l2: 0.02641\n",
            "Loss: 2.152498e-03, l1: 0.89725, l2: 0.02652\n",
            "Loss: 2.129979e-03, l1: 0.90519, l2: 0.02698\n",
            "Loss: 2.110456e-03, l1: 0.90410, l2: 0.02705\n",
            "Loss: 2.094035e-03, l1: 0.90834, l2: 0.02732\n",
            "Loss: 2.088064e-03, l1: 0.90471, l2: 0.02714\n",
            "Loss: 2.083482e-03, l1: 0.90411, l2: 0.02714\n",
            "Loss: 2.074668e-03, l1: 0.90207, l2: 0.02708\n",
            "Loss: 2.044632e-03, l1: 0.89550, l2: 0.02694\n",
            "Loss: 1.994966e-03, l1: 0.88807, l2: 0.02696\n",
            "Loss: 1.918976e-03, l1: 0.87995, l2: 0.02728\n",
            "Loss: 1.860258e-03, l1: 0.87626, l2: 0.02770\n",
            "Loss: 1.828065e-03, l1: 0.87552, l2: 0.02796\n",
            "Loss: 1.813267e-03, l1: 0.88211, l2: 0.02836\n",
            "Loss: 1.799135e-03, l1: 0.88706, l2: 0.02854\n",
            "Loss: 1.777859e-03, l1: 0.89533, l2: 0.02902\n",
            "Loss: 1.751919e-03, l1: 0.91924, l2: 0.03072\n",
            "Loss: 1.701789e-03, l1: 0.91205, l2: 0.03053\n",
            "Loss: 1.687656e-03, l1: 0.90741, l2: 0.03038\n",
            "Loss: 1.671271e-03, l1: 0.90350, l2: 0.03051\n",
            "Loss: 1.664593e-03, l1: 0.90040, l2: 0.03038\n",
            "Loss: 1.642417e-03, l1: 0.89729, l2: 0.03028\n",
            "Loss: 1.611467e-03, l1: 0.89353, l2: 0.03022\n",
            "Loss: 1.588326e-03, l1: 0.89261, l2: 0.03027\n",
            "Loss: 1.628003e-03, l1: 0.89526, l2: 0.03058\n",
            "Loss: 1.581853e-03, l1: 0.89333, l2: 0.03036\n",
            "Loss: 1.570641e-03, l1: 0.89449, l2: 0.03058\n",
            "Loss: 1.566336e-03, l1: 0.89676, l2: 0.03073\n",
            "Loss: 1.562725e-03, l1: 0.89946, l2: 0.03101\n",
            "Loss: 1.556857e-03, l1: 0.90220, l2: 0.03128\n",
            "Loss: 1.547550e-03, l1: 0.90434, l2: 0.03165\n",
            "Loss: 1.534049e-03, l1: 0.90468, l2: 0.03194\n",
            "Loss: 1.507745e-03, l1: 0.90831, l2: 0.03267\n",
            "Loss: 1.488098e-03, l1: 0.90351, l2: 0.03251\n",
            "Loss: 1.467672e-03, l1: 0.90523, l2: 0.03275\n",
            "Loss: 1.458616e-03, l1: 0.90548, l2: 0.03238\n",
            "Loss: 1.457167e-03, l1: 0.90567, l2: 0.03226\n",
            "Loss: 1.450730e-03, l1: 0.90516, l2: 0.03224\n",
            "Loss: 1.444657e-03, l1: 0.90551, l2: 0.03227\n",
            "Loss: 1.435794e-03, l1: 0.90482, l2: 0.03228\n",
            "Loss: 1.422002e-03, l1: 0.90491, l2: 0.03236\n",
            "Loss: 1.406486e-03, l1: 0.90451, l2: 0.03253\n",
            "Loss: 1.397576e-03, l1: 0.90504, l2: 0.03273\n",
            "Loss: 1.393908e-03, l1: 0.90406, l2: 0.03271\n",
            "Loss: 1.391980e-03, l1: 0.90428, l2: 0.03278\n",
            "Loss: 1.389462e-03, l1: 0.90355, l2: 0.03278\n",
            "Loss: 1.383587e-03, l1: 0.90285, l2: 0.03289\n",
            "Loss: 1.377105e-03, l1: 0.90122, l2: 0.03283\n",
            "Loss: 1.381341e-03, l1: 0.89680, l2: 0.03253\n",
            "Loss: 1.373488e-03, l1: 0.89944, l2: 0.03271\n",
            "Loss: 1.365450e-03, l1: 0.90278, l2: 0.03290\n",
            "Loss: 1.358429e-03, l1: 0.90769, l2: 0.03319\n",
            "Loss: 1.350101e-03, l1: 0.91258, l2: 0.03351\n",
            "Loss: 1.344155e-03, l1: 0.91703, l2: 0.03388\n",
            "Loss: 1.338457e-03, l1: 0.91842, l2: 0.03407\n",
            "Loss: 1.331521e-03, l1: 0.92168, l2: 0.03468\n",
            "Loss: 1.322187e-03, l1: 0.92056, l2: 0.03482\n",
            "Loss: 1.309811e-03, l1: 0.91877, l2: 0.03519\n",
            "Loss: 1.316034e-03, l1: 0.91551, l2: 0.03550\n",
            "Loss: 1.301672e-03, l1: 0.91737, l2: 0.03533\n",
            "Loss: 1.297896e-03, l1: 0.91400, l2: 0.03560\n",
            "Loss: 1.289740e-03, l1: 0.90666, l2: 0.03504\n",
            "Loss: 1.281880e-03, l1: 0.90949, l2: 0.03493\n",
            "Loss: 1.275806e-03, l1: 0.90750, l2: 0.03470\n",
            "Loss: 1.266871e-03, l1: 0.89952, l2: 0.03410\n",
            "Loss: 1.265640e-03, l1: 0.89695, l2: 0.03392\n",
            "Loss: 1.265069e-03, l1: 0.89600, l2: 0.03388\n",
            "Loss: 1.264612e-03, l1: 0.89567, l2: 0.03388\n",
            "Loss: 1.263574e-03, l1: 0.89527, l2: 0.03389\n",
            "Loss: 1.261024e-03, l1: 0.89475, l2: 0.03394\n",
            "Loss: 1.254131e-03, l1: 0.89419, l2: 0.03410\n",
            "Loss: 1.238316e-03, l1: 0.89442, l2: 0.03472\n",
            "Loss: 1.218338e-03, l1: 0.89149, l2: 0.03441\n",
            "Loss: 1.212179e-03, l1: 0.89071, l2: 0.03471\n",
            "Loss: 1.207414e-03, l1: 0.88802, l2: 0.03432\n",
            "Loss: 1.198133e-03, l1: 0.89026, l2: 0.03455\n",
            "Loss: 1.197335e-03, l1: 0.88995, l2: 0.03455\n",
            "Loss: 1.196283e-03, l1: 0.88919, l2: 0.03450\n",
            "Loss: 1.195282e-03, l1: 0.88852, l2: 0.03444\n",
            "Loss: 1.193085e-03, l1: 0.88734, l2: 0.03435\n",
            "Loss: 1.193797e-03, l1: 0.88580, l2: 0.03418\n",
            "Loss: 1.191253e-03, l1: 0.88663, l2: 0.03427\n",
            "Loss: 1.187893e-03, l1: 0.88580, l2: 0.03419\n",
            "Loss: 1.182340e-03, l1: 0.88425, l2: 0.03406\n",
            "Loss: 1.174583e-03, l1: 0.88350, l2: 0.03392\n",
            "Loss: 1.165209e-03, l1: 0.88036, l2: 0.03367\n",
            "Loss: 1.157614e-03, l1: 0.88018, l2: 0.03353\n",
            "Loss: 1.151839e-03, l1: 0.87624, l2: 0.03339\n",
            "Loss: 1.147586e-03, l1: 0.87573, l2: 0.03337\n",
            "Loss: 1.145086e-03, l1: 0.87642, l2: 0.03342\n",
            "Loss: 1.143103e-03, l1: 0.87846, l2: 0.03349\n",
            "Loss: 1.141037e-03, l1: 0.88019, l2: 0.03364\n",
            "Loss: 1.136852e-03, l1: 0.88267, l2: 0.03390\n",
            "Loss: 1.133300e-03, l1: 0.88386, l2: 0.03418\n",
            "Loss: 1.129841e-03, l1: 0.88469, l2: 0.03445\n",
            "Loss: 1.127806e-03, l1: 0.88317, l2: 0.03450\n",
            "Loss: 1.126174e-03, l1: 0.88224, l2: 0.03446\n",
            "Loss: 1.125250e-03, l1: 0.88238, l2: 0.03452\n",
            "Loss: 1.124007e-03, l1: 0.88276, l2: 0.03461\n",
            "Loss: 1.124395e-03, l1: 0.88183, l2: 0.03470\n",
            "Loss: 1.122474e-03, l1: 0.88232, l2: 0.03466\n",
            "Loss: 1.120364e-03, l1: 0.88091, l2: 0.03477\n",
            "Loss: 1.117165e-03, l1: 0.88124, l2: 0.03478\n",
            "Loss: 1.111703e-03, l1: 0.88180, l2: 0.03491\n",
            "Loss: 1.108356e-03, l1: 0.88167, l2: 0.03485\n",
            "Loss: 1.104268e-03, l1: 0.88139, l2: 0.03494\n",
            "Loss: 1.100585e-03, l1: 0.88109, l2: 0.03505\n",
            "Loss: 1.097389e-03, l1: 0.88061, l2: 0.03498\n",
            "Loss: 1.088343e-03, l1: 0.87975, l2: 0.03488\n",
            "Loss: 1.070326e-03, l1: 0.88119, l2: 0.03476\n",
            "Loss: 1.065188e-03, l1: 0.87552, l2: 0.03434\n",
            "Loss: 1.047956e-03, l1: 0.88373, l2: 0.03471\n",
            "Loss: 1.063189e-03, l1: 0.89174, l2: 0.03475\n",
            "Loss: 1.044340e-03, l1: 0.88603, l2: 0.03472\n",
            "Loss: 1.038174e-03, l1: 0.88742, l2: 0.03483\n",
            "Loss: 1.029755e-03, l1: 0.89036, l2: 0.03490\n",
            "Loss: 1.022239e-03, l1: 0.89175, l2: 0.03506\n",
            "Loss: 1.021013e-03, l1: 0.88520, l2: 0.03458\n",
            "Loss: 1.013452e-03, l1: 0.89000, l2: 0.03480\n",
            "Loss: 1.011096e-03, l1: 0.89062, l2: 0.03482\n",
            "Loss: 1.009143e-03, l1: 0.89070, l2: 0.03480\n",
            "Loss: 1.007080e-03, l1: 0.89169, l2: 0.03478\n",
            "Loss: 1.003575e-03, l1: 0.89108, l2: 0.03467\n",
            "Loss: 9.992281e-04, l1: 0.89189, l2: 0.03461\n",
            "Loss: 9.901973e-04, l1: 0.89184, l2: 0.03446\n",
            "Loss: 9.823364e-04, l1: 0.89461, l2: 0.03433\n",
            "Loss: 9.734026e-04, l1: 0.89415, l2: 0.03430\n",
            "Loss: 9.664005e-04, l1: 0.89188, l2: 0.03424\n",
            "Loss: 9.660721e-04, l1: 0.88817, l2: 0.03381\n",
            "Loss: 9.625209e-04, l1: 0.89000, l2: 0.03402\n",
            "Loss: 9.570025e-04, l1: 0.89111, l2: 0.03401\n",
            "Loss: 9.499178e-04, l1: 0.89182, l2: 0.03376\n",
            "Loss: 9.486518e-04, l1: 0.89506, l2: 0.03394\n",
            "Loss: 9.457652e-04, l1: 0.89437, l2: 0.03393\n",
            "Loss: 9.391498e-04, l1: 0.89392, l2: 0.03408\n",
            "Loss: 9.355942e-04, l1: 0.89444, l2: 0.03428\n",
            "Loss: 9.322885e-04, l1: 0.89473, l2: 0.03442\n",
            "Loss: 9.297382e-04, l1: 0.89517, l2: 0.03459\n",
            "Loss: 9.268458e-04, l1: 0.89642, l2: 0.03475\n",
            "Loss: 9.248628e-04, l1: 0.89711, l2: 0.03491\n",
            "Loss: 9.230500e-04, l1: 0.89669, l2: 0.03483\n",
            "Loss: 9.218314e-04, l1: 0.89623, l2: 0.03476\n",
            "Loss: 9.209110e-04, l1: 0.89583, l2: 0.03463\n",
            "Loss: 9.202163e-04, l1: 0.89552, l2: 0.03455\n",
            "Loss: 9.193139e-04, l1: 0.89571, l2: 0.03449\n",
            "Loss: 9.180465e-04, l1: 0.89619, l2: 0.03446\n",
            "Loss: 9.151798e-04, l1: 0.89711, l2: 0.03442\n",
            "Loss: 9.102943e-04, l1: 0.89855, l2: 0.03449\n",
            "Loss: 9.161474e-04, l1: 0.89891, l2: 0.03417\n",
            "Loss: 9.076959e-04, l1: 0.89868, l2: 0.03437\n",
            "Loss: 9.001745e-04, l1: 0.90085, l2: 0.03443\n",
            "Loss: 9.194719e-04, l1: 0.90249, l2: 0.03444\n",
            "Loss: 8.891814e-04, l1: 0.90147, l2: 0.03444\n",
            "Loss: 8.731127e-04, l1: 0.90167, l2: 0.03452\n",
            "Loss: 8.550107e-04, l1: 0.90162, l2: 0.03446\n",
            "Loss: 8.472089e-04, l1: 0.90172, l2: 0.03455\n",
            "Loss: 8.428521e-04, l1: 0.89963, l2: 0.03417\n",
            "Loss: 8.400097e-04, l1: 0.89948, l2: 0.03416\n",
            "Loss: 8.384917e-04, l1: 0.89927, l2: 0.03406\n",
            "Loss: 8.376614e-04, l1: 0.89860, l2: 0.03388\n",
            "Loss: 8.368362e-04, l1: 0.89796, l2: 0.03376\n",
            "Loss: 8.342770e-04, l1: 0.89759, l2: 0.03357\n",
            "Loss: 8.301011e-04, l1: 0.89693, l2: 0.03335\n",
            "Loss: 8.216694e-04, l1: 0.89882, l2: 0.03335\n",
            "Loss: 8.078558e-04, l1: 0.90265, l2: 0.03356\n",
            "Loss: 8.148730e-04, l1: 0.91017, l2: 0.03403\n",
            "Loss: 8.011240e-04, l1: 0.90592, l2: 0.03376\n",
            "Loss: 7.922847e-04, l1: 0.90888, l2: 0.03408\n",
            "Loss: 8.022188e-04, l1: 0.90232, l2: 0.03418\n",
            "Loss: 7.882934e-04, l1: 0.90659, l2: 0.03411\n",
            "Loss: 7.901180e-04, l1: 0.91942, l2: 0.03459\n",
            "Loss: 7.781610e-04, l1: 0.91274, l2: 0.03434\n",
            "Loss: 7.729445e-04, l1: 0.91177, l2: 0.03418\n",
            "Loss: 7.758333e-04, l1: 0.90977, l2: 0.03397\n",
            "Loss: 7.703551e-04, l1: 0.91096, l2: 0.03409\n",
            "Loss: 7.686983e-04, l1: 0.91269, l2: 0.03400\n",
            "Loss: 7.678929e-04, l1: 0.91359, l2: 0.03401\n",
            "Loss: 7.666372e-04, l1: 0.91424, l2: 0.03402\n",
            "Loss: 7.654287e-04, l1: 0.91496, l2: 0.03404\n",
            "Loss: 7.639601e-04, l1: 0.91489, l2: 0.03409\n",
            "Loss: 7.615344e-04, l1: 0.91526, l2: 0.03419\n",
            "Loss: 7.583504e-04, l1: 0.91663, l2: 0.03430\n",
            "Loss: 7.490803e-04, l1: 0.91949, l2: 0.03439\n",
            "Loss: 7.437379e-04, l1: 0.92248, l2: 0.03462\n",
            "Loss: 7.379361e-04, l1: 0.92198, l2: 0.03439\n",
            "Loss: 7.332524e-04, l1: 0.92064, l2: 0.03443\n",
            "Loss: 7.298219e-04, l1: 0.91894, l2: 0.03436\n",
            "Loss: 7.269456e-04, l1: 0.91653, l2: 0.03420\n",
            "Loss: 7.238935e-04, l1: 0.91476, l2: 0.03408\n",
            "Loss: 7.216550e-04, l1: 0.91312, l2: 0.03398\n",
            "Loss: 7.230761e-04, l1: 0.90986, l2: 0.03382\n",
            "Loss: 7.200493e-04, l1: 0.91175, l2: 0.03391\n",
            "Loss: 7.175558e-04, l1: 0.90980, l2: 0.03379\n",
            "Loss: 7.162401e-04, l1: 0.91094, l2: 0.03386\n",
            "Loss: 7.143560e-04, l1: 0.91088, l2: 0.03389\n",
            "Loss: 7.111275e-04, l1: 0.90983, l2: 0.03393\n",
            "Loss: 7.086650e-04, l1: 0.90993, l2: 0.03395\n",
            "Loss: 7.037135e-04, l1: 0.91019, l2: 0.03401\n",
            "Loss: 6.978919e-04, l1: 0.91084, l2: 0.03400\n",
            "Loss: 6.885810e-04, l1: 0.91180, l2: 0.03399\n",
            "Loss: 7.504801e-04, l1: 0.90998, l2: 0.03337\n",
            "Loss: 6.832492e-04, l1: 0.91140, l2: 0.03385\n",
            "Loss: 6.740986e-04, l1: 0.91120, l2: 0.03371\n",
            "Loss: 7.665828e-04, l1: 0.91696, l2: 0.03356\n",
            "Loss: 6.690667e-04, l1: 0.91242, l2: 0.03368\n",
            "Loss: 6.582796e-04, l1: 0.91328, l2: 0.03357\n",
            "Loss: 6.535773e-04, l1: 0.91221, l2: 0.03344\n",
            "Loss: 6.449731e-04, l1: 0.91057, l2: 0.03329\n",
            "Loss: 6.425927e-04, l1: 0.90854, l2: 0.03314\n",
            "Loss: 6.399292e-04, l1: 0.90817, l2: 0.03302\n",
            "Loss: 6.370809e-04, l1: 0.90965, l2: 0.03313\n",
            "Loss: 6.345951e-04, l1: 0.91111, l2: 0.03321\n",
            "Loss: 6.334207e-04, l1: 0.91252, l2: 0.03328\n",
            "Loss: 6.321709e-04, l1: 0.91266, l2: 0.03329\n",
            "Loss: 6.307467e-04, l1: 0.91262, l2: 0.03331\n",
            "Loss: 6.288390e-04, l1: 0.91275, l2: 0.03334\n",
            "Loss: 6.287494e-04, l1: 0.91365, l2: 0.03338\n",
            "Loss: 6.273037e-04, l1: 0.91320, l2: 0.03336\n",
            "Loss: 8.397019e-04, l1: 0.92164, l2: 0.03288\n",
            "Loss: 6.260294e-04, l1: 0.91384, l2: 0.03332\n",
            "Loss: 6.231134e-04, l1: 0.91460, l2: 0.03332\n",
            "Loss: 6.208529e-04, l1: 0.91560, l2: 0.03331\n",
            "Loss: 6.202702e-04, l1: 0.91566, l2: 0.03319\n",
            "Loss: 6.191268e-04, l1: 0.91563, l2: 0.03325\n",
            "Loss: 6.184876e-04, l1: 0.91574, l2: 0.03329\n",
            "Loss: 6.175960e-04, l1: 0.91570, l2: 0.03330\n",
            "Loss: 6.161447e-04, l1: 0.91554, l2: 0.03335\n",
            "Loss: 6.142049e-04, l1: 0.91586, l2: 0.03340\n",
            "Loss: 6.111960e-04, l1: 0.91691, l2: 0.03347\n",
            "Loss: 6.055468e-04, l1: 0.91850, l2: 0.03352\n",
            "Loss: 5.959996e-04, l1: 0.92141, l2: 0.03350\n",
            "Loss: 6.034222e-04, l1: 0.92501, l2: 0.03332\n",
            "Loss: 5.892472e-04, l1: 0.92293, l2: 0.03342\n",
            "Loss: 5.775919e-04, l1: 0.92765, l2: 0.03328\n",
            "Loss: 5.694606e-04, l1: 0.92872, l2: 0.03310\n",
            "Loss: 5.680674e-04, l1: 0.92775, l2: 0.03305\n",
            "Loss: 5.606662e-04, l1: 0.92480, l2: 0.03286\n",
            "Loss: 5.571398e-04, l1: 0.92516, l2: 0.03291\n",
            "Loss: 5.528160e-04, l1: 0.92459, l2: 0.03294\n",
            "Loss: 5.505674e-04, l1: 0.92440, l2: 0.03292\n",
            "Loss: 5.493951e-04, l1: 0.92330, l2: 0.03290\n",
            "Loss: 5.484496e-04, l1: 0.92418, l2: 0.03293\n",
            "Loss: 5.477439e-04, l1: 0.92494, l2: 0.03295\n",
            "Loss: 5.471803e-04, l1: 0.92525, l2: 0.03298\n",
            "Loss: 5.465118e-04, l1: 0.92514, l2: 0.03300\n",
            "Loss: 5.460826e-04, l1: 0.92486, l2: 0.03290\n",
            "Loss: 5.446399e-04, l1: 0.92432, l2: 0.03291\n",
            "Loss: 5.434041e-04, l1: 0.92461, l2: 0.03292\n",
            "Loss: 5.419523e-04, l1: 0.92428, l2: 0.03289\n",
            "Loss: 5.381975e-04, l1: 0.92353, l2: 0.03279\n",
            "Loss: 5.349820e-04, l1: 0.92316, l2: 0.03274\n",
            "Loss: 5.291196e-04, l1: 0.92256, l2: 0.03263\n",
            "Loss: 5.209927e-04, l1: 0.92184, l2: 0.03251\n",
            "Loss: 5.119013e-04, l1: 0.92109, l2: 0.03235\n",
            "Loss: 5.055146e-04, l1: 0.92457, l2: 0.03268\n",
            "Loss: 4.999121e-04, l1: 0.92415, l2: 0.03251\n",
            "Loss: 5.008616e-04, l1: 0.92741, l2: 0.03232\n",
            "Loss: 4.970216e-04, l1: 0.92566, l2: 0.03242\n",
            "Loss: 4.930076e-04, l1: 0.92701, l2: 0.03245\n",
            "Loss: 4.890853e-04, l1: 0.92944, l2: 0.03249\n",
            "Loss: 4.863521e-04, l1: 0.93141, l2: 0.03246\n",
            "Loss: 4.830133e-04, l1: 0.93441, l2: 0.03245\n",
            "Loss: 4.820569e-04, l1: 0.93315, l2: 0.03220\n",
            "Loss: 4.798569e-04, l1: 0.93412, l2: 0.03233\n",
            "Loss: 4.789412e-04, l1: 0.93482, l2: 0.03238\n",
            "Loss: 4.781929e-04, l1: 0.93427, l2: 0.03236\n",
            "Loss: 4.773441e-04, l1: 0.93499, l2: 0.03234\n",
            "Loss: 4.766281e-04, l1: 0.93474, l2: 0.03229\n",
            "Loss: 4.761426e-04, l1: 0.93480, l2: 0.03228\n",
            "Loss: 4.754877e-04, l1: 0.93500, l2: 0.03228\n",
            "Loss: 4.741536e-04, l1: 0.93545, l2: 0.03229\n",
            "Loss: 4.720537e-04, l1: 0.93590, l2: 0.03226\n",
            "Loss: 4.684944e-04, l1: 0.93690, l2: 0.03221\n",
            "Loss: 4.643564e-04, l1: 0.93844, l2: 0.03209\n",
            "Loss: 4.694685e-04, l1: 0.94003, l2: 0.03211\n",
            "Loss: 4.625623e-04, l1: 0.93898, l2: 0.03210\n",
            "Loss: 4.574335e-04, l1: 0.93970, l2: 0.03189\n",
            "Loss: 4.530521e-04, l1: 0.93990, l2: 0.03182\n",
            "Loss: 4.440611e-04, l1: 0.94036, l2: 0.03185\n",
            "Loss: 4.392734e-04, l1: 0.94257, l2: 0.03171\n",
            "Loss: 4.405161e-04, l1: 0.94430, l2: 0.03188\n",
            "Loss: 4.373858e-04, l1: 0.94335, l2: 0.03179\n",
            "Loss: 4.358683e-04, l1: 0.94449, l2: 0.03186\n",
            "Loss: 4.322192e-04, l1: 0.94765, l2: 0.03190\n",
            "Loss: 4.267999e-04, l1: 0.94945, l2: 0.03208\n",
            "Loss: 4.228827e-04, l1: 0.94807, l2: 0.03208\n",
            "Loss: 4.199295e-04, l1: 0.94569, l2: 0.03209\n",
            "Loss: 6.110957e-04, l1: 0.93515, l2: 0.03159\n",
            "Loss: 4.192254e-04, l1: 0.94509, l2: 0.03206\n",
            "Loss: 4.172147e-04, l1: 0.94478, l2: 0.03208\n",
            "Loss: 4.123608e-04, l1: 0.94354, l2: 0.03212\n",
            "Loss: 4.101875e-04, l1: 0.94530, l2: 0.03222\n",
            "Loss: 4.084255e-04, l1: 0.94588, l2: 0.03222\n",
            "Loss: 4.067227e-04, l1: 0.94668, l2: 0.03224\n",
            "Loss: 4.048196e-04, l1: 0.94712, l2: 0.03225\n",
            "Loss: 4.026478e-04, l1: 0.94736, l2: 0.03223\n",
            "Loss: 4.008192e-04, l1: 0.94734, l2: 0.03225\n",
            "Loss: 3.999557e-04, l1: 0.94643, l2: 0.03208\n",
            "Loss: 4.029800e-04, l1: 0.94781, l2: 0.03202\n",
            "Loss: 3.977246e-04, l1: 0.94698, l2: 0.03206\n",
            "Loss: 3.965993e-04, l1: 0.94866, l2: 0.03206\n",
            "Loss: 3.949140e-04, l1: 0.94793, l2: 0.03201\n",
            "Loss: 3.936457e-04, l1: 0.94679, l2: 0.03194\n",
            "Loss: 3.916030e-04, l1: 0.94540, l2: 0.03175\n",
            "Loss: 3.905080e-04, l1: 0.94534, l2: 0.03166\n",
            "Loss: 3.892218e-04, l1: 0.94542, l2: 0.03152\n",
            "Loss: 3.876755e-04, l1: 0.94620, l2: 0.03149\n",
            "Loss: 3.858120e-04, l1: 0.94703, l2: 0.03151\n",
            "Loss: 3.838623e-04, l1: 0.94839, l2: 0.03155\n",
            "Loss: 3.821383e-04, l1: 0.94877, l2: 0.03158\n",
            "Loss: 3.798647e-04, l1: 0.94912, l2: 0.03154\n",
            "Loss: 3.764795e-04, l1: 0.95049, l2: 0.03147\n",
            "Loss: 3.721322e-04, l1: 0.95511, l2: 0.03130\n",
            "Loss: 3.672346e-04, l1: 0.95701, l2: 0.03129\n",
            "Loss: 4.744672e-04, l1: 0.96464, l2: 0.03088\n",
            "Loss: 3.653846e-04, l1: 0.95790, l2: 0.03124\n",
            "Loss: 3.591302e-04, l1: 0.96150, l2: 0.03131\n",
            "Loss: 3.533995e-04, l1: 0.96254, l2: 0.03150\n",
            "Loss: 3.443889e-04, l1: 0.96642, l2: 0.03166\n",
            "Loss: 3.341887e-04, l1: 0.96915, l2: 0.03205\n",
            "Loss: 4.679791e-04, l1: 0.97631, l2: 0.03272\n",
            "Loss: 3.315874e-04, l1: 0.97004, l2: 0.03214\n",
            "Loss: 3.270689e-04, l1: 0.97001, l2: 0.03225\n",
            "Loss: 3.243836e-04, l1: 0.97089, l2: 0.03227\n",
            "Loss: 3.233452e-04, l1: 0.96944, l2: 0.03222\n",
            "Loss: 3.228491e-04, l1: 0.96897, l2: 0.03218\n",
            "Loss: 3.218333e-04, l1: 0.96861, l2: 0.03213\n",
            "Loss: 3.208400e-04, l1: 0.96846, l2: 0.03207\n",
            "Loss: 3.199273e-04, l1: 0.96825, l2: 0.03203\n",
            "Loss: 3.198368e-04, l1: 0.96704, l2: 0.03195\n",
            "Loss: 3.208701e-04, l1: 0.96749, l2: 0.03190\n",
            "Loss: 3.188257e-04, l1: 0.96723, l2: 0.03193\n",
            "Loss: 3.178498e-04, l1: 0.96738, l2: 0.03198\n",
            "Loss: 3.169815e-04, l1: 0.96763, l2: 0.03200\n",
            "Loss: 3.155810e-04, l1: 0.96790, l2: 0.03197\n",
            "Loss: 3.145796e-04, l1: 0.96823, l2: 0.03203\n",
            "Loss: 3.138992e-04, l1: 0.96830, l2: 0.03202\n",
            "Loss: 3.132252e-04, l1: 0.96841, l2: 0.03203\n",
            "Loss: 3.122814e-04, l1: 0.96825, l2: 0.03201\n",
            "Loss: 3.107658e-04, l1: 0.96789, l2: 0.03198\n",
            "Loss: 3.094533e-04, l1: 0.96699, l2: 0.03193\n",
            "Loss: 3.074859e-04, l1: 0.96506, l2: 0.03179\n",
            "Loss: 3.074323e-04, l1: 0.96523, l2: 0.03176\n",
            "Loss: 3.071884e-04, l1: 0.96514, l2: 0.03178\n",
            "Loss: 3.068641e-04, l1: 0.96553, l2: 0.03178\n",
            "Loss: 3.066072e-04, l1: 0.96580, l2: 0.03179\n",
            "Loss: 3.054384e-04, l1: 0.96490, l2: 0.03181\n",
            "Loss: 3.073014e-04, l1: 0.97182, l2: 0.03211\n",
            "Loss: 3.046766e-04, l1: 0.96735, l2: 0.03191\n",
            "Loss: 3.034880e-04, l1: 0.96722, l2: 0.03194\n",
            "Loss: 3.061531e-04, l1: 0.96544, l2: 0.03181\n",
            "Loss: 3.025266e-04, l1: 0.96657, l2: 0.03189\n",
            "Loss: 3.014964e-04, l1: 0.96558, l2: 0.03184\n",
            "Loss: 3.010357e-04, l1: 0.96382, l2: 0.03187\n",
            "Loss: 3.001702e-04, l1: 0.96380, l2: 0.03175\n",
            "Loss: 2.997894e-04, l1: 0.96383, l2: 0.03173\n",
            "Loss: 2.994143e-04, l1: 0.96245, l2: 0.03166\n",
            "Loss: 2.995019e-04, l1: 0.96395, l2: 0.03160\n",
            "Loss: 2.989595e-04, l1: 0.96317, l2: 0.03163\n",
            "Loss: 2.988204e-04, l1: 0.96423, l2: 0.03171\n",
            "Loss: 2.992813e-04, l1: 0.96614, l2: 0.03182\n",
            "Loss: 2.985158e-04, l1: 0.96494, l2: 0.03175\n",
            "Loss: 2.981452e-04, l1: 0.96429, l2: 0.03169\n",
            "Loss: 2.978637e-04, l1: 0.96420, l2: 0.03169\n",
            "Loss: 2.969176e-04, l1: 0.96438, l2: 0.03169\n",
            "Loss: 2.964938e-04, l1: 0.96490, l2: 0.03170\n",
            "Loss: 2.961065e-04, l1: 0.96525, l2: 0.03166\n",
            "Loss: 2.956181e-04, l1: 0.96512, l2: 0.03162\n",
            "Loss: 2.951897e-04, l1: 0.96474, l2: 0.03156\n",
            "Loss: 2.948152e-04, l1: 0.96407, l2: 0.03152\n",
            "Loss: 2.943169e-04, l1: 0.96346, l2: 0.03150\n",
            "Loss: 2.937201e-04, l1: 0.96308, l2: 0.03150\n",
            "Loss: 2.928509e-04, l1: 0.96328, l2: 0.03151\n",
            "Loss: 2.919100e-04, l1: 0.96399, l2: 0.03154\n",
            "Loss: 2.914616e-04, l1: 0.96468, l2: 0.03151\n",
            "Loss: 2.906753e-04, l1: 0.96521, l2: 0.03152\n",
            "Loss: 2.902580e-04, l1: 0.96538, l2: 0.03149\n",
            "Loss: 2.893947e-04, l1: 0.96617, l2: 0.03144\n",
            "Loss: 2.885861e-04, l1: 0.96601, l2: 0.03143\n",
            "Loss: 2.876928e-04, l1: 0.96634, l2: 0.03139\n",
            "Loss: 2.873671e-04, l1: 0.96577, l2: 0.03135\n",
            "Loss: 2.871634e-04, l1: 0.96614, l2: 0.03135\n",
            "Loss: 2.866751e-04, l1: 0.96633, l2: 0.03138\n",
            "Loss: 2.864454e-04, l1: 0.96622, l2: 0.03135\n",
            "Loss: 2.860994e-04, l1: 0.96638, l2: 0.03134\n",
            "Loss: 2.852294e-04, l1: 0.96609, l2: 0.03129\n",
            "Loss: 2.844922e-04, l1: 0.96683, l2: 0.03133\n",
            "Loss: 2.834256e-04, l1: 0.96608, l2: 0.03131\n",
            "Loss: 2.825490e-04, l1: 0.96622, l2: 0.03133\n",
            "Loss: 2.815497e-04, l1: 0.96709, l2: 0.03142\n",
            "Loss: 2.807842e-04, l1: 0.96720, l2: 0.03142\n",
            "Loss: 2.799623e-04, l1: 0.96790, l2: 0.03146\n",
            "Loss: 2.794377e-04, l1: 0.96828, l2: 0.03149\n",
            "Loss: 2.786163e-04, l1: 0.96856, l2: 0.03151\n",
            "Loss: 2.781695e-04, l1: 0.96826, l2: 0.03148\n",
            "Loss: 2.781188e-04, l1: 0.96840, l2: 0.03150\n",
            "Loss: 2.778861e-04, l1: 0.96834, l2: 0.03149\n",
            "Loss: 2.775633e-04, l1: 0.96817, l2: 0.03147\n",
            "Loss: 2.779861e-04, l1: 0.97008, l2: 0.03155\n",
            "Loss: 2.772454e-04, l1: 0.96892, l2: 0.03150\n",
            "Loss: 2.766382e-04, l1: 0.96802, l2: 0.03144\n",
            "Loss: 2.763896e-04, l1: 0.96902, l2: 0.03151\n",
            "Loss: 2.748519e-04, l1: 0.96819, l2: 0.03148\n",
            "Loss: 2.734432e-04, l1: 0.96796, l2: 0.03148\n",
            "Loss: 2.718505e-04, l1: 0.96845, l2: 0.03153\n",
            "Loss: 2.743199e-04, l1: 0.96715, l2: 0.03170\n",
            "Loss: 2.711293e-04, l1: 0.96803, l2: 0.03159\n",
            "Loss: 2.696974e-04, l1: 0.96950, l2: 0.03166\n",
            "Loss: 2.687535e-04, l1: 0.96989, l2: 0.03174\n",
            "Loss: 2.677271e-04, l1: 0.97026, l2: 0.03173\n",
            "Loss: 2.669282e-04, l1: 0.97013, l2: 0.03172\n",
            "Loss: 2.656281e-04, l1: 0.96971, l2: 0.03172\n",
            "Loss: 2.642814e-04, l1: 0.96917, l2: 0.03172\n",
            "Loss: 2.630338e-04, l1: 0.96953, l2: 0.03178\n",
            "Loss: 2.621991e-04, l1: 0.97014, l2: 0.03185\n",
            "Loss: 2.616729e-04, l1: 0.97045, l2: 0.03188\n",
            "Loss: 2.611505e-04, l1: 0.97072, l2: 0.03189\n",
            "Loss: 2.604041e-04, l1: 0.97123, l2: 0.03187\n",
            "Loss: 2.593648e-04, l1: 0.97147, l2: 0.03186\n",
            "Loss: 2.633363e-04, l1: 0.97487, l2: 0.03208\n",
            "Loss: 2.587611e-04, l1: 0.97238, l2: 0.03192\n",
            "Loss: 2.570559e-04, l1: 0.97269, l2: 0.03196\n",
            "Loss: 2.540767e-04, l1: 0.97287, l2: 0.03205\n",
            "Loss: 2.536530e-04, l1: 0.97331, l2: 0.03218\n",
            "Loss: 2.520902e-04, l1: 0.97248, l2: 0.03213\n",
            "Loss: 2.515533e-04, l1: 0.97254, l2: 0.03213\n",
            "Loss: 2.503051e-04, l1: 0.97301, l2: 0.03216\n",
            "Loss: 2.487990e-04, l1: 0.97324, l2: 0.03218\n",
            "Loss: 2.479047e-04, l1: 0.97530, l2: 0.03224\n",
            "Loss: 2.448241e-04, l1: 0.97417, l2: 0.03224\n",
            "Loss: 2.439634e-04, l1: 0.97449, l2: 0.03225\n",
            "Loss: 2.433897e-04, l1: 0.97480, l2: 0.03222\n",
            "Loss: 2.431038e-04, l1: 0.97512, l2: 0.03222\n",
            "Loss: 2.429477e-04, l1: 0.97523, l2: 0.03221\n",
            "Loss: 2.427880e-04, l1: 0.97528, l2: 0.03219\n",
            "Loss: 2.424863e-04, l1: 0.97527, l2: 0.03216\n",
            "Loss: 2.421893e-04, l1: 0.97528, l2: 0.03214\n",
            "Loss: 2.419147e-04, l1: 0.97552, l2: 0.03217\n",
            "Loss: 2.459400e-04, l1: 0.97671, l2: 0.03202\n",
            "Loss: 2.417818e-04, l1: 0.97570, l2: 0.03215\n",
            "Loss: 2.415586e-04, l1: 0.97612, l2: 0.03220\n",
            "Loss: 2.413659e-04, l1: 0.97672, l2: 0.03225\n",
            "Loss: 2.412607e-04, l1: 0.97697, l2: 0.03227\n",
            "Loss: 2.410689e-04, l1: 0.97699, l2: 0.03226\n",
            "Loss: 2.408400e-04, l1: 0.97745, l2: 0.03227\n",
            "Loss: 2.406574e-04, l1: 0.97740, l2: 0.03224\n",
            "Loss: 2.402999e-04, l1: 0.97705, l2: 0.03219\n",
            "Loss: 2.398394e-04, l1: 0.97662, l2: 0.03214\n",
            "Loss: 2.389804e-04, l1: 0.97605, l2: 0.03206\n",
            "Loss: 2.383902e-04, l1: 0.97556, l2: 0.03198\n",
            "Loss: 2.378902e-04, l1: 0.97606, l2: 0.03202\n",
            "Loss: 2.375253e-04, l1: 0.97668, l2: 0.03204\n",
            "Loss: 2.369157e-04, l1: 0.97798, l2: 0.03209\n",
            "Loss: 2.366175e-04, l1: 0.97887, l2: 0.03212\n",
            "Loss: 2.361596e-04, l1: 0.97964, l2: 0.03216\n",
            "Loss: 2.355654e-04, l1: 0.98034, l2: 0.03218\n",
            "Loss: 2.349686e-04, l1: 0.98028, l2: 0.03217\n",
            "Loss: 2.343732e-04, l1: 0.98020, l2: 0.03219\n",
            "Loss: 2.337838e-04, l1: 0.97945, l2: 0.03210\n",
            "Loss: 2.331693e-04, l1: 0.97908, l2: 0.03207\n",
            "Loss: 2.325352e-04, l1: 0.97898, l2: 0.03202\n",
            "Loss: 2.320386e-04, l1: 0.97909, l2: 0.03199\n",
            "Loss: 2.310771e-04, l1: 0.97952, l2: 0.03193\n",
            "Loss: 2.295590e-04, l1: 0.97914, l2: 0.03185\n",
            "Loss: 2.286313e-04, l1: 0.97967, l2: 0.03183\n",
            "Loss: 2.279582e-04, l1: 0.97997, l2: 0.03185\n",
            "Loss: 2.275340e-04, l1: 0.98053, l2: 0.03187\n",
            "Loss: 2.271243e-04, l1: 0.98097, l2: 0.03191\n",
            "Loss: 2.266879e-04, l1: 0.98115, l2: 0.03192\n",
            "Loss: 2.268512e-04, l1: 0.98115, l2: 0.03187\n",
            "Loss: 2.264532e-04, l1: 0.98115, l2: 0.03190\n",
            "Loss: 2.259948e-04, l1: 0.98137, l2: 0.03190\n",
            "Loss: 2.253142e-04, l1: 0.98121, l2: 0.03188\n",
            "Loss: 2.236849e-04, l1: 0.98054, l2: 0.03193\n",
            "Loss: 2.214156e-04, l1: 0.98039, l2: 0.03188\n",
            "Loss: 2.189085e-04, l1: 0.98036, l2: 0.03197\n",
            "Loss: 2.150282e-04, l1: 0.97941, l2: 0.03211\n",
            "Loss: 2.142676e-04, l1: 0.97729, l2: 0.03213\n",
            "Loss: 2.111451e-04, l1: 0.97804, l2: 0.03209\n",
            "Loss: 2.099180e-04, l1: 0.97783, l2: 0.03204\n",
            "Loss: 2.090267e-04, l1: 0.97769, l2: 0.03203\n",
            "Loss: 2.080149e-04, l1: 0.97745, l2: 0.03205\n",
            "Loss: 2.067422e-04, l1: 0.97761, l2: 0.03213\n",
            "Loss: 2.051803e-04, l1: 0.97729, l2: 0.03217\n",
            "Loss: 2.043107e-04, l1: 0.97814, l2: 0.03232\n",
            "Loss: 2.033911e-04, l1: 0.97865, l2: 0.03229\n",
            "Loss: 2.026597e-04, l1: 0.97820, l2: 0.03231\n",
            "Loss: 2.016945e-04, l1: 0.97787, l2: 0.03232\n",
            "Loss: 1.999622e-04, l1: 0.97698, l2: 0.03236\n",
            "Loss: 1.985396e-04, l1: 0.97582, l2: 0.03235\n",
            "Loss: 1.966558e-04, l1: 0.97420, l2: 0.03234\n",
            "Loss: 1.957645e-04, l1: 0.97331, l2: 0.03227\n",
            "Loss: 1.953554e-04, l1: 0.97310, l2: 0.03226\n",
            "Loss: 1.950439e-04, l1: 0.97314, l2: 0.03224\n",
            "Loss: 1.946625e-04, l1: 0.97299, l2: 0.03219\n",
            "Loss: 1.943333e-04, l1: 0.97235, l2: 0.03214\n",
            "Loss: 1.944236e-04, l1: 0.97077, l2: 0.03202\n",
            "Loss: 1.940903e-04, l1: 0.97162, l2: 0.03209\n",
            "Loss: 1.937475e-04, l1: 0.97110, l2: 0.03207\n",
            "Loss: 1.932477e-04, l1: 0.97057, l2: 0.03206\n",
            "Loss: 1.921361e-04, l1: 0.96898, l2: 0.03205\n",
            "Loss: 1.912908e-04, l1: 0.96815, l2: 0.03206\n",
            "Loss: 1.897254e-04, l1: 0.96707, l2: 0.03206\n",
            "Loss: 1.885417e-04, l1: 0.96523, l2: 0.03202\n",
            "Loss: 1.871907e-04, l1: 0.96523, l2: 0.03208\n",
            "Loss: 1.856194e-04, l1: 0.96600, l2: 0.03207\n",
            "Loss: 1.843068e-04, l1: 0.96737, l2: 0.03201\n",
            "Loss: 1.832625e-04, l1: 0.96790, l2: 0.03206\n",
            "Loss: 1.820505e-04, l1: 0.96703, l2: 0.03205\n",
            "Loss: 1.811730e-04, l1: 0.96632, l2: 0.03212\n",
            "Loss: 1.802061e-04, l1: 0.96643, l2: 0.03217\n",
            "Loss: 1.793695e-04, l1: 0.96709, l2: 0.03223\n",
            "Loss: 1.774499e-04, l1: 0.96879, l2: 0.03238\n",
            "Loss: 1.763365e-04, l1: 0.96968, l2: 0.03243\n",
            "Loss: 1.744004e-04, l1: 0.97071, l2: 0.03249\n",
            "Loss: 1.734322e-04, l1: 0.97244, l2: 0.03249\n",
            "Loss: 1.712742e-04, l1: 0.97146, l2: 0.03240\n",
            "Loss: 1.702796e-04, l1: 0.97092, l2: 0.03234\n",
            "Loss: 1.692286e-04, l1: 0.97009, l2: 0.03221\n",
            "Loss: 1.679709e-04, l1: 0.97056, l2: 0.03221\n",
            "Loss: 1.667178e-04, l1: 0.97075, l2: 0.03218\n",
            "Loss: 1.658351e-04, l1: 0.97033, l2: 0.03215\n",
            "Loss: 1.654763e-04, l1: 0.97116, l2: 0.03221\n",
            "Loss: 1.650507e-04, l1: 0.97082, l2: 0.03221\n",
            "Loss: 1.645875e-04, l1: 0.97081, l2: 0.03220\n",
            "Loss: 1.640090e-04, l1: 0.97083, l2: 0.03221\n",
            "Loss: 1.634270e-04, l1: 0.97128, l2: 0.03221\n",
            "Loss: 1.625389e-04, l1: 0.97159, l2: 0.03221\n",
            "Loss: 1.619146e-04, l1: 0.97201, l2: 0.03216\n",
            "Loss: 1.605605e-04, l1: 0.97207, l2: 0.03218\n",
            "Loss: 1.595936e-04, l1: 0.97248, l2: 0.03218\n",
            "Loss: 1.607380e-04, l1: 0.97117, l2: 0.03218\n",
            "Loss: 1.593500e-04, l1: 0.97209, l2: 0.03218\n",
            "Loss: 1.589442e-04, l1: 0.97256, l2: 0.03218\n",
            "Loss: 1.585269e-04, l1: 0.97308, l2: 0.03219\n",
            "Loss: 1.580485e-04, l1: 0.97363, l2: 0.03221\n",
            "Loss: 1.574029e-04, l1: 0.97429, l2: 0.03223\n",
            "Loss: 1.563990e-04, l1: 0.97465, l2: 0.03224\n",
            "Loss: 1.566621e-04, l1: 0.97686, l2: 0.03224\n",
            "Loss: 1.558588e-04, l1: 0.97564, l2: 0.03224\n",
            "Loss: 1.550437e-04, l1: 0.97565, l2: 0.03225\n",
            "Loss: 1.544519e-04, l1: 0.97528, l2: 0.03220\n",
            "Loss: 1.551661e-04, l1: 0.97500, l2: 0.03203\n",
            "Loss: 1.540605e-04, l1: 0.97518, l2: 0.03214\n",
            "Loss: 1.535900e-04, l1: 0.97520, l2: 0.03212\n",
            "Loss: 1.532491e-04, l1: 0.97505, l2: 0.03212\n",
            "Loss: 1.528633e-04, l1: 0.97515, l2: 0.03214\n",
            "Loss: 1.525955e-04, l1: 0.97519, l2: 0.03216\n",
            "Loss: 1.524020e-04, l1: 0.97558, l2: 0.03219\n",
            "Loss: 1.521969e-04, l1: 0.97584, l2: 0.03220\n",
            "Loss: 1.523636e-04, l1: 0.97773, l2: 0.03228\n",
            "Loss: 1.519244e-04, l1: 0.97667, l2: 0.03224\n",
            "Loss: 1.515182e-04, l1: 0.97724, l2: 0.03226\n",
            "Loss: 1.513111e-04, l1: 0.97713, l2: 0.03227\n",
            "Loss: 1.506636e-04, l1: 0.97721, l2: 0.03225\n",
            "Loss: 1.500109e-04, l1: 0.97725, l2: 0.03219\n",
            "Loss: 1.489594e-04, l1: 0.97791, l2: 0.03218\n",
            "Loss: 1.481326e-04, l1: 0.97853, l2: 0.03216\n",
            "Loss: 1.473863e-04, l1: 0.97947, l2: 0.03214\n",
            "Loss: 1.469304e-04, l1: 0.97945, l2: 0.03213\n",
            "Loss: 1.465734e-04, l1: 0.98049, l2: 0.03215\n",
            "Loss: 1.463667e-04, l1: 0.98014, l2: 0.03216\n",
            "Loss: 1.461914e-04, l1: 0.98040, l2: 0.03216\n",
            "Loss: 1.459852e-04, l1: 0.98084, l2: 0.03216\n",
            "Loss: 1.464819e-04, l1: 0.98123, l2: 0.03210\n",
            "Loss: 1.458305e-04, l1: 0.98097, l2: 0.03214\n",
            "Loss: 1.455829e-04, l1: 0.98151, l2: 0.03216\n",
            "Loss: 1.454428e-04, l1: 0.98168, l2: 0.03217\n",
            "Loss: 1.453296e-04, l1: 0.98203, l2: 0.03218\n",
            "Loss: 1.451769e-04, l1: 0.98172, l2: 0.03219\n",
            "Loss: 1.449628e-04, l1: 0.98131, l2: 0.03219\n",
            "Loss: 1.446663e-04, l1: 0.98090, l2: 0.03220\n",
            "Loss: 1.442180e-04, l1: 0.98069, l2: 0.03221\n",
            "Loss: 1.443966e-04, l1: 0.98067, l2: 0.03223\n",
            "Loss: 1.439757e-04, l1: 0.98068, l2: 0.03221\n",
            "Loss: 1.436165e-04, l1: 0.98091, l2: 0.03220\n",
            "Loss: 1.434477e-04, l1: 0.98116, l2: 0.03220\n",
            "Loss: 1.431921e-04, l1: 0.98163, l2: 0.03223\n",
            "Loss: 1.429074e-04, l1: 0.98205, l2: 0.03226\n",
            "Loss: 1.426766e-04, l1: 0.98229, l2: 0.03228\n",
            "Loss: 1.423801e-04, l1: 0.98233, l2: 0.03229\n",
            "Loss: 1.428109e-04, l1: 0.98297, l2: 0.03233\n",
            "Loss: 1.422191e-04, l1: 0.98255, l2: 0.03230\n",
            "Loss: 1.418530e-04, l1: 0.98218, l2: 0.03227\n",
            "Loss: 1.415950e-04, l1: 0.98152, l2: 0.03224\n",
            "Loss: 1.412998e-04, l1: 0.98082, l2: 0.03220\n",
            "Loss: 1.407096e-04, l1: 0.98001, l2: 0.03220\n",
            "Loss: 1.407131e-04, l1: 0.97862, l2: 0.03211\n",
            "Loss: 1.401061e-04, l1: 0.97931, l2: 0.03215\n",
            "Loss: 1.390563e-04, l1: 0.97894, l2: 0.03220\n",
            "Loss: 1.373077e-04, l1: 0.97908, l2: 0.03233\n",
            "Loss: 1.363651e-04, l1: 0.97930, l2: 0.03238\n",
            "Loss: 1.355437e-04, l1: 0.97963, l2: 0.03237\n",
            "Loss: 1.347015e-04, l1: 0.98037, l2: 0.03240\n",
            "Loss: 1.341246e-04, l1: 0.98089, l2: 0.03239\n",
            "Loss: 1.337116e-04, l1: 0.98070, l2: 0.03241\n",
            "Loss: 1.332335e-04, l1: 0.98011, l2: 0.03242\n",
            "Loss: 1.327843e-04, l1: 0.97954, l2: 0.03244\n",
            "Loss: 1.323745e-04, l1: 0.97920, l2: 0.03245\n",
            "Loss: 1.319634e-04, l1: 0.97926, l2: 0.03244\n",
            "Loss: 1.315182e-04, l1: 0.97956, l2: 0.03243\n",
            "Loss: 1.310330e-04, l1: 0.98045, l2: 0.03237\n",
            "Loss: 1.306782e-04, l1: 0.98098, l2: 0.03236\n",
            "Loss: 1.303861e-04, l1: 0.98111, l2: 0.03233\n",
            "Loss: 1.302100e-04, l1: 0.98107, l2: 0.03231\n",
            "Loss: 1.300815e-04, l1: 0.98069, l2: 0.03229\n",
            "Loss: 1.301268e-04, l1: 0.98075, l2: 0.03222\n",
            "Loss: 1.299765e-04, l1: 0.98072, l2: 0.03226\n",
            "Loss: 1.298798e-04, l1: 0.98053, l2: 0.03225\n",
            "Loss: 1.297887e-04, l1: 0.98037, l2: 0.03224\n",
            "Loss: 1.297153e-04, l1: 0.98032, l2: 0.03223\n",
            "Loss: 1.295982e-04, l1: 0.98034, l2: 0.03223\n",
            "Loss: 1.294452e-04, l1: 0.98047, l2: 0.03222\n",
            "Loss: 1.292479e-04, l1: 0.98067, l2: 0.03223\n",
            "Loss: 1.290541e-04, l1: 0.98082, l2: 0.03224\n",
            "Loss: 1.288877e-04, l1: 0.98085, l2: 0.03224\n",
            "Loss: 1.286780e-04, l1: 0.98077, l2: 0.03221\n",
            "Loss: 1.312319e-04, l1: 0.97883, l2: 0.03203\n",
            "Loss: 1.286370e-04, l1: 0.98055, l2: 0.03219\n",
            "Loss: 1.283805e-04, l1: 0.98054, l2: 0.03214\n",
            "Loss: 1.282301e-04, l1: 0.97989, l2: 0.03208\n",
            "Loss: 1.280155e-04, l1: 0.98012, l2: 0.03206\n",
            "Loss: 1.278182e-04, l1: 0.98008, l2: 0.03204\n",
            "Loss: 1.276032e-04, l1: 0.97978, l2: 0.03200\n",
            "Loss: 1.272783e-04, l1: 0.97973, l2: 0.03198\n",
            "Loss: 1.270113e-04, l1: 0.97936, l2: 0.03195\n",
            "Loss: 1.268379e-04, l1: 0.97958, l2: 0.03192\n",
            "Loss: 1.266377e-04, l1: 0.97965, l2: 0.03190\n",
            "Loss: 1.268376e-04, l1: 0.98190, l2: 0.03192\n",
            "Loss: 1.263376e-04, l1: 0.98063, l2: 0.03191\n",
            "Loss: 1.258722e-04, l1: 0.98063, l2: 0.03188\n",
            "Loss: 1.254755e-04, l1: 0.98071, l2: 0.03186\n",
            "Loss: 1.252051e-04, l1: 0.98090, l2: 0.03185\n",
            "Loss: 1.247828e-04, l1: 0.98131, l2: 0.03184\n",
            "Loss: 1.240828e-04, l1: 0.98242, l2: 0.03185\n",
            "Loss: 1.234871e-04, l1: 0.98347, l2: 0.03182\n",
            "Loss: 1.231176e-04, l1: 0.98434, l2: 0.03188\n",
            "Loss: 1.227661e-04, l1: 0.98455, l2: 0.03189\n",
            "Loss: 1.221995e-04, l1: 0.98512, l2: 0.03191\n",
            "Loss: 1.217608e-04, l1: 0.98561, l2: 0.03194\n",
            "Loss: 1.208223e-04, l1: 0.98649, l2: 0.03197\n",
            "Loss: 1.201754e-04, l1: 0.98788, l2: 0.03197\n",
            "Loss: 1.197463e-04, l1: 0.98794, l2: 0.03200\n",
            "Loss: 1.193239e-04, l1: 0.98785, l2: 0.03203\n",
            "Loss: 1.190238e-04, l1: 0.98834, l2: 0.03205\n",
            "Loss: 1.192987e-04, l1: 0.98925, l2: 0.03205\n",
            "Loss: 1.189155e-04, l1: 0.98866, l2: 0.03205\n",
            "Loss: 1.187956e-04, l1: 0.98905, l2: 0.03204\n",
            "Loss: 1.186662e-04, l1: 0.98943, l2: 0.03203\n",
            "Loss: 1.185186e-04, l1: 0.99005, l2: 0.03205\n",
            "Loss: 1.183520e-04, l1: 0.99016, l2: 0.03205\n",
            "Loss: 1.182094e-04, l1: 0.99034, l2: 0.03205\n",
            "Loss: 1.181053e-04, l1: 0.99024, l2: 0.03206\n",
            "Loss: 1.179500e-04, l1: 0.99024, l2: 0.03207\n",
            "Loss: 1.177765e-04, l1: 0.99013, l2: 0.03206\n",
            "Loss: 1.175411e-04, l1: 0.99005, l2: 0.03205\n",
            "Loss: 1.172696e-04, l1: 0.98992, l2: 0.03202\n",
            "Loss: 1.169321e-04, l1: 0.98982, l2: 0.03200\n",
            "Loss: 1.183345e-04, l1: 0.99144, l2: 0.03190\n",
            "Loss: 1.166060e-04, l1: 0.99031, l2: 0.03197\n",
            "Loss: 1.166366e-04, l1: 0.98979, l2: 0.03198\n",
            "Loss: 1.162966e-04, l1: 0.99005, l2: 0.03197\n",
            "Loss: 1.167867e-04, l1: 0.98879, l2: 0.03200\n",
            "Loss: 1.160198e-04, l1: 0.98958, l2: 0.03198\n",
            "Loss: 1.157956e-04, l1: 0.98977, l2: 0.03202\n",
            "Loss: 1.156075e-04, l1: 0.99027, l2: 0.03204\n",
            "Loss: 1.154341e-04, l1: 0.99047, l2: 0.03204\n",
            "Loss: 1.157575e-04, l1: 0.99138, l2: 0.03206\n",
            "Loss: 1.152826e-04, l1: 0.99080, l2: 0.03205\n",
            "Loss: 1.150293e-04, l1: 0.99124, l2: 0.03206\n",
            "Loss: 1.147284e-04, l1: 0.99089, l2: 0.03199\n",
            "Loss: 1.145131e-04, l1: 0.99101, l2: 0.03198\n",
            "Loss: 1.143291e-04, l1: 0.99065, l2: 0.03198\n",
            "Loss: 1.142024e-04, l1: 0.99054, l2: 0.03197\n",
            "Loss: 1.141189e-04, l1: 0.99041, l2: 0.03196\n",
            "Loss: 1.140589e-04, l1: 0.99055, l2: 0.03196\n",
            "Loss: 1.140239e-04, l1: 0.99057, l2: 0.03195\n",
            "Loss: 1.139897e-04, l1: 0.99053, l2: 0.03194\n",
            "Loss: 1.139595e-04, l1: 0.99042, l2: 0.03193\n",
            "Loss: 1.139218e-04, l1: 0.99032, l2: 0.03193\n",
            "Loss: 1.138796e-04, l1: 0.99024, l2: 0.03193\n",
            "Loss: 1.138316e-04, l1: 0.99015, l2: 0.03194\n",
            "Loss: 1.137611e-04, l1: 0.99017, l2: 0.03195\n",
            "Loss: 1.136611e-04, l1: 0.99023, l2: 0.03197\n",
            "Loss: 1.135312e-04, l1: 0.99040, l2: 0.03200\n",
            "Loss: 1.133510e-04, l1: 0.99036, l2: 0.03200\n",
            "Loss: 1.131400e-04, l1: 0.99078, l2: 0.03203\n",
            "Loss: 1.129397e-04, l1: 0.99037, l2: 0.03197\n",
            "Loss: 1.126682e-04, l1: 0.99136, l2: 0.03202\n",
            "Loss: 1.124442e-04, l1: 0.99123, l2: 0.03200\n",
            "Loss: 1.121521e-04, l1: 0.99106, l2: 0.03196\n",
            "Loss: 1.120086e-04, l1: 0.99119, l2: 0.03194\n",
            "Loss: 1.119196e-04, l1: 0.99121, l2: 0.03197\n",
            "Loss: 1.148153e-04, l1: 0.99058, l2: 0.03180\n",
            "Loss: 1.117579e-04, l1: 0.99109, l2: 0.03194\n",
            "Loss: 1.116662e-04, l1: 0.99133, l2: 0.03188\n",
            "Loss: 1.112799e-04, l1: 0.99105, l2: 0.03192\n",
            "Loss: 1.110510e-04, l1: 0.99110, l2: 0.03196\n",
            "Loss: 1.108037e-04, l1: 0.99106, l2: 0.03197\n",
            "Loss: 1.103007e-04, l1: 0.99116, l2: 0.03196\n",
            "Loss: 1.097995e-04, l1: 0.99107, l2: 0.03194\n",
            "Loss: 1.103134e-04, l1: 0.99146, l2: 0.03187\n",
            "Loss: 1.093044e-04, l1: 0.99123, l2: 0.03191\n",
            "Loss: 1.083123e-04, l1: 0.99128, l2: 0.03190\n",
            "Loss: 1.071375e-04, l1: 0.98975, l2: 0.03182\n",
            "Loss: 1.143761e-04, l1: 0.99566, l2: 0.03199\n",
            "Loss: 1.065193e-04, l1: 0.99105, l2: 0.03186\n",
            "Loss: 1.076805e-04, l1: 0.98960, l2: 0.03181\n",
            "Loss: 1.061177e-04, l1: 0.99057, l2: 0.03184\n",
            "Loss: 1.053792e-04, l1: 0.99036, l2: 0.03182\n",
            "Loss: 1.044798e-04, l1: 0.98964, l2: 0.03179\n",
            "Loss: 1.041753e-04, l1: 0.98979, l2: 0.03174\n",
            "Loss: 1.037812e-04, l1: 0.98984, l2: 0.03177\n",
            "Loss: 1.033991e-04, l1: 0.99015, l2: 0.03179\n",
            "Loss: 1.032228e-04, l1: 0.99027, l2: 0.03178\n",
            "Loss: 1.035814e-04, l1: 0.98993, l2: 0.03183\n",
            "Loss: 1.029389e-04, l1: 0.99013, l2: 0.03180\n",
            "Loss: 1.027485e-04, l1: 0.98950, l2: 0.03168\n",
            "Loss: 1.023479e-04, l1: 0.98923, l2: 0.03169\n",
            "Loss: 1.022027e-04, l1: 0.98895, l2: 0.03167\n",
            "Loss: 1.020578e-04, l1: 0.98864, l2: 0.03164\n",
            "Loss: 1.019620e-04, l1: 0.98858, l2: 0.03162\n",
            "Loss: 1.018873e-04, l1: 0.98871, l2: 0.03161\n",
            "Loss: 1.017498e-04, l1: 0.98904, l2: 0.03159\n",
            "Loss: 1.016045e-04, l1: 0.98939, l2: 0.03159\n",
            "Loss: 1.014404e-04, l1: 0.98981, l2: 0.03160\n",
            "Loss: 1.011979e-04, l1: 0.99035, l2: 0.03162\n",
            "Loss: 1.008431e-04, l1: 0.99094, l2: 0.03166\n",
            "Loss: 1.004303e-04, l1: 0.99149, l2: 0.03167\n",
            "Loss: 1.002429e-04, l1: 0.99189, l2: 0.03173\n",
            "Loss: 9.985128e-05, l1: 0.99161, l2: 0.03169\n",
            "Loss: 9.970304e-05, l1: 0.99128, l2: 0.03167\n",
            "Loss: 9.960053e-05, l1: 0.99100, l2: 0.03166\n",
            "Loss: 9.945433e-05, l1: 0.99072, l2: 0.03167\n",
            "Loss: 9.940931e-05, l1: 0.99033, l2: 0.03165\n",
            "Loss: 9.932554e-05, l1: 0.99042, l2: 0.03167\n",
            "Loss: 9.926736e-05, l1: 0.99052, l2: 0.03168\n",
            "Loss: 9.920436e-05, l1: 0.99045, l2: 0.03168\n",
            "Loss: 9.916850e-05, l1: 0.99029, l2: 0.03168\n",
            "Loss: 9.910789e-05, l1: 0.99006, l2: 0.03167\n",
            "Loss: 9.902597e-05, l1: 0.98983, l2: 0.03166\n",
            "Loss: 9.890505e-05, l1: 0.98972, l2: 0.03166\n",
            "Loss: 9.869191e-05, l1: 0.98957, l2: 0.03166\n",
            "Loss: 9.855482e-05, l1: 0.98942, l2: 0.03166\n",
            "Loss: 9.841127e-05, l1: 0.98926, l2: 0.03166\n",
            "Loss: 9.819445e-05, l1: 0.98861, l2: 0.03165\n",
            "Loss: 9.800561e-05, l1: 0.98867, l2: 0.03167\n",
            "Loss: 9.788125e-05, l1: 0.98853, l2: 0.03168\n",
            "Loss: 9.764998e-05, l1: 0.98820, l2: 0.03166\n",
            "Loss: 9.748731e-05, l1: 0.98850, l2: 0.03166\n",
            "Loss: 9.721627e-05, l1: 0.98915, l2: 0.03168\n",
            "Loss: 9.701273e-05, l1: 0.98950, l2: 0.03169\n",
            "Loss: 9.772738e-05, l1: 0.99127, l2: 0.03168\n",
            "Loss: 9.689487e-05, l1: 0.98998, l2: 0.03169\n",
            "Loss: 1.042925e-04, l1: 0.99507, l2: 0.03192\n",
            "Loss: 9.659442e-05, l1: 0.99083, l2: 0.03173\n",
            "Loss: 9.646602e-05, l1: 0.99082, l2: 0.03168\n",
            "Loss: 9.602038e-05, l1: 0.99055, l2: 0.03169\n",
            "Loss: 9.579517e-05, l1: 0.99036, l2: 0.03169\n",
            "Loss: 9.555366e-05, l1: 0.99012, l2: 0.03169\n",
            "Loss: 9.539513e-05, l1: 0.98997, l2: 0.03168\n",
            "Loss: 9.517530e-05, l1: 0.98994, l2: 0.03168\n",
            "Loss: 9.501248e-05, l1: 0.98931, l2: 0.03166\n",
            "Loss: 9.479428e-05, l1: 0.98965, l2: 0.03168\n",
            "Loss: 9.455557e-05, l1: 0.99012, l2: 0.03170\n",
            "Loss: 9.434366e-05, l1: 0.99014, l2: 0.03171\n",
            "Loss: 9.417528e-05, l1: 0.98996, l2: 0.03172\n",
            "Loss: 9.407804e-05, l1: 0.98964, l2: 0.03173\n",
            "Loss: 9.395173e-05, l1: 0.98910, l2: 0.03171\n",
            "Loss: 9.377387e-05, l1: 0.98863, l2: 0.03173\n",
            "Loss: 9.348553e-05, l1: 0.98815, l2: 0.03171\n",
            "Loss: 9.324936e-05, l1: 0.98832, l2: 0.03171\n",
            "Loss: 9.302462e-05, l1: 0.98873, l2: 0.03172\n",
            "Loss: 9.284801e-05, l1: 0.98922, l2: 0.03174\n",
            "Loss: 9.261123e-05, l1: 0.98964, l2: 0.03175\n",
            "Loss: 9.223603e-05, l1: 0.99000, l2: 0.03175\n",
            "Loss: 9.191925e-05, l1: 0.99012, l2: 0.03170\n",
            "Loss: 9.174539e-05, l1: 0.98996, l2: 0.03166\n",
            "Loss: 9.161490e-05, l1: 0.98997, l2: 0.03165\n",
            "Loss: 9.148775e-05, l1: 0.99004, l2: 0.03164\n",
            "Loss: 9.136328e-05, l1: 0.99014, l2: 0.03164\n",
            "Loss: 9.122537e-05, l1: 0.99029, l2: 0.03164\n",
            "Loss: 9.111246e-05, l1: 0.99044, l2: 0.03164\n",
            "Loss: 9.095188e-05, l1: 0.99058, l2: 0.03164\n",
            "Loss: 9.067830e-05, l1: 0.99042, l2: 0.03164\n",
            "Loss: 9.045797e-05, l1: 0.99082, l2: 0.03162\n",
            "Loss: 9.009884e-05, l1: 0.99037, l2: 0.03161\n",
            "Loss: 8.977589e-05, l1: 0.99005, l2: 0.03160\n",
            "Loss: 8.934820e-05, l1: 0.98918, l2: 0.03159\n",
            "Loss: 8.894994e-05, l1: 0.98924, l2: 0.03157\n",
            "Loss: 8.854218e-05, l1: 0.98980, l2: 0.03157\n",
            "Loss: 8.847125e-05, l1: 0.98963, l2: 0.03154\n",
            "Loss: 8.836751e-05, l1: 0.98972, l2: 0.03156\n",
            "Loss: 8.824396e-05, l1: 0.98973, l2: 0.03156\n",
            "Loss: 8.798840e-05, l1: 0.98982, l2: 0.03155\n",
            "Loss: 8.780652e-05, l1: 0.98943, l2: 0.03152\n",
            "Loss: 8.768962e-05, l1: 0.98906, l2: 0.03148\n",
            "Loss: 8.758953e-05, l1: 0.98879, l2: 0.03147\n",
            "Loss: 8.748872e-05, l1: 0.98845, l2: 0.03146\n",
            "Loss: 8.738943e-05, l1: 0.98828, l2: 0.03147\n",
            "Loss: 8.726908e-05, l1: 0.98775, l2: 0.03147\n",
            "Loss: 8.727341e-05, l1: 0.98763, l2: 0.03147\n",
            "Loss: 8.718333e-05, l1: 0.98769, l2: 0.03147\n",
            "Loss: 8.704478e-05, l1: 0.98764, l2: 0.03147\n",
            "Loss: 8.685265e-05, l1: 0.98759, l2: 0.03146\n",
            "Loss: 8.665739e-05, l1: 0.98763, l2: 0.03145\n",
            "Loss: 8.644981e-05, l1: 0.98735, l2: 0.03143\n",
            "Loss: 8.623946e-05, l1: 0.98770, l2: 0.03144\n",
            "Loss: 8.601244e-05, l1: 0.98772, l2: 0.03144\n",
            "Loss: 8.571174e-05, l1: 0.98797, l2: 0.03147\n",
            "Loss: 8.557788e-05, l1: 0.98804, l2: 0.03148\n",
            "Loss: 8.546558e-05, l1: 0.98828, l2: 0.03150\n",
            "Loss: 8.537237e-05, l1: 0.98842, l2: 0.03150\n",
            "Loss: 8.524243e-05, l1: 0.98859, l2: 0.03151\n",
            "Loss: 8.499423e-05, l1: 0.98943, l2: 0.03155\n",
            "Loss: 8.472262e-05, l1: 0.98942, l2: 0.03154\n",
            "Loss: 8.447774e-05, l1: 0.98937, l2: 0.03153\n",
            "Loss: 8.493612e-05, l1: 0.98891, l2: 0.03151\n",
            "Loss: 8.442939e-05, l1: 0.98927, l2: 0.03153\n",
            "Loss: 8.435844e-05, l1: 0.98939, l2: 0.03152\n",
            "Loss: 8.428069e-05, l1: 0.98972, l2: 0.03152\n",
            "Loss: 8.419181e-05, l1: 0.98999, l2: 0.03152\n",
            "Loss: 8.412501e-05, l1: 0.99029, l2: 0.03153\n",
            "Loss: 8.407027e-05, l1: 0.99048, l2: 0.03154\n",
            "Loss: 8.398893e-05, l1: 0.99074, l2: 0.03156\n",
            "Loss: 8.387033e-05, l1: 0.99109, l2: 0.03156\n",
            "Loss: 8.378927e-05, l1: 0.99123, l2: 0.03156\n",
            "Loss: 8.373032e-05, l1: 0.99121, l2: 0.03156\n",
            "Loss: 8.366884e-05, l1: 0.99120, l2: 0.03155\n",
            "Loss: 8.359626e-05, l1: 0.99108, l2: 0.03154\n",
            "Loss: 8.350328e-05, l1: 0.99109, l2: 0.03153\n",
            "Loss: 8.340544e-05, l1: 0.99113, l2: 0.03154\n",
            "Loss: 8.328662e-05, l1: 0.99107, l2: 0.03154\n",
            "Loss: 8.313858e-05, l1: 0.99152, l2: 0.03157\n",
            "Loss: 8.392421e-05, l1: 0.99035, l2: 0.03151\n",
            "Loss: 8.301662e-05, l1: 0.99121, l2: 0.03155\n",
            "Loss: 8.283364e-05, l1: 0.99121, l2: 0.03156\n",
            "Loss: 8.263791e-05, l1: 0.99152, l2: 0.03156\n",
            "Loss: 8.235802e-05, l1: 0.99192, l2: 0.03157\n",
            "Loss: 8.213516e-05, l1: 0.99257, l2: 0.03158\n",
            "Loss: 8.192277e-05, l1: 0.99265, l2: 0.03159\n",
            "Loss: 8.172724e-05, l1: 0.99245, l2: 0.03160\n",
            "Loss: 8.151054e-05, l1: 0.99190, l2: 0.03161\n",
            "Loss: 8.133968e-05, l1: 0.99144, l2: 0.03161\n",
            "Loss: 8.099395e-05, l1: 0.99090, l2: 0.03162\n",
            "Loss: 8.860274e-05, l1: 0.98673, l2: 0.03159\n",
            "Loss: 8.096362e-05, l1: 0.99065, l2: 0.03162\n",
            "Loss: 8.079709e-05, l1: 0.99056, l2: 0.03162\n",
            "Loss: 8.072777e-05, l1: 0.99082, l2: 0.03161\n",
            "Loss: 8.067550e-05, l1: 0.99104, l2: 0.03161\n",
            "Loss: 8.062342e-05, l1: 0.99121, l2: 0.03160\n",
            "Loss: 8.056209e-05, l1: 0.99125, l2: 0.03160\n",
            "Loss: 8.111849e-05, l1: 0.99007, l2: 0.03153\n",
            "Loss: 8.052871e-05, l1: 0.99103, l2: 0.03159\n",
            "Loss: 8.041205e-05, l1: 0.99080, l2: 0.03158\n",
            "Loss: 8.026994e-05, l1: 0.99058, l2: 0.03158\n",
            "Loss: 8.018654e-05, l1: 0.99009, l2: 0.03156\n",
            "Loss: 8.011027e-05, l1: 0.99025, l2: 0.03156\n",
            "Loss: 8.005173e-05, l1: 0.99049, l2: 0.03157\n",
            "Loss: 8.000690e-05, l1: 0.99067, l2: 0.03157\n",
            "Loss: 7.989918e-05, l1: 0.99104, l2: 0.03157\n",
            "Loss: 7.975377e-05, l1: 0.99132, l2: 0.03158\n",
            "Loss: 7.959788e-05, l1: 0.99146, l2: 0.03158\n",
            "Loss: 8.049891e-05, l1: 0.99044, l2: 0.03154\n",
            "Loss: 7.955314e-05, l1: 0.99128, l2: 0.03157\n",
            "Loss: 7.939361e-05, l1: 0.99143, l2: 0.03160\n",
            "Loss: 7.924982e-05, l1: 0.99152, l2: 0.03161\n",
            "Loss: 9.390844e-05, l1: 0.99089, l2: 0.03159\n",
            "Loss: 7.915049e-05, l1: 0.99147, l2: 0.03161\n",
            "Loss: 7.900631e-05, l1: 0.99139, l2: 0.03161\n",
            "Loss: 7.887624e-05, l1: 0.99152, l2: 0.03161\n",
            "Loss: 7.867667e-05, l1: 0.99190, l2: 0.03164\n",
            "Loss: 7.850853e-05, l1: 0.99207, l2: 0.03166\n",
            "Loss: 7.836914e-05, l1: 0.99240, l2: 0.03167\n",
            "Loss: 7.878640e-05, l1: 0.99362, l2: 0.03168\n",
            "Loss: 7.830570e-05, l1: 0.99273, l2: 0.03167\n",
            "Loss: 7.812542e-05, l1: 0.99300, l2: 0.03169\n",
            "Loss: 7.799643e-05, l1: 0.99290, l2: 0.03169\n",
            "Loss: 7.755999e-05, l1: 0.99242, l2: 0.03175\n",
            "Loss: 7.762981e-05, l1: 0.99390, l2: 0.03182\n",
            "Loss: 7.739243e-05, l1: 0.99310, l2: 0.03179\n",
            "Loss: 7.716366e-05, l1: 0.99301, l2: 0.03180\n",
            "Loss: 7.695275e-05, l1: 0.99309, l2: 0.03183\n",
            "Loss: 7.680684e-05, l1: 0.99275, l2: 0.03181\n",
            "Loss: 7.661516e-05, l1: 0.99236, l2: 0.03180\n",
            "Loss: 7.646110e-05, l1: 0.99202, l2: 0.03179\n",
            "Loss: 7.630145e-05, l1: 0.99171, l2: 0.03179\n",
            "Loss: 7.635023e-05, l1: 0.99197, l2: 0.03182\n",
            "Loss: 7.623875e-05, l1: 0.99182, l2: 0.03180\n",
            "Loss: 7.614322e-05, l1: 0.99190, l2: 0.03181\n",
            "Loss: 7.607462e-05, l1: 0.99180, l2: 0.03183\n",
            "Loss: 7.601905e-05, l1: 0.99197, l2: 0.03183\n",
            "Loss: 7.593194e-05, l1: 0.99232, l2: 0.03184\n",
            "Loss: 7.576075e-05, l1: 0.99285, l2: 0.03186\n",
            "Loss: 7.564455e-05, l1: 0.99407, l2: 0.03188\n",
            "Loss: 7.543368e-05, l1: 0.99385, l2: 0.03189\n",
            "Loss: 7.535569e-05, l1: 0.99385, l2: 0.03188\n",
            "Loss: 7.525542e-05, l1: 0.99394, l2: 0.03189\n",
            "Loss: 7.514603e-05, l1: 0.99417, l2: 0.03190\n",
            "Loss: 7.506075e-05, l1: 0.99402, l2: 0.03190\n",
            "Loss: 7.497697e-05, l1: 0.99380, l2: 0.03189\n",
            "Loss: 7.487168e-05, l1: 0.99367, l2: 0.03189\n",
            "Loss: 7.478795e-05, l1: 0.99366, l2: 0.03187\n",
            "Loss: 7.473958e-05, l1: 0.99371, l2: 0.03188\n",
            "Loss: 7.470361e-05, l1: 0.99379, l2: 0.03188\n",
            "Loss: 7.462945e-05, l1: 0.99380, l2: 0.03188\n",
            "Loss: 7.446886e-05, l1: 0.99378, l2: 0.03188\n",
            "Loss: 7.435154e-05, l1: 0.99348, l2: 0.03188\n",
            "Loss: 7.418191e-05, l1: 0.99356, l2: 0.03187\n",
            "Loss: 7.402657e-05, l1: 0.99367, l2: 0.03187\n",
            "Loss: 7.387139e-05, l1: 0.99388, l2: 0.03186\n",
            "Loss: 7.366003e-05, l1: 0.99426, l2: 0.03187\n",
            "Loss: 7.345501e-05, l1: 0.99478, l2: 0.03188\n",
            "Loss: 7.328105e-05, l1: 0.99534, l2: 0.03191\n",
            "Loss: 7.317753e-05, l1: 0.99555, l2: 0.03191\n",
            "Loss: 7.310376e-05, l1: 0.99563, l2: 0.03192\n",
            "Loss: 7.305044e-05, l1: 0.99554, l2: 0.03192\n",
            "Loss: 7.298023e-05, l1: 0.99555, l2: 0.03191\n",
            "Loss: 7.291127e-05, l1: 0.99533, l2: 0.03189\n",
            "Loss: 7.285435e-05, l1: 0.99531, l2: 0.03187\n",
            "Loss: 7.281395e-05, l1: 0.99535, l2: 0.03187\n",
            "Loss: 7.277256e-05, l1: 0.99539, l2: 0.03186\n",
            "Loss: 7.266243e-05, l1: 0.99556, l2: 0.03186\n",
            "Loss: 7.256361e-05, l1: 0.99577, l2: 0.03186\n",
            "Loss: 7.246318e-05, l1: 0.99597, l2: 0.03187\n",
            "Loss: 7.321147e-05, l1: 0.99820, l2: 0.03194\n",
            "Loss: 7.242864e-05, l1: 0.99636, l2: 0.03188\n",
            "Loss: 7.233143e-05, l1: 0.99653, l2: 0.03190\n",
            "Loss: 7.221910e-05, l1: 0.99668, l2: 0.03191\n",
            "Loss: 7.212296e-05, l1: 0.99657, l2: 0.03191\n",
            "Loss: 7.198114e-05, l1: 0.99613, l2: 0.03188\n",
            "Loss: 7.191137e-05, l1: 0.99595, l2: 0.03186\n",
            "Loss: 7.186677e-05, l1: 0.99579, l2: 0.03184\n",
            "Loss: 7.182331e-05, l1: 0.99574, l2: 0.03183\n",
            "Loss: 7.173852e-05, l1: 0.99571, l2: 0.03182\n",
            "Loss: 7.169363e-05, l1: 0.99592, l2: 0.03181\n",
            "Loss: 7.157953e-05, l1: 0.99584, l2: 0.03182\n",
            "Loss: 7.148183e-05, l1: 0.99581, l2: 0.03183\n",
            "Loss: 7.186244e-05, l1: 0.99556, l2: 0.03186\n",
            "Loss: 7.145195e-05, l1: 0.99575, l2: 0.03184\n",
            "Loss: 7.201695e-05, l1: 0.99612, l2: 0.03187\n",
            "Loss: 7.132566e-05, l1: 0.99586, l2: 0.03185\n",
            "Loss: 7.125865e-05, l1: 0.99607, l2: 0.03186\n",
            "Loss: 7.119280e-05, l1: 0.99608, l2: 0.03186\n",
            "Loss: 7.105796e-05, l1: 0.99585, l2: 0.03184\n",
            "Loss: 7.093084e-05, l1: 0.99544, l2: 0.03182\n",
            "Loss: 7.075694e-05, l1: 0.99476, l2: 0.03181\n",
            "Loss: 7.063521e-05, l1: 0.99466, l2: 0.03182\n",
            "Loss: 7.052560e-05, l1: 0.99465, l2: 0.03184\n",
            "Loss: 7.049838e-05, l1: 0.99501, l2: 0.03186\n",
            "Loss: 7.039442e-05, l1: 0.99495, l2: 0.03185\n",
            "Loss: 7.030794e-05, l1: 0.99501, l2: 0.03185\n",
            "Loss: 7.017516e-05, l1: 0.99523, l2: 0.03183\n",
            "Loss: 7.000707e-05, l1: 0.99550, l2: 0.03184\n",
            "Loss: 6.985635e-05, l1: 0.99618, l2: 0.03184\n",
            "Loss: 6.969320e-05, l1: 0.99574, l2: 0.03182\n",
            "Loss: 6.957670e-05, l1: 0.99558, l2: 0.03184\n",
            "Loss: 6.948647e-05, l1: 0.99534, l2: 0.03184\n",
            "Loss: 6.943376e-05, l1: 0.99524, l2: 0.03184\n",
            "Loss: 6.934137e-05, l1: 0.99494, l2: 0.03183\n",
            "Loss: 6.927556e-05, l1: 0.99478, l2: 0.03182\n",
            "Loss: 6.917452e-05, l1: 0.99459, l2: 0.03181\n",
            "Loss: 6.904998e-05, l1: 0.99459, l2: 0.03180\n",
            "Loss: 6.895467e-05, l1: 0.99462, l2: 0.03181\n",
            "Loss: 6.886222e-05, l1: 0.99444, l2: 0.03181\n",
            "Loss: 6.877088e-05, l1: 0.99442, l2: 0.03181\n",
            "Loss: 6.863354e-05, l1: 0.99462, l2: 0.03180\n",
            "Loss: 6.858777e-05, l1: 0.99450, l2: 0.03179\n",
            "Loss: 6.854255e-05, l1: 0.99447, l2: 0.03178\n",
            "Loss: 6.849417e-05, l1: 0.99445, l2: 0.03178\n",
            "Loss: 6.834199e-05, l1: 0.99436, l2: 0.03177\n",
            "Loss: 6.815848e-05, l1: 0.99444, l2: 0.03175\n",
            "Loss: 6.793687e-05, l1: 0.99463, l2: 0.03177\n",
            "Loss: 6.771093e-05, l1: 0.99483, l2: 0.03179\n",
            "Loss: 6.756851e-05, l1: 0.99487, l2: 0.03179\n",
            "Loss: 6.749312e-05, l1: 0.99491, l2: 0.03178\n",
            "Loss: 6.741327e-05, l1: 0.99502, l2: 0.03177\n",
            "Loss: 6.734583e-05, l1: 0.99502, l2: 0.03177\n",
            "Loss: 6.726371e-05, l1: 0.99506, l2: 0.03177\n",
            "Loss: 6.720202e-05, l1: 0.99501, l2: 0.03177\n",
            "Loss: 6.712724e-05, l1: 0.99502, l2: 0.03177\n",
            "Loss: 6.709195e-05, l1: 0.99517, l2: 0.03179\n",
            "Loss: 6.703204e-05, l1: 0.99502, l2: 0.03179\n",
            "Loss: 6.696791e-05, l1: 0.99491, l2: 0.03178\n",
            "Loss: 6.691605e-05, l1: 0.99485, l2: 0.03179\n",
            "Loss: 6.686721e-05, l1: 0.99483, l2: 0.03178\n",
            "Loss: 6.681847e-05, l1: 0.99476, l2: 0.03179\n",
            "Loss: 6.673617e-05, l1: 0.99470, l2: 0.03178\n",
            "Loss: 6.665570e-05, l1: 0.99465, l2: 0.03178\n",
            "Loss: 6.658572e-05, l1: 0.99456, l2: 0.03177\n",
            "Loss: 6.651347e-05, l1: 0.99455, l2: 0.03178\n",
            "Loss: 6.642842e-05, l1: 0.99445, l2: 0.03178\n",
            "Loss: 6.640820e-05, l1: 0.99426, l2: 0.03178\n",
            "Loss: 6.626039e-05, l1: 0.99430, l2: 0.03178\n",
            "Loss: 6.614205e-05, l1: 0.99418, l2: 0.03178\n",
            "Loss: 6.599432e-05, l1: 0.99385, l2: 0.03177\n",
            "Loss: 6.587635e-05, l1: 0.99345, l2: 0.03176\n",
            "Loss: 6.570824e-05, l1: 0.99306, l2: 0.03176\n",
            "Loss: 6.719905e-05, l1: 0.99029, l2: 0.03164\n",
            "Loss: 6.563620e-05, l1: 0.99257, l2: 0.03174\n",
            "Loss: 6.544920e-05, l1: 0.99234, l2: 0.03174\n",
            "Loss: 6.524053e-05, l1: 0.99221, l2: 0.03176\n",
            "Loss: 6.503215e-05, l1: 0.99216, l2: 0.03177\n",
            "Loss: 6.487373e-05, l1: 0.99217, l2: 0.03180\n",
            "Loss: 6.475755e-05, l1: 0.99222, l2: 0.03180\n",
            "Loss: 6.465059e-05, l1: 0.99214, l2: 0.03181\n",
            "Loss: 6.452830e-05, l1: 0.99209, l2: 0.03181\n",
            "Loss: 6.437174e-05, l1: 0.99183, l2: 0.03180\n",
            "Loss: 6.424756e-05, l1: 0.99152, l2: 0.03180\n",
            "Loss: 6.414930e-05, l1: 0.99118, l2: 0.03180\n",
            "Loss: 6.405758e-05, l1: 0.99095, l2: 0.03179\n",
            "Loss: 6.398126e-05, l1: 0.99081, l2: 0.03179\n",
            "Loss: 6.391744e-05, l1: 0.99076, l2: 0.03179\n",
            "Loss: 6.382492e-05, l1: 0.99062, l2: 0.03179\n",
            "Loss: 6.371712e-05, l1: 0.99069, l2: 0.03180\n",
            "Loss: 6.366677e-05, l1: 0.99128, l2: 0.03182\n",
            "Loss: 6.360692e-05, l1: 0.99092, l2: 0.03181\n",
            "Loss: 6.343309e-05, l1: 0.99097, l2: 0.03181\n",
            "Loss: 6.337318e-05, l1: 0.99104, l2: 0.03182\n",
            "Loss: 6.331540e-05, l1: 0.99115, l2: 0.03182\n",
            "Loss: 6.320214e-05, l1: 0.99082, l2: 0.03182\n",
            "Loss: 6.312061e-05, l1: 0.99088, l2: 0.03183\n",
            "Loss: 6.306623e-05, l1: 0.99077, l2: 0.03183\n",
            "Loss: 6.301307e-05, l1: 0.99077, l2: 0.03184\n",
            "Loss: 6.291120e-05, l1: 0.99082, l2: 0.03185\n",
            "Loss: 6.280669e-05, l1: 0.99090, l2: 0.03187\n",
            "Loss: 6.292285e-05, l1: 0.99126, l2: 0.03191\n",
            "Loss: 6.275682e-05, l1: 0.99103, l2: 0.03189\n",
            "Loss: 6.268394e-05, l1: 0.99102, l2: 0.03190\n",
            "Loss: 6.265564e-05, l1: 0.99110, l2: 0.03190\n",
            "Loss: 6.263513e-05, l1: 0.99126, l2: 0.03190\n",
            "Loss: 6.261068e-05, l1: 0.99158, l2: 0.03190\n",
            "Loss: 6.258371e-05, l1: 0.99190, l2: 0.03192\n",
            "Loss: 6.255141e-05, l1: 0.99194, l2: 0.03192\n",
            "Loss: 6.249284e-05, l1: 0.99212, l2: 0.03192\n",
            "Loss: 6.244235e-05, l1: 0.99231, l2: 0.03193\n",
            "Loss: 6.237833e-05, l1: 0.99263, l2: 0.03194\n",
            "Loss: 6.236533e-05, l1: 0.99302, l2: 0.03193\n",
            "Loss: 6.231492e-05, l1: 0.99297, l2: 0.03194\n",
            "Loss: 6.228079e-05, l1: 0.99297, l2: 0.03195\n",
            "Loss: 6.222283e-05, l1: 0.99303, l2: 0.03196\n",
            "Loss: 6.216987e-05, l1: 0.99317, l2: 0.03197\n",
            "Loss: 6.206914e-05, l1: 0.99333, l2: 0.03197\n",
            "Loss: 6.197763e-05, l1: 0.99342, l2: 0.03197\n",
            "Loss: 6.301460e-05, l1: 0.99363, l2: 0.03190\n",
            "Loss: 6.195335e-05, l1: 0.99344, l2: 0.03196\n",
            "Loss: 6.189804e-05, l1: 0.99348, l2: 0.03195\n",
            "Loss: 6.183087e-05, l1: 0.99351, l2: 0.03195\n",
            "Loss: 6.179746e-05, l1: 0.99330, l2: 0.03194\n",
            "Loss: 6.176229e-05, l1: 0.99336, l2: 0.03194\n",
            "Loss: 6.173231e-05, l1: 0.99342, l2: 0.03194\n",
            "Loss: 6.170862e-05, l1: 0.99343, l2: 0.03194\n",
            "Loss: 6.167498e-05, l1: 0.99344, l2: 0.03194\n",
            "Loss: 6.164278e-05, l1: 0.99342, l2: 0.03194\n",
            "Loss: 6.158897e-05, l1: 0.99337, l2: 0.03194\n",
            "Loss: 6.151851e-05, l1: 0.99336, l2: 0.03194\n",
            "Loss: 6.143830e-05, l1: 0.99328, l2: 0.03195\n",
            "Loss: 6.137826e-05, l1: 0.99320, l2: 0.03196\n",
            "Loss: 6.131979e-05, l1: 0.99314, l2: 0.03196\n",
            "Loss: 6.128296e-05, l1: 0.99312, l2: 0.03196\n",
            "Loss: 6.125786e-05, l1: 0.99300, l2: 0.03197\n",
            "Loss: 6.121406e-05, l1: 0.99278, l2: 0.03196\n",
            "Loss: 6.118567e-05, l1: 0.99231, l2: 0.03196\n",
            "Loss: 6.116243e-05, l1: 0.99240, l2: 0.03195\n",
            "Loss: 6.112138e-05, l1: 0.99246, l2: 0.03196\n",
            "Loss: 6.107496e-05, l1: 0.99250, l2: 0.03196\n",
            "Loss: 6.102721e-05, l1: 0.99252, l2: 0.03197\n",
            "Loss: 6.098516e-05, l1: 0.99249, l2: 0.03198\n",
            "Loss: 6.094835e-05, l1: 0.99236, l2: 0.03198\n",
            "Loss: 6.092089e-05, l1: 0.99217, l2: 0.03198\n",
            "Loss: 6.089955e-05, l1: 0.99200, l2: 0.03198\n",
            "Loss: 6.087046e-05, l1: 0.99189, l2: 0.03198\n",
            "Loss: 6.083082e-05, l1: 0.99166, l2: 0.03198\n",
            "Loss: 6.079598e-05, l1: 0.99179, l2: 0.03199\n",
            "Loss: 6.076010e-05, l1: 0.99200, l2: 0.03199\n",
            "Loss: 6.072527e-05, l1: 0.99230, l2: 0.03201\n",
            "Loss: 6.069155e-05, l1: 0.99246, l2: 0.03202\n",
            "Loss: 6.062860e-05, l1: 0.99271, l2: 0.03203\n",
            "Loss: 6.055170e-05, l1: 0.99279, l2: 0.03204\n",
            "Loss: 6.045556e-05, l1: 0.99322, l2: 0.03207\n",
            "Loss: 6.036051e-05, l1: 0.99323, l2: 0.03207\n",
            "Loss: 6.031383e-05, l1: 0.99321, l2: 0.03207\n",
            "Loss: 6.028737e-05, l1: 0.99331, l2: 0.03207\n",
            "Loss: 6.024517e-05, l1: 0.99340, l2: 0.03207\n",
            "Loss: 6.019145e-05, l1: 0.99345, l2: 0.03207\n",
            "Loss: 6.019161e-05, l1: 0.99377, l2: 0.03208\n",
            "Loss: 6.016100e-05, l1: 0.99361, l2: 0.03207\n",
            "Loss: 6.011682e-05, l1: 0.99346, l2: 0.03208\n",
            "Loss: 6.006629e-05, l1: 0.99345, l2: 0.03208\n",
            "Loss: 6.002835e-05, l1: 0.99341, l2: 0.03209\n",
            "Loss: 5.999987e-05, l1: 0.99345, l2: 0.03210\n",
            "Loss: 5.995966e-05, l1: 0.99363, l2: 0.03211\n",
            "Loss: 5.992031e-05, l1: 0.99381, l2: 0.03211\n",
            "Loss: 5.988709e-05, l1: 0.99402, l2: 0.03211\n",
            "Loss: 5.985883e-05, l1: 0.99407, l2: 0.03210\n",
            "Loss: 5.983168e-05, l1: 0.99405, l2: 0.03210\n",
            "Loss: 5.979307e-05, l1: 0.99400, l2: 0.03209\n",
            "Loss: 5.972284e-05, l1: 0.99399, l2: 0.03209\n",
            "Loss: 5.964034e-05, l1: 0.99401, l2: 0.03209\n",
            "Loss: 5.952406e-05, l1: 0.99418, l2: 0.03209\n",
            "Loss: 5.937250e-05, l1: 0.99474, l2: 0.03211\n",
            "Loss: 5.922489e-05, l1: 0.99444, l2: 0.03208\n",
            "Loss: 5.908315e-05, l1: 0.99466, l2: 0.03206\n",
            "Loss: 5.901731e-05, l1: 0.99481, l2: 0.03206\n",
            "Loss: 5.894280e-05, l1: 0.99473, l2: 0.03205\n",
            "Loss: 5.924033e-05, l1: 0.99581, l2: 0.03206\n",
            "Loss: 5.890577e-05, l1: 0.99500, l2: 0.03205\n",
            "Loss: 5.886023e-05, l1: 0.99505, l2: 0.03204\n",
            "Loss: 5.883252e-05, l1: 0.99511, l2: 0.03205\n",
            "Loss: 5.877251e-05, l1: 0.99517, l2: 0.03203\n",
            "Loss: 5.872576e-05, l1: 0.99524, l2: 0.03204\n",
            "Loss: 5.867632e-05, l1: 0.99504, l2: 0.03202\n",
            "Loss: 5.864997e-05, l1: 0.99521, l2: 0.03203\n",
            "Loss: 5.865905e-05, l1: 0.99546, l2: 0.03204\n",
            "Loss: 5.859147e-05, l1: 0.99533, l2: 0.03204\n",
            "Loss: 5.854018e-05, l1: 0.99526, l2: 0.03203\n",
            "Loss: 5.843636e-05, l1: 0.99507, l2: 0.03202\n",
            "Loss: 5.834769e-05, l1: 0.99493, l2: 0.03201\n",
            "Loss: 5.826134e-05, l1: 0.99473, l2: 0.03200\n",
            "Loss: 5.818967e-05, l1: 0.99475, l2: 0.03200\n",
            "Loss: 5.811945e-05, l1: 0.99477, l2: 0.03200\n",
            "Loss: 5.805450e-05, l1: 0.99492, l2: 0.03201\n",
            "Loss: 5.802109e-05, l1: 0.99494, l2: 0.03201\n",
            "Loss: 5.798163e-05, l1: 0.99511, l2: 0.03201\n",
            "Loss: 5.792478e-05, l1: 0.99523, l2: 0.03200\n",
            "Loss: 5.788370e-05, l1: 0.99541, l2: 0.03200\n",
            "Loss: 5.780117e-05, l1: 0.99594, l2: 0.03200\n",
            "Loss: 5.773603e-05, l1: 0.99617, l2: 0.03200\n",
            "Loss: 5.810483e-05, l1: 0.99793, l2: 0.03203\n",
            "Loss: 5.766482e-05, l1: 0.99668, l2: 0.03201\n",
            "Loss: 5.790756e-05, l1: 0.99639, l2: 0.03197\n",
            "Loss: 5.762088e-05, l1: 0.99660, l2: 0.03200\n",
            "Loss: 5.752118e-05, l1: 0.99683, l2: 0.03198\n",
            "Loss: 5.746095e-05, l1: 0.99666, l2: 0.03199\n",
            "Loss: 5.742876e-05, l1: 0.99667, l2: 0.03200\n",
            "Loss: 5.738280e-05, l1: 0.99674, l2: 0.03200\n",
            "Loss: 5.736337e-05, l1: 0.99714, l2: 0.03202\n",
            "Loss: 5.727558e-05, l1: 0.99742, l2: 0.03203\n",
            "Loss: 5.722983e-05, l1: 0.99731, l2: 0.03202\n",
            "Loss: 5.716911e-05, l1: 0.99735, l2: 0.03201\n",
            "Loss: 5.712580e-05, l1: 0.99736, l2: 0.03200\n",
            "Loss: 5.707719e-05, l1: 0.99742, l2: 0.03200\n",
            "Loss: 5.704215e-05, l1: 0.99741, l2: 0.03200\n",
            "Loss: 5.700310e-05, l1: 0.99734, l2: 0.03200\n",
            "Loss: 5.693785e-05, l1: 0.99738, l2: 0.03201\n",
            "Loss: 5.698887e-05, l1: 0.99654, l2: 0.03199\n",
            "Loss: 5.689399e-05, l1: 0.99704, l2: 0.03200\n",
            "Loss: 5.682198e-05, l1: 0.99721, l2: 0.03200\n",
            "Loss: 5.677079e-05, l1: 0.99744, l2: 0.03199\n",
            "Loss: 5.674006e-05, l1: 0.99754, l2: 0.03198\n",
            "Loss: 5.667187e-05, l1: 0.99803, l2: 0.03198\n",
            "Loss: 5.692439e-05, l1: 0.99787, l2: 0.03185\n",
            "Loss: 5.655010e-05, l1: 0.99798, l2: 0.03193\n",
            "Loss: 5.644230e-05, l1: 0.99766, l2: 0.03193\n",
            "Loss: 5.627738e-05, l1: 0.99705, l2: 0.03194\n",
            "Loss: 5.627767e-05, l1: 0.99761, l2: 0.03191\n",
            "Loss: 5.618406e-05, l1: 0.99733, l2: 0.03193\n",
            "Loss: 5.608062e-05, l1: 0.99732, l2: 0.03191\n",
            "Loss: 5.597733e-05, l1: 0.99729, l2: 0.03188\n",
            "Loss: 5.594061e-05, l1: 0.99710, l2: 0.03185\n",
            "Loss: 5.589501e-05, l1: 0.99709, l2: 0.03184\n",
            "Loss: 5.586830e-05, l1: 0.99706, l2: 0.03184\n",
            "Loss: 5.583582e-05, l1: 0.99701, l2: 0.03183\n",
            "Loss: 5.582123e-05, l1: 0.99689, l2: 0.03183\n",
            "Loss: 5.579020e-05, l1: 0.99689, l2: 0.03182\n",
            "Loss: 5.579821e-05, l1: 0.99652, l2: 0.03179\n",
            "Loss: 5.577794e-05, l1: 0.99673, l2: 0.03181\n",
            "Loss: 5.576033e-05, l1: 0.99675, l2: 0.03181\n",
            "Loss: 5.572927e-05, l1: 0.99678, l2: 0.03180\n",
            "Loss: 5.570650e-05, l1: 0.99679, l2: 0.03180\n",
            "Loss: 5.567201e-05, l1: 0.99678, l2: 0.03180\n",
            "Loss: 5.567802e-05, l1: 0.99668, l2: 0.03179\n",
            "Loss: 5.565988e-05, l1: 0.99674, l2: 0.03180\n",
            "Loss: 5.561519e-05, l1: 0.99668, l2: 0.03180\n",
            "Loss: 5.557443e-05, l1: 0.99663, l2: 0.03179\n",
            "Loss: 5.548537e-05, l1: 0.99653, l2: 0.03178\n",
            "Loss: 5.565977e-05, l1: 0.99713, l2: 0.03178\n",
            "Loss: 5.546996e-05, l1: 0.99666, l2: 0.03178\n",
            "Loss: 5.541447e-05, l1: 0.99665, l2: 0.03178\n",
            "Loss: 5.531552e-05, l1: 0.99677, l2: 0.03178\n",
            "Loss: 5.551247e-05, l1: 0.99671, l2: 0.03174\n",
            "Loss: 5.528860e-05, l1: 0.99675, l2: 0.03177\n",
            "Loss: 5.518507e-05, l1: 0.99740, l2: 0.03179\n",
            "Loss: 5.517325e-05, l1: 0.99708, l2: 0.03177\n",
            "Loss: 5.509090e-05, l1: 0.99727, l2: 0.03178\n",
            "Loss: 5.506165e-05, l1: 0.99732, l2: 0.03178\n",
            "Loss: 5.499724e-05, l1: 0.99733, l2: 0.03178\n",
            "Loss: 5.491207e-05, l1: 0.99735, l2: 0.03176\n",
            "Loss: 5.484192e-05, l1: 0.99724, l2: 0.03176\n",
            "Loss: 5.478676e-05, l1: 0.99725, l2: 0.03175\n",
            "Loss: 5.470365e-05, l1: 0.99728, l2: 0.03173\n",
            "Loss: 5.465130e-05, l1: 0.99746, l2: 0.03173\n",
            "Loss: 5.460068e-05, l1: 0.99773, l2: 0.03173\n",
            "Loss: 5.457340e-05, l1: 0.99786, l2: 0.03173\n",
            "Loss: 5.451143e-05, l1: 0.99811, l2: 0.03173\n",
            "Loss: 5.446331e-05, l1: 0.99835, l2: 0.03172\n",
            "Loss: 5.438782e-05, l1: 0.99868, l2: 0.03173\n",
            "Loss: 5.433270e-05, l1: 0.99853, l2: 0.03172\n",
            "Loss: 5.424082e-05, l1: 0.99838, l2: 0.03172\n",
            "Loss: 5.418574e-05, l1: 0.99839, l2: 0.03172\n",
            "Loss: 5.412803e-05, l1: 0.99837, l2: 0.03171\n",
            "Loss: 5.408166e-05, l1: 0.99849, l2: 0.03172\n",
            "Loss: 5.402353e-05, l1: 0.99834, l2: 0.03171\n",
            "Loss: 5.396598e-05, l1: 0.99838, l2: 0.03172\n",
            "Loss: 5.391920e-05, l1: 0.99831, l2: 0.03173\n",
            "Loss: 5.387919e-05, l1: 0.99812, l2: 0.03172\n",
            "Loss: 5.383835e-05, l1: 0.99809, l2: 0.03172\n",
            "Loss: 5.377144e-05, l1: 0.99813, l2: 0.03171\n",
            "Loss: 5.369202e-05, l1: 0.99824, l2: 0.03171\n",
            "Loss: 5.359710e-05, l1: 0.99820, l2: 0.03170\n",
            "Loss: 5.352073e-05, l1: 0.99825, l2: 0.03172\n",
            "Loss: 5.344798e-05, l1: 0.99799, l2: 0.03171\n",
            "Loss: 5.338200e-05, l1: 0.99782, l2: 0.03174\n",
            "Loss: 5.332201e-05, l1: 0.99754, l2: 0.03172\n",
            "Loss: 5.784823e-05, l1: 0.99729, l2: 0.03173\n",
            "Loss: 5.330765e-05, l1: 0.99752, l2: 0.03172\n",
            "Loss: 5.324850e-05, l1: 0.99734, l2: 0.03171\n",
            "Loss: 5.322762e-05, l1: 0.99761, l2: 0.03171\n",
            "Loss: 5.314771e-05, l1: 0.99743, l2: 0.03171\n",
            "Loss: 5.308292e-05, l1: 0.99742, l2: 0.03172\n",
            "Loss: 5.301868e-05, l1: 0.99746, l2: 0.03173\n",
            "Loss: 5.297195e-05, l1: 0.99743, l2: 0.03174\n",
            "Loss: 5.292556e-05, l1: 0.99744, l2: 0.03174\n",
            "Loss: 5.287628e-05, l1: 0.99735, l2: 0.03173\n",
            "Loss: 5.283090e-05, l1: 0.99733, l2: 0.03172\n",
            "Loss: 5.277874e-05, l1: 0.99723, l2: 0.03172\n",
            "Loss: 5.272191e-05, l1: 0.99731, l2: 0.03172\n",
            "Loss: 5.264859e-05, l1: 0.99751, l2: 0.03175\n",
            "Loss: 5.257584e-05, l1: 0.99778, l2: 0.03178\n",
            "Loss: 5.250125e-05, l1: 0.99800, l2: 0.03179\n",
            "Loss: 5.240895e-05, l1: 0.99815, l2: 0.03180\n",
            "Loss: 5.230994e-05, l1: 0.99810, l2: 0.03178\n",
            "Loss: 5.222018e-05, l1: 0.99802, l2: 0.03175\n",
            "Loss: 5.211978e-05, l1: 0.99776, l2: 0.03172\n",
            "Loss: 5.204564e-05, l1: 0.99763, l2: 0.03170\n",
            "Loss: 5.195508e-05, l1: 0.99764, l2: 0.03168\n",
            "Loss: 5.187123e-05, l1: 0.99764, l2: 0.03169\n",
            "Loss: 5.180452e-05, l1: 0.99775, l2: 0.03170\n",
            "Loss: 5.174852e-05, l1: 0.99772, l2: 0.03173\n",
            "Loss: 5.172270e-05, l1: 0.99771, l2: 0.03172\n",
            "Loss: 5.169744e-05, l1: 0.99769, l2: 0.03172\n",
            "Loss: 5.167113e-05, l1: 0.99767, l2: 0.03172\n",
            "Loss: 5.175421e-05, l1: 0.99754, l2: 0.03171\n",
            "Loss: 5.164786e-05, l1: 0.99763, l2: 0.03172\n",
            "Loss: 5.209120e-05, l1: 0.99750, l2: 0.03170\n",
            "Loss: 5.162728e-05, l1: 0.99760, l2: 0.03172\n",
            "Loss: 5.156839e-05, l1: 0.99793, l2: 0.03173\n",
            "Loss: 5.151374e-05, l1: 0.99799, l2: 0.03173\n",
            "Loss: 5.141516e-05, l1: 0.99811, l2: 0.03173\n",
            "Loss: 5.136693e-05, l1: 0.99808, l2: 0.03173\n",
            "Loss: 5.127617e-05, l1: 0.99796, l2: 0.03171\n",
            "Loss: 5.123481e-05, l1: 0.99791, l2: 0.03171\n",
            "Loss: 5.116698e-05, l1: 0.99785, l2: 0.03172\n",
            "Loss: 5.110085e-05, l1: 0.99790, l2: 0.03173\n",
            "Loss: 5.101958e-05, l1: 0.99773, l2: 0.03174\n",
            "Loss: 5.093515e-05, l1: 0.99776, l2: 0.03174\n",
            "Loss: 5.086386e-05, l1: 0.99768, l2: 0.03173\n",
            "Loss: 5.081661e-05, l1: 0.99732, l2: 0.03171\n",
            "Loss: 5.076527e-05, l1: 0.99721, l2: 0.03172\n",
            "Loss: 5.072287e-05, l1: 0.99729, l2: 0.03173\n",
            "Loss: 5.068137e-05, l1: 0.99733, l2: 0.03172\n",
            "Loss: 5.064623e-05, l1: 0.99736, l2: 0.03172\n",
            "Loss: 5.056276e-05, l1: 0.99743, l2: 0.03171\n",
            "Loss: 5.050202e-05, l1: 0.99748, l2: 0.03171\n",
            "Loss: 5.044449e-05, l1: 0.99755, l2: 0.03171\n",
            "Loss: 5.041469e-05, l1: 0.99770, l2: 0.03172\n",
            "Loss: 5.040257e-05, l1: 0.99774, l2: 0.03173\n",
            "Loss: 5.038644e-05, l1: 0.99778, l2: 0.03173\n",
            "Loss: 5.036186e-05, l1: 0.99785, l2: 0.03173\n",
            "Loss: 5.032688e-05, l1: 0.99798, l2: 0.03173\n",
            "Loss: 5.030500e-05, l1: 0.99797, l2: 0.03171\n",
            "Loss: 5.028639e-05, l1: 0.99798, l2: 0.03170\n",
            "Loss: 5.027629e-05, l1: 0.99797, l2: 0.03170\n",
            "Loss: 5.026792e-05, l1: 0.99771, l2: 0.03170\n",
            "Loss: 5.024757e-05, l1: 0.99792, l2: 0.03170\n",
            "Loss: 5.022674e-05, l1: 0.99791, l2: 0.03171\n",
            "Loss: 5.021106e-05, l1: 0.99784, l2: 0.03171\n",
            "Loss: 5.019517e-05, l1: 0.99772, l2: 0.03170\n",
            "Loss: 5.018056e-05, l1: 0.99760, l2: 0.03170\n",
            "Loss: 5.023268e-05, l1: 0.99717, l2: 0.03170\n",
            "Loss: 5.016626e-05, l1: 0.99747, l2: 0.03170\n",
            "Loss: 5.014724e-05, l1: 0.99745, l2: 0.03170\n",
            "Loss: 5.010913e-05, l1: 0.99743, l2: 0.03171\n",
            "Loss: 5.006930e-05, l1: 0.99741, l2: 0.03172\n",
            "Loss: 5.001665e-05, l1: 0.99743, l2: 0.03174\n",
            "Loss: 4.998712e-05, l1: 0.99743, l2: 0.03177\n",
            "Loss: 4.995154e-05, l1: 0.99742, l2: 0.03177\n",
            "Loss: 4.992429e-05, l1: 0.99734, l2: 0.03177\n",
            "Loss: 4.989818e-05, l1: 0.99724, l2: 0.03176\n",
            "Loss: 4.986068e-05, l1: 0.99711, l2: 0.03177\n",
            "Loss: 4.983925e-05, l1: 0.99684, l2: 0.03178\n",
            "Loss: 4.981610e-05, l1: 0.99690, l2: 0.03179\n",
            "Loss: 4.980047e-05, l1: 0.99691, l2: 0.03179\n",
            "Loss: 4.978483e-05, l1: 0.99701, l2: 0.03179\n",
            "Loss: 4.977440e-05, l1: 0.99696, l2: 0.03179\n",
            "Loss: 4.975091e-05, l1: 0.99687, l2: 0.03179\n",
            "Loss: 4.970779e-05, l1: 0.99692, l2: 0.03179\n",
            "Loss: 4.960078e-05, l1: 0.99714, l2: 0.03181\n",
            "Loss: 4.955700e-05, l1: 0.99720, l2: 0.03182\n",
            "Loss: 4.951370e-05, l1: 0.99736, l2: 0.03183\n",
            "Loss: 4.948459e-05, l1: 0.99744, l2: 0.03183\n",
            "Loss: 4.944059e-05, l1: 0.99747, l2: 0.03183\n",
            "Loss: 4.943780e-05, l1: 0.99791, l2: 0.03183\n",
            "Loss: 4.941419e-05, l1: 0.99770, l2: 0.03183\n",
            "Loss: 4.938423e-05, l1: 0.99763, l2: 0.03183\n",
            "Loss: 4.935483e-05, l1: 0.99757, l2: 0.03183\n",
            "Loss: 4.942398e-05, l1: 0.99714, l2: 0.03181\n",
            "Loss: 4.934556e-05, l1: 0.99746, l2: 0.03182\n",
            "Loss: 4.931921e-05, l1: 0.99753, l2: 0.03183\n",
            "Loss: 4.930346e-05, l1: 0.99747, l2: 0.03183\n",
            "Loss: 4.928603e-05, l1: 0.99745, l2: 0.03183\n",
            "Loss: 4.925743e-05, l1: 0.99752, l2: 0.03183\n",
            "Loss: 4.924348e-05, l1: 0.99746, l2: 0.03182\n",
            "Loss: 4.921837e-05, l1: 0.99751, l2: 0.03183\n",
            "Loss: 4.919132e-05, l1: 0.99759, l2: 0.03184\n",
            "Loss: 4.917461e-05, l1: 0.99762, l2: 0.03186\n",
            "Loss: 4.915510e-05, l1: 0.99763, l2: 0.03186\n",
            "Loss: 4.913455e-05, l1: 0.99768, l2: 0.03187\n",
            "Loss: 4.912771e-05, l1: 0.99769, l2: 0.03187\n",
            "Loss: 4.911196e-05, l1: 0.99778, l2: 0.03187\n",
            "Loss: 4.909546e-05, l1: 0.99774, l2: 0.03186\n",
            "Loss: 4.906750e-05, l1: 0.99777, l2: 0.03186\n",
            "Loss: 4.901116e-05, l1: 0.99777, l2: 0.03186\n",
            "Loss: 4.898004e-05, l1: 0.99772, l2: 0.03185\n",
            "Loss: 4.893930e-05, l1: 0.99765, l2: 0.03186\n",
            "Loss: 4.890637e-05, l1: 0.99755, l2: 0.03187\n",
            "Loss: 4.888344e-05, l1: 0.99755, l2: 0.03188\n",
            "Loss: 4.887123e-05, l1: 0.99756, l2: 0.03188\n",
            "Loss: 4.886107e-05, l1: 0.99760, l2: 0.03189\n",
            "Loss: 4.883509e-05, l1: 0.99774, l2: 0.03189\n",
            "Loss: 4.880390e-05, l1: 0.99778, l2: 0.03189\n",
            "Loss: 4.873772e-05, l1: 0.99786, l2: 0.03190\n",
            "Loss: 4.869450e-05, l1: 0.99788, l2: 0.03190\n",
            "Loss: 4.866836e-05, l1: 0.99786, l2: 0.03190\n",
            "Loss: 4.864333e-05, l1: 0.99766, l2: 0.03190\n",
            "Loss: 4.862349e-05, l1: 0.99761, l2: 0.03189\n",
            "Loss: 4.860602e-05, l1: 0.99762, l2: 0.03189\n",
            "Loss: 4.858517e-05, l1: 0.99762, l2: 0.03189\n",
            "Loss: 4.855419e-05, l1: 0.99758, l2: 0.03190\n",
            "Loss: 4.853338e-05, l1: 0.99754, l2: 0.03191\n",
            "Loss: 4.851471e-05, l1: 0.99748, l2: 0.03191\n",
            "Loss: 4.851335e-05, l1: 0.99731, l2: 0.03191\n",
            "Loss: 4.850049e-05, l1: 0.99739, l2: 0.03191\n",
            "Loss: 4.846189e-05, l1: 0.99728, l2: 0.03191\n",
            "Loss: 4.853076e-05, l1: 0.99723, l2: 0.03190\n",
            "Loss: 4.844426e-05, l1: 0.99727, l2: 0.03191\n",
            "Loss: 4.839337e-05, l1: 0.99719, l2: 0.03191\n",
            "Loss: 4.834035e-05, l1: 0.99708, l2: 0.03190\n",
            "Loss: 4.827932e-05, l1: 0.99708, l2: 0.03190\n",
            "Loss: 4.820056e-05, l1: 0.99689, l2: 0.03190\n",
            "Loss: 4.813295e-05, l1: 0.99688, l2: 0.03190\n",
            "Loss: 4.808928e-05, l1: 0.99682, l2: 0.03189\n",
            "Loss: 4.806004e-05, l1: 0.99684, l2: 0.03189\n",
            "Loss: 4.802997e-05, l1: 0.99689, l2: 0.03189\n",
            "Loss: 4.799763e-05, l1: 0.99695, l2: 0.03189\n",
            "Loss: 4.794183e-05, l1: 0.99705, l2: 0.03190\n",
            "Loss: 4.786192e-05, l1: 0.99709, l2: 0.03191\n",
            "Loss: 4.788127e-05, l1: 0.99752, l2: 0.03194\n",
            "Loss: 4.781538e-05, l1: 0.99729, l2: 0.03192\n",
            "Loss: 4.770466e-05, l1: 0.99713, l2: 0.03194\n",
            "Loss: 4.764125e-05, l1: 0.99693, l2: 0.03193\n",
            "Loss: 4.759493e-05, l1: 0.99664, l2: 0.03192\n",
            "Loss: 4.757176e-05, l1: 0.99661, l2: 0.03192\n",
            "Loss: 4.754382e-05, l1: 0.99658, l2: 0.03191\n",
            "Loss: 4.749779e-05, l1: 0.99659, l2: 0.03191\n",
            "Loss: 4.745489e-05, l1: 0.99648, l2: 0.03190\n",
            "Loss: 4.741224e-05, l1: 0.99638, l2: 0.03190\n",
            "Loss: 4.737316e-05, l1: 0.99639, l2: 0.03191\n",
            "Loss: 4.734254e-05, l1: 0.99634, l2: 0.03191\n",
            "Loss: 4.731047e-05, l1: 0.99614, l2: 0.03191\n",
            "Loss: 4.728528e-05, l1: 0.99602, l2: 0.03191\n",
            "Loss: 4.727986e-05, l1: 0.99571, l2: 0.03191\n",
            "Loss: 4.725414e-05, l1: 0.99584, l2: 0.03191\n",
            "Loss: 4.722931e-05, l1: 0.99595, l2: 0.03192\n",
            "Loss: 4.720346e-05, l1: 0.99603, l2: 0.03193\n",
            "Loss: 4.718225e-05, l1: 0.99605, l2: 0.03194\n",
            "Loss: 4.734910e-05, l1: 0.99599, l2: 0.03195\n",
            "Loss: 4.717926e-05, l1: 0.99604, l2: 0.03194\n",
            "Loss: 4.716213e-05, l1: 0.99600, l2: 0.03195\n",
            "Loss: 4.714587e-05, l1: 0.99593, l2: 0.03195\n",
            "Loss: 4.712260e-05, l1: 0.99583, l2: 0.03195\n",
            "Loss: 4.709280e-05, l1: 0.99577, l2: 0.03195\n",
            "Loss: 4.766320e-05, l1: 0.99554, l2: 0.03196\n",
            "Loss: 4.708056e-05, l1: 0.99574, l2: 0.03195\n",
            "Loss: 4.705363e-05, l1: 0.99580, l2: 0.03195\n",
            "Loss: 4.702209e-05, l1: 0.99598, l2: 0.03196\n",
            "Loss: 4.700179e-05, l1: 0.99613, l2: 0.03196\n",
            "Loss: 4.696328e-05, l1: 0.99636, l2: 0.03197\n",
            "Loss: 4.691690e-05, l1: 0.99664, l2: 0.03198\n",
            "Loss: 4.740501e-05, l1: 0.99691, l2: 0.03203\n",
            "Loss: 4.687782e-05, l1: 0.99669, l2: 0.03199\n",
            "Loss: 4.686495e-05, l1: 0.99668, l2: 0.03200\n",
            "Loss: 4.679040e-05, l1: 0.99678, l2: 0.03199\n",
            "Loss: 4.674090e-05, l1: 0.99680, l2: 0.03198\n",
            "Loss: 4.665240e-05, l1: 0.99693, l2: 0.03197\n",
            "Loss: 4.676202e-05, l1: 0.99755, l2: 0.03197\n",
            "Loss: 4.662325e-05, l1: 0.99713, l2: 0.03197\n",
            "Loss: 4.656849e-05, l1: 0.99725, l2: 0.03197\n",
            "Loss: 4.654939e-05, l1: 0.99743, l2: 0.03198\n",
            "Loss: 4.653686e-05, l1: 0.99745, l2: 0.03198\n",
            "Loss: 4.652730e-05, l1: 0.99748, l2: 0.03198\n",
            "Loss: 4.650311e-05, l1: 0.99746, l2: 0.03199\n",
            "Loss: 4.646797e-05, l1: 0.99742, l2: 0.03199\n",
            "Loss: 4.642782e-05, l1: 0.99730, l2: 0.03199\n",
            "Loss: 4.639033e-05, l1: 0.99736, l2: 0.03199\n",
            "Loss: 4.636540e-05, l1: 0.99730, l2: 0.03198\n",
            "Loss: 4.632927e-05, l1: 0.99723, l2: 0.03197\n",
            "Loss: 4.627019e-05, l1: 0.99705, l2: 0.03195\n",
            "Loss: 4.637003e-05, l1: 0.99772, l2: 0.03195\n",
            "Loss: 4.622011e-05, l1: 0.99730, l2: 0.03195\n",
            "Loss: 4.619843e-05, l1: 0.99700, l2: 0.03190\n",
            "Loss: 4.606630e-05, l1: 0.99704, l2: 0.03193\n",
            "Loss: 4.601872e-05, l1: 0.99716, l2: 0.03195\n",
            "Loss: 4.597538e-05, l1: 0.99725, l2: 0.03196\n",
            "Loss: 4.592754e-05, l1: 0.99729, l2: 0.03196\n",
            "Loss: 4.587150e-05, l1: 0.99732, l2: 0.03196\n",
            "Loss: 4.581083e-05, l1: 0.99721, l2: 0.03195\n",
            "Loss: 4.575310e-05, l1: 0.99717, l2: 0.03194\n",
            "Loss: 4.568246e-05, l1: 0.99693, l2: 0.03191\n",
            "Loss: 4.564580e-05, l1: 0.99727, l2: 0.03192\n",
            "Loss: 4.671572e-05, l1: 0.99649, l2: 0.03193\n",
            "Loss: 4.560202e-05, l1: 0.99714, l2: 0.03192\n",
            "Loss: 4.557155e-05, l1: 0.99712, l2: 0.03193\n",
            "Loss: 4.553720e-05, l1: 0.99718, l2: 0.03193\n",
            "Loss: 4.551728e-05, l1: 0.99727, l2: 0.03193\n",
            "Loss: 4.560019e-05, l1: 0.99788, l2: 0.03194\n",
            "Loss: 4.551030e-05, l1: 0.99740, l2: 0.03193\n",
            "Loss: 4.549941e-05, l1: 0.99745, l2: 0.03193\n",
            "Loss: 4.546388e-05, l1: 0.99757, l2: 0.03194\n",
            "Loss: 4.542636e-05, l1: 0.99758, l2: 0.03194\n",
            "Loss: 4.537501e-05, l1: 0.99762, l2: 0.03194\n",
            "Loss: 4.533086e-05, l1: 0.99733, l2: 0.03194\n",
            "Loss: 4.528912e-05, l1: 0.99691, l2: 0.03193\n",
            "Loss: 4.522942e-05, l1: 0.99707, l2: 0.03194\n",
            "Loss: 4.517307e-05, l1: 0.99717, l2: 0.03194\n",
            "Loss: 4.513177e-05, l1: 0.99710, l2: 0.03195\n",
            "Loss: 4.510485e-05, l1: 0.99697, l2: 0.03195\n",
            "Loss: 4.507734e-05, l1: 0.99692, l2: 0.03196\n",
            "Loss: 4.506434e-05, l1: 0.99686, l2: 0.03196\n",
            "Loss: 4.502363e-05, l1: 0.99676, l2: 0.03197\n",
            "Loss: 4.499114e-05, l1: 0.99660, l2: 0.03197\n",
            "Loss: 4.496523e-05, l1: 0.99659, l2: 0.03198\n",
            "Loss: 4.498509e-05, l1: 0.99656, l2: 0.03199\n",
            "Loss: 4.494964e-05, l1: 0.99658, l2: 0.03198\n",
            "Loss: 4.492762e-05, l1: 0.99657, l2: 0.03198\n",
            "Loss: 4.491334e-05, l1: 0.99654, l2: 0.03197\n",
            "Loss: 4.488583e-05, l1: 0.99650, l2: 0.03197\n",
            "Loss: 4.485508e-05, l1: 0.99636, l2: 0.03196\n",
            "Loss: 4.483173e-05, l1: 0.99637, l2: 0.03195\n",
            "Loss: 4.480376e-05, l1: 0.99628, l2: 0.03195\n",
            "Loss: 4.477455e-05, l1: 0.99626, l2: 0.03195\n",
            "Loss: 4.474416e-05, l1: 0.99620, l2: 0.03196\n",
            "Loss: 4.837195e-05, l1: 0.99647, l2: 0.03192\n",
            "Loss: 4.474147e-05, l1: 0.99621, l2: 0.03195\n",
            "Loss: 4.471336e-05, l1: 0.99617, l2: 0.03196\n",
            "Loss: 4.481133e-05, l1: 0.99587, l2: 0.03194\n",
            "Loss: 4.469727e-05, l1: 0.99609, l2: 0.03195\n",
            "Loss: 4.465679e-05, l1: 0.99615, l2: 0.03195\n",
            "Loss: 4.462416e-05, l1: 0.99624, l2: 0.03195\n",
            "Loss: 4.460362e-05, l1: 0.99638, l2: 0.03195\n",
            "Loss: 4.459109e-05, l1: 0.99644, l2: 0.03195\n",
            "Loss: 4.458184e-05, l1: 0.99644, l2: 0.03196\n",
            "Loss: 4.457431e-05, l1: 0.99645, l2: 0.03196\n",
            "Loss: 4.456835e-05, l1: 0.99645, l2: 0.03196\n",
            "Loss: 4.455461e-05, l1: 0.99644, l2: 0.03197\n",
            "Loss: 4.454020e-05, l1: 0.99641, l2: 0.03197\n",
            "Loss: 4.451192e-05, l1: 0.99637, l2: 0.03197\n",
            "Loss: 4.459885e-05, l1: 0.99628, l2: 0.03197\n",
            "Loss: 4.448853e-05, l1: 0.99634, l2: 0.03197\n",
            "Loss: 4.443068e-05, l1: 0.99626, l2: 0.03197\n",
            "Loss: 4.437145e-05, l1: 0.99616, l2: 0.03196\n",
            "Loss: 4.433282e-05, l1: 0.99611, l2: 0.03197\n",
            "Loss: 4.430305e-05, l1: 0.99611, l2: 0.03197\n",
            "Loss: 4.425059e-05, l1: 0.99611, l2: 0.03197\n",
            "Loss: 4.421341e-05, l1: 0.99608, l2: 0.03198\n",
            "Loss: 4.419633e-05, l1: 0.99612, l2: 0.03199\n",
            "Loss: 4.416333e-05, l1: 0.99615, l2: 0.03198\n",
            "Loss: 4.413150e-05, l1: 0.99613, l2: 0.03198\n",
            "Loss: 4.407968e-05, l1: 0.99608, l2: 0.03197\n",
            "Loss: 4.402631e-05, l1: 0.99606, l2: 0.03196\n",
            "Loss: 4.397742e-05, l1: 0.99593, l2: 0.03195\n",
            "Loss: 4.398713e-05, l1: 0.99623, l2: 0.03195\n",
            "Loss: 4.396405e-05, l1: 0.99606, l2: 0.03195\n",
            "Loss: 4.394666e-05, l1: 0.99597, l2: 0.03195\n",
            "Loss: 4.392157e-05, l1: 0.99586, l2: 0.03194\n",
            "Loss: 4.390829e-05, l1: 0.99585, l2: 0.03194\n",
            "Loss: 4.388648e-05, l1: 0.99586, l2: 0.03194\n",
            "Loss: 4.386622e-05, l1: 0.99589, l2: 0.03194\n",
            "Loss: 4.383629e-05, l1: 0.99587, l2: 0.03194\n",
            "Loss: 4.381275e-05, l1: 0.99604, l2: 0.03194\n",
            "Loss: 4.377186e-05, l1: 0.99592, l2: 0.03194\n",
            "Loss: 4.374702e-05, l1: 0.99585, l2: 0.03194\n",
            "Loss: 4.371917e-05, l1: 0.99578, l2: 0.03193\n",
            "Loss: 4.368114e-05, l1: 0.99577, l2: 0.03193\n",
            "Loss: 4.366496e-05, l1: 0.99570, l2: 0.03192\n",
            "Loss: 4.361210e-05, l1: 0.99582, l2: 0.03192\n",
            "Loss: 4.359027e-05, l1: 0.99587, l2: 0.03192\n",
            "Loss: 4.354982e-05, l1: 0.99596, l2: 0.03193\n",
            "Loss: 4.351177e-05, l1: 0.99604, l2: 0.03192\n",
            "Loss: 4.344639e-05, l1: 0.99610, l2: 0.03191\n",
            "Loss: 4.338225e-05, l1: 0.99627, l2: 0.03189\n",
            "Loss: 4.335788e-05, l1: 0.99637, l2: 0.03188\n",
            "Loss: 4.332392e-05, l1: 0.99630, l2: 0.03188\n",
            "Loss: 4.331109e-05, l1: 0.99625, l2: 0.03188\n",
            "Loss: 4.329678e-05, l1: 0.99623, l2: 0.03188\n",
            "Loss: 4.327406e-05, l1: 0.99618, l2: 0.03188\n",
            "Loss: 4.325358e-05, l1: 0.99611, l2: 0.03187\n",
            "Loss: 4.322251e-05, l1: 0.99595, l2: 0.03186\n",
            "Loss: 4.324411e-05, l1: 0.99585, l2: 0.03185\n",
            "Loss: 4.320994e-05, l1: 0.99591, l2: 0.03186\n",
            "Loss: 4.318871e-05, l1: 0.99570, l2: 0.03185\n",
            "Loss: 4.315795e-05, l1: 0.99569, l2: 0.03186\n",
            "Loss: 4.312908e-05, l1: 0.99578, l2: 0.03186\n",
            "Loss: 4.309085e-05, l1: 0.99582, l2: 0.03187\n",
            "Loss: 4.308086e-05, l1: 0.99575, l2: 0.03186\n",
            "Loss: 4.319181e-05, l1: 0.99614, l2: 0.03182\n",
            "Loss: 4.303973e-05, l1: 0.99589, l2: 0.03184\n",
            "Loss: 4.298215e-05, l1: 0.99582, l2: 0.03184\n",
            "Loss: 4.291332e-05, l1: 0.99566, l2: 0.03182\n",
            "Loss: 4.287299e-05, l1: 0.99559, l2: 0.03181\n",
            "Loss: 4.283800e-05, l1: 0.99556, l2: 0.03180\n",
            "Loss: 4.281797e-05, l1: 0.99557, l2: 0.03180\n",
            "Loss: 4.279439e-05, l1: 0.99562, l2: 0.03179\n",
            "Loss: 4.275672e-05, l1: 0.99572, l2: 0.03179\n",
            "Loss: 4.270087e-05, l1: 0.99590, l2: 0.03177\n",
            "Loss: 4.262901e-05, l1: 0.99618, l2: 0.03175\n",
            "Loss: 4.372562e-05, l1: 0.99620, l2: 0.03167\n",
            "Loss: 4.261619e-05, l1: 0.99618, l2: 0.03175\n",
            "Loss: 4.254491e-05, l1: 0.99651, l2: 0.03174\n",
            "Loss: 4.248039e-05, l1: 0.99676, l2: 0.03174\n",
            "Loss: 4.246438e-05, l1: 0.99705, l2: 0.03176\n",
            "Loss: 4.237988e-05, l1: 0.99684, l2: 0.03175\n",
            "Loss: 4.235048e-05, l1: 0.99673, l2: 0.03176\n",
            "Loss: 4.232767e-05, l1: 0.99678, l2: 0.03176\n",
            "Loss: 4.231503e-05, l1: 0.99686, l2: 0.03176\n",
            "Loss: 4.230090e-05, l1: 0.99699, l2: 0.03177\n",
            "Loss: 4.228529e-05, l1: 0.99709, l2: 0.03176\n",
            "Loss: 4.226976e-05, l1: 0.99723, l2: 0.03176\n",
            "Loss: 4.223703e-05, l1: 0.99717, l2: 0.03176\n",
            "Loss: 4.221940e-05, l1: 0.99702, l2: 0.03175\n",
            "Loss: 4.220429e-05, l1: 0.99693, l2: 0.03175\n",
            "Loss: 4.218911e-05, l1: 0.99685, l2: 0.03174\n",
            "Loss: 4.216899e-05, l1: 0.99683, l2: 0.03174\n",
            "Loss: 4.216084e-05, l1: 0.99682, l2: 0.03175\n",
            "Loss: 4.213504e-05, l1: 0.99688, l2: 0.03175\n",
            "Loss: 4.212400e-05, l1: 0.99697, l2: 0.03174\n",
            "Loss: 4.211540e-05, l1: 0.99703, l2: 0.03175\n",
            "Loss: 4.209935e-05, l1: 0.99715, l2: 0.03175\n",
            "Loss: 4.207120e-05, l1: 0.99729, l2: 0.03175\n",
            "Loss: 4.203013e-05, l1: 0.99744, l2: 0.03175\n",
            "Loss: 4.199237e-05, l1: 0.99746, l2: 0.03176\n",
            "Loss: 4.196235e-05, l1: 0.99742, l2: 0.03175\n",
            "Loss: 4.194145e-05, l1: 0.99743, l2: 0.03175\n",
            "Loss: 4.251867e-05, l1: 0.99626, l2: 0.03182\n",
            "Loss: 4.192949e-05, l1: 0.99728, l2: 0.03176\n",
            "Loss: 4.190814e-05, l1: 0.99732, l2: 0.03176\n",
            "Loss: 4.189063e-05, l1: 0.99740, l2: 0.03177\n",
            "Loss: 4.188157e-05, l1: 0.99743, l2: 0.03177\n",
            "Loss: 4.186502e-05, l1: 0.99752, l2: 0.03178\n",
            "Loss: 4.200742e-05, l1: 0.99742, l2: 0.03180\n",
            "Loss: 4.186153e-05, l1: 0.99751, l2: 0.03178\n",
            "Loss: 4.185064e-05, l1: 0.99755, l2: 0.03179\n",
            "Loss: 4.183298e-05, l1: 0.99765, l2: 0.03179\n",
            "Loss: 4.182126e-05, l1: 0.99774, l2: 0.03179\n",
            "Loss: 4.180639e-05, l1: 0.99789, l2: 0.03180\n",
            "Loss: 4.179363e-05, l1: 0.99804, l2: 0.03180\n",
            "Loss: 4.180395e-05, l1: 0.99822, l2: 0.03181\n",
            "Loss: 4.178995e-05, l1: 0.99810, l2: 0.03180\n",
            "Loss: 4.178467e-05, l1: 0.99812, l2: 0.03181\n",
            "Loss: 4.179601e-05, l1: 0.99815, l2: 0.03182\n",
            "Loss: 4.178138e-05, l1: 0.99813, l2: 0.03181\n",
            "Loss: 4.177533e-05, l1: 0.99814, l2: 0.03182\n",
            "Loss: 4.176559e-05, l1: 0.99807, l2: 0.03182\n",
            "Loss: 4.175230e-05, l1: 0.99810, l2: 0.03182\n",
            "Loss: 4.173176e-05, l1: 0.99812, l2: 0.03182\n",
            "Loss: 4.171015e-05, l1: 0.99813, l2: 0.03181\n",
            "Loss: 4.169041e-05, l1: 0.99815, l2: 0.03182\n",
            "Loss: 4.167409e-05, l1: 0.99813, l2: 0.03181\n",
            "Loss: 4.165761e-05, l1: 0.99809, l2: 0.03181\n",
            "Loss: 4.163720e-05, l1: 0.99803, l2: 0.03182\n",
            "Loss: 4.162653e-05, l1: 0.99801, l2: 0.03182\n",
            "Loss: 4.161528e-05, l1: 0.99800, l2: 0.03182\n",
            "Loss: 4.159837e-05, l1: 0.99799, l2: 0.03182\n",
            "Loss: 4.157830e-05, l1: 0.99798, l2: 0.03181\n",
            "Loss: 4.155806e-05, l1: 0.99796, l2: 0.03181\n",
            "Loss: 4.154355e-05, l1: 0.99799, l2: 0.03181\n",
            "Loss: 4.153153e-05, l1: 0.99802, l2: 0.03181\n",
            "Loss: 4.152364e-05, l1: 0.99804, l2: 0.03181\n",
            "Loss: 4.151868e-05, l1: 0.99808, l2: 0.03180\n",
            "Loss: 4.151143e-05, l1: 0.99806, l2: 0.03180\n",
            "Loss: 4.149807e-05, l1: 0.99804, l2: 0.03180\n",
            "Loss: 4.148674e-05, l1: 0.99803, l2: 0.03179\n",
            "Loss: 4.146669e-05, l1: 0.99797, l2: 0.03178\n",
            "Loss: 4.162023e-05, l1: 0.99805, l2: 0.03176\n",
            "Loss: 4.146051e-05, l1: 0.99799, l2: 0.03178\n",
            "Loss: 4.145283e-05, l1: 0.99805, l2: 0.03178\n",
            "Loss: 4.144156e-05, l1: 0.99804, l2: 0.03178\n",
            "Loss: 4.143571e-05, l1: 0.99802, l2: 0.03178\n",
            "Loss: 4.142837e-05, l1: 0.99800, l2: 0.03177\n",
            "Loss: 4.142258e-05, l1: 0.99798, l2: 0.03177\n",
            "Loss: 4.141500e-05, l1: 0.99791, l2: 0.03177\n",
            "Loss: 4.141706e-05, l1: 0.99792, l2: 0.03176\n",
            "Loss: 4.141210e-05, l1: 0.99791, l2: 0.03177\n",
            "Loss: 4.140948e-05, l1: 0.99789, l2: 0.03177\n",
            "Loss: 4.140880e-05, l1: 0.99788, l2: 0.03177\n",
            "Loss: 4.140618e-05, l1: 0.99787, l2: 0.03177\n",
            "Loss: 4.140219e-05, l1: 0.99785, l2: 0.03177\n",
            "Loss: 4.139961e-05, l1: 0.99781, l2: 0.03177\n",
            "Loss: 4.139823e-05, l1: 0.99786, l2: 0.03176\n",
            "Loss: 4.138962e-05, l1: 0.99784, l2: 0.03177\n",
            "Loss: 4.138739e-05, l1: 0.99786, l2: 0.03177\n",
            "Loss: 4.138316e-05, l1: 0.99788, l2: 0.03176\n",
            "Loss: 4.137945e-05, l1: 0.99792, l2: 0.03176\n",
            "Loss: 4.137747e-05, l1: 0.99798, l2: 0.03176\n",
            "Loss: 4.136591e-05, l1: 0.99807, l2: 0.03175\n",
            "Loss: 4.135956e-05, l1: 0.99809, l2: 0.03175\n",
            "Loss: 4.135329e-05, l1: 0.99810, l2: 0.03175\n",
            "Loss: 4.135445e-05, l1: 0.99817, l2: 0.03176\n",
            "Loss: 4.135152e-05, l1: 0.99813, l2: 0.03175\n",
            "Loss: 4.134783e-05, l1: 0.99811, l2: 0.03175\n",
            "Loss: 4.133891e-05, l1: 0.99806, l2: 0.03175\n",
            "Loss: 4.133313e-05, l1: 0.99803, l2: 0.03176\n",
            "Loss: 4.132598e-05, l1: 0.99800, l2: 0.03176\n",
            "Loss: 4.132302e-05, l1: 0.99807, l2: 0.03177\n",
            "Loss: 4.131634e-05, l1: 0.99807, l2: 0.03177\n",
            "Loss: 4.131197e-05, l1: 0.99808, l2: 0.03177\n",
            "Loss: 4.130815e-05, l1: 0.99810, l2: 0.03177\n",
            "Loss: 4.130191e-05, l1: 0.99810, l2: 0.03177\n",
            "Loss: 4.129165e-05, l1: 0.99809, l2: 0.03177\n",
            "Loss: 4.128209e-05, l1: 0.99804, l2: 0.03177\n",
            "Loss: 4.127430e-05, l1: 0.99799, l2: 0.03176\n",
            "Loss: 4.126770e-05, l1: 0.99794, l2: 0.03176\n",
            "Loss: 4.125886e-05, l1: 0.99789, l2: 0.03175\n",
            "Loss: 4.124791e-05, l1: 0.99785, l2: 0.03175\n",
            "Loss: 4.123257e-05, l1: 0.99784, l2: 0.03174\n",
            "Loss: 4.121856e-05, l1: 0.99785, l2: 0.03175\n",
            "Loss: 4.121167e-05, l1: 0.99789, l2: 0.03176\n",
            "Loss: 4.119297e-05, l1: 0.99789, l2: 0.03175\n",
            "Loss: 4.118100e-05, l1: 0.99786, l2: 0.03175\n",
            "Loss: 4.116627e-05, l1: 0.99783, l2: 0.03176\n",
            "Loss: 4.115101e-05, l1: 0.99778, l2: 0.03176\n",
            "Loss: 4.113378e-05, l1: 0.99769, l2: 0.03176\n",
            "Loss: 4.111792e-05, l1: 0.99761, l2: 0.03177\n",
            "Loss: 4.110935e-05, l1: 0.99751, l2: 0.03177\n",
            "Loss: 4.110213e-05, l1: 0.99754, l2: 0.03177\n",
            "Loss: 4.109710e-05, l1: 0.99755, l2: 0.03178\n",
            "Loss: 4.109067e-05, l1: 0.99752, l2: 0.03178\n",
            "Loss: 4.108254e-05, l1: 0.99747, l2: 0.03179\n",
            "Loss: 4.107282e-05, l1: 0.99742, l2: 0.03179\n",
            "Loss: 4.106478e-05, l1: 0.99738, l2: 0.03179\n",
            "Loss: 4.105905e-05, l1: 0.99736, l2: 0.03180\n",
            "Loss: 4.105176e-05, l1: 0.99738, l2: 0.03180\n",
            "Loss: 4.103972e-05, l1: 0.99741, l2: 0.03180\n",
            "Loss: 4.103166e-05, l1: 0.99744, l2: 0.03180\n",
            "Loss: 4.101723e-05, l1: 0.99747, l2: 0.03182\n",
            "Loss: 4.110292e-05, l1: 0.99740, l2: 0.03185\n",
            "Loss: 4.101345e-05, l1: 0.99746, l2: 0.03182\n",
            "Loss: 4.100092e-05, l1: 0.99750, l2: 0.03183\n",
            "Loss: 4.100490e-05, l1: 0.99737, l2: 0.03184\n",
            "Loss: 4.099667e-05, l1: 0.99745, l2: 0.03184\n",
            "Loss: 4.099061e-05, l1: 0.99740, l2: 0.03184\n",
            "Loss: 4.098652e-05, l1: 0.99737, l2: 0.03183\n",
            "Loss: 4.098023e-05, l1: 0.99734, l2: 0.03183\n",
            "Loss: 4.096766e-05, l1: 0.99730, l2: 0.03183\n",
            "Loss: 4.095651e-05, l1: 0.99726, l2: 0.03182\n",
            "Loss: 4.109611e-05, l1: 0.99689, l2: 0.03184\n",
            "Loss: 4.094661e-05, l1: 0.99719, l2: 0.03183\n",
            "Loss: 4.092802e-05, l1: 0.99714, l2: 0.03183\n",
            "Loss: 4.090358e-05, l1: 0.99702, l2: 0.03183\n",
            "Loss: 4.089208e-05, l1: 0.99693, l2: 0.03183\n",
            "Loss: 4.088102e-05, l1: 0.99680, l2: 0.03183\n",
            "Loss: 4.087392e-05, l1: 0.99669, l2: 0.03183\n",
            "Loss: 4.086631e-05, l1: 0.99662, l2: 0.03183\n",
            "Loss: 4.086010e-05, l1: 0.99658, l2: 0.03183\n",
            "Loss: 4.085571e-05, l1: 0.99659, l2: 0.03182\n",
            "Loss: 4.085218e-05, l1: 0.99660, l2: 0.03183\n",
            "Loss: 4.084810e-05, l1: 0.99660, l2: 0.03183\n",
            "Loss: 4.084284e-05, l1: 0.99657, l2: 0.03183\n",
            "Loss: 4.083487e-05, l1: 0.99653, l2: 0.03183\n",
            "Loss: 4.108628e-05, l1: 0.99596, l2: 0.03184\n",
            "Loss: 4.083323e-05, l1: 0.99648, l2: 0.03183\n",
            "Loss: 4.082381e-05, l1: 0.99639, l2: 0.03183\n",
            "Loss: 4.081448e-05, l1: 0.99633, l2: 0.03183\n",
            "Loss: 4.080385e-05, l1: 0.99621, l2: 0.03183\n",
            "Loss: 4.079432e-05, l1: 0.99621, l2: 0.03183\n",
            "Loss: 4.078584e-05, l1: 0.99610, l2: 0.03183\n",
            "Loss: 4.079964e-05, l1: 0.99608, l2: 0.03184\n",
            "Loss: 4.078001e-05, l1: 0.99609, l2: 0.03183\n",
            "Loss: 4.077231e-05, l1: 0.99612, l2: 0.03183\n",
            "Loss: 4.076321e-05, l1: 0.99612, l2: 0.03183\n",
            "Loss: 4.075564e-05, l1: 0.99612, l2: 0.03183\n",
            "Loss: 4.075070e-05, l1: 0.99607, l2: 0.03182\n",
            "Loss: 4.074688e-05, l1: 0.99607, l2: 0.03183\n",
            "Loss: 4.074059e-05, l1: 0.99608, l2: 0.03183\n",
            "Loss: 4.073558e-05, l1: 0.99608, l2: 0.03183\n",
            "Loss: 4.073244e-05, l1: 0.99616, l2: 0.03183\n",
            "Loss: 4.072651e-05, l1: 0.99605, l2: 0.03183\n",
            "Loss: 4.071644e-05, l1: 0.99608, l2: 0.03183\n",
            "Loss: 4.070929e-05, l1: 0.99613, l2: 0.03184\n",
            "Loss: 4.069641e-05, l1: 0.99611, l2: 0.03184\n",
            "Loss: 4.068905e-05, l1: 0.99609, l2: 0.03184\n",
            "Loss: 4.068056e-05, l1: 0.99607, l2: 0.03185\n",
            "Loss: 4.067312e-05, l1: 0.99608, l2: 0.03185\n",
            "Loss: 4.071010e-05, l1: 0.99586, l2: 0.03186\n",
            "Loss: 4.066327e-05, l1: 0.99601, l2: 0.03185\n",
            "Loss: 4.064800e-05, l1: 0.99599, l2: 0.03185\n",
            "Loss: 4.062336e-05, l1: 0.99591, l2: 0.03184\n",
            "Loss: 4.061637e-05, l1: 0.99588, l2: 0.03184\n",
            "Loss: 4.060479e-05, l1: 0.99573, l2: 0.03184\n",
            "Loss: 4.059808e-05, l1: 0.99571, l2: 0.03184\n",
            "Loss: 4.059006e-05, l1: 0.99574, l2: 0.03184\n",
            "Loss: 4.058602e-05, l1: 0.99573, l2: 0.03184\n",
            "Loss: 4.057777e-05, l1: 0.99568, l2: 0.03184\n",
            "Loss: 4.057087e-05, l1: 0.99562, l2: 0.03184\n",
            "Loss: 4.056154e-05, l1: 0.99545, l2: 0.03184\n",
            "Loss: 4.055274e-05, l1: 0.99538, l2: 0.03183\n",
            "Loss: 4.073846e-05, l1: 0.99507, l2: 0.03187\n",
            "Loss: 4.054783e-05, l1: 0.99534, l2: 0.03184\n",
            "Loss: 4.054072e-05, l1: 0.99533, l2: 0.03184\n",
            "Loss: 4.053557e-05, l1: 0.99533, l2: 0.03184\n",
            "Loss: 4.053268e-05, l1: 0.99533, l2: 0.03183\n",
            "Loss: 4.052029e-05, l1: 0.99525, l2: 0.03184\n",
            "Loss: 4.050668e-05, l1: 0.99515, l2: 0.03183\n",
            "Loss: 4.049337e-05, l1: 0.99504, l2: 0.03183\n",
            "Loss: 4.047226e-05, l1: 0.99498, l2: 0.03183\n",
            "Loss: 4.045659e-05, l1: 0.99496, l2: 0.03182\n",
            "Loss: 4.043639e-05, l1: 0.99503, l2: 0.03181\n",
            "Loss: 4.042553e-05, l1: 0.99505, l2: 0.03180\n",
            "Loss: 4.041956e-05, l1: 0.99514, l2: 0.03180\n",
            "Loss: 4.041337e-05, l1: 0.99519, l2: 0.03180\n",
            "Loss: 4.040755e-05, l1: 0.99518, l2: 0.03180\n",
            "Loss: 4.039325e-05, l1: 0.99517, l2: 0.03180\n",
            "Loss: 4.038055e-05, l1: 0.99519, l2: 0.03180\n",
            "Loss: 4.035218e-05, l1: 0.99524, l2: 0.03179\n",
            "Loss: 4.031794e-05, l1: 0.99529, l2: 0.03178\n",
            "Loss: 4.027578e-05, l1: 0.99546, l2: 0.03176\n",
            "Loss: 4.024030e-05, l1: 0.99548, l2: 0.03176\n",
            "Loss: 4.019452e-05, l1: 0.99555, l2: 0.03177\n",
            "Loss: 4.016658e-05, l1: 0.99555, l2: 0.03178\n",
            "Loss: 4.014458e-05, l1: 0.99559, l2: 0.03179\n",
            "Loss: 4.012777e-05, l1: 0.99566, l2: 0.03180\n",
            "Loss: 4.011297e-05, l1: 0.99573, l2: 0.03180\n",
            "Loss: 4.009708e-05, l1: 0.99577, l2: 0.03181\n",
            "Loss: 4.008145e-05, l1: 0.99577, l2: 0.03181\n",
            "Loss: 4.006231e-05, l1: 0.99573, l2: 0.03181\n",
            "Loss: 4.004689e-05, l1: 0.99569, l2: 0.03181\n",
            "Loss: 4.003363e-05, l1: 0.99569, l2: 0.03181\n",
            "Loss: 4.001696e-05, l1: 0.99570, l2: 0.03181\n",
            "Loss: 4.000203e-05, l1: 0.99574, l2: 0.03181\n",
            "Loss: 3.998311e-05, l1: 0.99580, l2: 0.03181\n",
            "Loss: 3.996469e-05, l1: 0.99582, l2: 0.03180\n",
            "Loss: 3.995179e-05, l1: 0.99586, l2: 0.03180\n",
            "Loss: 3.994022e-05, l1: 0.99585, l2: 0.03179\n",
            "Loss: 3.997791e-05, l1: 0.99581, l2: 0.03179\n",
            "Loss: 3.992941e-05, l1: 0.99584, l2: 0.03179\n",
            "Loss: 3.991264e-05, l1: 0.99577, l2: 0.03179\n",
            "Loss: 3.989483e-05, l1: 0.99574, l2: 0.03178\n",
            "Loss: 3.988285e-05, l1: 0.99577, l2: 0.03178\n",
            "Loss: 3.987448e-05, l1: 0.99575, l2: 0.03179\n",
            "Loss: 3.987894e-05, l1: 0.99592, l2: 0.03177\n",
            "Loss: 3.986391e-05, l1: 0.99583, l2: 0.03178\n",
            "Loss: 3.984933e-05, l1: 0.99585, l2: 0.03178\n",
            "Loss: 3.982737e-05, l1: 0.99590, l2: 0.03178\n",
            "Loss: 3.980108e-05, l1: 0.99601, l2: 0.03179\n",
            "Loss: 3.982421e-05, l1: 0.99600, l2: 0.03179\n",
            "Loss: 3.978287e-05, l1: 0.99601, l2: 0.03179\n",
            "Loss: 3.973610e-05, l1: 0.99616, l2: 0.03179\n",
            "Loss: 3.978048e-05, l1: 0.99591, l2: 0.03181\n",
            "Loss: 3.971926e-05, l1: 0.99608, l2: 0.03180\n",
            "Loss: 3.968590e-05, l1: 0.99615, l2: 0.03180\n",
            "Loss: 3.966623e-05, l1: 0.99614, l2: 0.03180\n",
            "Loss: 3.965911e-05, l1: 0.99610, l2: 0.03180\n",
            "Loss: 3.965210e-05, l1: 0.99604, l2: 0.03180\n",
            "Loss: 3.964666e-05, l1: 0.99602, l2: 0.03180\n",
            "Loss: 3.963529e-05, l1: 0.99585, l2: 0.03181\n",
            "Loss: 3.966712e-05, l1: 0.99592, l2: 0.03179\n",
            "Loss: 3.962294e-05, l1: 0.99587, l2: 0.03180\n",
            "Loss: 3.960797e-05, l1: 0.99593, l2: 0.03180\n",
            "Loss: 3.957525e-05, l1: 0.99605, l2: 0.03180\n",
            "Loss: 3.955314e-05, l1: 0.99602, l2: 0.03180\n",
            "Loss: 3.953257e-05, l1: 0.99600, l2: 0.03180\n",
            "Loss: 3.950366e-05, l1: 0.99597, l2: 0.03180\n",
            "Loss: 3.949310e-05, l1: 0.99599, l2: 0.03180\n",
            "Loss: 3.948646e-05, l1: 0.99602, l2: 0.03180\n",
            "Loss: 3.948122e-05, l1: 0.99604, l2: 0.03180\n",
            "Loss: 3.947865e-05, l1: 0.99601, l2: 0.03179\n",
            "Loss: 3.947517e-05, l1: 0.99596, l2: 0.03179\n",
            "Loss: 3.947261e-05, l1: 0.99592, l2: 0.03179\n",
            "Loss: 3.946769e-05, l1: 0.99591, l2: 0.03179\n",
            "Loss: 3.946324e-05, l1: 0.99592, l2: 0.03179\n",
            "Loss: 3.946851e-05, l1: 0.99600, l2: 0.03177\n",
            "Loss: 3.945992e-05, l1: 0.99595, l2: 0.03178\n",
            "Loss: 3.945106e-05, l1: 0.99597, l2: 0.03178\n",
            "Loss: 3.943845e-05, l1: 0.99601, l2: 0.03179\n",
            "Loss: 3.941849e-05, l1: 0.99602, l2: 0.03179\n",
            "Loss: 3.940085e-05, l1: 0.99599, l2: 0.03179\n",
            "Loss: 3.938593e-05, l1: 0.99606, l2: 0.03179\n",
            "Loss: 3.936928e-05, l1: 0.99595, l2: 0.03179\n",
            "Loss: 3.934824e-05, l1: 0.99594, l2: 0.03179\n",
            "Loss: 3.932224e-05, l1: 0.99599, l2: 0.03179\n",
            "Loss: 3.934489e-05, l1: 0.99623, l2: 0.03177\n",
            "Loss: 3.931140e-05, l1: 0.99608, l2: 0.03179\n",
            "Loss: 3.929560e-05, l1: 0.99617, l2: 0.03179\n",
            "Loss: 3.928521e-05, l1: 0.99621, l2: 0.03179\n",
            "Loss: 3.927253e-05, l1: 0.99623, l2: 0.03179\n",
            "Loss: 3.925755e-05, l1: 0.99622, l2: 0.03180\n",
            "Loss: 3.924286e-05, l1: 0.99620, l2: 0.03180\n",
            "Loss: 3.932240e-05, l1: 0.99611, l2: 0.03180\n",
            "Loss: 3.923670e-05, l1: 0.99618, l2: 0.03180\n",
            "Loss: 3.922501e-05, l1: 0.99614, l2: 0.03181\n",
            "Loss: 3.965021e-05, l1: 0.99603, l2: 0.03180\n",
            "Loss: 3.922005e-05, l1: 0.99613, l2: 0.03181\n",
            "Loss: 3.920537e-05, l1: 0.99612, l2: 0.03180\n",
            "Loss: 3.918651e-05, l1: 0.99612, l2: 0.03180\n",
            "Loss: 3.916630e-05, l1: 0.99615, l2: 0.03179\n",
            "Loss: 3.913035e-05, l1: 0.99624, l2: 0.03180\n",
            "Loss: 3.911116e-05, l1: 0.99629, l2: 0.03181\n",
            "Loss: 3.909149e-05, l1: 0.99642, l2: 0.03182\n",
            "Loss: 3.907625e-05, l1: 0.99649, l2: 0.03182\n",
            "Loss: 3.905988e-05, l1: 0.99658, l2: 0.03182\n",
            "Loss: 3.906482e-05, l1: 0.99675, l2: 0.03181\n",
            "Loss: 3.905079e-05, l1: 0.99666, l2: 0.03181\n",
            "Loss: 3.904033e-05, l1: 0.99667, l2: 0.03181\n",
            "Loss: 3.902973e-05, l1: 0.99672, l2: 0.03182\n",
            "Loss: 3.902446e-05, l1: 0.99676, l2: 0.03182\n",
            "Loss: 3.901422e-05, l1: 0.99680, l2: 0.03182\n",
            "Loss: 3.900446e-05, l1: 0.99683, l2: 0.03182\n",
            "Loss: 3.899531e-05, l1: 0.99684, l2: 0.03182\n",
            "Loss: 3.898563e-05, l1: 0.99683, l2: 0.03182\n",
            "Loss: 3.897971e-05, l1: 0.99681, l2: 0.03182\n",
            "Loss: 3.897019e-05, l1: 0.99683, l2: 0.03182\n",
            "Loss: 3.896597e-05, l1: 0.99683, l2: 0.03181\n",
            "Loss: 3.896205e-05, l1: 0.99683, l2: 0.03181\n",
            "Loss: 3.896009e-05, l1: 0.99683, l2: 0.03181\n",
            "Loss: 3.895612e-05, l1: 0.99684, l2: 0.03181\n",
            "Loss: 3.895078e-05, l1: 0.99686, l2: 0.03181\n",
            "Loss: 3.894297e-05, l1: 0.99692, l2: 0.03180\n",
            "Loss: 3.893235e-05, l1: 0.99696, l2: 0.03180\n",
            "Loss: 3.892250e-05, l1: 0.99701, l2: 0.03180\n",
            "Loss: 3.891957e-05, l1: 0.99705, l2: 0.03180\n",
            "Loss: 3.891708e-05, l1: 0.99705, l2: 0.03180\n",
            "Loss: 3.894047e-05, l1: 0.99700, l2: 0.03181\n",
            "Loss: 3.891595e-05, l1: 0.99705, l2: 0.03180\n",
            "Loss: 3.891375e-05, l1: 0.99705, l2: 0.03180\n",
            "Loss: 3.890977e-05, l1: 0.99708, l2: 0.03180\n",
            "Loss: 3.890350e-05, l1: 0.99713, l2: 0.03180\n",
            "Loss: 3.889987e-05, l1: 0.99730, l2: 0.03179\n",
            "Loss: 3.889504e-05, l1: 0.99730, l2: 0.03179\n",
            "Loss: 3.888944e-05, l1: 0.99726, l2: 0.03180\n",
            "Loss: 3.888641e-05, l1: 0.99730, l2: 0.03180\n",
            "Loss: 3.888357e-05, l1: 0.99735, l2: 0.03180\n",
            "Loss: 3.888158e-05, l1: 0.99739, l2: 0.03180\n",
            "Loss: 3.888110e-05, l1: 0.99743, l2: 0.03180\n",
            "Loss: 3.887657e-05, l1: 0.99743, l2: 0.03180\n",
            "Loss: 3.887267e-05, l1: 0.99742, l2: 0.03180\n",
            "Loss: 3.886787e-05, l1: 0.99743, l2: 0.03180\n",
            "Loss: 3.886511e-05, l1: 0.99745, l2: 0.03180\n",
            "Loss: 3.886481e-05, l1: 0.99756, l2: 0.03180\n",
            "Loss: 3.886252e-05, l1: 0.99750, l2: 0.03180\n",
            "Loss: 3.885901e-05, l1: 0.99755, l2: 0.03180\n",
            "Loss: 3.885671e-05, l1: 0.99762, l2: 0.03180\n",
            "Loss: 3.885402e-05, l1: 0.99769, l2: 0.03180\n",
            "Loss: 3.885092e-05, l1: 0.99778, l2: 0.03180\n",
            "Loss: 3.884755e-05, l1: 0.99786, l2: 0.03180\n",
            "Loss: 3.884110e-05, l1: 0.99794, l2: 0.03180\n",
            "Loss: 3.883335e-05, l1: 0.99799, l2: 0.03180\n",
            "Loss: 3.884065e-05, l1: 0.99800, l2: 0.03180\n",
            "Loss: 3.883171e-05, l1: 0.99800, l2: 0.03180\n",
            "Loss: 3.882452e-05, l1: 0.99798, l2: 0.03180\n",
            "Loss: 3.882033e-05, l1: 0.99795, l2: 0.03181\n",
            "Loss: 3.881797e-05, l1: 0.99790, l2: 0.03181\n",
            "Loss: 3.881537e-05, l1: 0.99790, l2: 0.03181\n",
            "Loss: 3.880955e-05, l1: 0.99792, l2: 0.03182\n",
            "Loss: 3.880414e-05, l1: 0.99793, l2: 0.03182\n",
            "Loss: 3.882588e-05, l1: 0.99813, l2: 0.03184\n",
            "Loss: 3.880091e-05, l1: 0.99799, l2: 0.03182\n",
            "Loss: 3.879148e-05, l1: 0.99800, l2: 0.03182\n",
            "Loss: 3.878379e-05, l1: 0.99803, l2: 0.03182\n",
            "Loss: 3.877475e-05, l1: 0.99801, l2: 0.03182\n",
            "Loss: 3.876750e-05, l1: 0.99800, l2: 0.03182\n",
            "Loss: 3.875666e-05, l1: 0.99793, l2: 0.03183\n",
            "Loss: 3.874778e-05, l1: 0.99798, l2: 0.03183\n",
            "Loss: 3.874258e-05, l1: 0.99801, l2: 0.03183\n",
            "Loss: 3.874035e-05, l1: 0.99796, l2: 0.03183\n",
            "Loss: 3.873874e-05, l1: 0.99804, l2: 0.03182\n",
            "Loss: 3.873527e-05, l1: 0.99799, l2: 0.03182\n",
            "Loss: 3.873410e-05, l1: 0.99800, l2: 0.03182\n",
            "Loss: 3.873015e-05, l1: 0.99793, l2: 0.03182\n",
            "Loss: 3.872795e-05, l1: 0.99790, l2: 0.03182\n",
            "Loss: 3.872562e-05, l1: 0.99788, l2: 0.03182\n",
            "Loss: 3.872310e-05, l1: 0.99790, l2: 0.03182\n",
            "Loss: 3.872189e-05, l1: 0.99792, l2: 0.03182\n",
            "Loss: 3.872052e-05, l1: 0.99794, l2: 0.03182\n",
            "Loss: 3.871814e-05, l1: 0.99798, l2: 0.03182\n",
            "Loss: 3.875282e-05, l1: 0.99807, l2: 0.03182\n",
            "Loss: 3.871628e-05, l1: 0.99800, l2: 0.03182\n",
            "Loss: 3.871429e-05, l1: 0.99800, l2: 0.03182\n",
            "Loss: 3.871125e-05, l1: 0.99799, l2: 0.03183\n",
            "Loss: 3.871626e-05, l1: 0.99803, l2: 0.03182\n",
            "Loss: 3.870873e-05, l1: 0.99800, l2: 0.03182\n",
            "Loss: 3.870789e-05, l1: 0.99801, l2: 0.03182\n",
            "Loss: 3.870447e-05, l1: 0.99805, l2: 0.03182\n",
            "Loss: 3.870181e-05, l1: 0.99809, l2: 0.03182\n",
            "Loss: 3.869672e-05, l1: 0.99815, l2: 0.03183\n",
            "Loss: 3.869811e-05, l1: 0.99825, l2: 0.03182\n",
            "Loss: 3.869379e-05, l1: 0.99820, l2: 0.03182\n",
            "Loss: 3.868822e-05, l1: 0.99824, l2: 0.03183\n",
            "Loss: 3.868408e-05, l1: 0.99828, l2: 0.03183\n",
            "Loss: 3.868153e-05, l1: 0.99831, l2: 0.03183\n",
            "Loss: 3.867805e-05, l1: 0.99836, l2: 0.03183\n",
            "Loss: 3.868109e-05, l1: 0.99853, l2: 0.03183\n",
            "Loss: 3.867479e-05, l1: 0.99843, l2: 0.03183\n",
            "Loss: 3.867111e-05, l1: 0.99849, l2: 0.03184\n",
            "Loss: 3.866688e-05, l1: 0.99856, l2: 0.03184\n",
            "Loss: 3.866264e-05, l1: 0.99861, l2: 0.03184\n",
            "Loss: 3.865819e-05, l1: 0.99865, l2: 0.03185\n",
            "Loss: 3.865457e-05, l1: 0.99868, l2: 0.03185\n",
            "Loss: 3.865111e-05, l1: 0.99865, l2: 0.03185\n",
            "Loss: 3.864793e-05, l1: 0.99861, l2: 0.03185\n",
            "Loss: 3.864573e-05, l1: 0.99854, l2: 0.03184\n",
            "Loss: 3.864255e-05, l1: 0.99851, l2: 0.03184\n",
            "Loss: 3.863466e-05, l1: 0.99850, l2: 0.03184\n",
            "Loss: 3.862832e-05, l1: 0.99854, l2: 0.03185\n",
            "Loss: 3.862061e-05, l1: 0.99861, l2: 0.03185\n",
            "Loss: 3.860963e-05, l1: 0.99874, l2: 0.03185\n",
            "Loss: 3.859805e-05, l1: 0.99885, l2: 0.03185\n",
            "Loss: 3.860593e-05, l1: 0.99911, l2: 0.03183\n",
            "Loss: 3.859132e-05, l1: 0.99895, l2: 0.03184\n",
            "Loss: 3.858121e-05, l1: 0.99895, l2: 0.03185\n",
            "Loss: 3.857213e-05, l1: 0.99891, l2: 0.03185\n",
            "Loss: 3.856721e-05, l1: 0.99890, l2: 0.03185\n",
            "Loss: 3.855712e-05, l1: 0.99891, l2: 0.03185\n",
            "Loss: 3.854488e-05, l1: 0.99896, l2: 0.03185\n",
            "Loss: 3.854050e-05, l1: 0.99899, l2: 0.03184\n",
            "Loss: 3.853817e-05, l1: 0.99905, l2: 0.03184\n",
            "Loss: 3.853726e-05, l1: 0.99905, l2: 0.03184\n",
            "Loss: 3.853654e-05, l1: 0.99907, l2: 0.03184\n",
            "Loss: 3.853552e-05, l1: 0.99909, l2: 0.03184\n",
            "Loss: 3.853374e-05, l1: 0.99912, l2: 0.03184\n",
            "Loss: 3.853472e-05, l1: 0.99919, l2: 0.03184\n",
            "Loss: 3.853308e-05, l1: 0.99915, l2: 0.03184\n",
            "Loss: 3.853006e-05, l1: 0.99918, l2: 0.03184\n",
            "Loss: 3.852736e-05, l1: 0.99917, l2: 0.03184\n",
            "Loss: 3.852350e-05, l1: 0.99913, l2: 0.03183\n",
            "Loss: 3.852008e-05, l1: 0.99914, l2: 0.03183\n",
            "Loss: 3.851688e-05, l1: 0.99915, l2: 0.03183\n",
            "Loss: 3.851418e-05, l1: 0.99915, l2: 0.03183\n",
            "Loss: 3.851183e-05, l1: 0.99920, l2: 0.03183\n",
            "Loss: 3.850779e-05, l1: 0.99918, l2: 0.03182\n",
            "Loss: 3.850440e-05, l1: 0.99919, l2: 0.03182\n",
            "Loss: 3.849792e-05, l1: 0.99919, l2: 0.03182\n",
            "Loss: 3.848934e-05, l1: 0.99921, l2: 0.03182\n",
            "Loss: 3.935655e-05, l1: 0.99916, l2: 0.03178\n",
            "Loss: 3.848479e-05, l1: 0.99921, l2: 0.03182\n",
            "Loss: 3.847342e-05, l1: 0.99918, l2: 0.03182\n",
            "Loss: 3.849358e-05, l1: 0.99930, l2: 0.03181\n",
            "Loss: 3.847008e-05, l1: 0.99921, l2: 0.03181\n",
            "Loss: 3.846144e-05, l1: 0.99918, l2: 0.03181\n",
            "Loss: 3.845891e-05, l1: 0.99916, l2: 0.03181\n",
            "Loss: 3.845313e-05, l1: 0.99919, l2: 0.03181\n",
            "Loss: 3.844441e-05, l1: 0.99918, l2: 0.03181\n",
            "Loss: 3.843195e-05, l1: 0.99923, l2: 0.03182\n",
            "Loss: 3.842279e-05, l1: 0.99921, l2: 0.03182\n",
            "Loss: 3.842169e-05, l1: 0.99918, l2: 0.03181\n",
            "Loss: 3.841465e-05, l1: 0.99920, l2: 0.03181\n",
            "Loss: 3.840354e-05, l1: 0.99920, l2: 0.03182\n",
            "Loss: 3.839100e-05, l1: 0.99919, l2: 0.03182\n",
            "Loss: 3.838178e-05, l1: 0.99916, l2: 0.03182\n",
            "Loss: 3.837083e-05, l1: 0.99912, l2: 0.03182\n",
            "Loss: 3.836862e-05, l1: 0.99899, l2: 0.03182\n",
            "Loss: 3.835341e-05, l1: 0.99906, l2: 0.03182\n",
            "Loss: 3.834362e-05, l1: 0.99906, l2: 0.03182\n",
            "Loss: 3.833374e-05, l1: 0.99912, l2: 0.03182\n",
            "Loss: 3.832759e-05, l1: 0.99910, l2: 0.03182\n",
            "Loss: 3.832224e-05, l1: 0.99908, l2: 0.03183\n",
            "Loss: 3.831938e-05, l1: 0.99909, l2: 0.03183\n",
            "Loss: 3.831549e-05, l1: 0.99912, l2: 0.03183\n",
            "Loss: 3.831227e-05, l1: 0.99916, l2: 0.03183\n",
            "Loss: 3.830556e-05, l1: 0.99920, l2: 0.03183\n",
            "Loss: 3.834025e-05, l1: 0.99921, l2: 0.03182\n",
            "Loss: 3.830282e-05, l1: 0.99920, l2: 0.03183\n",
            "Loss: 3.829045e-05, l1: 0.99919, l2: 0.03183\n",
            "Loss: 3.828250e-05, l1: 0.99923, l2: 0.03183\n",
            "Loss: 3.827585e-05, l1: 0.99919, l2: 0.03183\n",
            "Loss: 3.826809e-05, l1: 0.99910, l2: 0.03182\n",
            "Loss: 3.826256e-05, l1: 0.99903, l2: 0.03182\n",
            "Loss: 3.825655e-05, l1: 0.99898, l2: 0.03182\n",
            "Loss: 3.824459e-05, l1: 0.99892, l2: 0.03182\n",
            "Loss: 3.822920e-05, l1: 0.99885, l2: 0.03182\n",
            "Loss: 3.820737e-05, l1: 0.99854, l2: 0.03183\n",
            "Loss: 3.843435e-05, l1: 0.99893, l2: 0.03180\n",
            "Loss: 3.820082e-05, l1: 0.99860, l2: 0.03183\n",
            "Loss: 3.818173e-05, l1: 0.99865, l2: 0.03183\n",
            "Loss: 3.815769e-05, l1: 0.99871, l2: 0.03182\n",
            "Loss: 3.817289e-05, l1: 0.99864, l2: 0.03184\n",
            "Loss: 3.815338e-05, l1: 0.99869, l2: 0.03183\n",
            "Loss: 3.813620e-05, l1: 0.99873, l2: 0.03182\n",
            "Loss: 3.813021e-05, l1: 0.99871, l2: 0.03182\n",
            "Loss: 3.812732e-05, l1: 0.99869, l2: 0.03182\n",
            "Loss: 3.812605e-05, l1: 0.99868, l2: 0.03182\n",
            "Loss: 3.812083e-05, l1: 0.99868, l2: 0.03181\n",
            "Loss: 3.811612e-05, l1: 0.99865, l2: 0.03181\n",
            "Loss: 3.811047e-05, l1: 0.99863, l2: 0.03181\n",
            "Loss: 3.809845e-05, l1: 0.99861, l2: 0.03181\n",
            "Loss: 3.808055e-05, l1: 0.99858, l2: 0.03181\n",
            "Loss: 3.806360e-05, l1: 0.99868, l2: 0.03181\n",
            "Loss: 3.803382e-05, l1: 0.99858, l2: 0.03181\n",
            "Loss: 3.801314e-05, l1: 0.99860, l2: 0.03181\n",
            "Loss: 3.799710e-05, l1: 0.99858, l2: 0.03181\n",
            "Loss: 3.798842e-05, l1: 0.99859, l2: 0.03180\n",
            "Loss: 3.798188e-05, l1: 0.99854, l2: 0.03180\n",
            "Loss: 3.797007e-05, l1: 0.99844, l2: 0.03180\n",
            "Loss: 3.796533e-05, l1: 0.99842, l2: 0.03180\n",
            "Loss: 3.795504e-05, l1: 0.99837, l2: 0.03180\n",
            "Loss: 3.794593e-05, l1: 0.99837, l2: 0.03180\n",
            "Loss: 3.793460e-05, l1: 0.99843, l2: 0.03180\n",
            "Loss: 3.792632e-05, l1: 0.99852, l2: 0.03181\n",
            "Loss: 3.851347e-05, l1: 0.99934, l2: 0.03184\n",
            "Loss: 3.792137e-05, l1: 0.99859, l2: 0.03181\n",
            "Loss: 3.791537e-05, l1: 0.99863, l2: 0.03181\n",
            "Loss: 3.790574e-05, l1: 0.99868, l2: 0.03181\n",
            "Loss: 3.789947e-05, l1: 0.99869, l2: 0.03182\n",
            "Loss: 3.788464e-05, l1: 0.99864, l2: 0.03182\n",
            "Loss: 3.786629e-05, l1: 0.99859, l2: 0.03183\n",
            "Loss: 3.784524e-05, l1: 0.99838, l2: 0.03182\n",
            "Loss: 3.783416e-05, l1: 0.99844, l2: 0.03183\n",
            "Loss: 3.782046e-05, l1: 0.99845, l2: 0.03183\n",
            "Loss: 3.781279e-05, l1: 0.99841, l2: 0.03182\n",
            "Loss: 3.780655e-05, l1: 0.99844, l2: 0.03182\n",
            "Loss: 3.779920e-05, l1: 0.99849, l2: 0.03182\n",
            "Loss: 3.778866e-05, l1: 0.99853, l2: 0.03182\n",
            "Loss: 3.834390e-05, l1: 0.99886, l2: 0.03182\n",
            "Loss: 3.778225e-05, l1: 0.99856, l2: 0.03182\n",
            "Loss: 3.777562e-05, l1: 0.99858, l2: 0.03182\n",
            "Loss: 3.776786e-05, l1: 0.99855, l2: 0.03182\n",
            "Loss: 3.776205e-05, l1: 0.99858, l2: 0.03182\n",
            "Loss: 3.775774e-05, l1: 0.99858, l2: 0.03182\n",
            "Loss: 3.774428e-05, l1: 0.99862, l2: 0.03183\n",
            "Loss: 3.773584e-05, l1: 0.99866, l2: 0.03183\n",
            "Loss: 3.772565e-05, l1: 0.99874, l2: 0.03183\n",
            "Loss: 3.771735e-05, l1: 0.99881, l2: 0.03183\n",
            "Loss: 3.770596e-05, l1: 0.99892, l2: 0.03182\n",
            "Loss: 3.774559e-05, l1: 0.99940, l2: 0.03183\n",
            "Loss: 3.769637e-05, l1: 0.99907, l2: 0.03183\n",
            "Loss: 3.771219e-05, l1: 0.99903, l2: 0.03182\n",
            "Loss: 3.769064e-05, l1: 0.99906, l2: 0.03182\n",
            "Loss: 3.768053e-05, l1: 0.99906, l2: 0.03182\n",
            "Loss: 3.767667e-05, l1: 0.99905, l2: 0.03182\n",
            "Loss: 3.767387e-05, l1: 0.99904, l2: 0.03182\n",
            "Loss: 3.766797e-05, l1: 0.99903, l2: 0.03182\n",
            "Loss: 3.767437e-05, l1: 0.99893, l2: 0.03182\n",
            "Loss: 3.766244e-05, l1: 0.99899, l2: 0.03182\n",
            "Loss: 3.765482e-05, l1: 0.99899, l2: 0.03182\n",
            "Loss: 3.765153e-05, l1: 0.99899, l2: 0.03182\n",
            "Loss: 3.764559e-05, l1: 0.99899, l2: 0.03182\n",
            "Loss: 3.764014e-05, l1: 0.99898, l2: 0.03182\n",
            "Loss: 3.762928e-05, l1: 0.99902, l2: 0.03182\n",
            "Loss: 3.765410e-05, l1: 0.99878, l2: 0.03181\n",
            "Loss: 3.761632e-05, l1: 0.99893, l2: 0.03182\n",
            "Loss: 3.759686e-05, l1: 0.99900, l2: 0.03182\n",
            "Loss: 3.756909e-05, l1: 0.99918, l2: 0.03182\n",
            "Loss: 3.755556e-05, l1: 0.99921, l2: 0.03182\n",
            "Loss: 3.752948e-05, l1: 0.99929, l2: 0.03182\n",
            "Loss: 3.751940e-05, l1: 0.99932, l2: 0.03182\n",
            "Loss: 3.751071e-05, l1: 0.99934, l2: 0.03182\n",
            "Loss: 3.750114e-05, l1: 0.99935, l2: 0.03182\n",
            "Loss: 3.749098e-05, l1: 0.99934, l2: 0.03182\n",
            "Loss: 3.748290e-05, l1: 0.99933, l2: 0.03182\n",
            "Loss: 3.747653e-05, l1: 0.99928, l2: 0.03183\n",
            "Loss: 3.747297e-05, l1: 0.99925, l2: 0.03183\n",
            "Loss: 3.747133e-05, l1: 0.99922, l2: 0.03183\n",
            "Loss: 3.746904e-05, l1: 0.99922, l2: 0.03183\n",
            "Loss: 3.746608e-05, l1: 0.99920, l2: 0.03183\n",
            "Loss: 3.746089e-05, l1: 0.99920, l2: 0.03182\n",
            "Loss: 3.746677e-05, l1: 0.99913, l2: 0.03183\n",
            "Loss: 3.745810e-05, l1: 0.99917, l2: 0.03182\n",
            "Loss: 3.745270e-05, l1: 0.99913, l2: 0.03182\n",
            "Loss: 3.744635e-05, l1: 0.99909, l2: 0.03182\n",
            "Loss: 3.744057e-05, l1: 0.99908, l2: 0.03182\n",
            "Loss: 3.743661e-05, l1: 0.99884, l2: 0.03180\n",
            "Loss: 3.742190e-05, l1: 0.99904, l2: 0.03183\n",
            "Loss: 3.740751e-05, l1: 0.99893, l2: 0.03182\n",
            "Loss: 3.739948e-05, l1: 0.99894, l2: 0.03182\n",
            "Loss: 3.739233e-05, l1: 0.99896, l2: 0.03181\n",
            "Loss: 3.738332e-05, l1: 0.99896, l2: 0.03181\n",
            "Loss: 3.737191e-05, l1: 0.99892, l2: 0.03181\n",
            "Loss: 3.793554e-05, l1: 0.99905, l2: 0.03183\n",
            "Loss: 3.737025e-05, l1: 0.99893, l2: 0.03181\n",
            "Loss: 3.735887e-05, l1: 0.99886, l2: 0.03181\n",
            "Loss: 3.735144e-05, l1: 0.99881, l2: 0.03181\n",
            "Loss: 3.734572e-05, l1: 0.99878, l2: 0.03181\n",
            "Loss: 3.734082e-05, l1: 0.99877, l2: 0.03181\n",
            "Loss: 3.733757e-05, l1: 0.99873, l2: 0.03180\n",
            "Loss: 3.733339e-05, l1: 0.99874, l2: 0.03180\n",
            "Loss: 3.733110e-05, l1: 0.99876, l2: 0.03180\n",
            "Loss: 3.732878e-05, l1: 0.99877, l2: 0.03180\n",
            "Loss: 3.732532e-05, l1: 0.99881, l2: 0.03180\n",
            "Loss: 3.734438e-05, l1: 0.99875, l2: 0.03179\n",
            "Loss: 3.732290e-05, l1: 0.99880, l2: 0.03179\n",
            "Loss: 3.732010e-05, l1: 0.99882, l2: 0.03179\n",
            "Loss: 3.731755e-05, l1: 0.99883, l2: 0.03179\n",
            "Loss: 3.731601e-05, l1: 0.99884, l2: 0.03179\n",
            "Loss: 3.731054e-05, l1: 0.99886, l2: 0.03180\n",
            "Loss: 3.730289e-05, l1: 0.99891, l2: 0.03180\n",
            "Loss: 3.729103e-05, l1: 0.99898, l2: 0.03180\n",
            "Loss: 3.727953e-05, l1: 0.99905, l2: 0.03181\n",
            "Loss: 3.727329e-05, l1: 0.99910, l2: 0.03181\n",
            "Loss: 3.726947e-05, l1: 0.99908, l2: 0.03181\n",
            "Loss: 3.726566e-05, l1: 0.99907, l2: 0.03181\n",
            "Loss: 3.726321e-05, l1: 0.99905, l2: 0.03181\n",
            "Loss: 3.725861e-05, l1: 0.99905, l2: 0.03181\n",
            "Loss: 3.725090e-05, l1: 0.99904, l2: 0.03181\n",
            "Loss: 3.723738e-05, l1: 0.99902, l2: 0.03181\n",
            "Loss: 3.723504e-05, l1: 0.99902, l2: 0.03181\n",
            "Loss: 3.721823e-05, l1: 0.99901, l2: 0.03181\n",
            "Loss: 3.720800e-05, l1: 0.99902, l2: 0.03180\n",
            "Loss: 3.719473e-05, l1: 0.99904, l2: 0.03180\n",
            "Loss: 3.718594e-05, l1: 0.99909, l2: 0.03180\n",
            "Loss: 3.732503e-05, l1: 0.99916, l2: 0.03180\n",
            "Loss: 3.718171e-05, l1: 0.99910, l2: 0.03180\n",
            "Loss: 3.717394e-05, l1: 0.99918, l2: 0.03180\n",
            "Loss: 3.716886e-05, l1: 0.99923, l2: 0.03180\n",
            "Loss: 3.716734e-05, l1: 0.99928, l2: 0.03180\n",
            "Loss: 3.716563e-05, l1: 0.99927, l2: 0.03180\n",
            "Loss: 3.716367e-05, l1: 0.99925, l2: 0.03180\n",
            "Loss: 3.715873e-05, l1: 0.99923, l2: 0.03180\n",
            "Loss: 3.715541e-05, l1: 0.99920, l2: 0.03181\n",
            "Loss: 3.714850e-05, l1: 0.99923, l2: 0.03181\n",
            "Loss: 3.714020e-05, l1: 0.99924, l2: 0.03181\n",
            "Loss: 3.712899e-05, l1: 0.99921, l2: 0.03180\n",
            "Loss: 3.712219e-05, l1: 0.99916, l2: 0.03180\n",
            "Loss: 3.711456e-05, l1: 0.99908, l2: 0.03180\n",
            "Loss: 3.711075e-05, l1: 0.99903, l2: 0.03180\n",
            "Loss: 3.710468e-05, l1: 0.99899, l2: 0.03179\n",
            "Loss: 3.709793e-05, l1: 0.99897, l2: 0.03180\n",
            "Loss: 3.709022e-05, l1: 0.99889, l2: 0.03179\n",
            "Loss: 3.708845e-05, l1: 0.99892, l2: 0.03181\n",
            "Loss: 3.708070e-05, l1: 0.99890, l2: 0.03180\n",
            "Loss: 3.707887e-05, l1: 0.99888, l2: 0.03180\n",
            "Loss: 3.707479e-05, l1: 0.99882, l2: 0.03180\n",
            "Loss: 3.706910e-05, l1: 0.99873, l2: 0.03180\n",
            "Loss: 3.706488e-05, l1: 0.99864, l2: 0.03180\n",
            "Loss: 3.705932e-05, l1: 0.99858, l2: 0.03180\n",
            "Loss: 3.705526e-05, l1: 0.99842, l2: 0.03180\n",
            "Loss: 3.704881e-05, l1: 0.99841, l2: 0.03180\n",
            "Loss: 3.704091e-05, l1: 0.99846, l2: 0.03180\n",
            "Loss: 3.703514e-05, l1: 0.99850, l2: 0.03180\n",
            "Loss: 3.712856e-05, l1: 0.99869, l2: 0.03180\n",
            "Loss: 3.703350e-05, l1: 0.99852, l2: 0.03180\n",
            "Loss: 3.702864e-05, l1: 0.99854, l2: 0.03180\n",
            "Loss: 3.702110e-05, l1: 0.99854, l2: 0.03180\n",
            "Loss: 3.701353e-05, l1: 0.99850, l2: 0.03180\n",
            "Loss: 3.700854e-05, l1: 0.99849, l2: 0.03180\n",
            "Loss: 3.700392e-05, l1: 0.99848, l2: 0.03180\n",
            "Loss: 3.700073e-05, l1: 0.99848, l2: 0.03180\n",
            "Loss: 3.699760e-05, l1: 0.99848, l2: 0.03180\n",
            "Loss: 3.699256e-05, l1: 0.99848, l2: 0.03180\n",
            "Loss: 3.698787e-05, l1: 0.99851, l2: 0.03180\n",
            "Loss: 3.698306e-05, l1: 0.99853, l2: 0.03181\n",
            "Loss: 3.697991e-05, l1: 0.99854, l2: 0.03180\n",
            "Loss: 3.697535e-05, l1: 0.99854, l2: 0.03180\n",
            "Loss: 3.697049e-05, l1: 0.99854, l2: 0.03180\n",
            "Loss: 3.696855e-05, l1: 0.99849, l2: 0.03179\n",
            "Loss: 3.695864e-05, l1: 0.99851, l2: 0.03179\n",
            "Loss: 3.695114e-05, l1: 0.99849, l2: 0.03179\n",
            "Loss: 3.693401e-05, l1: 0.99841, l2: 0.03179\n",
            "Loss: 3.692788e-05, l1: 0.99838, l2: 0.03179\n",
            "Loss: 3.691972e-05, l1: 0.99833, l2: 0.03179\n",
            "Loss: 3.691279e-05, l1: 0.99830, l2: 0.03179\n",
            "Loss: 3.690270e-05, l1: 0.99830, l2: 0.03179\n",
            "Loss: 3.689127e-05, l1: 0.99831, l2: 0.03179\n",
            "Loss: 3.687360e-05, l1: 0.99835, l2: 0.03178\n",
            "Loss: 3.691570e-05, l1: 0.99841, l2: 0.03178\n",
            "Loss: 3.686907e-05, l1: 0.99836, l2: 0.03178\n",
            "Loss: 3.685918e-05, l1: 0.99833, l2: 0.03178\n",
            "Loss: 3.684925e-05, l1: 0.99830, l2: 0.03178\n",
            "Loss: 3.684109e-05, l1: 0.99823, l2: 0.03178\n",
            "Loss: 3.724401e-05, l1: 0.99797, l2: 0.03177\n",
            "Loss: 3.683801e-05, l1: 0.99821, l2: 0.03178\n",
            "Loss: 3.682988e-05, l1: 0.99816, l2: 0.03178\n",
            "Loss: 3.682021e-05, l1: 0.99807, l2: 0.03177\n",
            "Loss: 3.681245e-05, l1: 0.99803, l2: 0.03177\n",
            "Loss: 3.680694e-05, l1: 0.99812, l2: 0.03176\n",
            "Loss: 3.679905e-05, l1: 0.99807, l2: 0.03176\n",
            "Loss: 3.679446e-05, l1: 0.99806, l2: 0.03176\n",
            "Loss: 3.679044e-05, l1: 0.99805, l2: 0.03176\n",
            "Loss: 3.678738e-05, l1: 0.99803, l2: 0.03175\n",
            "Loss: 3.686065e-05, l1: 0.99771, l2: 0.03174\n",
            "Loss: 3.678550e-05, l1: 0.99799, l2: 0.03175\n",
            "Loss: 3.678190e-05, l1: 0.99797, l2: 0.03175\n",
            "Loss: 3.677389e-05, l1: 0.99793, l2: 0.03175\n",
            "Loss: 3.676281e-05, l1: 0.99790, l2: 0.03175\n",
            "Loss: 3.679377e-05, l1: 0.99767, l2: 0.03174\n",
            "Loss: 3.675823e-05, l1: 0.99783, l2: 0.03175\n",
            "Loss: 3.675047e-05, l1: 0.99788, l2: 0.03175\n",
            "Loss: 3.674347e-05, l1: 0.99790, l2: 0.03175\n",
            "Loss: 3.673970e-05, l1: 0.99793, l2: 0.03175\n",
            "Loss: 3.673520e-05, l1: 0.99792, l2: 0.03175\n",
            "Loss: 3.674944e-05, l1: 0.99780, l2: 0.03175\n",
            "Loss: 3.672934e-05, l1: 0.99788, l2: 0.03175\n",
            "Loss: 3.671973e-05, l1: 0.99785, l2: 0.03175\n",
            "Loss: 3.671482e-05, l1: 0.99783, l2: 0.03175\n",
            "Loss: 3.671184e-05, l1: 0.99781, l2: 0.03175\n",
            "Loss: 3.670840e-05, l1: 0.99778, l2: 0.03175\n",
            "Loss: 3.670176e-05, l1: 0.99775, l2: 0.03174\n",
            "Loss: 3.672386e-05, l1: 0.99748, l2: 0.03174\n",
            "Loss: 3.669939e-05, l1: 0.99768, l2: 0.03174\n",
            "Loss: 3.669131e-05, l1: 0.99763, l2: 0.03174\n",
            "Loss: 3.668475e-05, l1: 0.99760, l2: 0.03174\n",
            "Loss: 3.667572e-05, l1: 0.99755, l2: 0.03173\n",
            "Loss: 3.666585e-05, l1: 0.99748, l2: 0.03173\n",
            "Loss: 3.665956e-05, l1: 0.99739, l2: 0.03174\n",
            "Loss: 3.671405e-05, l1: 0.99683, l2: 0.03172\n",
            "Loss: 3.664818e-05, l1: 0.99722, l2: 0.03173\n",
            "Loss: 3.663348e-05, l1: 0.99726, l2: 0.03173\n",
            "Loss: 3.661904e-05, l1: 0.99723, l2: 0.03173\n",
            "Loss: 3.660524e-05, l1: 0.99718, l2: 0.03173\n",
            "Loss: 3.659664e-05, l1: 0.99715, l2: 0.03173\n",
            "Loss: 3.658534e-05, l1: 0.99710, l2: 0.03173\n",
            "Loss: 3.657855e-05, l1: 0.99710, l2: 0.03173\n",
            "Loss: 3.657398e-05, l1: 0.99712, l2: 0.03173\n",
            "Loss: 3.657005e-05, l1: 0.99711, l2: 0.03173\n",
            "Loss: 3.656530e-05, l1: 0.99709, l2: 0.03173\n",
            "Loss: 3.656185e-05, l1: 0.99705, l2: 0.03173\n",
            "Loss: 3.655893e-05, l1: 0.99698, l2: 0.03173\n",
            "Loss: 3.655293e-05, l1: 0.99698, l2: 0.03173\n",
            "Loss: 3.654178e-05, l1: 0.99697, l2: 0.03172\n",
            "Loss: 3.653479e-05, l1: 0.99695, l2: 0.03172\n",
            "Loss: 3.652716e-05, l1: 0.99692, l2: 0.03172\n",
            "Loss: 3.659112e-05, l1: 0.99714, l2: 0.03172\n",
            "Loss: 3.652525e-05, l1: 0.99695, l2: 0.03172\n",
            "Loss: 3.651522e-05, l1: 0.99692, l2: 0.03172\n",
            "Loss: 3.650798e-05, l1: 0.99688, l2: 0.03172\n",
            "Loss: 3.650190e-05, l1: 0.99690, l2: 0.03172\n",
            "Loss: 3.649633e-05, l1: 0.99691, l2: 0.03172\n",
            "Loss: 3.649117e-05, l1: 0.99690, l2: 0.03173\n",
            "Loss: 3.648486e-05, l1: 0.99688, l2: 0.03173\n",
            "Loss: 3.647953e-05, l1: 0.99687, l2: 0.03173\n",
            "Loss: 3.647586e-05, l1: 0.99685, l2: 0.03173\n",
            "Loss: 3.647249e-05, l1: 0.99686, l2: 0.03173\n",
            "Loss: 3.646723e-05, l1: 0.99688, l2: 0.03172\n",
            "Loss: 3.646045e-05, l1: 0.99691, l2: 0.03172\n",
            "Loss: 3.645173e-05, l1: 0.99696, l2: 0.03172\n",
            "Loss: 3.644646e-05, l1: 0.99694, l2: 0.03173\n",
            "Loss: 3.643792e-05, l1: 0.99699, l2: 0.03173\n",
            "Loss: 3.643288e-05, l1: 0.99698, l2: 0.03172\n",
            "Loss: 3.642687e-05, l1: 0.99697, l2: 0.03172\n",
            "Loss: 3.641684e-05, l1: 0.99695, l2: 0.03172\n",
            "Loss: 3.639949e-05, l1: 0.99692, l2: 0.03173\n",
            "Loss: 3.638618e-05, l1: 0.99693, l2: 0.03173\n",
            "Loss: 3.637443e-05, l1: 0.99696, l2: 0.03173\n",
            "Loss: 3.636636e-05, l1: 0.99697, l2: 0.03173\n",
            "Loss: 3.635821e-05, l1: 0.99701, l2: 0.03174\n",
            "Loss: 3.634737e-05, l1: 0.99720, l2: 0.03174\n",
            "Loss: 3.633788e-05, l1: 0.99715, l2: 0.03175\n",
            "Loss: 3.632300e-05, l1: 0.99717, l2: 0.03175\n",
            "Loss: 3.631069e-05, l1: 0.99717, l2: 0.03174\n",
            "Loss: 3.628998e-05, l1: 0.99716, l2: 0.03174\n",
            "Loss: 3.626843e-05, l1: 0.99708, l2: 0.03174\n",
            "Loss: 3.625561e-05, l1: 0.99688, l2: 0.03174\n",
            "Loss: 3.623410e-05, l1: 0.99688, l2: 0.03174\n",
            "Loss: 3.622085e-05, l1: 0.99689, l2: 0.03174\n",
            "Loss: 3.621148e-05, l1: 0.99690, l2: 0.03175\n",
            "Loss: 3.620364e-05, l1: 0.99688, l2: 0.03175\n",
            "Loss: 3.619517e-05, l1: 0.99687, l2: 0.03175\n",
            "Loss: 3.618900e-05, l1: 0.99682, l2: 0.03175\n",
            "Loss: 3.618513e-05, l1: 0.99681, l2: 0.03175\n",
            "Loss: 3.617984e-05, l1: 0.99684, l2: 0.03175\n",
            "Loss: 3.617570e-05, l1: 0.99688, l2: 0.03175\n",
            "Loss: 3.617238e-05, l1: 0.99692, l2: 0.03175\n",
            "Loss: 3.616343e-05, l1: 0.99695, l2: 0.03175\n",
            "Loss: 3.615474e-05, l1: 0.99695, l2: 0.03176\n",
            "Loss: 3.614622e-05, l1: 0.99696, l2: 0.03176\n",
            "Loss: 3.614038e-05, l1: 0.99693, l2: 0.03176\n",
            "Loss: 3.613631e-05, l1: 0.99692, l2: 0.03176\n",
            "Loss: 3.613347e-05, l1: 0.99694, l2: 0.03176\n",
            "Loss: 3.612788e-05, l1: 0.99700, l2: 0.03176\n",
            "Loss: 3.612499e-05, l1: 0.99703, l2: 0.03176\n",
            "Loss: 3.612140e-05, l1: 0.99707, l2: 0.03176\n",
            "Loss: 3.611359e-05, l1: 0.99709, l2: 0.03176\n",
            "Loss: 3.610166e-05, l1: 0.99713, l2: 0.03176\n",
            "Loss: 3.608562e-05, l1: 0.99718, l2: 0.03177\n",
            "Loss: 3.607936e-05, l1: 0.99720, l2: 0.03177\n",
            "Loss: 3.607559e-05, l1: 0.99721, l2: 0.03177\n",
            "Loss: 3.607059e-05, l1: 0.99724, l2: 0.03177\n",
            "Loss: 3.606677e-05, l1: 0.99724, l2: 0.03177\n",
            "Loss: 3.606232e-05, l1: 0.99722, l2: 0.03176\n",
            "Loss: 3.605748e-05, l1: 0.99724, l2: 0.03176\n",
            "Loss: 3.605241e-05, l1: 0.99724, l2: 0.03176\n",
            "Loss: 3.604887e-05, l1: 0.99725, l2: 0.03176\n",
            "Loss: 3.604570e-05, l1: 0.99724, l2: 0.03176\n",
            "Loss: 3.604134e-05, l1: 0.99722, l2: 0.03176\n",
            "Loss: 3.603412e-05, l1: 0.99720, l2: 0.03176\n",
            "Loss: 3.602561e-05, l1: 0.99720, l2: 0.03176\n",
            "Loss: 3.601863e-05, l1: 0.99721, l2: 0.03176\n",
            "Loss: 3.601160e-05, l1: 0.99725, l2: 0.03176\n",
            "Loss: 3.600471e-05, l1: 0.99731, l2: 0.03176\n",
            "Loss: 3.599926e-05, l1: 0.99738, l2: 0.03176\n",
            "Loss: 3.599468e-05, l1: 0.99741, l2: 0.03176\n",
            "Loss: 3.598979e-05, l1: 0.99744, l2: 0.03176\n",
            "Loss: 3.598192e-05, l1: 0.99749, l2: 0.03177\n",
            "Loss: 3.597399e-05, l1: 0.99755, l2: 0.03177\n",
            "Loss: 3.596107e-05, l1: 0.99758, l2: 0.03177\n",
            "Loss: 3.595113e-05, l1: 0.99772, l2: 0.03178\n",
            "Loss: 3.593642e-05, l1: 0.99772, l2: 0.03178\n",
            "Loss: 3.592813e-05, l1: 0.99765, l2: 0.03178\n",
            "Loss: 3.592479e-05, l1: 0.99760, l2: 0.03178\n",
            "Loss: 3.592156e-05, l1: 0.99759, l2: 0.03178\n",
            "Loss: 3.591144e-05, l1: 0.99758, l2: 0.03178\n",
            "Loss: 3.591618e-05, l1: 0.99749, l2: 0.03178\n",
            "Loss: 3.590716e-05, l1: 0.99754, l2: 0.03178\n",
            "Loss: 3.590134e-05, l1: 0.99754, l2: 0.03179\n",
            "Loss: 3.589771e-05, l1: 0.99755, l2: 0.03179\n",
            "Loss: 3.589511e-05, l1: 0.99759, l2: 0.03179\n",
            "Loss: 3.589271e-05, l1: 0.99761, l2: 0.03179\n",
            "Loss: 3.589008e-05, l1: 0.99764, l2: 0.03179\n",
            "Loss: 3.588668e-05, l1: 0.99769, l2: 0.03179\n",
            "Loss: 3.588331e-05, l1: 0.99772, l2: 0.03179\n",
            "Loss: 3.587990e-05, l1: 0.99774, l2: 0.03179\n",
            "Loss: 3.587687e-05, l1: 0.99774, l2: 0.03179\n",
            "Loss: 3.587311e-05, l1: 0.99774, l2: 0.03179\n",
            "Loss: 3.586940e-05, l1: 0.99773, l2: 0.03179\n",
            "Loss: 3.586364e-05, l1: 0.99771, l2: 0.03179\n",
            "Loss: 3.592202e-05, l1: 0.99772, l2: 0.03179\n",
            "Loss: 3.586042e-05, l1: 0.99771, l2: 0.03179\n",
            "Loss: 3.585194e-05, l1: 0.99767, l2: 0.03179\n",
            "Loss: 3.584681e-05, l1: 0.99768, l2: 0.03179\n",
            "Loss: 3.584056e-05, l1: 0.99769, l2: 0.03179\n",
            "Loss: 3.583523e-05, l1: 0.99771, l2: 0.03179\n",
            "Loss: 3.583212e-05, l1: 0.99765, l2: 0.03179\n",
            "Loss: 3.582759e-05, l1: 0.99771, l2: 0.03178\n",
            "Loss: 3.582359e-05, l1: 0.99772, l2: 0.03178\n",
            "Loss: 3.581859e-05, l1: 0.99775, l2: 0.03178\n",
            "Loss: 3.580970e-05, l1: 0.99783, l2: 0.03178\n",
            "Loss: 3.586888e-05, l1: 0.99773, l2: 0.03179\n",
            "Loss: 3.580690e-05, l1: 0.99781, l2: 0.03178\n",
            "Loss: 3.579589e-05, l1: 0.99795, l2: 0.03179\n",
            "Loss: 3.578608e-05, l1: 0.99799, l2: 0.03179\n",
            "Loss: 3.577794e-05, l1: 0.99803, l2: 0.03179\n",
            "Loss: 3.577196e-05, l1: 0.99805, l2: 0.03179\n",
            "Loss: 3.576480e-05, l1: 0.99812, l2: 0.03180\n",
            "Loss: 3.575551e-05, l1: 0.99822, l2: 0.03180\n",
            "Loss: 3.574462e-05, l1: 0.99851, l2: 0.03181\n",
            "Loss: 3.583028e-05, l1: 0.99851, l2: 0.03181\n",
            "Loss: 3.573710e-05, l1: 0.99851, l2: 0.03181\n",
            "Loss: 3.572655e-05, l1: 0.99846, l2: 0.03181\n",
            "Loss: 3.572015e-05, l1: 0.99844, l2: 0.03180\n",
            "Loss: 3.570845e-05, l1: 0.99847, l2: 0.03181\n",
            "Loss: 3.569754e-05, l1: 0.99850, l2: 0.03181\n",
            "Loss: 3.568288e-05, l1: 0.99857, l2: 0.03181\n",
            "Loss: 3.566867e-05, l1: 0.99867, l2: 0.03182\n",
            "Loss: 3.565572e-05, l1: 0.99878, l2: 0.03182\n",
            "Loss: 3.564767e-05, l1: 0.99881, l2: 0.03182\n",
            "Loss: 3.564299e-05, l1: 0.99885, l2: 0.03182\n",
            "Loss: 3.564178e-05, l1: 0.99885, l2: 0.03182\n",
            "Loss: 3.563961e-05, l1: 0.99886, l2: 0.03182\n",
            "Loss: 3.563824e-05, l1: 0.99888, l2: 0.03182\n",
            "Loss: 3.563545e-05, l1: 0.99890, l2: 0.03182\n",
            "Loss: 3.563268e-05, l1: 0.99892, l2: 0.03182\n",
            "Loss: 3.562905e-05, l1: 0.99893, l2: 0.03182\n",
            "Loss: 3.564057e-05, l1: 0.99903, l2: 0.03181\n",
            "Loss: 3.562757e-05, l1: 0.99896, l2: 0.03182\n",
            "Loss: 3.562574e-05, l1: 0.99896, l2: 0.03181\n",
            "Loss: 3.561912e-05, l1: 0.99898, l2: 0.03181\n",
            "Loss: 3.561273e-05, l1: 0.99905, l2: 0.03182\n",
            "Loss: 3.560635e-05, l1: 0.99911, l2: 0.03182\n",
            "Loss: 3.560061e-05, l1: 0.99917, l2: 0.03182\n",
            "Loss: 3.559567e-05, l1: 0.99920, l2: 0.03182\n",
            "Loss: 3.559115e-05, l1: 0.99928, l2: 0.03182\n",
            "Loss: 3.558719e-05, l1: 0.99924, l2: 0.03182\n",
            "Loss: 3.558427e-05, l1: 0.99922, l2: 0.03182\n",
            "Loss: 3.558291e-05, l1: 0.99921, l2: 0.03183\n",
            "Loss: 3.558021e-05, l1: 0.99923, l2: 0.03183\n",
            "Loss: 3.557416e-05, l1: 0.99925, l2: 0.03183\n",
            "Loss: 3.556818e-05, l1: 0.99931, l2: 0.03183\n",
            "Loss: 3.556023e-05, l1: 0.99934, l2: 0.03183\n",
            "Loss: 3.555250e-05, l1: 0.99939, l2: 0.03183\n",
            "Loss: 3.556091e-05, l1: 0.99951, l2: 0.03182\n",
            "Loss: 3.554495e-05, l1: 0.99944, l2: 0.03183\n",
            "Loss: 3.552644e-05, l1: 0.99947, l2: 0.03182\n",
            "Loss: 3.551245e-05, l1: 0.99948, l2: 0.03182\n",
            "Loss: 3.549879e-05, l1: 0.99945, l2: 0.03182\n",
            "Loss: 3.549042e-05, l1: 0.99947, l2: 0.03183\n",
            "Loss: 3.548453e-05, l1: 0.99950, l2: 0.03183\n",
            "Loss: 3.548327e-05, l1: 0.99958, l2: 0.03183\n",
            "Loss: 3.547778e-05, l1: 0.99956, l2: 0.03183\n",
            "Loss: 3.547556e-05, l1: 0.99954, l2: 0.03183\n",
            "Loss: 3.547393e-05, l1: 0.99956, l2: 0.03183\n",
            "Loss: 3.547160e-05, l1: 0.99954, l2: 0.03183\n",
            "Loss: 3.547034e-05, l1: 0.99953, l2: 0.03183\n",
            "Loss: 3.546869e-05, l1: 0.99954, l2: 0.03183\n",
            "Loss: 3.546659e-05, l1: 0.99954, l2: 0.03183\n",
            "Loss: 3.546527e-05, l1: 0.99955, l2: 0.03183\n",
            "Loss: 3.546316e-05, l1: 0.99956, l2: 0.03183\n",
            "Loss: 3.546040e-05, l1: 0.99957, l2: 0.03183\n",
            "Loss: 3.545770e-05, l1: 0.99960, l2: 0.03183\n",
            "Loss: 3.545394e-05, l1: 0.99964, l2: 0.03184\n",
            "Loss: 3.544924e-05, l1: 0.99966, l2: 0.03184\n",
            "Loss: 3.544592e-05, l1: 0.99968, l2: 0.03184\n",
            "Loss: 3.544259e-05, l1: 0.99969, l2: 0.03184\n",
            "Loss: 3.543805e-05, l1: 0.99969, l2: 0.03184\n",
            "Loss: 3.543398e-05, l1: 0.99967, l2: 0.03184\n",
            "Loss: 3.543127e-05, l1: 0.99965, l2: 0.03184\n",
            "Loss: 3.542791e-05, l1: 0.99964, l2: 0.03184\n",
            "Loss: 3.542369e-05, l1: 0.99964, l2: 0.03184\n",
            "Loss: 3.541912e-05, l1: 0.99966, l2: 0.03184\n",
            "Loss: 3.541471e-05, l1: 0.99969, l2: 0.03184\n",
            "Loss: 3.540943e-05, l1: 0.99972, l2: 0.03184\n",
            "Loss: 3.540577e-05, l1: 0.99977, l2: 0.03184\n",
            "Loss: 3.540684e-05, l1: 0.99978, l2: 0.03184\n",
            "Loss: 3.540277e-05, l1: 0.99977, l2: 0.03184\n",
            "Loss: 3.539991e-05, l1: 0.99976, l2: 0.03184\n",
            "Loss: 3.539357e-05, l1: 0.99974, l2: 0.03184\n",
            "Loss: 3.539107e-05, l1: 0.99974, l2: 0.03184\n",
            "Loss: 3.538656e-05, l1: 0.99974, l2: 0.03184\n",
            "Loss: 3.538421e-05, l1: 0.99980, l2: 0.03184\n",
            "Loss: 3.538096e-05, l1: 0.99980, l2: 0.03184\n",
            "Loss: 3.537747e-05, l1: 0.99984, l2: 0.03184\n",
            "Loss: 3.537403e-05, l1: 0.99989, l2: 0.03184\n",
            "Loss: 3.542430e-05, l1: 1.00040, l2: 0.03186\n",
            "Loss: 3.537175e-05, l1: 0.99997, l2: 0.03185\n",
            "Loss: 3.536790e-05, l1: 1.00002, l2: 0.03185\n",
            "Loss: 3.536265e-05, l1: 1.00009, l2: 0.03185\n",
            "Loss: 3.536055e-05, l1: 1.00011, l2: 0.03185\n",
            "Loss: 3.535637e-05, l1: 1.00008, l2: 0.03185\n",
            "Loss: 3.535119e-05, l1: 1.00002, l2: 0.03185\n",
            "Loss: 3.534574e-05, l1: 0.99996, l2: 0.03185\n",
            "Loss: 3.534086e-05, l1: 0.99987, l2: 0.03184\n",
            "Loss: 3.533628e-05, l1: 0.99980, l2: 0.03184\n",
            "Loss: 3.533079e-05, l1: 0.99973, l2: 0.03183\n",
            "Loss: 3.532762e-05, l1: 0.99971, l2: 0.03183\n",
            "Loss: 3.532621e-05, l1: 0.99973, l2: 0.03183\n",
            "Loss: 3.532198e-05, l1: 0.99970, l2: 0.03183\n",
            "Loss: 3.531711e-05, l1: 0.99967, l2: 0.03183\n",
            "Loss: 3.531177e-05, l1: 0.99960, l2: 0.03183\n",
            "Loss: 3.530816e-05, l1: 0.99950, l2: 0.03183\n",
            "Loss: 3.530526e-05, l1: 0.99938, l2: 0.03182\n",
            "Loss: 3.530084e-05, l1: 0.99943, l2: 0.03183\n",
            "Loss: 3.529615e-05, l1: 0.99947, l2: 0.03183\n",
            "Loss: 3.529360e-05, l1: 0.99948, l2: 0.03183\n",
            "Loss: 3.529063e-05, l1: 0.99948, l2: 0.03183\n",
            "Loss: 3.528559e-05, l1: 0.99946, l2: 0.03183\n",
            "Loss: 3.530971e-05, l1: 0.99940, l2: 0.03184\n",
            "Loss: 3.528368e-05, l1: 0.99945, l2: 0.03183\n",
            "Loss: 3.528019e-05, l1: 0.99942, l2: 0.03183\n",
            "Loss: 3.528372e-05, l1: 0.99938, l2: 0.03183\n",
            "Loss: 3.527775e-05, l1: 0.99941, l2: 0.03183\n",
            "Loss: 3.527458e-05, l1: 0.99942, l2: 0.03183\n",
            "Loss: 3.526871e-05, l1: 0.99948, l2: 0.03183\n",
            "Loss: 3.526446e-05, l1: 0.99949, l2: 0.03183\n",
            "Loss: 3.525985e-05, l1: 0.99948, l2: 0.03183\n",
            "Loss: 3.525961e-05, l1: 0.99940, l2: 0.03183\n",
            "Loss: 3.525288e-05, l1: 0.99941, l2: 0.03183\n",
            "Loss: 3.524987e-05, l1: 0.99940, l2: 0.03183\n",
            "Loss: 3.524594e-05, l1: 0.99936, l2: 0.03183\n",
            "Loss: 3.524210e-05, l1: 0.99933, l2: 0.03182\n",
            "Loss: 3.523914e-05, l1: 0.99926, l2: 0.03182\n",
            "Loss: 3.523348e-05, l1: 0.99924, l2: 0.03182\n",
            "Loss: 3.522946e-05, l1: 0.99925, l2: 0.03182\n",
            "Loss: 3.522048e-05, l1: 0.99919, l2: 0.03182\n",
            "Loss: 3.522124e-05, l1: 0.99911, l2: 0.03182\n",
            "Loss: 3.521853e-05, l1: 0.99916, l2: 0.03182\n",
            "Loss: 3.521613e-05, l1: 0.99902, l2: 0.03182\n",
            "Loss: 3.521356e-05, l1: 0.99902, l2: 0.03182\n",
            "Loss: 3.521195e-05, l1: 0.99902, l2: 0.03182\n",
            "Loss: 3.520920e-05, l1: 0.99900, l2: 0.03182\n",
            "Loss: 3.526971e-05, l1: 0.99894, l2: 0.03182\n",
            "Loss: 3.520875e-05, l1: 0.99899, l2: 0.03182\n",
            "Loss: 3.520742e-05, l1: 0.99896, l2: 0.03182\n",
            "Loss: 3.520451e-05, l1: 0.99894, l2: 0.03182\n",
            "Loss: 3.520126e-05, l1: 0.99889, l2: 0.03182\n",
            "Loss: 3.519892e-05, l1: 0.99888, l2: 0.03183\n",
            "Loss: 3.519590e-05, l1: 0.99886, l2: 0.03183\n",
            "Loss: 3.519348e-05, l1: 0.99885, l2: 0.03183\n",
            "Loss: 3.519099e-05, l1: 0.99883, l2: 0.03183\n",
            "Loss: 3.518665e-05, l1: 0.99879, l2: 0.03183\n",
            "Loss: 3.518137e-05, l1: 0.99880, l2: 0.03183\n",
            "Loss: 3.517677e-05, l1: 0.99876, l2: 0.03183\n",
            "Loss: 3.517033e-05, l1: 0.99871, l2: 0.03183\n",
            "Loss: 3.516633e-05, l1: 0.99869, l2: 0.03183\n",
            "Loss: 3.525516e-05, l1: 0.99839, l2: 0.03183\n",
            "Loss: 3.516429e-05, l1: 0.99865, l2: 0.03183\n",
            "Loss: 3.515634e-05, l1: 0.99866, l2: 0.03183\n",
            "Loss: 3.515027e-05, l1: 0.99863, l2: 0.03183\n",
            "Loss: 3.514468e-05, l1: 0.99865, l2: 0.03184\n",
            "Loss: 3.514256e-05, l1: 0.99866, l2: 0.03183\n",
            "Loss: 3.514490e-05, l1: 0.99881, l2: 0.03184\n",
            "Loss: 3.514206e-05, l1: 0.99871, l2: 0.03184\n",
            "Loss: 3.514037e-05, l1: 0.99869, l2: 0.03184\n",
            "Loss: 3.513641e-05, l1: 0.99862, l2: 0.03183\n",
            "Loss: 3.513202e-05, l1: 0.99855, l2: 0.03183\n",
            "Loss: 3.512939e-05, l1: 0.99851, l2: 0.03183\n",
            "Loss: 3.512514e-05, l1: 0.99852, l2: 0.03183\n",
            "Loss: 3.512063e-05, l1: 0.99853, l2: 0.03183\n",
            "Loss: 3.511677e-05, l1: 0.99856, l2: 0.03183\n",
            "Loss: 3.511417e-05, l1: 0.99863, l2: 0.03183\n",
            "Loss: 3.533676e-05, l1: 0.99864, l2: 0.03183\n",
            "Loss: 3.511214e-05, l1: 0.99863, l2: 0.03183\n",
            "Loss: 3.511001e-05, l1: 0.99862, l2: 0.03183\n",
            "Loss: 3.510646e-05, l1: 0.99862, l2: 0.03183\n",
            "Loss: 3.510420e-05, l1: 0.99864, l2: 0.03183\n",
            "Loss: 3.510116e-05, l1: 0.99865, l2: 0.03184\n",
            "Loss: 3.509685e-05, l1: 0.99868, l2: 0.03184\n",
            "Loss: 3.509828e-05, l1: 0.99872, l2: 0.03184\n",
            "Loss: 3.509651e-05, l1: 0.99869, l2: 0.03184\n",
            "Loss: 3.509459e-05, l1: 0.99868, l2: 0.03184\n",
            "Loss: 3.509335e-05, l1: 0.99871, l2: 0.03184\n",
            "Loss: 3.509001e-05, l1: 0.99869, l2: 0.03184\n",
            "Loss: 3.508734e-05, l1: 0.99867, l2: 0.03184\n",
            "Loss: 3.508343e-05, l1: 0.99866, l2: 0.03184\n",
            "Loss: 3.508585e-05, l1: 0.99864, l2: 0.03184\n",
            "Loss: 3.508204e-05, l1: 0.99865, l2: 0.03184\n",
            "Loss: 3.507785e-05, l1: 0.99864, l2: 0.03184\n",
            "Loss: 3.507314e-05, l1: 0.99860, l2: 0.03184\n",
            "Loss: 3.506655e-05, l1: 0.99855, l2: 0.03184\n",
            "Loss: 3.505782e-05, l1: 0.99846, l2: 0.03184\n",
            "Loss: 3.531294e-05, l1: 0.99806, l2: 0.03184\n",
            "Loss: 3.505431e-05, l1: 0.99842, l2: 0.03184\n",
            "Loss: 3.504723e-05, l1: 0.99839, l2: 0.03184\n",
            "Loss: 3.504132e-05, l1: 0.99838, l2: 0.03184\n",
            "Loss: 3.503932e-05, l1: 0.99840, l2: 0.03184\n",
            "Loss: 3.503580e-05, l1: 0.99846, l2: 0.03185\n",
            "Loss: 3.503207e-05, l1: 0.99855, l2: 0.03185\n",
            "Loss: 3.502901e-05, l1: 0.99860, l2: 0.03185\n",
            "Loss: 3.502599e-05, l1: 0.99862, l2: 0.03185\n",
            "Loss: 3.502456e-05, l1: 0.99861, l2: 0.03185\n",
            "Loss: 3.502322e-05, l1: 0.99860, l2: 0.03185\n",
            "Loss: 3.502134e-05, l1: 0.99858, l2: 0.03185\n",
            "Loss: 3.501705e-05, l1: 0.99855, l2: 0.03185\n",
            "Loss: 3.501380e-05, l1: 0.99848, l2: 0.03184\n",
            "Loss: 3.500647e-05, l1: 0.99849, l2: 0.03184\n",
            "Loss: 3.500010e-05, l1: 0.99849, l2: 0.03184\n",
            "Loss: 3.499449e-05, l1: 0.99845, l2: 0.03184\n",
            "Loss: 3.499012e-05, l1: 0.99837, l2: 0.03184\n",
            "Loss: 3.498729e-05, l1: 0.99834, l2: 0.03184\n",
            "Loss: 3.498487e-05, l1: 0.99832, l2: 0.03184\n",
            "Loss: 3.498219e-05, l1: 0.99828, l2: 0.03184\n",
            "Loss: 3.497917e-05, l1: 0.99827, l2: 0.03184\n",
            "Loss: 3.497648e-05, l1: 0.99816, l2: 0.03184\n",
            "Loss: 3.497290e-05, l1: 0.99819, l2: 0.03184\n",
            "Loss: 3.497120e-05, l1: 0.99819, l2: 0.03184\n",
            "Loss: 3.496779e-05, l1: 0.99819, l2: 0.03184\n",
            "Loss: 3.496475e-05, l1: 0.99819, l2: 0.03184\n",
            "Loss: 3.495875e-05, l1: 0.99816, l2: 0.03184\n",
            "Loss: 3.495618e-05, l1: 0.99834, l2: 0.03185\n",
            "Loss: 3.494636e-05, l1: 0.99817, l2: 0.03184\n",
            "Loss: 3.494130e-05, l1: 0.99823, l2: 0.03184\n",
            "Loss: 3.492913e-05, l1: 0.99822, l2: 0.03184\n",
            "Loss: 3.492006e-05, l1: 0.99828, l2: 0.03184\n",
            "Loss: 3.491232e-05, l1: 0.99831, l2: 0.03184\n",
            "Loss: 3.490094e-05, l1: 0.99840, l2: 0.03185\n",
            "Loss: 3.489318e-05, l1: 0.99848, l2: 0.03185\n",
            "Loss: 3.509776e-05, l1: 0.99866, l2: 0.03185\n",
            "Loss: 3.488766e-05, l1: 0.99850, l2: 0.03185\n",
            "Loss: 3.488145e-05, l1: 0.99854, l2: 0.03185\n",
            "Loss: 3.487778e-05, l1: 0.99859, l2: 0.03185\n",
            "Loss: 3.487714e-05, l1: 0.99861, l2: 0.03185\n",
            "Loss: 3.487398e-05, l1: 0.99860, l2: 0.03185\n",
            "Loss: 3.487083e-05, l1: 0.99863, l2: 0.03185\n",
            "Loss: 3.486890e-05, l1: 0.99866, l2: 0.03185\n",
            "Loss: 3.486808e-05, l1: 0.99867, l2: 0.03185\n",
            "Loss: 3.486550e-05, l1: 0.99868, l2: 0.03185\n",
            "Loss: 3.486259e-05, l1: 0.99869, l2: 0.03185\n",
            "Loss: 3.485784e-05, l1: 0.99870, l2: 0.03185\n",
            "Loss: 3.485102e-05, l1: 0.99872, l2: 0.03185\n",
            "Loss: 3.484597e-05, l1: 0.99870, l2: 0.03185\n",
            "Loss: 3.484224e-05, l1: 0.99868, l2: 0.03185\n",
            "Loss: 3.483938e-05, l1: 0.99865, l2: 0.03185\n",
            "Loss: 3.483561e-05, l1: 0.99863, l2: 0.03185\n",
            "Loss: 3.483309e-05, l1: 0.99848, l2: 0.03185\n",
            "Loss: 3.482557e-05, l1: 0.99842, l2: 0.03185\n",
            "Loss: 3.481845e-05, l1: 0.99848, l2: 0.03185\n",
            "Loss: 3.481252e-05, l1: 0.99851, l2: 0.03185\n",
            "Loss: 3.480618e-05, l1: 0.99849, l2: 0.03185\n",
            "Loss: 3.480098e-05, l1: 0.99848, l2: 0.03185\n",
            "Loss: 3.479729e-05, l1: 0.99842, l2: 0.03185\n",
            "Loss: 3.479479e-05, l1: 0.99841, l2: 0.03185\n",
            "Loss: 3.479223e-05, l1: 0.99842, l2: 0.03185\n",
            "Loss: 3.478909e-05, l1: 0.99839, l2: 0.03185\n",
            "Loss: 3.479008e-05, l1: 0.99846, l2: 0.03184\n",
            "Loss: 3.478667e-05, l1: 0.99842, l2: 0.03185\n",
            "Loss: 3.478370e-05, l1: 0.99846, l2: 0.03185\n",
            "Loss: 3.478171e-05, l1: 0.99847, l2: 0.03185\n",
            "Loss: 3.477967e-05, l1: 0.99848, l2: 0.03185\n",
            "Loss: 3.477795e-05, l1: 0.99850, l2: 0.03184\n",
            "Loss: 3.477634e-05, l1: 0.99850, l2: 0.03184\n",
            "Loss: 3.477442e-05, l1: 0.99850, l2: 0.03184\n",
            "Loss: 3.477237e-05, l1: 0.99849, l2: 0.03184\n",
            "Loss: 3.477050e-05, l1: 0.99848, l2: 0.03184\n",
            "Loss: 3.484527e-05, l1: 0.99842, l2: 0.03184\n",
            "Loss: 3.476930e-05, l1: 0.99847, l2: 0.03184\n",
            "Loss: 3.476745e-05, l1: 0.99847, l2: 0.03184\n",
            "Loss: 3.476561e-05, l1: 0.99847, l2: 0.03184\n",
            "Loss: 3.476471e-05, l1: 0.99847, l2: 0.03184\n",
            "Loss: 3.476178e-05, l1: 0.99845, l2: 0.03184\n",
            "Loss: 3.476365e-05, l1: 0.99846, l2: 0.03183\n",
            "Loss: 3.475961e-05, l1: 0.99845, l2: 0.03184\n",
            "Loss: 3.475443e-05, l1: 0.99843, l2: 0.03183\n",
            "Loss: 3.474469e-05, l1: 0.99841, l2: 0.03183\n",
            "Loss: 3.473624e-05, l1: 0.99838, l2: 0.03183\n",
            "Loss: 3.472063e-05, l1: 0.99833, l2: 0.03183\n",
            "Loss: 3.471010e-05, l1: 0.99826, l2: 0.03182\n",
            "Loss: 3.470360e-05, l1: 0.99821, l2: 0.03182\n",
            "Loss: 3.470084e-05, l1: 0.99817, l2: 0.03182\n",
            "Loss: 3.469914e-05, l1: 0.99818, l2: 0.03182\n",
            "Loss: 3.469167e-05, l1: 0.99821, l2: 0.03181\n",
            "Loss: 3.468553e-05, l1: 0.99826, l2: 0.03181\n",
            "Loss: 3.468069e-05, l1: 0.99825, l2: 0.03181\n",
            "Loss: 3.468056e-05, l1: 0.99828, l2: 0.03181\n",
            "Loss: 3.467888e-05, l1: 0.99827, l2: 0.03181\n",
            "Loss: 3.467732e-05, l1: 0.99824, l2: 0.03181\n",
            "Loss: 3.467462e-05, l1: 0.99828, l2: 0.03181\n",
            "Loss: 3.467042e-05, l1: 0.99844, l2: 0.03181\n",
            "Loss: 3.469439e-05, l1: 0.99860, l2: 0.03181\n",
            "Loss: 3.466830e-05, l1: 0.99848, l2: 0.03181\n",
            "Loss: 3.466586e-05, l1: 0.99846, l2: 0.03181\n",
            "Loss: 3.466386e-05, l1: 0.99842, l2: 0.03180\n",
            "Loss: 3.466172e-05, l1: 0.99840, l2: 0.03180\n",
            "Loss: 3.465845e-05, l1: 0.99833, l2: 0.03180\n",
            "Loss: 3.465499e-05, l1: 0.99828, l2: 0.03179\n",
            "Loss: 3.465270e-05, l1: 0.99828, l2: 0.03179\n",
            "Loss: 3.465080e-05, l1: 0.99831, l2: 0.03179\n",
            "Loss: 3.464945e-05, l1: 0.99833, l2: 0.03179\n",
            "Loss: 3.464664e-05, l1: 0.99837, l2: 0.03179\n",
            "Loss: 3.464182e-05, l1: 0.99839, l2: 0.03179\n",
            "Loss: 3.463538e-05, l1: 0.99841, l2: 0.03179\n",
            "Loss: 3.473565e-05, l1: 0.99870, l2: 0.03178\n",
            "Loss: 3.462955e-05, l1: 0.99847, l2: 0.03179\n",
            "Loss: 3.462245e-05, l1: 0.99843, l2: 0.03179\n",
            "Loss: 3.461268e-05, l1: 0.99836, l2: 0.03179\n",
            "Loss: 3.460798e-05, l1: 0.99834, l2: 0.03179\n",
            "Loss: 3.460484e-05, l1: 0.99835, l2: 0.03179\n",
            "Loss: 3.460167e-05, l1: 0.99834, l2: 0.03179\n",
            "Loss: 3.460054e-05, l1: 0.99830, l2: 0.03178\n",
            "Loss: 3.459802e-05, l1: 0.99836, l2: 0.03178\n",
            "Loss: 3.459502e-05, l1: 0.99835, l2: 0.03178\n",
            "Loss: 3.459346e-05, l1: 0.99836, l2: 0.03178\n",
            "Loss: 3.459149e-05, l1: 0.99836, l2: 0.03178\n",
            "Loss: 3.458909e-05, l1: 0.99838, l2: 0.03178\n",
            "Loss: 3.458674e-05, l1: 0.99838, l2: 0.03178\n",
            "Loss: 3.458140e-05, l1: 0.99837, l2: 0.03178\n",
            "Loss: 3.457596e-05, l1: 0.99840, l2: 0.03178\n",
            "Loss: 3.459010e-05, l1: 0.99830, l2: 0.03177\n",
            "Loss: 3.457067e-05, l1: 0.99837, l2: 0.03178\n",
            "Loss: 3.456499e-05, l1: 0.99837, l2: 0.03178\n",
            "Loss: 3.455938e-05, l1: 0.99836, l2: 0.03178\n",
            "Loss: 3.456881e-05, l1: 0.99844, l2: 0.03178\n",
            "Loss: 3.455738e-05, l1: 0.99838, l2: 0.03178\n",
            "Loss: 3.455465e-05, l1: 0.99837, l2: 0.03178\n",
            "Loss: 3.454908e-05, l1: 0.99836, l2: 0.03178\n",
            "Loss: 3.454711e-05, l1: 0.99837, l2: 0.03178\n",
            "Loss: 3.454437e-05, l1: 0.99834, l2: 0.03177\n",
            "Loss: 3.454234e-05, l1: 0.99835, l2: 0.03177\n",
            "Loss: 3.453857e-05, l1: 0.99832, l2: 0.03177\n",
            "Loss: 3.453446e-05, l1: 0.99830, l2: 0.03177\n",
            "Loss: 3.454458e-05, l1: 0.99812, l2: 0.03177\n",
            "Loss: 3.453277e-05, l1: 0.99825, l2: 0.03177\n",
            "Loss: 3.452921e-05, l1: 0.99821, l2: 0.03177\n",
            "Loss: 3.452526e-05, l1: 0.99815, l2: 0.03177\n",
            "Loss: 3.453461e-05, l1: 0.99813, l2: 0.03178\n",
            "Loss: 3.452517e-05, l1: 0.99814, l2: 0.03177\n",
            "Loss: 3.452267e-05, l1: 0.99811, l2: 0.03177\n",
            "Loss: 3.455305e-05, l1: 0.99801, l2: 0.03176\n",
            "Loss: 3.452196e-05, l1: 0.99809, l2: 0.03177\n",
            "Loss: 3.452017e-05, l1: 0.99809, l2: 0.03177\n",
            "Loss: 3.451764e-05, l1: 0.99806, l2: 0.03176\n",
            "Loss: 3.451611e-05, l1: 0.99805, l2: 0.03176\n",
            "Loss: 3.451376e-05, l1: 0.99802, l2: 0.03176\n",
            "Loss: 3.451119e-05, l1: 0.99800, l2: 0.03176\n",
            "Loss: 3.450704e-05, l1: 0.99796, l2: 0.03176\n",
            "Loss: 3.450116e-05, l1: 0.99799, l2: 0.03176\n",
            "Loss: 3.449545e-05, l1: 0.99800, l2: 0.03176\n",
            "Loss: 3.449033e-05, l1: 0.99801, l2: 0.03176\n",
            "Loss: 3.448898e-05, l1: 0.99801, l2: 0.03176\n",
            "Loss: 3.448818e-05, l1: 0.99799, l2: 0.03176\n",
            "Loss: 3.448713e-05, l1: 0.99797, l2: 0.03176\n",
            "Loss: 3.448430e-05, l1: 0.99793, l2: 0.03175\n",
            "Loss: 3.448265e-05, l1: 0.99788, l2: 0.03175\n",
            "Loss: 3.448178e-05, l1: 0.99792, l2: 0.03175\n",
            "Loss: 3.448009e-05, l1: 0.99788, l2: 0.03175\n",
            "Loss: 3.447900e-05, l1: 0.99788, l2: 0.03175\n",
            "Loss: 3.447684e-05, l1: 0.99789, l2: 0.03175\n",
            "Loss: 3.447497e-05, l1: 0.99790, l2: 0.03175\n",
            "Loss: 3.447100e-05, l1: 0.99788, l2: 0.03175\n",
            "Loss: 3.450665e-05, l1: 0.99805, l2: 0.03175\n",
            "Loss: 3.446895e-05, l1: 0.99791, l2: 0.03175\n",
            "Loss: 3.446431e-05, l1: 0.99786, l2: 0.03175\n",
            "Loss: 3.445836e-05, l1: 0.99779, l2: 0.03175\n",
            "Loss: 3.445378e-05, l1: 0.99775, l2: 0.03175\n",
            "Loss: 3.445011e-05, l1: 0.99773, l2: 0.03174\n",
            "Loss: 3.444536e-05, l1: 0.99774, l2: 0.03174\n",
            "Loss: 3.444028e-05, l1: 0.99777, l2: 0.03174\n",
            "Loss: 3.443678e-05, l1: 0.99780, l2: 0.03174\n",
            "Loss: 3.443231e-05, l1: 0.99787, l2: 0.03174\n",
            "Loss: 3.442852e-05, l1: 0.99791, l2: 0.03174\n",
            "Loss: 3.442537e-05, l1: 0.99795, l2: 0.03174\n",
            "Loss: 3.442164e-05, l1: 0.99797, l2: 0.03174\n",
            "Loss: 3.441394e-05, l1: 0.99803, l2: 0.03174\n",
            "Loss: 3.440682e-05, l1: 0.99807, l2: 0.03174\n",
            "Loss: 3.440062e-05, l1: 0.99808, l2: 0.03174\n",
            "Loss: 3.439368e-05, l1: 0.99813, l2: 0.03175\n",
            "Loss: 3.439242e-05, l1: 0.99819, l2: 0.03175\n",
            "Loss: 3.438505e-05, l1: 0.99820, l2: 0.03175\n",
            "Loss: 3.438146e-05, l1: 0.99820, l2: 0.03175\n",
            "Loss: 3.437843e-05, l1: 0.99821, l2: 0.03175\n",
            "Loss: 3.437666e-05, l1: 0.99822, l2: 0.03175\n",
            "Loss: 3.437326e-05, l1: 0.99818, l2: 0.03175\n",
            "Loss: 3.437065e-05, l1: 0.99814, l2: 0.03176\n",
            "Loss: 3.436864e-05, l1: 0.99809, l2: 0.03175\n",
            "Loss: 3.436637e-05, l1: 0.99809, l2: 0.03175\n",
            "Loss: 3.436339e-05, l1: 0.99811, l2: 0.03175\n",
            "Loss: 3.436101e-05, l1: 0.99810, l2: 0.03175\n",
            "Loss: 3.435979e-05, l1: 0.99812, l2: 0.03176\n",
            "Loss: 3.435819e-05, l1: 0.99813, l2: 0.03176\n",
            "Loss: 3.435625e-05, l1: 0.99815, l2: 0.03176\n",
            "Loss: 3.435611e-05, l1: 0.99828, l2: 0.03175\n",
            "Loss: 3.435385e-05, l1: 0.99821, l2: 0.03175\n",
            "Loss: 3.437542e-05, l1: 0.99825, l2: 0.03175\n",
            "Loss: 3.434912e-05, l1: 0.99822, l2: 0.03175\n",
            "Loss: 3.434678e-05, l1: 0.99823, l2: 0.03175\n",
            "Loss: 3.434219e-05, l1: 0.99826, l2: 0.03175\n",
            "Loss: 3.433881e-05, l1: 0.99828, l2: 0.03175\n",
            "Loss: 3.433309e-05, l1: 0.99833, l2: 0.03175\n",
            "Loss: 3.432815e-05, l1: 0.99835, l2: 0.03175\n",
            "Loss: 3.432453e-05, l1: 0.99834, l2: 0.03175\n",
            "Loss: 3.432110e-05, l1: 0.99829, l2: 0.03175\n",
            "Loss: 3.432313e-05, l1: 0.99830, l2: 0.03175\n",
            "Loss: 3.431821e-05, l1: 0.99829, l2: 0.03175\n",
            "Loss: 3.431358e-05, l1: 0.99828, l2: 0.03175\n",
            "Loss: 3.430923e-05, l1: 0.99826, l2: 0.03175\n",
            "Loss: 3.430573e-05, l1: 0.99827, l2: 0.03175\n",
            "Loss: 3.430144e-05, l1: 0.99828, l2: 0.03175\n",
            "Loss: 3.429614e-05, l1: 0.99826, l2: 0.03174\n",
            "Loss: 3.428890e-05, l1: 0.99822, l2: 0.03174\n",
            "Loss: 3.429468e-05, l1: 0.99801, l2: 0.03173\n",
            "Loss: 3.428492e-05, l1: 0.99814, l2: 0.03174\n",
            "Loss: 3.427809e-05, l1: 0.99812, l2: 0.03174\n",
            "Loss: 3.427194e-05, l1: 0.99805, l2: 0.03173\n",
            "Loss: 3.426846e-05, l1: 0.99807, l2: 0.03173\n",
            "Loss: 3.426653e-05, l1: 0.99807, l2: 0.03173\n",
            "Loss: 3.426474e-05, l1: 0.99806, l2: 0.03173\n",
            "Loss: 3.426332e-05, l1: 0.99810, l2: 0.03173\n",
            "Loss: 3.425985e-05, l1: 0.99816, l2: 0.03173\n",
            "Loss: 3.425538e-05, l1: 0.99823, l2: 0.03173\n",
            "Loss: 3.425173e-05, l1: 0.99844, l2: 0.03173\n",
            "Loss: 3.424125e-05, l1: 0.99839, l2: 0.03173\n",
            "Loss: 3.423175e-05, l1: 0.99837, l2: 0.03173\n",
            "Loss: 3.422490e-05, l1: 0.99836, l2: 0.03173\n",
            "Loss: 3.422017e-05, l1: 0.99837, l2: 0.03173\n",
            "Loss: 3.421738e-05, l1: 0.99838, l2: 0.03173\n",
            "Loss: 3.421433e-05, l1: 0.99842, l2: 0.03173\n",
            "Loss: 3.421231e-05, l1: 0.99843, l2: 0.03173\n",
            "Loss: 3.420997e-05, l1: 0.99846, l2: 0.03173\n",
            "Loss: 3.420946e-05, l1: 0.99850, l2: 0.03173\n",
            "Loss: 3.420510e-05, l1: 0.99851, l2: 0.03173\n",
            "Loss: 3.420263e-05, l1: 0.99850, l2: 0.03173\n",
            "Loss: 3.419883e-05, l1: 0.99849, l2: 0.03174\n",
            "Loss: 3.419600e-05, l1: 0.99848, l2: 0.03174\n",
            "Loss: 3.419170e-05, l1: 0.99845, l2: 0.03174\n",
            "Loss: 3.418961e-05, l1: 0.99843, l2: 0.03174\n",
            "Loss: 3.418704e-05, l1: 0.99840, l2: 0.03174\n",
            "Loss: 3.418434e-05, l1: 0.99839, l2: 0.03173\n",
            "Loss: 3.418054e-05, l1: 0.99840, l2: 0.03173\n",
            "Loss: 3.430911e-05, l1: 0.99833, l2: 0.03170\n",
            "Loss: 3.417935e-05, l1: 0.99839, l2: 0.03173\n",
            "Loss: 3.417655e-05, l1: 0.99841, l2: 0.03173\n",
            "Loss: 3.417443e-05, l1: 0.99842, l2: 0.03173\n",
            "Loss: 3.417210e-05, l1: 0.99842, l2: 0.03173\n",
            "Loss: 3.418688e-05, l1: 0.99850, l2: 0.03174\n",
            "Loss: 3.417007e-05, l1: 0.99844, l2: 0.03173\n",
            "Loss: 3.416599e-05, l1: 0.99845, l2: 0.03173\n",
            "Loss: 3.415865e-05, l1: 0.99846, l2: 0.03173\n",
            "Loss: 3.415380e-05, l1: 0.99845, l2: 0.03174\n",
            "Loss: 3.415148e-05, l1: 0.99843, l2: 0.03174\n",
            "Loss: 3.414932e-05, l1: 0.99842, l2: 0.03174\n",
            "Loss: 3.414713e-05, l1: 0.99842, l2: 0.03174\n",
            "Loss: 3.414397e-05, l1: 0.99844, l2: 0.03174\n",
            "Loss: 3.414113e-05, l1: 0.99848, l2: 0.03175\n",
            "Loss: 3.415193e-05, l1: 0.99863, l2: 0.03176\n",
            "Loss: 3.414051e-05, l1: 0.99851, l2: 0.03175\n",
            "Loss: 3.413810e-05, l1: 0.99856, l2: 0.03175\n",
            "Loss: 3.413564e-05, l1: 0.99864, l2: 0.03175\n",
            "Loss: 3.413211e-05, l1: 0.99874, l2: 0.03175\n",
            "Loss: 3.413051e-05, l1: 0.99887, l2: 0.03175\n",
            "Loss: 3.413729e-05, l1: 0.99900, l2: 0.03176\n",
            "Loss: 3.412949e-05, l1: 0.99891, l2: 0.03175\n",
            "Loss: 3.412762e-05, l1: 0.99886, l2: 0.03176\n",
            "Loss: 3.412700e-05, l1: 0.99884, l2: 0.03175\n",
            "Loss: 3.412613e-05, l1: 0.99882, l2: 0.03175\n",
            "Loss: 3.412599e-05, l1: 0.99883, l2: 0.03175\n",
            "Loss: 3.412522e-05, l1: 0.99889, l2: 0.03176\n",
            "Loss: 3.412422e-05, l1: 0.99888, l2: 0.03176\n",
            "Loss: 3.412305e-05, l1: 0.99889, l2: 0.03176\n",
            "Loss: 3.412194e-05, l1: 0.99891, l2: 0.03176\n",
            "Loss: 3.412120e-05, l1: 0.99892, l2: 0.03176\n",
            "Loss: 3.412024e-05, l1: 0.99892, l2: 0.03176\n",
            "Loss: 3.412097e-05, l1: 0.99894, l2: 0.03176\n",
            "Loss: 3.411905e-05, l1: 0.99893, l2: 0.03176\n",
            "Loss: 3.411786e-05, l1: 0.99891, l2: 0.03176\n",
            "Loss: 3.411556e-05, l1: 0.99889, l2: 0.03176\n",
            "Loss: 3.411678e-05, l1: 0.99885, l2: 0.03176\n",
            "Loss: 3.411368e-05, l1: 0.99887, l2: 0.03176\n",
            "Loss: 3.411138e-05, l1: 0.99893, l2: 0.03176\n",
            "Loss: 3.410785e-05, l1: 0.99900, l2: 0.03177\n",
            "Loss: 3.410525e-05, l1: 0.99906, l2: 0.03177\n",
            "Loss: 3.410062e-05, l1: 0.99914, l2: 0.03177\n",
            "Loss: 3.409777e-05, l1: 0.99932, l2: 0.03178\n",
            "Loss: 3.411461e-05, l1: 0.99931, l2: 0.03179\n",
            "Loss: 3.409493e-05, l1: 0.99932, l2: 0.03178\n",
            "Loss: 3.409121e-05, l1: 0.99925, l2: 0.03178\n",
            "Loss: 3.408649e-05, l1: 0.99913, l2: 0.03178\n",
            "Loss: 3.408418e-05, l1: 0.99911, l2: 0.03178\n",
            "Loss: 3.408214e-05, l1: 0.99913, l2: 0.03178\n",
            "Loss: 3.407595e-05, l1: 0.99918, l2: 0.03179\n",
            "Loss: 3.407359e-05, l1: 0.99931, l2: 0.03179\n",
            "Loss: 3.406723e-05, l1: 0.99925, l2: 0.03179\n",
            "Loss: 3.406564e-05, l1: 0.99926, l2: 0.03179\n",
            "Loss: 3.406382e-05, l1: 0.99925, l2: 0.03179\n",
            "Loss: 3.406112e-05, l1: 0.99925, l2: 0.03178\n",
            "Loss: 3.405765e-05, l1: 0.99923, l2: 0.03178\n",
            "Loss: 3.405161e-05, l1: 0.99920, l2: 0.03178\n",
            "Loss: 3.404662e-05, l1: 0.99921, l2: 0.03178\n",
            "Loss: 3.404484e-05, l1: 0.99921, l2: 0.03179\n",
            "Loss: 3.404355e-05, l1: 0.99920, l2: 0.03179\n",
            "Loss: 3.404228e-05, l1: 0.99921, l2: 0.03179\n",
            "Loss: 3.404138e-05, l1: 0.99921, l2: 0.03179\n",
            "Loss: 3.405024e-05, l1: 0.99932, l2: 0.03179\n",
            "Loss: 3.404043e-05, l1: 0.99924, l2: 0.03179\n",
            "Loss: 3.403873e-05, l1: 0.99925, l2: 0.03179\n",
            "Loss: 3.403787e-05, l1: 0.99928, l2: 0.03179\n",
            "Loss: 3.403619e-05, l1: 0.99923, l2: 0.03179\n",
            "Loss: 3.403570e-05, l1: 0.99923, l2: 0.03179\n",
            "Loss: 3.403487e-05, l1: 0.99923, l2: 0.03179\n",
            "Loss: 3.403425e-05, l1: 0.99923, l2: 0.03179\n",
            "Loss: 3.403275e-05, l1: 0.99924, l2: 0.03179\n",
            "Loss: 3.403380e-05, l1: 0.99929, l2: 0.03180\n",
            "Loss: 3.403229e-05, l1: 0.99926, l2: 0.03179\n",
            "Loss: 3.403159e-05, l1: 0.99926, l2: 0.03179\n",
            "Loss: 3.403090e-05, l1: 0.99926, l2: 0.03179\n",
            "Loss: 3.402986e-05, l1: 0.99924, l2: 0.03179\n",
            "Loss: 3.402888e-05, l1: 0.99923, l2: 0.03179\n",
            "Loss: 3.402764e-05, l1: 0.99923, l2: 0.03179\n",
            "Loss: 3.402681e-05, l1: 0.99924, l2: 0.03180\n",
            "Loss: 3.402600e-05, l1: 0.99926, l2: 0.03180\n",
            "Loss: 3.402499e-05, l1: 0.99929, l2: 0.03180\n",
            "Loss: 3.402397e-05, l1: 0.99932, l2: 0.03180\n",
            "Loss: 3.402224e-05, l1: 0.99933, l2: 0.03180\n",
            "Loss: 3.402041e-05, l1: 0.99932, l2: 0.03180\n",
            "Loss: 3.401882e-05, l1: 0.99932, l2: 0.03180\n",
            "Loss: 3.401724e-05, l1: 0.99935, l2: 0.03180\n",
            "Loss: 3.407895e-05, l1: 0.99929, l2: 0.03181\n",
            "Loss: 3.401507e-05, l1: 0.99935, l2: 0.03181\n",
            "Loss: 3.401296e-05, l1: 0.99931, l2: 0.03180\n",
            "Loss: 3.401187e-05, l1: 0.99928, l2: 0.03180\n",
            "Loss: 3.401123e-05, l1: 0.99926, l2: 0.03180\n",
            "Loss: 3.400980e-05, l1: 0.99924, l2: 0.03180\n",
            "Loss: 3.400862e-05, l1: 0.99921, l2: 0.03180\n",
            "Loss: 3.400791e-05, l1: 0.99921, l2: 0.03181\n",
            "Loss: 3.400715e-05, l1: 0.99922, l2: 0.03181\n",
            "Loss: 3.400635e-05, l1: 0.99923, l2: 0.03181\n",
            "Loss: 3.400560e-05, l1: 0.99925, l2: 0.03181\n",
            "Loss: 3.400439e-05, l1: 0.99926, l2: 0.03181\n",
            "Loss: 3.400319e-05, l1: 0.99927, l2: 0.03181\n",
            "Loss: 3.400402e-05, l1: 0.99927, l2: 0.03182\n",
            "Loss: 3.400207e-05, l1: 0.99927, l2: 0.03181\n",
            "Loss: 3.400082e-05, l1: 0.99924, l2: 0.03181\n",
            "Loss: 3.399929e-05, l1: 0.99921, l2: 0.03181\n",
            "Loss: 3.399907e-05, l1: 0.99917, l2: 0.03181\n",
            "Loss: 3.399821e-05, l1: 0.99917, l2: 0.03181\n",
            "Loss: 3.399629e-05, l1: 0.99918, l2: 0.03181\n",
            "Loss: 3.399633e-05, l1: 0.99906, l2: 0.03181\n",
            "Loss: 3.399367e-05, l1: 0.99912, l2: 0.03181\n",
            "Loss: 3.399149e-05, l1: 0.99914, l2: 0.03182\n",
            "Loss: 3.399428e-05, l1: 0.99924, l2: 0.03182\n",
            "Loss: 3.398996e-05, l1: 0.99918, l2: 0.03182\n",
            "Loss: 3.398868e-05, l1: 0.99916, l2: 0.03182\n",
            "Loss: 3.398609e-05, l1: 0.99910, l2: 0.03182\n",
            "Loss: 3.398430e-05, l1: 0.99907, l2: 0.03182\n",
            "Loss: 3.398120e-05, l1: 0.99899, l2: 0.03182\n",
            "Loss: 3.397963e-05, l1: 0.99898, l2: 0.03182\n",
            "Loss: 3.397812e-05, l1: 0.99897, l2: 0.03182\n",
            "Loss: 3.397719e-05, l1: 0.99899, l2: 0.03182\n",
            "Loss: 3.397607e-05, l1: 0.99899, l2: 0.03182\n",
            "Loss: 3.397517e-05, l1: 0.99899, l2: 0.03182\n",
            "Loss: 3.397416e-05, l1: 0.99898, l2: 0.03182\n",
            "Loss: 3.397352e-05, l1: 0.99898, l2: 0.03182\n",
            "Loss: 3.397268e-05, l1: 0.99897, l2: 0.03182\n",
            "Loss: 3.397137e-05, l1: 0.99897, l2: 0.03182\n",
            "Loss: 3.396937e-05, l1: 0.99897, l2: 0.03182\n",
            "Loss: 3.396631e-05, l1: 0.99895, l2: 0.03182\n",
            "Loss: 3.396564e-05, l1: 0.99890, l2: 0.03182\n",
            "Loss: 3.396128e-05, l1: 0.99889, l2: 0.03182\n",
            "Loss: 3.396004e-05, l1: 0.99888, l2: 0.03182\n",
            "Loss: 3.395837e-05, l1: 0.99887, l2: 0.03182\n",
            "Loss: 3.395631e-05, l1: 0.99885, l2: 0.03182\n",
            "Loss: 3.395489e-05, l1: 0.99873, l2: 0.03182\n",
            "Loss: 3.395154e-05, l1: 0.99872, l2: 0.03183\n",
            "Loss: 3.394934e-05, l1: 0.99873, l2: 0.03183\n",
            "Loss: 3.394737e-05, l1: 0.99872, l2: 0.03183\n",
            "Loss: 3.394774e-05, l1: 0.99868, l2: 0.03183\n",
            "Loss: 3.394603e-05, l1: 0.99870, l2: 0.03183\n",
            "Loss: 3.394494e-05, l1: 0.99869, l2: 0.03183\n",
            "Loss: 3.394332e-05, l1: 0.99865, l2: 0.03183\n",
            "Loss: 3.394152e-05, l1: 0.99861, l2: 0.03182\n",
            "Loss: 3.393998e-05, l1: 0.99863, l2: 0.03182\n",
            "Loss: 3.393866e-05, l1: 0.99863, l2: 0.03182\n",
            "Loss: 3.393604e-05, l1: 0.99864, l2: 0.03183\n",
            "Loss: 3.393308e-05, l1: 0.99863, l2: 0.03183\n",
            "Loss: 3.392975e-05, l1: 0.99868, l2: 0.03183\n",
            "Loss: 3.392710e-05, l1: 0.99869, l2: 0.03183\n",
            "Loss: 3.392426e-05, l1: 0.99867, l2: 0.03184\n",
            "Loss: 3.392113e-05, l1: 0.99866, l2: 0.03184\n",
            "Loss: 3.391634e-05, l1: 0.99866, l2: 0.03184\n",
            "Loss: 3.391233e-05, l1: 0.99861, l2: 0.03184\n",
            "Loss: 3.390819e-05, l1: 0.99853, l2: 0.03184\n",
            "Loss: 3.392286e-05, l1: 0.99864, l2: 0.03186\n",
            "Loss: 3.390592e-05, l1: 0.99856, l2: 0.03185\n",
            "Loss: 3.390118e-05, l1: 0.99847, l2: 0.03185\n",
            "Loss: 3.389719e-05, l1: 0.99839, l2: 0.03185\n",
            "Loss: 3.389791e-05, l1: 0.99827, l2: 0.03184\n",
            "Loss: 3.389462e-05, l1: 0.99833, l2: 0.03184\n",
            "Loss: 3.389096e-05, l1: 0.99826, l2: 0.03184\n",
            "Loss: 3.388969e-05, l1: 0.99824, l2: 0.03184\n",
            "Loss: 3.388864e-05, l1: 0.99826, l2: 0.03184\n",
            "Loss: 3.388810e-05, l1: 0.99827, l2: 0.03184\n",
            "Loss: 3.388724e-05, l1: 0.99821, l2: 0.03185\n",
            "Loss: 3.389633e-05, l1: 0.99828, l2: 0.03184\n",
            "Loss: 3.388662e-05, l1: 0.99822, l2: 0.03184\n",
            "Loss: 3.388510e-05, l1: 0.99823, l2: 0.03184\n",
            "Loss: 3.388260e-05, l1: 0.99820, l2: 0.03184\n",
            "Loss: 3.388110e-05, l1: 0.99817, l2: 0.03184\n",
            "Loss: 3.388436e-05, l1: 0.99803, l2: 0.03183\n",
            "Loss: 3.387966e-05, l1: 0.99812, l2: 0.03184\n",
            "Loss: 3.387518e-05, l1: 0.99811, l2: 0.03184\n",
            "Loss: 3.387436e-05, l1: 0.99798, l2: 0.03185\n",
            "Loss: 3.386911e-05, l1: 0.99804, l2: 0.03184\n",
            "Loss: 3.386754e-05, l1: 0.99806, l2: 0.03184\n",
            "Loss: 3.386537e-05, l1: 0.99806, l2: 0.03184\n",
            "Loss: 3.386128e-05, l1: 0.99806, l2: 0.03184\n",
            "Loss: 3.389562e-05, l1: 0.99817, l2: 0.03185\n",
            "Loss: 3.386020e-05, l1: 0.99807, l2: 0.03185\n",
            "Loss: 3.385413e-05, l1: 0.99805, l2: 0.03185\n",
            "Loss: 3.384382e-05, l1: 0.99808, l2: 0.03185\n",
            "Loss: 3.383701e-05, l1: 0.99812, l2: 0.03185\n",
            "Loss: 3.383050e-05, l1: 0.99811, l2: 0.03186\n",
            "Loss: 3.382167e-05, l1: 0.99812, l2: 0.03186\n",
            "Loss: 3.380832e-05, l1: 0.99810, l2: 0.03186\n",
            "Loss: 3.379746e-05, l1: 0.99816, l2: 0.03185\n",
            "Loss: 3.380947e-05, l1: 0.99801, l2: 0.03184\n",
            "Loss: 3.379470e-05, l1: 0.99811, l2: 0.03185\n",
            "Loss: 3.378848e-05, l1: 0.99807, l2: 0.03185\n",
            "Loss: 3.378513e-05, l1: 0.99806, l2: 0.03185\n",
            "Loss: 3.378201e-05, l1: 0.99805, l2: 0.03185\n",
            "Loss: 3.378009e-05, l1: 0.99807, l2: 0.03185\n",
            "Loss: 3.377783e-05, l1: 0.99810, l2: 0.03185\n",
            "Loss: 3.377596e-05, l1: 0.99812, l2: 0.03186\n",
            "Loss: 3.377392e-05, l1: 0.99818, l2: 0.03186\n",
            "Loss: 3.377187e-05, l1: 0.99816, l2: 0.03186\n",
            "Loss: 3.377055e-05, l1: 0.99817, l2: 0.03186\n",
            "Loss: 3.376839e-05, l1: 0.99818, l2: 0.03186\n",
            "Loss: 3.376621e-05, l1: 0.99820, l2: 0.03186\n",
            "Loss: 3.376264e-05, l1: 0.99823, l2: 0.03186\n",
            "Loss: 3.375970e-05, l1: 0.99824, l2: 0.03186\n",
            "Loss: 3.375724e-05, l1: 0.99826, l2: 0.03187\n",
            "Loss: 3.375613e-05, l1: 0.99823, l2: 0.03187\n",
            "Loss: 3.374986e-05, l1: 0.99831, l2: 0.03187\n",
            "Loss: 3.374612e-05, l1: 0.99828, l2: 0.03187\n",
            "Loss: 3.374201e-05, l1: 0.99824, l2: 0.03186\n",
            "Loss: 3.373776e-05, l1: 0.99819, l2: 0.03186\n",
            "Loss: 3.374508e-05, l1: 0.99815, l2: 0.03186\n",
            "Loss: 3.373484e-05, l1: 0.99817, l2: 0.03186\n",
            "Loss: 3.373104e-05, l1: 0.99819, l2: 0.03186\n",
            "Loss: 3.372908e-05, l1: 0.99822, l2: 0.03186\n",
            "Loss: 3.372860e-05, l1: 0.99821, l2: 0.03187\n",
            "Loss: 3.372720e-05, l1: 0.99821, l2: 0.03187\n",
            "Loss: 3.372606e-05, l1: 0.99820, l2: 0.03187\n",
            "Loss: 3.372436e-05, l1: 0.99820, l2: 0.03187\n",
            "Loss: 3.372100e-05, l1: 0.99819, l2: 0.03187\n",
            "Loss: 3.371716e-05, l1: 0.99820, l2: 0.03187\n",
            "Loss: 3.372908e-05, l1: 0.99812, l2: 0.03188\n",
            "Loss: 3.371570e-05, l1: 0.99818, l2: 0.03187\n",
            "Loss: 3.371175e-05, l1: 0.99819, l2: 0.03187\n",
            "Loss: 3.370770e-05, l1: 0.99823, l2: 0.03187\n",
            "Loss: 3.370555e-05, l1: 0.99828, l2: 0.03187\n",
            "Loss: 3.370221e-05, l1: 0.99833, l2: 0.03187\n",
            "Loss: 3.369899e-05, l1: 0.99833, l2: 0.03186\n",
            "Loss: 3.369361e-05, l1: 0.99841, l2: 0.03186\n",
            "Loss: 3.368853e-05, l1: 0.99838, l2: 0.03186\n",
            "Loss: 3.368377e-05, l1: 0.99833, l2: 0.03186\n",
            "Loss: 3.368059e-05, l1: 0.99829, l2: 0.03186\n",
            "Loss: 3.367141e-05, l1: 0.99828, l2: 0.03186\n",
            "Loss: 3.367358e-05, l1: 0.99830, l2: 0.03187\n",
            "Loss: 3.366543e-05, l1: 0.99828, l2: 0.03186\n",
            "Loss: 3.365462e-05, l1: 0.99830, l2: 0.03187\n",
            "Loss: 3.364712e-05, l1: 0.99834, l2: 0.03187\n",
            "Loss: 3.363800e-05, l1: 0.99836, l2: 0.03188\n",
            "Loss: 3.363121e-05, l1: 0.99836, l2: 0.03188\n",
            "Loss: 3.362755e-05, l1: 0.99834, l2: 0.03188\n",
            "Loss: 3.362423e-05, l1: 0.99831, l2: 0.03188\n",
            "Loss: 3.362203e-05, l1: 0.99830, l2: 0.03188\n",
            "Loss: 3.361774e-05, l1: 0.99827, l2: 0.03188\n",
            "Loss: 3.361222e-05, l1: 0.99827, l2: 0.03187\n",
            "Loss: 3.363996e-05, l1: 0.99819, l2: 0.03186\n",
            "Loss: 3.361011e-05, l1: 0.99825, l2: 0.03187\n",
            "Loss: 3.360433e-05, l1: 0.99828, l2: 0.03187\n",
            "Loss: 3.360215e-05, l1: 0.99828, l2: 0.03187\n",
            "Loss: 3.360095e-05, l1: 0.99828, l2: 0.03187\n",
            "Loss: 3.359912e-05, l1: 0.99826, l2: 0.03187\n",
            "Loss: 3.359662e-05, l1: 0.99825, l2: 0.03187\n",
            "Loss: 3.359286e-05, l1: 0.99825, l2: 0.03187\n",
            "Loss: 3.358898e-05, l1: 0.99828, l2: 0.03187\n",
            "Loss: 3.358468e-05, l1: 0.99831, l2: 0.03187\n",
            "Loss: 3.357935e-05, l1: 0.99837, l2: 0.03187\n",
            "Loss: 3.357775e-05, l1: 0.99834, l2: 0.03187\n",
            "Loss: 3.357761e-05, l1: 0.99837, l2: 0.03186\n",
            "Loss: 3.357559e-05, l1: 0.99836, l2: 0.03187\n",
            "Loss: 3.357435e-05, l1: 0.99831, l2: 0.03187\n",
            "Loss: 3.357355e-05, l1: 0.99828, l2: 0.03186\n",
            "Loss: 3.357221e-05, l1: 0.99826, l2: 0.03186\n",
            "Loss: 3.356980e-05, l1: 0.99825, l2: 0.03187\n",
            "Loss: 3.356858e-05, l1: 0.99826, l2: 0.03187\n",
            "Loss: 3.356625e-05, l1: 0.99828, l2: 0.03187\n",
            "Loss: 3.356371e-05, l1: 0.99826, l2: 0.03187\n",
            "Loss: 3.356266e-05, l1: 0.99827, l2: 0.03187\n",
            "Loss: 3.356155e-05, l1: 0.99824, l2: 0.03187\n",
            "Loss: 3.356033e-05, l1: 0.99822, l2: 0.03187\n",
            "Loss: 3.355898e-05, l1: 0.99819, l2: 0.03187\n",
            "Loss: 3.355825e-05, l1: 0.99817, l2: 0.03187\n",
            "Loss: 3.355689e-05, l1: 0.99816, l2: 0.03187\n",
            "Loss: 3.362549e-05, l1: 0.99829, l2: 0.03187\n",
            "Loss: 3.355524e-05, l1: 0.99818, l2: 0.03187\n",
            "Loss: 3.355244e-05, l1: 0.99819, l2: 0.03187\n",
            "Loss: 3.354790e-05, l1: 0.99823, l2: 0.03187\n",
            "Loss: 3.354421e-05, l1: 0.99826, l2: 0.03188\n",
            "Loss: 3.354097e-05, l1: 0.99830, l2: 0.03188\n",
            "Loss: 3.356440e-05, l1: 0.99851, l2: 0.03188\n",
            "Loss: 3.354024e-05, l1: 0.99833, l2: 0.03188\n",
            "Loss: 3.353753e-05, l1: 0.99837, l2: 0.03188\n",
            "Loss: 3.353559e-05, l1: 0.99840, l2: 0.03188\n",
            "Loss: 3.353360e-05, l1: 0.99844, l2: 0.03188\n",
            "Loss: 3.353135e-05, l1: 0.99847, l2: 0.03188\n",
            "Loss: 3.352946e-05, l1: 0.99849, l2: 0.03187\n",
            "Loss: 3.352604e-05, l1: 0.99848, l2: 0.03187\n",
            "Loss: 3.352202e-05, l1: 0.99843, l2: 0.03187\n",
            "Loss: 3.351680e-05, l1: 0.99835, l2: 0.03187\n",
            "Loss: 3.351286e-05, l1: 0.99822, l2: 0.03187\n",
            "Loss: 3.350892e-05, l1: 0.99821, l2: 0.03187\n",
            "Loss: 3.350506e-05, l1: 0.99826, l2: 0.03187\n",
            "Loss: 3.350202e-05, l1: 0.99831, l2: 0.03187\n",
            "Loss: 3.349895e-05, l1: 0.99838, l2: 0.03187\n",
            "Loss: 3.349753e-05, l1: 0.99841, l2: 0.03187\n",
            "Loss: 3.349503e-05, l1: 0.99843, l2: 0.03187\n",
            "Loss: 3.349507e-05, l1: 0.99845, l2: 0.03187\n",
            "Loss: 3.349399e-05, l1: 0.99844, l2: 0.03187\n",
            "Loss: 3.349248e-05, l1: 0.99841, l2: 0.03187\n",
            "Loss: 3.349194e-05, l1: 0.99840, l2: 0.03187\n",
            "Loss: 3.349138e-05, l1: 0.99838, l2: 0.03187\n",
            "Loss: 3.348919e-05, l1: 0.99834, l2: 0.03187\n",
            "Loss: 3.348706e-05, l1: 0.99831, l2: 0.03187\n",
            "Loss: 3.348472e-05, l1: 0.99833, l2: 0.03187\n",
            "Loss: 3.348246e-05, l1: 0.99833, l2: 0.03187\n",
            "Loss: 3.348185e-05, l1: 0.99830, l2: 0.03187\n",
            "Loss: 3.347860e-05, l1: 0.99832, l2: 0.03187\n",
            "Loss: 3.347655e-05, l1: 0.99833, l2: 0.03187\n",
            "Loss: 3.347442e-05, l1: 0.99836, l2: 0.03187\n",
            "Loss: 3.347294e-05, l1: 0.99836, l2: 0.03187\n",
            "Loss: 3.347222e-05, l1: 0.99836, l2: 0.03187\n",
            "Loss: 3.347170e-05, l1: 0.99836, l2: 0.03187\n",
            "Loss: 3.347030e-05, l1: 0.99837, l2: 0.03187\n",
            "Loss: 3.346930e-05, l1: 0.99836, l2: 0.03187\n",
            "Loss: 3.347592e-05, l1: 0.99850, l2: 0.03186\n",
            "Loss: 3.346767e-05, l1: 0.99840, l2: 0.03187\n",
            "Loss: 3.346563e-05, l1: 0.99839, l2: 0.03187\n",
            "Loss: 3.345991e-05, l1: 0.99836, l2: 0.03186\n",
            "Loss: 3.345784e-05, l1: 0.99835, l2: 0.03186\n",
            "Loss: 3.345361e-05, l1: 0.99832, l2: 0.03186\n",
            "Loss: 3.345602e-05, l1: 0.99832, l2: 0.03186\n",
            "Loss: 3.345166e-05, l1: 0.99832, l2: 0.03186\n",
            "Loss: 3.344776e-05, l1: 0.99833, l2: 0.03186\n",
            "Loss: 3.344268e-05, l1: 0.99832, l2: 0.03186\n",
            "Loss: 3.343826e-05, l1: 0.99832, l2: 0.03186\n",
            "Loss: 3.343326e-05, l1: 0.99835, l2: 0.03186\n",
            "Loss: 3.342477e-05, l1: 0.99834, l2: 0.03186\n",
            "Loss: 3.344027e-05, l1: 0.99862, l2: 0.03186\n",
            "Loss: 3.342041e-05, l1: 0.99843, l2: 0.03186\n",
            "Loss: 3.340583e-05, l1: 0.99842, l2: 0.03186\n",
            "Loss: 3.338520e-05, l1: 0.99840, l2: 0.03186\n",
            "Loss: 3.337192e-05, l1: 0.99840, l2: 0.03186\n",
            "Loss: 3.335995e-05, l1: 0.99839, l2: 0.03186\n",
            "Loss: 3.335231e-05, l1: 0.99844, l2: 0.03186\n",
            "Loss: 3.334478e-05, l1: 0.99851, l2: 0.03186\n",
            "Loss: 3.333977e-05, l1: 0.99857, l2: 0.03186\n",
            "Loss: 3.333507e-05, l1: 0.99863, l2: 0.03186\n",
            "Loss: 3.333161e-05, l1: 0.99868, l2: 0.03186\n",
            "Loss: 3.332748e-05, l1: 0.99871, l2: 0.03186\n",
            "Loss: 3.333520e-05, l1: 0.99880, l2: 0.03185\n",
            "Loss: 3.332472e-05, l1: 0.99874, l2: 0.03186\n",
            "Loss: 3.332164e-05, l1: 0.99868, l2: 0.03186\n",
            "Loss: 3.331849e-05, l1: 0.99866, l2: 0.03186\n",
            "Loss: 3.331594e-05, l1: 0.99864, l2: 0.03185\n",
            "Loss: 3.331198e-05, l1: 0.99862, l2: 0.03185\n",
            "Loss: 3.330860e-05, l1: 0.99859, l2: 0.03185\n",
            "Loss: 3.330598e-05, l1: 0.99858, l2: 0.03185\n",
            "Loss: 3.330677e-05, l1: 0.99856, l2: 0.03185\n",
            "Loss: 3.330237e-05, l1: 0.99857, l2: 0.03185\n",
            "Loss: 3.329642e-05, l1: 0.99856, l2: 0.03185\n",
            "Loss: 3.328362e-05, l1: 0.99855, l2: 0.03184\n",
            "Loss: 3.327795e-05, l1: 0.99859, l2: 0.03184\n",
            "Loss: 3.327137e-05, l1: 0.99866, l2: 0.03184\n",
            "Loss: 3.326517e-05, l1: 0.99872, l2: 0.03184\n",
            "Loss: 3.325488e-05, l1: 0.99881, l2: 0.03184\n",
            "Loss: 3.324473e-05, l1: 0.99888, l2: 0.03184\n",
            "Loss: 3.323352e-05, l1: 0.99889, l2: 0.03184\n",
            "Loss: 3.322798e-05, l1: 0.99878, l2: 0.03184\n",
            "Loss: 3.325500e-05, l1: 0.99894, l2: 0.03183\n",
            "Loss: 3.322690e-05, l1: 0.99880, l2: 0.03184\n",
            "Loss: 3.322408e-05, l1: 0.99882, l2: 0.03184\n",
            "Loss: 3.322188e-05, l1: 0.99883, l2: 0.03184\n",
            "Loss: 3.321790e-05, l1: 0.99884, l2: 0.03183\n",
            "Loss: 3.321121e-05, l1: 0.99888, l2: 0.03183\n",
            "Loss: 3.320281e-05, l1: 0.99889, l2: 0.03183\n",
            "Loss: 3.319860e-05, l1: 0.99890, l2: 0.03183\n",
            "Loss: 3.319529e-05, l1: 0.99892, l2: 0.03182\n",
            "Loss: 3.319112e-05, l1: 0.99890, l2: 0.03182\n",
            "Loss: 3.318687e-05, l1: 0.99891, l2: 0.03182\n",
            "Loss: 3.318241e-05, l1: 0.99894, l2: 0.03182\n",
            "Loss: 3.317690e-05, l1: 0.99898, l2: 0.03182\n",
            "Loss: 3.316843e-05, l1: 0.99907, l2: 0.03182\n",
            "Loss: 3.316020e-05, l1: 0.99914, l2: 0.03182\n",
            "Loss: 3.316410e-05, l1: 0.99933, l2: 0.03182\n",
            "Loss: 3.315672e-05, l1: 0.99921, l2: 0.03182\n",
            "Loss: 3.314942e-05, l1: 0.99923, l2: 0.03182\n",
            "Loss: 3.314510e-05, l1: 0.99923, l2: 0.03182\n",
            "Loss: 3.313724e-05, l1: 0.99921, l2: 0.03182\n",
            "Loss: 3.313214e-05, l1: 0.99921, l2: 0.03182\n",
            "Loss: 3.312480e-05, l1: 0.99920, l2: 0.03182\n",
            "Loss: 3.311903e-05, l1: 0.99920, l2: 0.03182\n",
            "Loss: 3.311257e-05, l1: 0.99917, l2: 0.03182\n",
            "Loss: 3.310694e-05, l1: 0.99916, l2: 0.03182\n",
            "Loss: 3.310094e-05, l1: 0.99915, l2: 0.03182\n",
            "Loss: 3.309773e-05, l1: 0.99916, l2: 0.03182\n",
            "Loss: 3.309482e-05, l1: 0.99919, l2: 0.03182\n",
            "Loss: 3.309265e-05, l1: 0.99921, l2: 0.03182\n",
            "Loss: 3.309016e-05, l1: 0.99924, l2: 0.03182\n",
            "Loss: 3.308862e-05, l1: 0.99921, l2: 0.03182\n",
            "Loss: 3.308487e-05, l1: 0.99922, l2: 0.03182\n",
            "Loss: 3.308316e-05, l1: 0.99920, l2: 0.03182\n",
            "Loss: 3.308018e-05, l1: 0.99914, l2: 0.03182\n",
            "Loss: 3.307846e-05, l1: 0.99914, l2: 0.03183\n",
            "Loss: 3.307576e-05, l1: 0.99914, l2: 0.03183\n",
            "Loss: 3.307102e-05, l1: 0.99918, l2: 0.03183\n",
            "Loss: 3.306909e-05, l1: 0.99922, l2: 0.03183\n",
            "Loss: 3.306489e-05, l1: 0.99928, l2: 0.03183\n",
            "Loss: 3.305991e-05, l1: 0.99933, l2: 0.03183\n",
            "Loss: 3.305504e-05, l1: 0.99936, l2: 0.03183\n",
            "Loss: 3.305241e-05, l1: 0.99929, l2: 0.03183\n",
            "Loss: 3.304789e-05, l1: 0.99926, l2: 0.03183\n",
            "Loss: 3.304578e-05, l1: 0.99923, l2: 0.03183\n",
            "Loss: 3.304445e-05, l1: 0.99921, l2: 0.03183\n",
            "Loss: 3.304232e-05, l1: 0.99919, l2: 0.03183\n",
            "Loss: 3.303984e-05, l1: 0.99921, l2: 0.03183\n",
            "Loss: 3.303585e-05, l1: 0.99927, l2: 0.03183\n",
            "Loss: 3.304720e-05, l1: 0.99916, l2: 0.03184\n",
            "Loss: 3.303345e-05, l1: 0.99923, l2: 0.03183\n",
            "Loss: 3.302960e-05, l1: 0.99925, l2: 0.03183\n",
            "Loss: 3.302433e-05, l1: 0.99932, l2: 0.03183\n",
            "Loss: 3.302165e-05, l1: 0.99931, l2: 0.03183\n",
            "Loss: 3.301857e-05, l1: 0.99931, l2: 0.03183\n",
            "Loss: 3.301585e-05, l1: 0.99930, l2: 0.03184\n",
            "Loss: 3.301158e-05, l1: 0.99931, l2: 0.03184\n",
            "Loss: 3.300821e-05, l1: 0.99933, l2: 0.03184\n",
            "Loss: 3.300439e-05, l1: 0.99936, l2: 0.03184\n",
            "Loss: 3.300164e-05, l1: 0.99938, l2: 0.03184\n",
            "Loss: 3.299904e-05, l1: 0.99940, l2: 0.03184\n",
            "Loss: 3.299689e-05, l1: 0.99942, l2: 0.03184\n",
            "Loss: 3.300310e-05, l1: 0.99955, l2: 0.03184\n",
            "Loss: 3.299450e-05, l1: 0.99946, l2: 0.03184\n",
            "Loss: 3.299160e-05, l1: 0.99948, l2: 0.03184\n",
            "Loss: 3.298785e-05, l1: 0.99953, l2: 0.03184\n",
            "Loss: 3.298645e-05, l1: 0.99955, l2: 0.03184\n",
            "Loss: 3.298452e-05, l1: 0.99957, l2: 0.03184\n",
            "Loss: 3.298109e-05, l1: 0.99960, l2: 0.03183\n",
            "Loss: 3.297728e-05, l1: 0.99962, l2: 0.03183\n",
            "Loss: 3.297139e-05, l1: 0.99967, l2: 0.03183\n",
            "Loss: 3.296811e-05, l1: 0.99966, l2: 0.03183\n",
            "Loss: 3.296570e-05, l1: 0.99964, l2: 0.03183\n",
            "Loss: 3.296266e-05, l1: 0.99961, l2: 0.03183\n",
            "Loss: 3.296067e-05, l1: 0.99955, l2: 0.03184\n",
            "Loss: 3.295841e-05, l1: 0.99957, l2: 0.03183\n",
            "Loss: 3.295633e-05, l1: 0.99958, l2: 0.03183\n",
            "Loss: 3.295450e-05, l1: 0.99957, l2: 0.03183\n",
            "Loss: 3.295170e-05, l1: 0.99955, l2: 0.03183\n",
            "Loss: 3.294730e-05, l1: 0.99955, l2: 0.03183\n",
            "Loss: 3.294133e-05, l1: 0.99960, l2: 0.03183\n",
            "Loss: 3.293578e-05, l1: 0.99966, l2: 0.03183\n",
            "Loss: 3.294435e-05, l1: 0.99995, l2: 0.03182\n",
            "Loss: 3.293300e-05, l1: 0.99976, l2: 0.03182\n",
            "Loss: 3.292767e-05, l1: 0.99982, l2: 0.03182\n",
            "Loss: 3.292222e-05, l1: 0.99988, l2: 0.03182\n",
            "Loss: 3.291525e-05, l1: 0.99994, l2: 0.03182\n",
            "Loss: 3.290890e-05, l1: 0.99995, l2: 0.03182\n",
            "Loss: 3.290263e-05, l1: 0.99996, l2: 0.03182\n",
            "Loss: 3.290090e-05, l1: 0.99989, l2: 0.03182\n",
            "Loss: 3.289661e-05, l1: 0.99992, l2: 0.03182\n",
            "Loss: 3.289391e-05, l1: 0.99993, l2: 0.03182\n",
            "Loss: 3.288949e-05, l1: 0.99993, l2: 0.03182\n",
            "Loss: 3.288386e-05, l1: 0.99995, l2: 0.03182\n",
            "Loss: 3.287854e-05, l1: 0.99992, l2: 0.03181\n",
            "Loss: 3.287754e-05, l1: 0.99984, l2: 0.03181\n",
            "Loss: 3.287097e-05, l1: 0.99990, l2: 0.03181\n",
            "Loss: 3.286677e-05, l1: 0.99987, l2: 0.03181\n",
            "Loss: 3.286295e-05, l1: 0.99986, l2: 0.03181\n",
            "Loss: 3.286126e-05, l1: 0.99984, l2: 0.03181\n",
            "Loss: 3.285998e-05, l1: 0.99983, l2: 0.03181\n",
            "Loss: 3.285859e-05, l1: 0.99983, l2: 0.03181\n",
            "Loss: 3.285546e-05, l1: 0.99982, l2: 0.03181\n",
            "Loss: 3.285284e-05, l1: 0.99981, l2: 0.03181\n",
            "Loss: 3.284956e-05, l1: 0.99980, l2: 0.03180\n",
            "Loss: 3.287952e-05, l1: 0.99951, l2: 0.03181\n",
            "Loss: 3.284887e-05, l1: 0.99976, l2: 0.03180\n",
            "Loss: 3.284635e-05, l1: 0.99975, l2: 0.03180\n",
            "Loss: 3.284250e-05, l1: 0.99972, l2: 0.03180\n",
            "Loss: 3.284074e-05, l1: 0.99970, l2: 0.03180\n",
            "Loss: 3.283962e-05, l1: 0.99969, l2: 0.03180\n",
            "Loss: 3.283850e-05, l1: 0.99969, l2: 0.03180\n",
            "Loss: 3.283753e-05, l1: 0.99967, l2: 0.03180\n",
            "Loss: 3.283633e-05, l1: 0.99967, l2: 0.03180\n",
            "Loss: 3.283528e-05, l1: 0.99965, l2: 0.03180\n",
            "Loss: 3.283207e-05, l1: 0.99961, l2: 0.03179\n",
            "Loss: 3.282844e-05, l1: 0.99957, l2: 0.03179\n",
            "Loss: 3.282408e-05, l1: 0.99952, l2: 0.03179\n",
            "Loss: 3.282152e-05, l1: 0.99950, l2: 0.03179\n",
            "Loss: 3.281799e-05, l1: 0.99948, l2: 0.03179\n",
            "Loss: 3.281443e-05, l1: 0.99949, l2: 0.03179\n",
            "Loss: 3.280940e-05, l1: 0.99952, l2: 0.03179\n",
            "Loss: 3.280521e-05, l1: 0.99953, l2: 0.03179\n",
            "Loss: 3.280351e-05, l1: 0.99961, l2: 0.03179\n",
            "Loss: 3.280171e-05, l1: 0.99958, l2: 0.03179\n",
            "Loss: 3.280072e-05, l1: 0.99957, l2: 0.03179\n",
            "Loss: 3.279979e-05, l1: 0.99958, l2: 0.03178\n",
            "Loss: 3.279901e-05, l1: 0.99951, l2: 0.03178\n",
            "Loss: 3.279689e-05, l1: 0.99954, l2: 0.03178\n",
            "Loss: 3.279548e-05, l1: 0.99958, l2: 0.03178\n",
            "Loss: 3.279537e-05, l1: 0.99958, l2: 0.03178\n",
            "Loss: 3.279453e-05, l1: 0.99957, l2: 0.03178\n",
            "Loss: 3.279365e-05, l1: 0.99955, l2: 0.03178\n",
            "Loss: 3.279235e-05, l1: 0.99952, l2: 0.03178\n",
            "Loss: 3.279121e-05, l1: 0.99951, l2: 0.03178\n",
            "Loss: 3.279028e-05, l1: 0.99950, l2: 0.03178\n",
            "Loss: 3.278852e-05, l1: 0.99949, l2: 0.03178\n",
            "Loss: 3.278684e-05, l1: 0.99953, l2: 0.03178\n",
            "Loss: 3.278512e-05, l1: 0.99951, l2: 0.03178\n",
            "Loss: 3.278346e-05, l1: 0.99949, l2: 0.03178\n",
            "Loss: 3.278258e-05, l1: 0.99946, l2: 0.03178\n",
            "Loss: 3.278212e-05, l1: 0.99946, l2: 0.03178\n",
            "Loss: 3.278112e-05, l1: 0.99946, l2: 0.03178\n",
            "Loss: 3.278050e-05, l1: 0.99943, l2: 0.03178\n",
            "Loss: 3.279841e-05, l1: 0.99948, l2: 0.03178\n",
            "Loss: 3.277980e-05, l1: 0.99943, l2: 0.03178\n",
            "Loss: 3.277914e-05, l1: 0.99944, l2: 0.03178\n",
            "Loss: 3.277767e-05, l1: 0.99945, l2: 0.03178\n",
            "Loss: 3.277713e-05, l1: 0.99946, l2: 0.03177\n",
            "Loss: 3.277600e-05, l1: 0.99947, l2: 0.03177\n",
            "Loss: 3.277413e-05, l1: 0.99947, l2: 0.03177\n",
            "Loss: 3.277112e-05, l1: 0.99947, l2: 0.03178\n",
            "Loss: 3.276730e-05, l1: 0.99945, l2: 0.03178\n",
            "Loss: 3.277674e-05, l1: 0.99947, l2: 0.03178\n",
            "Loss: 3.276601e-05, l1: 0.99945, l2: 0.03178\n",
            "Loss: 3.276369e-05, l1: 0.99945, l2: 0.03178\n",
            "Loss: 3.276215e-05, l1: 0.99945, l2: 0.03178\n",
            "Loss: 3.276132e-05, l1: 0.99944, l2: 0.03178\n",
            "Loss: 3.276063e-05, l1: 0.99944, l2: 0.03178\n",
            "Loss: 3.275908e-05, l1: 0.99946, l2: 0.03178\n",
            "Loss: 3.275910e-05, l1: 0.99940, l2: 0.03178\n",
            "Loss: 3.275880e-05, l1: 0.99943, l2: 0.03178\n",
            "Loss: 3.276006e-05, l1: 0.99940, l2: 0.03178\n",
            "Loss: 3.275735e-05, l1: 0.99942, l2: 0.03178\n",
            "Loss: 3.275628e-05, l1: 0.99939, l2: 0.03178\n",
            "Loss: 3.275403e-05, l1: 0.99934, l2: 0.03178\n",
            "Loss: 3.275286e-05, l1: 0.99933, l2: 0.03178\n",
            "Loss: 3.275171e-05, l1: 0.99932, l2: 0.03178\n",
            "Loss: 3.275068e-05, l1: 0.99933, l2: 0.03178\n",
            "Loss: 3.275059e-05, l1: 0.99934, l2: 0.03179\n",
            "Loss: 3.274985e-05, l1: 0.99936, l2: 0.03179\n",
            "Loss: 3.274917e-05, l1: 0.99937, l2: 0.03179\n",
            "Loss: 3.274843e-05, l1: 0.99936, l2: 0.03179\n",
            "Loss: 3.274792e-05, l1: 0.99935, l2: 0.03179\n",
            "Loss: 3.274667e-05, l1: 0.99933, l2: 0.03179\n",
            "Loss: 3.274538e-05, l1: 0.99931, l2: 0.03179\n",
            "Loss: 3.274437e-05, l1: 0.99930, l2: 0.03179\n",
            "Loss: 3.274298e-05, l1: 0.99931, l2: 0.03179\n",
            "Loss: 3.274214e-05, l1: 0.99932, l2: 0.03178\n",
            "Loss: 3.274104e-05, l1: 0.99933, l2: 0.03178\n",
            "Loss: 3.274000e-05, l1: 0.99932, l2: 0.03178\n",
            "Loss: 3.273875e-05, l1: 0.99931, l2: 0.03178\n",
            "Loss: 3.273609e-05, l1: 0.99929, l2: 0.03179\n",
            "Loss: 3.273299e-05, l1: 0.99927, l2: 0.03179\n",
            "Loss: 3.273159e-05, l1: 0.99932, l2: 0.03179\n",
            "Loss: 3.272868e-05, l1: 0.99929, l2: 0.03179\n",
            "Loss: 3.272767e-05, l1: 0.99928, l2: 0.03179\n",
            "Loss: 3.272694e-05, l1: 0.99927, l2: 0.03179\n",
            "Loss: 3.272536e-05, l1: 0.99925, l2: 0.03179\n",
            "Loss: 3.272241e-05, l1: 0.99920, l2: 0.03179\n",
            "Loss: 3.271897e-05, l1: 0.99914, l2: 0.03179\n",
            "Loss: 3.271800e-05, l1: 0.99906, l2: 0.03179\n",
            "Loss: 3.271536e-05, l1: 0.99908, l2: 0.03179\n",
            "Loss: 3.271353e-05, l1: 0.99910, l2: 0.03179\n",
            "Loss: 3.271238e-05, l1: 0.99909, l2: 0.03179\n",
            "Loss: 3.271100e-05, l1: 0.99905, l2: 0.03179\n",
            "Loss: 3.270925e-05, l1: 0.99901, l2: 0.03179\n",
            "Loss: 3.270764e-05, l1: 0.99894, l2: 0.03180\n",
            "Loss: 3.270583e-05, l1: 0.99892, l2: 0.03180\n",
            "Loss: 3.270463e-05, l1: 0.99895, l2: 0.03180\n",
            "Loss: 3.270272e-05, l1: 0.99895, l2: 0.03180\n",
            "Loss: 3.270093e-05, l1: 0.99896, l2: 0.03180\n",
            "Loss: 3.269994e-05, l1: 0.99896, l2: 0.03180\n",
            "Loss: 3.269785e-05, l1: 0.99895, l2: 0.03180\n",
            "Loss: 3.269600e-05, l1: 0.99894, l2: 0.03180\n",
            "Loss: 3.270198e-05, l1: 0.99900, l2: 0.03180\n",
            "Loss: 3.269456e-05, l1: 0.99896, l2: 0.03180\n",
            "Loss: 3.269219e-05, l1: 0.99895, l2: 0.03180\n",
            "Loss: 3.269039e-05, l1: 0.99895, l2: 0.03180\n",
            "Loss: 3.268981e-05, l1: 0.99897, l2: 0.03180\n",
            "Loss: 3.268851e-05, l1: 0.99898, l2: 0.03180\n",
            "Loss: 3.268741e-05, l1: 0.99899, l2: 0.03180\n",
            "Loss: 3.268577e-05, l1: 0.99901, l2: 0.03180\n",
            "Loss: 3.268416e-05, l1: 0.99899, l2: 0.03180\n",
            "Loss: 3.268279e-05, l1: 0.99895, l2: 0.03180\n",
            "Loss: 3.268231e-05, l1: 0.99895, l2: 0.03180\n",
            "Loss: 3.268095e-05, l1: 0.99895, l2: 0.03180\n",
            "Loss: 3.267991e-05, l1: 0.99896, l2: 0.03180\n",
            "Loss: 3.267849e-05, l1: 0.99897, l2: 0.03180\n",
            "Loss: 3.267744e-05, l1: 0.99899, l2: 0.03180\n",
            "Loss: 3.267678e-05, l1: 0.99899, l2: 0.03180\n",
            "Loss: 3.267542e-05, l1: 0.99899, l2: 0.03180\n",
            "Loss: 3.267297e-05, l1: 0.99900, l2: 0.03181\n",
            "Loss: 3.267203e-05, l1: 0.99900, l2: 0.03181\n",
            "Loss: 3.267024e-05, l1: 0.99901, l2: 0.03181\n",
            "Loss: 3.266960e-05, l1: 0.99899, l2: 0.03181\n",
            "Loss: 3.266848e-05, l1: 0.99899, l2: 0.03181\n",
            "Loss: 3.266717e-05, l1: 0.99893, l2: 0.03181\n",
            "Loss: 3.266620e-05, l1: 0.99892, l2: 0.03181\n",
            "Loss: 3.266551e-05, l1: 0.99890, l2: 0.03181\n",
            "Loss: 3.266440e-05, l1: 0.99888, l2: 0.03181\n",
            "Loss: 3.266308e-05, l1: 0.99884, l2: 0.03181\n",
            "Loss: 3.266229e-05, l1: 0.99882, l2: 0.03181\n",
            "Loss: 3.266077e-05, l1: 0.99880, l2: 0.03181\n",
            "Loss: 3.265869e-05, l1: 0.99879, l2: 0.03181\n",
            "Loss: 3.265697e-05, l1: 0.99877, l2: 0.03181\n",
            "Loss: 3.265447e-05, l1: 0.99877, l2: 0.03181\n",
            "Loss: 3.266160e-05, l1: 0.99862, l2: 0.03180\n",
            "Loss: 3.265391e-05, l1: 0.99873, l2: 0.03181\n",
            "Loss: 3.265223e-05, l1: 0.99872, l2: 0.03181\n",
            "Loss: 3.265019e-05, l1: 0.99870, l2: 0.03181\n",
            "Loss: 3.264828e-05, l1: 0.99868, l2: 0.03180\n",
            "Loss: 3.264604e-05, l1: 0.99866, l2: 0.03180\n",
            "Loss: 3.264432e-05, l1: 0.99864, l2: 0.03180\n",
            "Loss: 3.264281e-05, l1: 0.99864, l2: 0.03180\n",
            "Loss: 3.264234e-05, l1: 0.99865, l2: 0.03180\n",
            "Loss: 3.264161e-05, l1: 0.99865, l2: 0.03180\n",
            "Loss: 3.264104e-05, l1: 0.99866, l2: 0.03180\n",
            "Loss: 3.264001e-05, l1: 0.99866, l2: 0.03180\n",
            "Loss: 3.264269e-05, l1: 0.99870, l2: 0.03179\n",
            "Loss: 3.263966e-05, l1: 0.99868, l2: 0.03180\n",
            "Loss: 3.263744e-05, l1: 0.99871, l2: 0.03180\n",
            "Loss: 3.263634e-05, l1: 0.99862, l2: 0.03180\n",
            "Loss: 3.263457e-05, l1: 0.99865, l2: 0.03179\n",
            "Loss: 3.263225e-05, l1: 0.99867, l2: 0.03179\n",
            "Loss: 3.263070e-05, l1: 0.99866, l2: 0.03179\n",
            "Loss: 3.262918e-05, l1: 0.99865, l2: 0.03179\n",
            "Loss: 3.262674e-05, l1: 0.99862, l2: 0.03179\n",
            "Loss: 3.262447e-05, l1: 0.99858, l2: 0.03179\n",
            "Loss: 3.262336e-05, l1: 0.99858, l2: 0.03179\n",
            "Loss: 3.262086e-05, l1: 0.99853, l2: 0.03179\n",
            "Loss: 3.261961e-05, l1: 0.99849, l2: 0.03179\n",
            "Loss: 3.261753e-05, l1: 0.99851, l2: 0.03179\n",
            "Loss: 3.261520e-05, l1: 0.99853, l2: 0.03179\n",
            "Loss: 3.261262e-05, l1: 0.99854, l2: 0.03179\n",
            "Loss: 3.261019e-05, l1: 0.99854, l2: 0.03179\n",
            "Loss: 3.260998e-05, l1: 0.99854, l2: 0.03179\n",
            "Loss: 3.260890e-05, l1: 0.99854, l2: 0.03179\n",
            "Loss: 3.261464e-05, l1: 0.99855, l2: 0.03179\n",
            "Loss: 3.260813e-05, l1: 0.99854, l2: 0.03179\n",
            "Loss: 3.260653e-05, l1: 0.99853, l2: 0.03179\n",
            "Loss: 3.260565e-05, l1: 0.99852, l2: 0.03179\n",
            "Loss: 3.260424e-05, l1: 0.99851, l2: 0.03179\n",
            "Loss: 3.260184e-05, l1: 0.99851, l2: 0.03179\n",
            "Loss: 3.260006e-05, l1: 0.99852, l2: 0.03179\n",
            "Loss: 3.259881e-05, l1: 0.99854, l2: 0.03179\n",
            "Loss: 3.259842e-05, l1: 0.99854, l2: 0.03179\n",
            "Loss: 3.259751e-05, l1: 0.99854, l2: 0.03179\n",
            "Loss: 3.259751e-05, l1: 0.99851, l2: 0.03179\n",
            "Loss: 3.259613e-05, l1: 0.99853, l2: 0.03179\n",
            "Loss: 3.259433e-05, l1: 0.99852, l2: 0.03179\n",
            "Loss: 3.259142e-05, l1: 0.99849, l2: 0.03179\n",
            "Loss: 3.259000e-05, l1: 0.99848, l2: 0.03179\n",
            "Loss: 3.258781e-05, l1: 0.99849, l2: 0.03179\n",
            "Loss: 3.258505e-05, l1: 0.99847, l2: 0.03179\n",
            "Loss: 3.258158e-05, l1: 0.99846, l2: 0.03179\n",
            "Loss: 3.258526e-05, l1: 0.99847, l2: 0.03179\n",
            "Loss: 3.258022e-05, l1: 0.99846, l2: 0.03179\n",
            "Loss: 3.257793e-05, l1: 0.99845, l2: 0.03180\n",
            "Loss: 3.257735e-05, l1: 0.99844, l2: 0.03180\n",
            "Loss: 3.257672e-05, l1: 0.99843, l2: 0.03180\n",
            "Loss: 3.257582e-05, l1: 0.99842, l2: 0.03180\n",
            "Loss: 3.257500e-05, l1: 0.99843, l2: 0.03179\n",
            "Loss: 3.257348e-05, l1: 0.99845, l2: 0.03180\n",
            "Loss: 3.257214e-05, l1: 0.99847, l2: 0.03180\n",
            "Loss: 3.257051e-05, l1: 0.99849, l2: 0.03180\n",
            "Loss: 3.256806e-05, l1: 0.99849, l2: 0.03180\n",
            "Loss: 3.256503e-05, l1: 0.99852, l2: 0.03180\n",
            "Loss: 3.256614e-05, l1: 0.99851, l2: 0.03179\n",
            "Loss: 3.256344e-05, l1: 0.99852, l2: 0.03180\n",
            "Loss: 3.256170e-05, l1: 0.99850, l2: 0.03179\n",
            "Loss: 3.256039e-05, l1: 0.99851, l2: 0.03179\n",
            "Loss: 3.255993e-05, l1: 0.99848, l2: 0.03179\n",
            "Loss: 3.255980e-05, l1: 0.99849, l2: 0.03179\n",
            "Loss: 3.255945e-05, l1: 0.99850, l2: 0.03180\n",
            "Loss: 3.255894e-05, l1: 0.99851, l2: 0.03180\n",
            "Loss: 3.255829e-05, l1: 0.99852, l2: 0.03180\n",
            "Loss: 3.255760e-05, l1: 0.99853, l2: 0.03180\n",
            "Loss: 3.255722e-05, l1: 0.99854, l2: 0.03180\n",
            "Loss: 3.255661e-05, l1: 0.99854, l2: 0.03180\n",
            "Loss: 3.255588e-05, l1: 0.99854, l2: 0.03180\n",
            "Loss: 3.255558e-05, l1: 0.99855, l2: 0.03180\n",
            "Loss: 3.255403e-05, l1: 0.99855, l2: 0.03180\n",
            "Loss: 3.255326e-05, l1: 0.99855, l2: 0.03180\n",
            "Loss: 3.255292e-05, l1: 0.99854, l2: 0.03180\n",
            "Loss: 3.255242e-05, l1: 0.99853, l2: 0.03180\n",
            "Loss: 3.255168e-05, l1: 0.99852, l2: 0.03180\n",
            "Loss: 3.255068e-05, l1: 0.99851, l2: 0.03180\n",
            "Loss: 3.254929e-05, l1: 0.99853, l2: 0.03180\n",
            "Loss: 3.254879e-05, l1: 0.99854, l2: 0.03180\n",
            "Loss: 3.254787e-05, l1: 0.99855, l2: 0.03180\n",
            "Loss: 3.254735e-05, l1: 0.99856, l2: 0.03180\n",
            "Loss: 3.254645e-05, l1: 0.99856, l2: 0.03180\n",
            "Loss: 3.254581e-05, l1: 0.99855, l2: 0.03180\n",
            "Loss: 3.254470e-05, l1: 0.99852, l2: 0.03180\n",
            "Loss: 3.254320e-05, l1: 0.99851, l2: 0.03180\n",
            "Loss: 3.254216e-05, l1: 0.99851, l2: 0.03180\n",
            "Loss: 3.254168e-05, l1: 0.99853, l2: 0.03180\n",
            "Loss: 3.254109e-05, l1: 0.99856, l2: 0.03180\n",
            "Loss: 3.254045e-05, l1: 0.99861, l2: 0.03180\n",
            "Loss: 3.253996e-05, l1: 0.99873, l2: 0.03180\n",
            "Loss: 3.253824e-05, l1: 0.99873, l2: 0.03180\n",
            "Loss: 3.253677e-05, l1: 0.99873, l2: 0.03180\n",
            "Loss: 3.253580e-05, l1: 0.99875, l2: 0.03180\n",
            "Loss: 3.253503e-05, l1: 0.99877, l2: 0.03180\n",
            "Loss: 3.253428e-05, l1: 0.99876, l2: 0.03180\n",
            "Loss: 3.253264e-05, l1: 0.99878, l2: 0.03180\n",
            "Loss: 3.253251e-05, l1: 0.99868, l2: 0.03180\n",
            "Loss: 3.253105e-05, l1: 0.99873, l2: 0.03180\n",
            "Loss: 3.252843e-05, l1: 0.99877, l2: 0.03180\n",
            "Loss: 3.253392e-05, l1: 0.99880, l2: 0.03180\n",
            "Loss: 3.252732e-05, l1: 0.99877, l2: 0.03180\n",
            "Loss: 3.252425e-05, l1: 0.99886, l2: 0.03180\n",
            "Loss: 3.252841e-05, l1: 0.99889, l2: 0.03180\n",
            "Loss: 3.252367e-05, l1: 0.99887, l2: 0.03180\n",
            "Loss: 3.252109e-05, l1: 0.99890, l2: 0.03180\n",
            "Loss: 3.251693e-05, l1: 0.99900, l2: 0.03180\n",
            "Loss: 3.251497e-05, l1: 0.99904, l2: 0.03179\n",
            "Loss: 3.251331e-05, l1: 0.99907, l2: 0.03179\n",
            "Loss: 3.251306e-05, l1: 0.99908, l2: 0.03179\n",
            "Loss: 3.251224e-05, l1: 0.99909, l2: 0.03179\n",
            "Loss: 3.251117e-05, l1: 0.99911, l2: 0.03179\n",
            "Loss: 3.250988e-05, l1: 0.99911, l2: 0.03179\n",
            "Loss: 3.250872e-05, l1: 0.99910, l2: 0.03179\n",
            "Loss: 3.250772e-05, l1: 0.99909, l2: 0.03179\n",
            "Loss: 3.250706e-05, l1: 0.99908, l2: 0.03179\n",
            "Loss: 3.250599e-05, l1: 0.99908, l2: 0.03179\n",
            "Loss: 3.251243e-05, l1: 0.99910, l2: 0.03179\n",
            "Loss: 3.250615e-05, l1: 0.99909, l2: 0.03179\n",
            "Loss: 3.250616e-05, l1: 0.99909, l2: 0.03179\n",
            "Loss: 3.250652e-05, l1: 0.99908, l2: 0.03179\n",
            "Loss: 3.250606e-05, l1: 0.99908, l2: 0.03179\n",
            "Loss: 3.250599e-05, l1: 0.99908, l2: 0.03179\n",
            "Loss: 3.250599e-05, l1: 0.99908, l2: 0.03179\n",
            "Loss: 3.250599e-05, l1: 0.99908, l2: 0.03179\n",
            "Loss: 3.250599e-05, l1: 0.99908, l2: 0.03179\n",
            "Loss: 3.250599e-05, l1: 0.99908, l2: 0.03179\n",
            "Loss: 3.250599e-05, l1: 0.99908, l2: 0.03179\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
            "  Objective function value: 0.000033\n",
            "  Number of iterations: 3256\n",
            "  Number of functions evaluations: 3534\n",
            "Error lambda_1: 0.091511%\n",
            "Error lambda_2: 0.118274%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "######################################################################\n",
        "############################# Plotting ###############################\n",
        "######################################################################    \n",
        "    \n",
        "fig, ax = newfig(1.0, 1.4)\n",
        "ax.axis('off')\n",
        "    \n",
        "####### Row 0: u(t,x) ##################    \n",
        "gs0 = gridspec.GridSpec(1, 2)\n",
        "gs0.update(top=1-0.06, bottom=1-1.0/3.0+0.06, left=0.15, right=0.85, wspace=0)\n",
        "ax = plt.subplot(gs0[:, :])\n",
        "    \n",
        "h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
        "                  extent=[t.min(), t.max(), x.min(), x.max()], \n",
        "                  origin='lower', aspect='auto')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "fig.colorbar(h, cax=cax)\n",
        "    \n",
        "ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 2, clip_on = False)\n",
        "    \n",
        "line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    \n",
        "ax.set_xlabel('$t$')\n",
        "ax.set_ylabel('$x$')\n",
        "ax.legend(loc='upper center', bbox_to_anchor=(1.0, -0.125), ncol=5, frameon=False)\n",
        "ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "    \n",
        "####### Row 1: u(t,x) slices ##################    \n",
        "gs1 = gridspec.GridSpec(1, 3)\n",
        "gs1.update(top=1-1.0/3.0-0.1, bottom=1.0-2.0/3.0, left=0.1, right=0.9, wspace=0.5)\n",
        "    \n",
        "ax = plt.subplot(gs1[0, 0])\n",
        "ax.plot(x,Exact[25,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$u(t,x)$')    \n",
        "ax.set_title('$t = 0.25$', fontsize = 10)\n",
        "ax.axis('square')\n",
        "ax.set_xlim([-1.1,1.1])\n",
        "ax.set_ylim([-1.1,1.1])\n",
        "    \n",
        "ax = plt.subplot(gs1[0, 1])\n",
        "ax.plot(x,Exact[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$u(t,x)$')\n",
        "ax.axis('square')\n",
        "ax.set_xlim([-1.1,1.1])\n",
        "ax.set_ylim([-1.1,1.1])\n",
        "ax.set_title('$t = 0.50$', fontsize = 10)\n",
        "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
        "    \n",
        "ax = plt.subplot(gs1[0, 2])\n",
        "ax.plot(x,Exact[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "ax.set_xlabel('$x$')\n",
        "ax.set_ylabel('$u(t,x)$')\n",
        "ax.axis('square')\n",
        "ax.set_xlim([-1.1,1.1])\n",
        "ax.set_ylim([-1.1,1.1])    \n",
        "ax.set_title('$t = 0.75$', fontsize = 10)\n",
        "    \n",
        "####### Row 3: Identified PDE ##################    \n",
        "gs2 = gridspec.GridSpec(1, 3)\n",
        "gs2.update(top=1.0-2.0/3.0, bottom=0, left=0.0, right=1.0, wspace=0.0)\n",
        "    \n",
        "ax = plt.subplot(gs2[:, :])\n",
        "ax.axis('off')\n",
        "s1 = r'$\\begin{tabular}{ |c|c| }  \\hline Correct PDE & $u_t + u u_x - 0.031831 u_{xx} = 0$ \\\\  \\hline Identified PDE (clean data) & '\n",
        "s2 = r'$u_t + %.5f u u_x - %.7f u_{xx} = 0$ \\\\  \\hline ' % (lambda_1_value, lambda_2_value)\n",
        "s3 = r'Identified PDE (1\\% noise) & '\n",
        "s4 = r'$u_t + %.5f u u_x - %.7f u_{xx} = 0$  \\\\  \\hline ' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "s5 = r'\\end{tabular}$'\n",
        "s = s1+s2+s3+s4+s5\n",
        "ax.text(0.1,0.1,s)\n",
        "        \n",
        "savefig('./Burgers_identification')   \n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "wQJocGkFn0j4",
        "outputId": "814771f5-237d-4fb9-88b5-68fdfa854608"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 388.543x336.186 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}